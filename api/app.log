ERROR:fastapi:Form data requires "python-multipart" to be installed. 
You can install "python-multipart" with: 

pip install python-multipart

INFO:root:File ID: 7, Temp file path: temp_MLpdf.pdf
INFO:root:File ID: 8, Temp file path: temp_MLpdf.pdf
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:File ID: 9, Temp file path: temp_MLpdf.pdf
INFO:root:File ID: 9, Temp file path: temp_MLpdf.pdf
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:File ID: 10, Temp file path: temp_MLpdf.pdf
INFO:root:File ID: 10, Temp file path: temp_MLpdf.pdf
INFO:root:File ID: 11, Temp file path: temp_document.pdf
INFO:root:File ID: 11, Temp file path: temp_document.pdf
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:File ID: 12, Temp file path: temp_document.pdf
INFO:root:File ID: 12, file path: temp_document.pdf
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:File ID: 13, Temp file path: temp_document.pdf
INFO:root:File ID: 13, file path: temp_document.pdf
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:File ID: 14, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 14, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:File ID: 15, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 15, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:root:File ID: 16, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 16, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:File ID: 17, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 17, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: None, User Query:what is ML in one line,Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: None, User Query: what is ML in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: None, User Query: what is ML in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: None, User Query: ML in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: None, User Query: What is ML in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: 12, User Query: What is ml in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: 13, User Query: What is ml in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: None, User Query: what is ml in one word, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: None, User Query: what is ml in one word, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ERROR:root:Failed to parse gpt_response as JSON
INFO:root:Session ID: 527eacc2-888c-404d-b451-2ff84559dafd, AI response: Learning.
INFO:root:File ID: 18, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 18, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. \n2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. \n3. Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. \n4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. \n5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. \n6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. \n7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. \n8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. \n9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. \n10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. \n11. \uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. \n12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. \n13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. \n14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. \n15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. \n16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. \n17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. \n18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. \n19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. \n20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:splits: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. 2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. 3.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. 4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. 5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. 6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. 7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. 8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. 9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. 10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. 11.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='\uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. 12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. 13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. 14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. 15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. 16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. 17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. 18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. 19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. 20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Session ID: None, User Query: what is ml in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ERROR:root:Failed to parse gpt_response as JSON
INFO:root:Session ID: bf3fc624-21df-456d-9af2-238a49228388, AI response: Machine learning (ML) is a subset of artificial intelligence that enables systems to learn from data and make predictions or decisions without explicit programming.
INFO:backoff:Backing off send_request(...) for 0.7s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Read timed out. (read timeout=15))
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: None, User Query: what is ml in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 18f6dfad-7304-42a5-b4bd-18067c104e8a, AI response: Machine learning (ML) is a branch of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.
INFO:root:Session ID: 18f6dfad-7304-42a5-b4bd-18067c104e8a, User Query: what are types of it, in one line, Model: gpt-4o-mini
INFO:root:Session ID: 18f6dfad-7304-42a5-b4bd-18067c104e8a, User Query: what are Key components of it, Model: gpt-4o-mini
INFO:root:Session ID: 18f6dfad-7304-42a5-b4bd-18067c104e8a, User Query: what are Key components of it, Model: gpt-4o-mini
INFO:root:Session ID: None, User Query: what is AI in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, AI response: AI, or artificial intelligence, is the simulation of human intelligence processes by machines, especially computer systems.
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it, Model: gpt-4o-mini
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it, Model: gpt-4o-mini
INFO:root:Session ID: None, User Query: what are key components of it, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 6ff9f1f9-b5f1-45ea-8e2b-f910f50be27e, AI response: The key components of Information Technology (IT) generally include:

1. **Hardware**: This refers to the physical components of technology, such as computers, servers, networking devices, and peripherals like printers and scanners.

2. **Software**: This encompasses the applications and operating systems that run on the hardware. Software can be categorized into system software (like operating systems) and application software (such as word processors, databases, and enterprise applications).

3. **Networking**: This includes the infrastructure that enables communication and data exchange between devices. It involves routers, switches, firewalls, and protocols used to connect devices and manage data traffic.

4. **Data Management**: This pertains to the processes of storing, organizing, securing, and accessing data. Data management systems include databases and data warehouses, ensuring that data is available for analysis and decision-making.

5. **Security**: This component focuses on protecting information systems from threats. It includes cybersecurity measures, data encryption, access controls, and policies to safeguard information integrity and confidentiality.

6. **Cloud Computing**: This involves using remote servers hosted on the internet to store, manage, and process data, rather than local servers or personal computers. Cloud services can provide scalable resources and on-demand accessibility.

7. **IT Services and Support**: This includes the management and delivery of IT services, such as tech support, system maintenance, and help desk services, ensuring that IT systems operate effectively.

8. **User Training and Support**: Offering education and training to users on how to effectively utilize IT systems and tools is crucial for maximizing productivity and minimizing errors.

These components work together to create an effective IT infrastructure that supports individual and organizational needs.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it one line, Model: gpt-4o-mini
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it one line, Model: gpt-4o-mini
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it one line, Model: gpt-4o-mini
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it one line, Model: gpt-4o-mini
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it one line, Model: gpt-4o-mini
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it one line, Model: gpt-4o-mini
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it one line, Model: gpt-4o-mini
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it one line, Model: gpt-4o-mini
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, User Query: what are key components of it one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 487c7537-cb2a-464a-b7d9-9e9b26c73a45, AI response: Key components of IT include hardware, software, networks, data management, and IT services.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:root:File ID: 19, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 19, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. \n2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. \n3. Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. \n4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. \n5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. \n6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. \n7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. \n8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. \n9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. \n10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. \n11. \uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. \n12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. \n13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. \n14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. \n15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. \n16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. \n17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. \n18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. \n19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. \n20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Splits content: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. 2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. 3.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. 4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. 5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. 6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. 7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. 8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. 9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. 10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. 11.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='\uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. 12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. 13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. 14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. 15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. 16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. 17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. 18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. 19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. 20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')], Type: <class 'list'>
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: page_content='Artificial Intelligence Overview 
1. Artificial Intelligence (AI) is a branch of computer science focused on creating 
systems capable of performing tasks that usually require human intelligence. 2. Key components of AI include machine learning, natural language processing, 
robotics, and computer vision. 3.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'file_id': 19}
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: page_content='Machine learning enables systems to learn from data and make predictions or 
decisions without explicit programming. 4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate 
human language effectively. 5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. 6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. 7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to 
recommendation systems and personal assistants. 8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive 
analytics. 9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts 
of data. 10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine 
learning techniques. 11.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'file_id': 19}
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: page_content='\uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. 12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. 13. \uf0b7  The development of AI technologies requires significant computational power and 
data. 14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. 15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. 16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected 
scenarios. 17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. 18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. 19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. 20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'file_id': 19}
INFO:root:Document indexed successfully
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:backoff:Backing off send_request(...) for 0.0s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Read timed out. (read timeout=15))
INFO:root:File ID: 20, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 20, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. \n2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. \n3. Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. \n4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. \n5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. \n6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. \n7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. \n8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. \n9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. \n10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. \n11. \uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. \n12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. \n13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. \n14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. \n15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. \n16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. \n17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. \n18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. \n19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. \n20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Splits content: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. 2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. 3.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. 4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. 5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. 6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. 7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. 8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. 9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. 10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. 11.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='\uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. 12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. 13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. 14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. 15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. 16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. 17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. 18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. 19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. 20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')], Type: <class 'list'>
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: page_content='Artificial Intelligence Overview 
1. Artificial Intelligence (AI) is a branch of computer science focused on creating 
systems capable of performing tasks that usually require human intelligence. 2. Key components of AI include machine learning, natural language processing, 
robotics, and computer vision. 3.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'file_id': 20}
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: page_content='Machine learning enables systems to learn from data and make predictions or 
decisions without explicit programming. 4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate 
human language effectively. 5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. 6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. 7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to 
recommendation systems and personal assistants. 8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive 
analytics. 9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts 
of data. 10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine 
learning techniques. 11.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'file_id': 20}
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: page_content='\uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. 12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. 13. \uf0b7  The development of AI technologies requires significant computational power and 
data. 14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. 15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. 16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected 
scenarios. 17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. 18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. 19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. 20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'file_id': 20}
INFO:root:Document indexed successfully
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:root:File ID: 21, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 21, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. \n2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. \n3. Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. \n4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. \n5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. \n6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. \n7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. \n8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. \n9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. \n10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. \n11. \uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. \n12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. \n13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. \n14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. \n15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. \n16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. \n17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. \n18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. \n19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. \n20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Splits content: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. 2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. 3.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. 4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. 5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. 6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. 7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. 8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. 9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. 10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. 11.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='\uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. 12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. 13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. 14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. 15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. 16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. 17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. 18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. 19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. 20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')], Type: <class 'list'>
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: page_content='Artificial Intelligence Overview 
1. Artificial Intelligence (AI) is a branch of computer science focused on creating 
systems capable of performing tasks that usually require human intelligence. 2. Key components of AI include machine learning, natural language processing, 
robotics, and computer vision. 3.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'file_id': 21}
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: page_content='Machine learning enables systems to learn from data and make predictions or 
decisions without explicit programming. 4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate 
human language effectively. 5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. 6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. 7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to 
recommendation systems and personal assistants. 8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive 
analytics. 9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts 
of data. 10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine 
learning techniques. 11.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'file_id': 21}
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: page_content='\uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. 12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. 13. \uf0b7  The development of AI technologies requires significant computational power and 
data. 14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. 15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. 16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected 
scenarios. 17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. 18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. 19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. 20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'file_id': 21}
INFO:root:Document indexed successfully
INFO:root:Session ID: None, User Query: what is ai in one line, Model: gpt-4o-mini
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:root:Session ID: None, User Query: what is ai in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 6476a0cc-e4d8-47a8-a84c-cd554703d408, AI response: AI, or artificial intelligence, is the simulation of human intelligence processes by machines, particularly computer systems.
INFO:root:Session ID: 6476a0cc-e4d8-47a8-a84c-cd554703d408, User Query: what are key components of it in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 6476a0cc-e4d8-47a8-a84c-cd554703d408, AI response: Key components of AI include machine learning, natural language processing, computer vision, robotics, and cognitive computing.
INFO:root:Documents to return: [{'id': 20, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 08:20:12'}, {'id': 21, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 09:19:14'}]
INFO:root:Documents to return: [{'id': 20, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 08:20:12'}]
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:root:Documents to return: [{'id': 20, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 08:20:12'}]
INFO:root:Documents to return: [{'id': 20, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 08:20:12'}]
INFO:root:Documents to return: [{'id': 20, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 08:20:12'}]
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:root:Documents to return: [{'id': 20, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 08:20:12'}]
INFO:root:Documents to return: [{'id': 20, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 08:20:12'}]
INFO:root:Documents to return: []
INFO:root:File ID: 22, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 22, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. \n2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. \n3. Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. \n4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. \n5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. \n6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. \n7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. \n8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. \n9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. \n10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. \n11. \uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. \n12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. \n13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. \n14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. \n15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. \n16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. \n17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. \n18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. \n19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. \n20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Splits content: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. 2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. 3.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. 4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. 5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. 6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. 7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. 8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. 9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. 10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. 11.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='\uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. 12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. 13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. 14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. 15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. 16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. 17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. 18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. 19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. 20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')], Type: <class 'list'>
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: temp_documentInfo.pdf
INFO:root:Document indexed successfully
INFO:root:Session ID: None, User Query: what is AI in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 0eb83d1c-8569-4236-9eda-e7db76f135de, AI response: Artificial Intelligence (AI) is a branch of computer science that focuses on creating systems capable of performing tasks that typically require human intelligence.
INFO:root:Session ID: 0eb83d1c-8569-4236-9eda-e7db76f135de, User Query: what are key components of it in one line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 0eb83d1c-8569-4236-9eda-e7db76f135de, AI response: Key components of AI include machine learning, natural language processing, robotics, and computer vision.
INFO:root:Documents to return: [{'id': 22, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 15:11:04'}]
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:root:Documents to return: [{'id': 22, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 15:11:04'}]
INFO:root:Documents to return: [{'id': 22, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 15:11:04'}]
INFO:root:File ID: 23, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 23, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. \n2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. \n3. Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. \n4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. \n5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. \n6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. \n7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. \n8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. \n9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. \n10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. \n11. \uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. \n12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. \n13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. \n14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. \n15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. \n16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. \n17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. \n18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. \n19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. \n20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Splits content: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. 2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. 3.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. 4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. 5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. 6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. 7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. 8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. 9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. 10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. 11.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='\uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. 12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. 13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. 14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. 15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. 16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. 17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. 18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. 19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. 20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')], Type: <class 'list'>
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:root:Document added to vectorstore: temp_documentInfo.pdf
INFO:root:Document indexed successfully
INFO:root:Documents to return: [{'id': 22, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 15:11:04'}, {'id': 23, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-20 01:11:43'}]
INFO:root:Documents to return: [{'id': 22, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-19 15:11:04'}, {'id': 23, 'filename': 'documentInfo.pdf', 'upload_timestamp': '2025-04-20 01:11:43'}]
INFO:root:Session ID: None, User Query: what is AI, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: a52b3300-47a8-4984-adca-d8bb6ae185b0, AI response: Artificial Intelligence (AI) is a branch of computer science focused on creating systems that can perform tasks typically requiring human intelligence. This includes abilities like learning, reasoning, problem-solving, perception, and language understanding. Key components of AI include:

- **Machine Learning**: The process by which systems learn from data to improve their performance over time.
- **Natural Language Processing**: The ability of machines to understand and respond to human language.
- **Robotics**: The design and application of robots that can perform tasks.
- **Computer Vision**: Enabling machines to interpret and make decisions based on visual data.

AI is increasingly being integrated into various industries, impacting fields such as finance, education, and entertainment, and is seen as a way to augment human capabilities, although it also raises ethical concerns related to fairness, privacy, and job displacement due to automation.
INFO:root:Session ID: a52b3300-47a8-4984-adca-d8bb6ae185b0, User Query: what are the types of it in single line, Model: gpt-4o-mini
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: a52b3300-47a8-4984-adca-d8bb6ae185b0, AI response: The main types of AI include machine learning, natural language processing, robotics, and computer vision.
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:root:File ID: None, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: None, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. \n2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. \n3. Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. \n4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. \n5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. \n6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. \n7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. \n8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. \n9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. \n10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. \n11. \uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. \n12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. \n13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. \n14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. \n15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. \n16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. \n17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. \n18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. \n19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. \n20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 401 Unauthorized"
ERROR:root:Error indexing document: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************zh0A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:root:File ID: 1, Temp file path: temp_documentInfo.pdf
INFO:root:File ID: 1, file path: temp_documentInfo.pdf
INFO:root:PDF file loaded: temp_documentInfo.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-18T17:32:09+00:00', 'author': 'venkateswari v', 'moddate': '2025-04-18T17:32:09+00:00', 'source': 'temp_documentInfo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Artificial Intelligence Overview \n1. Artificial Intelligence (AI) is a branch of computer science focused on creating \nsystems capable of performing tasks that usually require human intelligence. \n2. Key components of AI include machine learning, natural language processing, \nrobotics, and computer vision. \n3. Machine learning enables systems to learn from data and make predictions or \ndecisions without explicit programming. \n4. \uf0b7  Natural language processing allows machines to understand, interpret, and generate \nhuman language effectively. \n5. \uf0b7  Robotics involves AI-driven machines capable of performing complex physical tasks. \n6. \uf0b7  Computer vision equips machines to analyze and interpret visual data. \n7. \uf0b7  AI applications range from healthcare diagnostics and autonomous vehicles to \nrecommendation systems and personal assistants. \n8. \uf0b7  Some prominent AI technologies include chatbots, facial recognition, and predictive \nanalytics. \n9. \uf0b7  AI algorithms often rely on deep learning and neural networks to process vast amounts \nof data. \n10. \uf0b7  Supervised, unsupervised, and reinforcement learning are common types of machine \nlearning techniques. \n11. \uf0b7  Ethics in AI is a growing concern, focusing on fairness, privacy, and avoiding bias. \n12. \uf0b7  AI is revolutionizing industries like finance, education, and entertainment. \n13. \uf0b7  The development of AI technologies requires significant computational power and \ndata. \n14. \uf0b7  AI can augment human capabilities, but some fear job displacement due to automation. \n15. \uf0b7  Researchers are working on explainable AI (XAI) to improve transparency and trust. \n16. \uf0b7  AI-driven systems must be programmed to handle edge cases and unexpected \nscenarios. \n17. \uf0b7  Major AI breakthroughs include AlphaGo, GPT, and autonomous drones. \n18. \uf0b7  AI-powered simulations help solve complex scientific and engineering problems. \n19. \uf0b7  Collaboration between humans and AI is seen as the future of work and creativity. \n20. \uf0b7  AI continues to evolve rapidly, promising both challenges and opportunities.')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 401 Unauthorized"
ERROR:root:Error indexing document: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************zh0A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized
INFO:root:File ID: 1, Temp file path: temp_document.pdf
INFO:root:File ID: 1, file path: temp_document.pdf
INFO:root:PDF file loaded: temp_document.pdf
WARNING:pypdf._reader:invalid pdf header: b'Artif'
WARNING:pypdf._reader:EOF marker not found
ERROR:root:Error indexing document: Stream has ended unexpectedly
INFO:root:File ID: 2, Temp file path: temp_MLpdf.pdf
INFO:root:File ID: 2, file path: temp_MLpdf.pdf
INFO:root:PDF file loaded: temp_MLpdf.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 0, 'page_label': '1'}, page_content='INTRODUCTION\nTO\nMACHINE LEARNING\nAN EARLY DRAFT OF A PROPOSED\nTEXTBOOK\nNils J. Nilsson\nRobotics Laboratory\nDepartment of Computer Science\nStanford University\nStanford, CA 94305\ne-mail: nilsson@cs.stanford.edu\nNovember 3, 1998\nCopyright c\u20dd2005 Nils J. Nilsson\nThis material may not be copied, reproduced, or distributed without the\nwritten permission of the copyright holder.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 1, 'page_label': '2'}, page_content='ii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='Contents\n1 Preliminaries 1\n1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1.1 What is Machine Learning? . . . . . . . . . . . . . . . . . 1\n1.1.2 Wellsprings of Machine Learning . . . . . . . . . . . . . . 3\n1.1.3 Varieties of Machine Learning . . . . . . . . . . . . . . . . 4\n1.2 Learning Input-Output Functions . . . . . . . . . . . . . . . . . . 5\n1.2.1 Types of Learning . . . . . . . . . . . . . . . . . . . . . . 5\n1.2.2 Input Vectors . . . . . . . . . . . . . . . . . . . . . . . . . 7\n1.2.3 Outputs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.4 Training Regimes . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.5 Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.2.6 Performance Evaluation . . . . . . . . . . . . . . . . . . . 9\n1.3 Learning Requires Bias . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.4 Sample Applications . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.5 Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 13\n2 Boolean Functions 15\n2.1 Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1.1 Boolean Algebra . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1.2 Diagrammatic Representations . . . . . . . . . . . . . . . 16\n2.2 Classes of Boolean Functions . . . . . . . . . . . . . . . . . . . . 17\n2.2.1 Terms and Clauses . . . . . . . . . . . . . . . . . . . . . . 17\n2.2.2 DNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.2.3 CNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.2.4 Decision Lists . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.2.5 Symmetric and Voting Functions . . . . . . . . . . . . . . 23\n2.2.6 Linearly Separable Functions . . . . . . . . . . . . . . . . 23\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 25\niii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='3 Using Version Spaces for Learning 27\n3.1 Version Spaces and Mistake Bounds . . . . . . . . . . . . . . . . 27\n3.2 Version Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n3.3 Learning as Search of a Version Space . . . . . . . . . . . . . . . 32\n3.4 The Candidate Elimination Method . . . . . . . . . . . . . . . . 32\n3.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 34\n4 Neural Networks 35\n4.1 Threshold Logic Units . . . . . . . . . . . . . . . . . . . . . . . . 35\n4.1.1 De\ufb01nitions and Geometry . . . . . . . . . . . . . . . . . . 35\n4.1.2 Special Cases of Linearly Separable Functions . . . . . . . 37\n4.1.3 Error-Correction Training of a TLU . . . . . . . . . . . . 38\n4.1.4 Weight Space . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4.1.5 The Widrow-Ho\ufb00 Procedure . . . . . . . . . . . . . . . . . 42\n4.1.6 Training a TLU on Non-Linearly-Separable Training Sets 44\n4.2 Linear Machines . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.3 Networks of TLUs . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n4.3.1 Motivation and Examples . . . . . . . . . . . . . . . . . . 46\n4.3.2 Madalines . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.3.3 Piecewise Linear Machines . . . . . . . . . . . . . . . . . . 50\n4.3.4 Cascade Networks . . . . . . . . . . . . . . . . . . . . . . 51\n4.4 Training Feedforward Networks by Backpropagation . . . . . . . 52\n4.4.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.4.2 The Backpropagation Method . . . . . . . . . . . . . . . . 53\n4.4.3 Computing Weight Changes in the Final Layer . . . . . . 56\n4.4.4 Computing Changes to the Weights in Intermediate Layers 58\n4.4.5 Variations on Backprop . . . . . . . . . . . . . . . . . . . 59\n4.4.6 An Application: Steering a Van . . . . . . . . . . . . . . . 60\n4.5 Synergies Between Neural Network and Knowledge-Based Methods 61\n4.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 61\n5 Statistical Learning 63\n5.1 Using Statistical Decision Theory . . . . . . . . . . . . . . . . . . 63\n5.1.1 Background and General Method . . . . . . . . . . . . . . 63\n5.1.2 Gaussian (or Normal) Distributions . . . . . . . . . . . . 65\n5.1.3 Conditionally Independent Binary Components . . . . . . 68\n5.2 Learning Belief Networks . . . . . . . . . . . . . . . . . . . . . . 70\n5.3 Nearest-Neighbor Methods . . . . . . . . . . . . . . . . . . . . . . 70\n5.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 72\niv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='6 Decision Trees 73\n6.1 De\ufb01nitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n6.2 Supervised Learning of Univariate Decision Trees . . . . . . . . . 74\n6.2.1 Selecting the Type of Test . . . . . . . . . . . . . . . . . . 75\n6.2.2 Using Uncertainty Reduction to Select Tests . . . . . . . 75\n6.2.3 Non-Binary Attributes . . . . . . . . . . . . . . . . . . . . 79\n6.3 Networks Equivalent to Decision Trees . . . . . . . . . . . . . . . 79\n6.4 Over\ufb01tting and Evaluation . . . . . . . . . . . . . . . . . . . . . 80\n6.4.1 Over\ufb01tting . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n6.4.2 Validation Methods . . . . . . . . . . . . . . . . . . . . . 81\n6.4.3 Avoiding Over\ufb01tting in Decision Trees . . . . . . . . . . . 82\n6.4.4 Minimum-Description Length Methods . . . . . . . . . . . 83\n6.4.5 Noise in Data . . . . . . . . . . . . . . . . . . . . . . . . . 84\n6.5 The Problem of Replicated Subtrees . . . . . . . . . . . . . . . . 84\n6.6 The Problem of Missing Attributes . . . . . . . . . . . . . . . . . 86\n6.7 Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n6.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 87\n7 Inductive Logic Programming 89\n7.1 Notation and De\ufb01nitions . . . . . . . . . . . . . . . . . . . . . . . 90\n7.2 A Generic ILP Algorithm . . . . . . . . . . . . . . . . . . . . . . 91\n7.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n7.4 Inducing Recursive Programs . . . . . . . . . . . . . . . . . . . . 98\n7.5 Choosing Literals to Add . . . . . . . . . . . . . . . . . . . . . . 100\n7.6 Relationships Between ILP and Decision Tree Induction . . . . . 101\n7.7 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 104\n8 Computational Learning Theory 107\n8.1 Notation and Assumptions for PAC Learning Theory . . . . . . . 107\n8.2 PAC Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n8.2.1 The Fundamental Theorem . . . . . . . . . . . . . . . . . 109\n8.2.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n8.2.3 Some Properly PAC-Learnable Classes . . . . . . . . . . . 112\n8.3 The Vapnik-Chervonenkis Dimension . . . . . . . . . . . . . . . . 113\n8.3.1 Linear Dichotomies . . . . . . . . . . . . . . . . . . . . . . 113\n8.3.2 Capacity . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n8.3.3 A More General Capacity Result . . . . . . . . . . . . . . 116\n8.3.4 Some Facts and Speculations About the VC Dimension . 117\n8.4 VC Dimension and PAC Learning . . . . . . . . . . . . . . . . . 118\n8.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 118\nv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='9 Unsupervised Learning 119\n9.1 What is Unsupervised Learning? . . . . . . . . . . . . . . . . . . 119\n9.2 Clustering Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n9.2.1 A Method Based on Euclidean Distance . . . . . . . . . . 120\n9.2.2 A Method Based on Probabilities . . . . . . . . . . . . . . 124\n9.3 Hierarchical Clustering Methods . . . . . . . . . . . . . . . . . . 125\n9.3.1 A Method Based on Euclidean Distance . . . . . . . . . . 125\n9.3.2 A Method Based on Probabilities . . . . . . . . . . . . . . 126\n9.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 130\n10 Temporal-Di\ufb00erence Learning 131\n10.1 Temporal Patterns and Prediction Problems . . . . . . . . . . . . 131\n10.2 Supervised and Temporal-Di\ufb00erence Methods . . . . . . . . . . . 131\n10.3 Incremental Computation of the (\u2206 W)i . . . . . . . . . . . . . . 134\n10.4 An Experiment with TD Methods . . . . . . . . . . . . . . . . . 135\n10.5 Theoretical Results . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n10.6 Intra-Sequence Weight Updating . . . . . . . . . . . . . . . . . . 138\n10.7 An Example Application: TD-gammon . . . . . . . . . . . . . . . 140\n10.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 141\n11 Delayed-Reinforcement Learning 143\n11.1 The General Problem . . . . . . . . . . . . . . . . . . . . . . . . 143\n11.2 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n11.3 Temporal Discounting and Optimal Policies . . . . . . . . . . . . 145\n11.4 Q-Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n11.5 Discussion, Limitations, and Extensions of Q-Learning . . . . . . 150\n11.5.1 An Illustrative Example . . . . . . . . . . . . . . . . . . . 150\n11.5.2 Using Random Actions . . . . . . . . . . . . . . . . . . . 152\n11.5.3 Generalizing Over Inputs . . . . . . . . . . . . . . . . . . 153\n11.5.4 Partially Observable States . . . . . . . . . . . . . . . . . 154\n11.5.5 Scaling Problems . . . . . . . . . . . . . . . . . . . . . . . 154\n11.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 155\nvi'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='12 Explanation-Based Learning 157\n12.1 Deductive Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 157\n12.2 Domain Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n12.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n12.4 Evaluable Predicates . . . . . . . . . . . . . . . . . . . . . . . . . 162\n12.5 More General Proofs . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.6 Utility of EBL . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.7 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.7.1 Macro-Operators in Planning . . . . . . . . . . . . . . . . 164\n12.7.2 Learning Search Control Knowledge . . . . . . . . . . . . 167\n12.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 168\nvii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 7, 'page_label': '8'}, page_content='viii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 8, 'page_label': '9'}, page_content='Preface\nThese notes are in the process of becoming a textbook. The process is quite\nun\ufb01nished, and the author solicits corrections, criticisms, and suggestions from\nstudents and other readers. Although I have tried to eliminate errors, some un-\ndoubtedly remaincaveat lector. Many typographical infelicities will no doubt\npersist until the \ufb01nal version. More material has yet to be added. Please let Some of my plans for additions and\nother reminders are mentioned in\nmarginal notes.me have your suggestions about topics that are too important to be left out.\nI hope that future versions will cover Hop\ufb01eld nets, Elman nets and other re-\ncurrent nets, radial basis functions, grammar and automata learning, genetic\nalgorithms, and Bayes networks ... . I am also collecting exercises and project\nsuggestions which will appear in future versions.\nMy intention is to pursue a middle ground between a theoretical textbook\nand one that focusses on applications. The book concentrates on the important\nideas in machine learning. I do not give proofs of many of the theorems that I\nstate, but I do give plausibility arguments and citations to formal proofs. And, I\ndo not treat many matters that would be of practical importance in applications;\nthe book is not a handbook of machine learning practice. Instead, my goal is\nto give the reader su\ufb03cient preparation to make the extensive literature on\nmachine learning accessible.\nStudents in my Stanford courses on machine learning have already made\nseveral useful suggestions, as have my colleague, Pat Langley, and my teaching\nassistants, Ron Kohavi, Karl P\ufb02eger, Robert Allen, and Lise Getoor.\nix'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 9, 'page_label': '10'}, page_content='Chapter 1\nPreliminaries\n1.1 Introduction\n1.1.1 What is Machine Learning?\nLearning, like intelligence, covers such a broad range of processes that it is dif-\n\ufb01cult to de\ufb01ne precisely. A dictionary de\ufb01nition includes phrases such as to\ngain knowledge, or understanding of, or skill in, by study, instruction, or expe-\nrience, and modi\ufb01cation of a behavioral tendency by experience. Zoologists\nand psychologists study learning in animals and humans. In this book we fo-\ncus on learning in machines. There are several parallels between animal and\nmachine learning. Certainly, many techniques in machine learning derive from\nthe e\ufb00orts of psychologists to make more precise their theories of animal and\nhuman learning through computational models. It seems likely also that the\nconcepts and techniques being explored by researchers in machine learning may\nilluminate certain aspects of biological learning.\nAs regards machines, we might say, very broadly, that a machine learns\nwhenever it changes its structure, program, or data (based on its inputs or in\nresponse to external information) in such a manner that its expected future\nperformance improves. Some of these changes, such as the addition of a record\nto a data base, fall comfortably within the province of other disciplines and are\nnot necessarily better understood for being called learning. But, for example,\nwhen the performance of a speech-recognition machine improves after hearing\nseveral samples of a persons speech, we feel quite justi\ufb01ed in that case to say\nthat the machine has learned.\nMachine learning usually refers to the changes in systems that perform tasks\nassociated with arti\ufb01cial intelligence (AI) . Such tasks involve recognition, diag-\nnosis, planning, robot control, prediction, etc. The changes might be either\nenhancements to already performing systems or ab initio synthesis of new sys-\ntems. To be slightly more speci\ufb01c, we show the architecture of a typical AI\n1'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 10, 'page_label': '11'}, page_content='2 CHAPTER 1. PRELIMINARIES\nagent in Fig. 1.1. This agent perceives and models its environment and com-\nputes appropriate actions, perhaps by anticipating their e\ufb00ects. Changes made\nto any of the components shown in the \ufb01gure might count as learning. Di\ufb00erent\nlearning mechanisms might be employed depending on which subsystem is being\nchanged. We will study several di\ufb00erent learning methods in this book.\nSensory signals\nPerception\nActions\nAction\nComputation\nModel\nPlanning and\nReasoning\nGoals\nFigure 1.1: An AI System\nOne might ask Why should machines have to learn? Why not design ma-\nchines to perform as desired in the \ufb01rst place? There are several reasons why\nmachine learning is important. Of course, we have already mentioned that the\nachievement of learning in machines might help us understand how animals and\nhumans learn. But there are important engineering reasons as well. Some of\nthese are:\n Some tasks cannot be de\ufb01ned well except by example; that is, we might be\nable to specify input/output pairs but not a concise relationship between\ninputs and desired outputs. We would like machines to be able to adjust\ntheir internal structure to produce correct outputs for a large number of\nsample inputs and thus suitably constrain their input/output function to\napproximate the relationship implicit in the examples.\n It is possible that hidden among large piles of data are important rela-\ntionships and correlations. Machine learning methods can often be used\nto extract these relationships ( data mining).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 11, 'page_label': '12'}, page_content='1.1. INTRODUCTION 3\n Human designers often produce machines that do not work as well as\ndesired in the environments in which they are used. In fact, certain char-\nacteristics of the working environment might not be completely known\nat design time. Machine learning methods can be used for on-the-job\nimprovement of existing machine designs.\n The amount of knowledge available about certain tasks might be too large\nfor explicit encoding by humans. Machines that learn this knowledge\ngradually might be able to capture more of it than humans would want to\nwrite down.\n Environments change over time. Machines that can adapt to a changing\nenvironment would reduce the need for constant redesign.\n New knowledge about tasks is constantly being discovered by humans.\nVocabulary changes. There is a constant stream of new events in the\nworld. Continuing redesign of AI systems to conform to new knowledge is\nimpractical, but machine learning methods might be able to track much\nof it.\n1.1.2 Wellsprings of Machine Learning\nWork in machine learning is now converging from several sources. These dif-\nferent traditions each bring di\ufb00erent methods and di\ufb00erent vocabulary which\nare now being assimilated into a more uni\ufb01ed discipline. Here is a brief listing\nof some of the separate disciplines that have contributed to machine learning;\nmore details will follow in the the appropriate chapters:\n Statistics: A long-standing problem in statistics is how best to use sam-\nples drawn from unknown probability distributions to help decide from\nwhich distribution some new sample is drawn. A related problem is how\nto estimate the value of an unknown function at a new point given the\nvalues of this function at a set of sample points. Statistical methods\nfor dealing with these problems can be considered instances of machine\nlearning because the decision and estimation rules depend on a corpus of\nsamples drawn from the problem environment. We will explore some of\nthe statistical methods later in the book. Details about the statistical the-\nory underlying these methods can be found in statistical textbooks such\nas [Anderson, 1958].\n Brain Models: Non-linear elements with weighted inputs\nhave been suggested as simple models of biological neu-\nrons. Networks of these elements have been studied by sev-\neral researchers including [McCulloch & Pitts, 1943, Hebb, 1949,\nRosenblatt, 1958] and, more recently by [Gluck & Rumelhart, 1989,\nSejnowski, Koch, & Churchland, 1988]. Brain modelers are interested\nin how closely these networks approximate the learning phenomena of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 12, 'page_label': '13'}, page_content='4 CHAPTER 1. PRELIMINARIES\nliving brains. We shall see that several important machine learning\ntechniques are based on networks of nonlinear elementsoften called\nneural networks . Work inspired by this school is sometimes called\nconnectionism, brain-style computation, or sub-symbolic processing.\n Adaptive Control Theory: Control theorists study the problem of con-\ntrolling a process having unknown parameters which must be estimated\nduring operation. Often, the parameters change during operation, and the\ncontrol process must track these changes. Some aspects of controlling a\nrobot based on sensory inputs represent instances of this sort of problem.\nFor an introduction see [Bollinger & Du\ufb03e, 1988].\n Psychological Models: Psychologists have studied the performance of\nhumans in various learning tasks. An early example is the EPAM net-\nwork for storing and retrieving one member of a pair of words when\ngiven another [Feigenbaum, 1961]. Related work led to a number of\nearly decision tree [Hunt, Marin, & Stone, 1966] and semantic network\n[Anderson & Bower, 1973] methods. More recent work of this sort has\nbeen in\ufb02uenced by activities in arti\ufb01cial intelligence which we will be pre-\nsenting.\nSome of the work in reinforcement learning can be traced to e\ufb00orts to\nmodel how reward stimuli in\ufb02uence the learning of goal-seeking behavior in\nanimals [Sutton & Barto, 1987]. Reinforcement learning is an important\ntheme in machine learning research.\n Arti\ufb01cial Intelligence: From the beginning, AI research has been con-\ncerned with machine learning. Samuel developed a prominent early pro-\ngram that learned parameters of a function for evaluating board posi-\ntions in the game of checkers [Samuel, 1959]. AI researchers have also\nexplored the role of analogies in learning [Carbonell, 1983] and how fu-\nture actions and decisions can be based on previous exemplary cases\n[Kolodner, 1993]. Recent work has been directed at discovering rules\nfor expert systems using decision-tree methods [Quinlan, 1990] and in-\nductive logic programming [Muggleton, 1991, Lavra\u02c7 c & D\u02c7 zeroski, 1994].\nAnother theme has been saving and generalizing the results of prob-\nlem solving using explanation-based learning [DeJong & Mooney, 1986,\nLaird, et al., 1986, Minton, 1988, Etzioni, 1993].\n Evolutionary Models:\nIn nature, not only do individual animals learn to perform better, but\nspecies evolve to be better \ufb01t in their individual niches. Since the distinc-\ntion between evolving and learning can be blurred in computer systems,\ntechniques that model certain aspects of biological evolution have been\nproposed as learning methods to improve the performance of computer\nprograms. Genetic algorithms [Holland, 1975] and genetic programming\n[Koza, 1992, Koza, 1994] are the most prominent computational tech-\nniques for evolution.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 13, 'page_label': '14'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 5\n1.1.3 Varieties of Machine Learning\nOrthogonal to the question of the historical source of any learning technique is\nthe more important question of what is to be learned. In this book, we take it\nthat the thing to be learned is a computational structure of some sort. We will\nconsider a variety of di\ufb00erent computational structures:\n Functions\n Logic programs and rule sets\n Finite-state machines\n Grammars\n Problem solving systems\nWe will present methods both for the synthesis of these structures from examples\nand for changing existing structures. In the latter case, the change to the\nexisting structure might be simply to make it more computationally e\ufb03cient\nrather than to increase the coverage of the situations it can handle. Much of\nthe terminology that we shall be using throughout the book is best introduced\nby discussing the problem of learning functions, and we turn to that matter\n\ufb01rst.\n1.2 Learning Input-Output Functions\nWe use Fig. 1.2 to help de\ufb01ne some of the terminology used in describing the\nproblem of learning a function. Imagine that there is a function, f, and the task\nof the learner is to guess what it is. Our hypothesis about the function to be\nlearned is denoted by h. Both f and h are functions of a vector-valued input\nX = (x1,x2,...,x i,...,x n) which has n components. We think of h as being\nimplemented by a device that has X as input and h(X) as output. Both f and\nh themselves may be vector-valued. We assume a priori that the hypothesized\nfunction, h, is selected from a class of functions H. Sometimes we know that\nf also belongs to this class or to a subset of this class. We select h based on a\ntraining set, \u039e, of minput vector examples. Many important details depend on\nthe nature of the assumptions made about all of these entities.\n1.2.1 Types of Learning\nThere are two major settings in which we wish to learn a function. In one,\ncalled supervised learning, we know (sometimes only approximately) the values\nof f for the m samples in the training set, \u039e. We assume that if we can \ufb01nd\na hypothesis, h, that closely agrees with f for the members of \u039e, then this\nhypothesis will be a good guess for fespecially if \u039e is large.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 14, 'page_label': '15'}, page_content='6 CHAPTER 1. PRELIMINARIES\nh(X)\nh\nU = {X1, X2, . . . Xi, . . ., Xm}\nTraining Set:\nX =\nx1\n.\n.\n.\nxi\n.\n.\n.\nxn h D H\nFigure 1.2: An Input-Output Function\nCurve-\ufb01tting is a simple example of supervised learning of a function. Sup-\npose we are given the values of a two-dimensional function,f, at the four sample\npoints shown by the solid circles in Fig. 1.3. We want to \ufb01t these four points\nwith a function, h, drawn from the set, H, of second-degree functions. We show\nthere a two-dimensional parabolic surface above the x1, x2 plane that \ufb01ts the\npoints. This parabolic function, h, is our hypothesis about the function, f, that\nproduced the four samples. In this case, h= f at the four samples, but we need\nnot have required exact matches.\nIn the other setting, termed unsupervised learning, we simply have a train-\ning set of vectors without function values for them. The problem in this case,\ntypically, is to partition the training set into subsets, \u039e 1, . . . , \u039eR, in some ap-\npropriate way. (We can still regard the problem as one of learning a function;\nthe value of the function is the name of the subset to which an input vector be-\nlongs.) Unsupervised learning methods have application in taxonomic problems\nin which it is desired to invent ways to classify data into meaningful categories.\nWe shall also describe methods that are intermediate between supervised\nand unsupervised learning.\nWe might either be trying to \ufb01nd a new function, h, or to modify an existing\none. An interesting special case is that of changing an existing function into an\nequivalent one that is computationally more e\ufb03cient. This type of learning is\nsometimes called speed-uplearning. A very simple example of speed-up learning\ninvolves deduction processes. From the formulas A \u2283B and B \u2283C, we can\ndeduce C if we are given A. From this deductive process, we can create the\nformula A\u2283Ca new formula but one that does not sanction any more con-'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 15, 'page_label': '16'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 7\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n500\n1000\n1500\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n00\n00\n0\nx1\nx2\nh sample f-value\nFigure 1.3: A Surface that Fits Four Points\nclusions than those that could be derived from the formulas that we previously\nhad. But with this new formula we can derive C more quickly, given A, than\nwe could have done before. We can contrast speed-up learning with methods\nthat create genuinely new functionsones that might give di\ufb00erent results after\nlearning than they did before. We say that the latter methods involve inductive\nlearning. As opposed to deduction, there are no correct inductionsonly useful\nones.\n1.2.2 Input Vectors\nBecause machine learning methods derive from so many di\ufb00erent traditions, its\nterminology is rife with synonyms, and we will be using most of them in this\nbook. For example, the input vector is called by a variety of names. Some\nof these are: input vector, pattern vector, feature vector, sample, example, and\ninstance. The components, xi, of the input vector are variously called features,\nattributes, input variables, and components.\nThe values of the components can be of three main types. They might\nbe real-valued numbers, discrete-valued numbers, or categorical values. As an\nexample illustrating categorical values, information about a student might be\nrepresented by the values of the attributes class, major, sex, adviser . A par-\nticular student would then be represented by a vector such as: (sophomore,\nhistory, male, higgins). Additionally, categorical values may be ordered (as in\n{small, medium, large}) or unordered (as in the example just given). Of course,\nmixtures of all these types of values are possible.\nIn all cases, it is possible to represent the input in unordered form by listing\nthe names of the attributes together with their values. The vector form assumes\nthat the attributes are ordered and given implicitly by a form. As an example\nof an attribute-value representation, we might have: (major: history, sex: male,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 16, 'page_label': '17'}, page_content='8 CHAPTER 1. PRELIMINARIES\nclass: sophomore, adviser: higgins, age: 19). We will be using the vector form\nexclusively.\nAn important specialization uses Boolean values, which can be regarded as\na special case of either discrete numbers (1,0) or of categorical variables ( True,\nFalse).\n1.2.3 Outputs\nThe output may be a real number, in which case the process embodying the\nfunction, h, is called a function estimator , and the output is called an output\nvalue or estimate.\nAlternatively, the output may be a categorical value, in which case the pro-\ncess embodying h is variously called a classi\ufb01er, a recognizer, or a categorizer,\nand the output itself is called a label, a class, a category, or a decision. Classi-\n\ufb01ers have application in a number of recognition problems, for example in the\nrecognition of hand-printed characters. The input in that case is some suitable\nrepresentation of the printed character, and the classi\ufb01er maps this input into\none of, say, 64 categories.\nVector-valued outputs are also possible with components being real numbers\nor categorical values.\nAn important special case is that of Boolean output values. In that case,\na training pattern having value 1 is called a positive instance, and a training\nsample having value 0 is called a negative instance. When the input is also\nBoolean, the classi\ufb01er implements a Boolean function. We study the Boolean\ncase in some detail because it allows us to make important general points in\na simpli\ufb01ed setting. Learning a Boolean function is sometimes called concept\nlearning, and the function is called a concept.\n1.2.4 Training Regimes\nThere are several ways in which the training set, \u039e, can be used to produce a\nhypothesized function. In the batch method, the entire training set is available\nand used all at once to compute the function, h. A variation of this method\nuses the entire training set to modify a current hypothesis iteratively until an\nacceptable hypothesis is obtained. By contrast, in the incremental method, we\nselect one member at a time from the training set and use this instance alone\nto modify a current hypothesis. Then another member of the training set is\nselected, and so on. The selection method can be random (with replacement)\nor it can cycle through the training set iteratively. If the entire training set\nbecomes available one member at a time, then we might also use an incremental\nmethodselecting and using training set members as they arrive. (Alterna-\ntively, at any stage all training set members so far available could be used in a\nbatch process.) Using the training set members as they become available is\ncalled an online method. Online methods might be used, for example, when the'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 17, 'page_label': '18'}, page_content='1.3. LEARNING REQUIRES BIAS 9\nnext training instance is some function of the current hypothesis and the previ-\nous instanceas it would be when a classi\ufb01er is used to decide on a robots next\naction given its current set of sensory inputs. The next set of sensory inputs\nwill depend on which action was selected.\n1.2.5 Noise\nSometimes the vectors in the training set are corrupted by noise. There are two\nkinds of noise. Class noise randomly alters the value of the function; attribute\nnoise randomly alters the values of the components of the input vector. In either\ncase, it would be inappropriate to insist that the hypothesized function agree\nprecisely with the values of the samples in the training set.\n1.2.6 Performance Evaluation\nEven though there is no correct answer in inductive learning, it is important\nto have methods to evaluate the result of learning. We will discuss this matter\nin more detail later, but, brie\ufb02y, in supervised learning the induced function is\nusually evaluated on a separate set of inputs and function values for them called\nthe testing set . A hypothesized function is said to generalize when it guesses\nwell on the testing set. Both mean-squared-error and the total number of errors\nare common measures.\n1.3 Learning Requires Bias\nLong before now the reader has undoubtedly asked why is learning a function\npossible at all? Certainly, for example, there are an uncountable number of\ndi\ufb00erent functions having values that agree with the four samples shown in Fig.\n1.3. Why would a learning procedure happen to select the quadratic one shown\nin that \ufb01gure? In order to make that selection we had at least to limit a priori\nthe set of hypotheses to quadratic functions and then to insist that the one we\nchose passed through all four sample points. This kind of a priori information\nis called bias, and useful learning without bias is impossible.\nWe can gain more insight into the role of bias by considering the special case\nof learning a Boolean function of n dimensions. There are 2 n di\ufb00erent Boolean\ninputs possible. Suppose we had no bias; that is His the set of all 22n\nBoolean\nfunctions, and we have no preference among those that \ufb01t the samples in the\ntraining set. In this case, after being presented with one member of the training\nset and its value we can rule out precisely one-half of the members of Hthose\nBoolean functions that would misclassify this labeled sample. The remaining\nfunctions constitute what is called a version space; well explore that concept\nin more detail later. As we present more members of the training set, the graph\nof the number of hypotheses not yet ruled out as a function of the number of\ndi\ufb00erent patterns presented is as shown in Fig. 1.4. At any stage of the process,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 18, 'page_label': '19'}, page_content='10 CHAPTER 1. PRELIMINARIES\nhalf of the remaining Boolean functions have value 1 and half have value 0 for\nany training pattern not yet seen. No generalization is possible in this case\nbecause the training patterns give no clue about the value of a pattern not yet\nseen. Only memorization is possible here, which is a trivial sort of learning.\nlog2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n2n < j\n(generalization is not possible)\n|Hv| = no. of functions not ruled out\nFigure 1.4: Hypotheses Remaining as a Function of Labeled Patterns Presented\nBut suppose we limited Hto some subset, Hc, of all Boolean functions.\nDepending on the subset and on the order of presentation of training patterns,\na curve of hypotheses not yet ruled out might look something like the one\nshown in Fig. 1.5. In this case it is even possible that after seeing fewer than\nall 2 n labeled samples, there might be only one hypothesis that agrees with\nthe training set. Certainly, even if there is more than one hypothesis remaining,\nmost of them may have the same value formost of the patterns not yet seen! The\ntheory of Probably Approximately Correct (PAC) learning makes this intuitive\nidea precise. Well examine that theory later.\nLets look at a speci\ufb01c example of how bias aids learning. A Boolean function\ncan be represented by a hypercube each of whose vertices represents a di\ufb00erent\ninput pattern. We show a 3-dimensional version in Fig. 1.6. There, we show a\ntraining set of six sample patterns and have marked those having a value of 1 by\na small square and those having a value of 0 by a small circle. If the hypothesis\nset consists of just the linearly separable functionsthose for which the positive\nand negative instances can be separated by a linear surface, then there is only\none function remaining in this hypothsis set that is consistent with the training\nset. So, in this case, even though the training set does not contain all possible\npatterns, we can already pin down what the function must begiven the bias.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 19, 'page_label': '20'}, page_content='1.4. SAMPLE APPLICATIONS 11\nlog2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n|Hv| = no. of functions not ruled out\ndepends on order\nof presentation\nlog2|Hc|\nFigure 1.5: Hypotheses Remaining From a Restricted Subset\nMachine learning researchers have identi\ufb01ed two main varieties of bias, ab-\nsolute and preference. In absolute bias (also called restricted hypothesis-space\nbias), one restricts Hto a de\ufb01nite subset of functions. In our example of Fig. 1.6,\nthe restriction was to linearly separable Boolean functions. In preference bias,\none selects that hypothesis that is minimal according to some ordering scheme\nover all hypotheses. For example, if we had some way of measuring thecomplex-\nity of a hypothesis, we might select the one that was simplest among those that\nperformed satisfactorily on the training set. The principle of Occams razor,\nused in science to prefer simple explanations to more complex ones, is a type\nof preference bias. (William of Occam, 1285-?1349, was an English philosopher\nwho said:  non sunt multiplicanda entia praeter necessitatem , which means\nentities should not be multiplied unnecessarily.)\n1.4 Sample Applications\nOur main emphasis in this book is on the concepts of machine learningnot\non its applications. Nevertheless, if these concepts were irrelevant to real-world\nproblems they would probably not be of much interest. As motivation, we give\na short summary of some areas in which machine learning techniques have been\nsuccessfully applied. [Langley, 1992] cites some of the following applications and\nothers:\na. Rule discovery using a variant of ID3 for a printing industry problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 20, 'page_label': '21'}, page_content='12 CHAPTER 1. PRELIMINARIES\nx1\nx2\nx3\nFigure 1.6: A Training Set That Completely Determines a Linearly Separable\nFunction\n[Evans & Fisher, 1992].\nb. Electric power load forecasting using a k-nearest-neighbor rule system\n[Jabbour, K., et al., 1987].\nc. Automatic help desk assistant using a nearest-neighbor system\n[Acorn & Walden, 1992].\nd. Planning and scheduling for a steel mill using ExpertEase, a marketed\n(ID3-like) system [Michie, 1992].\ne. Classi\ufb01cation of stars and galaxies [Fayyad, et al., 1993].\nMany application-oriented papers are presented at the annual conferences\non Neural Information Processing Systems. Among these are papers on: speech\nrecognition, dolphin echo recognition, image processing, bio-engineering, diag-\nnosis, commodity trading, face recognition, music composition, optical character\nrecognition, and various control applications [Various Editors, 1989-1994].\nAs additional examples, [Hammerstrom, 1993] mentions:\na. Sharps Japanese kanji character recognition system processes 200 char-\nacters per second with 99+% accuracy. It recognizes 3000+ characters.\nb. NeuroForecasting Centres (London Business School and University Col-\nlege London) trading strategy selection network earned an average annual\npro\ufb01t of 18% against a conventional systems 12.3%.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 21, 'page_label': '22'}, page_content='1.5. SOURCES 13\nc. Fujitsus (plus a partners) neural network for monitoring a continuous\nsteel casting operation has been in successful operation since early 1990.\nIn summary, it is rather easy nowadays to \ufb01nd applications of machine learn-\ning techniques. This fact should come as no surprise inasmuch as many machine\nlearning techniques can be viewed as extensions of well known statistical meth-\nods which have been successfully applied for many years.\n1.5 Sources\nBesides the rich literature in machine learning (a small part of\nwhich is referenced in the Bibliography), there are several text-\nbooks that are worth mentioning [Hertz, Krogh, & Palmer, 1991,\nWeiss & Kulikowski, 1991, Natarjan, 1991, Fu, 1994, Langley, 1996].\n[Shavlik & Dietterich, 1990, Buchanan & Wilkins, 1993] are edited vol-\numes containing some of the most important papers. A survey paper by\n[Dietterich, 1990] gives a good overview of many important topics. There are\nalso well established conferences and publications where papers are given and\nappear including:\n The Annual Conferences on Advances in Neural Information Processing\nSystems\n The Annual Workshops on Computational Learning Theory\n The Annual International Workshops on Machine Learning\n The Annual International Conferences on Genetic Algorithms\n(The Proceedings of the above-listed four conferences are published by\nMorgan Kaufmann.)\n The journal Machine Learning (published by Kluwer Academic Publish-\ners).\nThere is also much information, as well as programs and datasets, available over\nthe Internet through the World Wide Web.\n1.6 Bibliographical and Historical Remarks\nTo be added. Every chapter will\ncontain a brief survey of the history\nof the material covered in that\nchapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 22, 'page_label': '23'}, page_content='14 CHAPTER 1. PRELIMINARIES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 23, 'page_label': '24'}, page_content='Chapter 2\nBoolean Functions\n2.1 Representation\n2.1.1 Boolean Algebra\nMany important ideas about learning of functions are most easily presented\nusing the special case of Boolean functions. There are several important sub-\nclasses of Boolean functions that are used as hypothesis classes for function\nlearning. Therefore, we digress in this chapter to present a review of Boolean\nfunctions and their properties. (For a more thorough treatment see, for example,\n[Unger, 1989].)\nA Boolean function, f(x1,x2,...,x n) maps an n-tuple of (0,1) values to\n{0,1}. Boolean algebra is a convenient notation for representing Boolean func-\ntions. Boolean algebra uses the connectives ·, +, and . For example, the and\nfunction of two variables is written x1 ·x2. By convention, the connective,  ·\nis usually suppressed, and the and function is written x1x2. x1x2 has value 1 if\nand only if both x1 and x2 have value 1; if either x1 or x2 has value 0, x1x2 has\nvalue 0. The (inclusive) or function of two variables is written x1 + x2. x1 + x2\nhas value 1 if and only if either or both of x1 or x2 has value 1; if both x1 and\nx2 have value 0, x1 + x2 has value 0. The complement or negation of a variable,\nx, is written x. xhas value 1 if and only if xhas value 0; if xhas value 1, xhas\nvalue 0.\nThese de\ufb01nitions are compactly given by the following rules for Boolean\nalgebra:\n1 + 1 = 1, 1 + 0 = 1, 0 + 0 = 0,\n1 ·1 = 1, 1 ·0 = 0, 0 ·0 = 0, and\n1 = 0, 0 = 1.\nSometimes the arguments and values of Boolean functions are expressed in\nterms of the constants T (True) and F (False) instead of 1 and 0, respectively.\n15'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 24, 'page_label': '25'}, page_content='16 CHAPTER 2. BOOLEAN FUNCTIONS\nThe connectives ·and + are each commutative and associative. Thus, for\nexample, x1(x2x3) = ( x1x2)x3, and both can be written simply as x1x2x3.\nSimilarly for +.\nA Boolean formula consisting of a single variable, such as x1 is called an\natom. One consisting of either a single variable or its complement, such as x1,\nis called a literal.\nThe operators ·and + do not commute between themselves. Instead, we\nhave DeMorgans laws (which can be veri\ufb01ed by using the above de\ufb01nitions):\nx1x2 = x1 + x2, and\nx1 + x2 = x1 x2.\n2.1.2 Diagrammatic Representations\nWe saw in the last chapter that a Boolean function could be represented by\nlabeling the vertices of a cube. For a function of n variables, we would need\nan n-dimensional hypercube. In Fig. 2.1 we show some 2- and 3-dimensional\nexamples. Vertices having value 1 are labeled with a small square, and vertices\nhaving value 0 are labeled with a small circle.\nx1\nx2\nx1\nx2\nx1\nx2\nand or\nxor (exclusive or)\nx1x2 x1 + x2\nx1x2  +  x1x2\neven parity functionx1\nx2\nx3\nx1x2x3  +  x1x2x3\n+ x1x2x3 + x1x2x3\nFigure 2.1: Representing Boolean Functions on Cubes\nUsing the hypercube representations, it is easy to see how many Boolean\nfunctions of n dimensions there are. A 3-dimensional cube has 2 3 = 8 vertices,\nand each may be labeled in two di\ufb00erent ways; thus there are 2 (23) = 256'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 25, 'page_label': '26'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 17\ndi\ufb00erent Boolean functions of 3 variables. In general, there are 2 2n\nBoolean\nfunctions of n variables.\nWe will be using 2- and 3-dimensional cubes later to provide some intuition\nabout the properties of certain Boolean functions. Of course, we cannot visualize\nhypercubes (for n > 3), and there are many surprising properties of higher\ndimensional spaces, so we must be careful in using intuitions gained in low\ndimensions. One diagrammatic technique for dimensions slightly higher than\n3 is the Karnaugh map . A Karnaugh map is an array of values of a Boolean\nfunction in which the horizontal rows are indexed by the values of some of\nthe variables and the vertical columns are indexed by the rest. The rows and\ncolumns are arranged in such a way that entries that are adjacent in the map\ncorrespond to vertices that are adjacent in the hypercube representation. We\nshow an example of the 4-dimensional even parity function in Fig. 2.2. (An\neven parity function is a Boolean function that has value 1 if there are an even\nnumber of its arguments that have value 1; otherwise it has value 0.) Note\nthat all adjacent cells in the table correspond to inputs di\ufb00ering in only one\ncomponent. Also describe general logic\ndiagrams, [Wnek, et al., 1990].\n00 01 1011\n00\n01\n10\n11\n11\n1\n1\n11\n1\n10\n00\n0\n0\n0\n0\n0\nx1,x2\nx3,x4\nFigure 2.2: A Karnaugh Map\n2.2 Classes of Boolean Functions\n2.2.1 Terms and Clauses\nTo use absolute bias in machine learning, we limit the class of hypotheses. In\nlearning Boolean functions, we frequently use some of the common sub-classes of\nthose functions. Therefore, it will be important to know about these subclasses.\nOne basic subclass is called terms. A term is any function written in the\nform l1l2 ···lk, where the li are literals. Such a form is called a conjunction of\nliterals. Some example terms are x1x7 and x1x2x4. The size of a term is the\nnumber of literals it contains. The examples are of sizes 2 and 3, respectively.\n(Strictly speaking, the class of conjunctions of literals is called the monomials,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 26, 'page_label': '27'}, page_content='18 CHAPTER 2. BOOLEAN FUNCTIONS\nand a conjunction of literals itself is called a term. This distinction is a \ufb01ne one\nwhich we elect to blur here.)\nIt is easy to show that there are exactly 3 n possible terms of n variables.\nThe number of terms of size kor less is bounded from above by \u2211k\ni=0 C(2n,i) =\nO(nk), where C(i,j) = i!\n(i\u2212j)!j! is the binomial coe\ufb03cient.Probably Ill put in a simple\nterm-learning algorithm hereso\nwe can get started on learning!\nAlso for DNF functions and\ndecision listsas they are de\ufb01ned\nin the next few pages.\nA clause is any function written in the form l1 +l2 +···+lk, where the li are\nliterals. Such a form is called a disjunction of literals. Some example clauses\nare x3 + x5 + x6 and x1 + x4. The size of a clause is the number of literals it\ncontains. There are 3 n possible clauses and fewer than \u2211k\ni=0 C(2n,i) clauses of\nsize k or less. If f is a term, then (by De Morgans laws) f is a clause, and vice\nversa. Thus, terms and clauses are duals of each other.\nIn psychological experiments, conjunctions of literals seem easier for humans\nto learn than disjunctions of literals.\n2.2.2 DNF Functions\nA Boolean function is said to be in disjunctive normal form (DNF) if it can be\nwritten as adisjunction of terms. Some examples in DNF are: f = x1x2+x2x3x4\nand f = x1x3 + x2 x3 + x1x2x3. A DNF expression is called a k-term DNF\nexpression if it is a disjunction of k terms; it is in the class k-DNF if the size of\nits largest term is k. The examples above are 2-term and 3-term expressions,\nrespectively. Both expressions are in the class 3-DNF.\nEach term in a DNF expression for a function is called an implicant because\nit implies the function (if the term has value 1, so does the function). In\ngeneral, a term, t, is an implicant of a function, f, if f has value 1 whenever\nt does. A term, t, is a prime implicant of f if the term, t\u2032, formed by taking\nany literal out of an implicant t is no longer an implicant of f. (The implicant\ncannot be divided by any term and remain an implicant.)\nThus, both x2x3 and x1 x3 are prime implicants off = x2x3+x1 x3+x2x1x3,\nbut x2x1x3 is not.\nThe relationship between implicants and prime implicants can be geometri-\ncally illustrated using the cube representation for Boolean functions. Consider,\nfor example, the function f = x2x3 + x1 x3 + x2x1x3. We illustrate it in Fig.\n2.3. Note that each of the three planes in the \ufb01gure cuts o\ufb00 a group of\nvertices having value 1, but none cuts o\ufb00 any vertices having value 0. These\nplanes are pictorial devices used to isolate certain lower dimensional subfaces\nof the cube. Two of them isolate one-dimensional edges, and the third isolates\na zero-dimensional vertex. Each group of vertices on a subface corresponds to\none of the implicants of the function, f, and thus each implicant corresponds\nto a subface of some dimension. A k-dimensional subface corresponds to an\n(n\u2212k)-size implicant term. The function is written as the disjunction of the\nimplicantscorresponding to the union of all the vertices cut o\ufb00 by all of the\nplanes. Geometrically, an implicant is prime if and only if its corresponding\nsubface is the largest dimensional subface that includes all of its vertices and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 27, 'page_label': '28'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 19\nno other vertices having value 0. Note that the term x2x1x3 is not a prime\nimplicant of f. (In this case, we dont even have to include this term in the\nfunction because the vertex cut o\ufb00 by the plane corresponding to x2x1x3 is\nalready cut o\ufb00 by the plane corresponding to x2x3.) The other two implicants\nare prime because their corresponding subfaces cannot be expanded without\nincluding vertices having value 0.\nx2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x2x1x3\n   = x2x3 + x1x3\nx2x3 and  x1x3 are prime implicants\nFigure 2.3: A Function and its Implicants\nNote that all Boolean functions can be represented in DNFtrivially by\ndisjunctions of terms of size nwhere each term corresponds to one of the vertices\nwhose value is 1. Whereas there are 22n\nfunctions of ndimensions in DNF (since\nany Boolean function can be written in DNF), there are just 2 O(nk) functions\nin k-DNF.\nAll Boolean functions can also be represented in DNF in which each term is\na prime implicant, but that representation is not unique, as shown in Fig. 2.4.\nIf we can express a function in DNF form, we can use the consensus method\nto \ufb01nd an expression for the function in which each term is a prime implicant.\nThe consensus method relies on two results: We may replace this section with\none describing the\nQuine-McCluskey method instead. Consensus:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 28, 'page_label': '29'}, page_content='20 CHAPTER 2. BOOLEAN FUNCTIONS\nx2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x1x2\n   = x1x2 + x1x3\nAll of the terms are prime implicants, but there\nis not a unique representation\nFigure 2.4: Non-Uniqueness of Representation by Prime Implicants\nxi ·f1 + xi ·f2 = xi ·f1 + xi ·f2 + f1 ·f2\nwhere f1 and f2 are terms such that no literal appearing in f1 appears\ncomplemented in f2. f1 ·f2 is called the consensus of xi ·f1 and xi ·\nf2. Readers familiar with the resolution rule of inference will note that\nconsensus is the dual of resolution.\nExamples: x1 is the consensus of x1x2 and x1x2. The terms x1x2 and x1x2\nhave no consensus since each term has more than one literal appearing\ncomplemented in the other.\n Subsumption:\nxi ·f1 + f1 = f1\nwhere f1 is a term. We say that f1 subsumes xi ·f1.\nExample: x1 x4x5 subsumes x1 x4 x2x5'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 29, 'page_label': '30'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 21\nThe consensus method for \ufb01nding a set of prime implicants for a function,\nf, iterates the following operations on the terms of a DNF expression for f until\nno more such operations can be applied:\na. initialize the process with the set, T, of terms in the DNF expression of\nf,\nb. compute the consensus of a pair of terms in T and add the result to T,\nc. eliminate any terms in T that are subsumed by other terms in T.\nWhen this process halts, the terms remaining in T are all prime implicants of\nf.\nExample: Let f = x1x2 + x1 x2x3 + x1 x2 x3 x4x5. We show a derivation of\na set of prime implicants in the consensus tree of Fig. 2.5. The circled numbers\nadjoining the terms indicate the order in which the consensus and subsumption\noperations were performed. Shaded boxes surrounding a term indicate that it\nwas subsumed. The \ufb01nal form of the function in which all terms are prime\nimplicants is: f = x1x2 + x1x3 + x1 x4x5. Its terms are all of the non-subsumed\nterms in the consensus tree.\n x1x2 x1x2x3 x1x2x3x4x5\n x1x3\nx1x2x4x5\nx1x4x5\nf =  x1x2 + + x1x3 x1x4x5\n1\n2\n6\n4\n5\n3\nFigure 2.5: A Consensus Tree\n2.2.3 CNF Functions\nDisjunctive normal form has a dual: conjunctive normal form (CNF). A Boolean\nfunction is said to be in CNF if it can be written as a conjunction of clauses.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 30, 'page_label': '31'}, page_content='22 CHAPTER 2. BOOLEAN FUNCTIONS\nAn example in CNF is: f = (x1 +x2)(x2 +x3 +x4). A CNF expression is called\na k-clause CNF expression if it is a conjunction of k clauses; it is in the class\nk-CNF if the size of its largest clause is k. The example is a 2-clause expression\nin 3-CNF. If f is written in DNF, an application of De Morgans law renders f\nin CNF, and vice versa. Because CNF and DNF are duals, there are also 2 O(nk)\nfunctions in k-CNF.\n2.2.4 Decision Lists\nRivest has proposed a class of Boolean functions calleddecision lists [Rivest, 1987].\nA decision list is written as an ordered list of pairs:\n(tq,vq)\n(tq\u22121,vq\u22121)\n···\n(ti,vi)\n···\n(t2,v2)\n(T,v1)\nwhere the vi are either 0 or 1, the ti are terms in ( x1,...,x n), and T is a term\nwhose value is 1 (regardless of the values of the xi). The value of a decision list\nis the value of vi for the \ufb01rst ti in the list that has value 1. (At least one ti will\nhave value 1, because the last one does; v1 can be regarded as a default value of\nthe decision list.) The decision list is of size k, if the size of the largest term in\nit is k. The class of decision lists of size k or less is called k-DL.\nAn example decision list is:\nf =\n(x1x2,1)\n(x1 x2x3,0)\nx2x3,1)\n(1,0)\nf has value 0 for x1 = 0, x2 = 0, and x3 = 1. It has value 1 for x1 = 1, x2 = 0,\nand x3 = 1. This function is in 3-DL.\nIt has been shown that the class k-DL is a strict superset of the union of\nk-DNF and k-CNF. There are 2 O[nkklog(n)] functions in k-DL [Rivest, 1987].\nInteresting generalizations of decision lists use other Boolean functions in\nplace of the terms, ti. For example we might use linearly separable functions in\nplace of the ti (see below and [Marchand & Golea, 1993]).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 31, 'page_label': '32'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 23\n2.2.5 Symmetric and Voting Functions\nA Boolean function is called symmetric if it is invariant under permutations\nof the input variables. For example, any function that is dependent only on\nthe number of input variables whose values are 1 is a symmetric function. The\nparity functions, which have value 1 depending on whether or not the number\nof input variables with value 1 is even or odd is a symmetric function. (The\nexclusive or function, illustrated in Fig. 2.1, is an odd-parity function of two\ndimensions. The or and and functions of two dimensions are also symmetric.)\nAn important subclass of the symmetric functions is the class of voting func-\ntions (also called m-of-nfunctions). A k-voting function has value 1 if and only\nif k or more of its n inputs has value 1. If k= 1, a voting function is the same\nas an n-sized clause; if k= n, a voting function is the same as an n-sized term;\nif k = (n+ 1)/2 for n odd or k = 1 + n/2 for n even, we have the majority\nfunction.\n2.2.6 Linearly Separable Functions\nThe linearly separable functions are those that can be expressed as follows:\nf = thresh(\nn\u2211\ni=1\nwixi,\u03b8)\nwhere wi, i= 1,...,n , are real-valued numbers called weights, \u03b8is a real-valued\nnumber called the threshold, and thresh( \u03c3,\u03b8) is 1 if \u03c3 \u2265\u03b8 and 0 otherwise.\n(Note that the concept of linearly separable functions can be extended to non-\nBoolean inputs.) The k-voting functions are all members of the class of linearly\nseparable functions in which the weights all have unit value and the threshold\ndepends on k. Thus, terms and clauses are special cases of linearly separable\nfunctions.\nA convenient way to write linearly separable functions uses vector notation:\nf = thresh(X ·W,\u03b8)\nwhere X = ( x1,...,x n) is an n-dimensional vector of input variables, W =\n(w1,...,w n) is an n-dimensional vector of weight values, and X ·W is the dot\n(or inner) product of the two vectors. Input vectors for which f has value 1 lie\nin a half-space on one side of (and on) a hyperplane whose orientation is normal\nto W and whose position (with respect to the origin) is determined by \u03b8. We\nsaw an example of such a separating plane in Fig. 1.6. With this idea in mind,\nit is easy to see that two of the functions in Fig. 2.1 are linearly separable, while\ntwo are not. Also note that the terms in Figs. 2.3 and 2.4 are linearly separable\nfunctions as evidenced by the separating planes shown.\nThere is no closed-form expression for the number of linearly separable func-\ntions of n dimensions, but the following table gives the numbers for n up to 6.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 32, 'page_label': '33'}, page_content='24 CHAPTER 2. BOOLEAN FUNCTIONS\nn Boolean Linearly Separable\nFunctions Functions\n1 4 4\n2 16 14\n3 256 104\n4 65,536 1,882\n5 \u22484.3 ×109 94,572\n6 \u22481.8 ×1019 15,028,134\n[Muroga, 1971] has shown that (for n> 1) there are no more than 2 n2\nlinearly\nseparable functions of n dimensions. (See also [Winder, 1961, Winder, 1962].)\n2.3 Summary\nThe diagram in Fig. 2.6 shows some of the set inclusions of the classes of Boolean\nfunctions that we have considered. We will be confronting these classes again\nin later chapters.\nDNF\n(All)\nk-DLk-DNFk-size-\nterms\nterms\nlin sep\nFigure 2.6: Classes of Boolean Functions\nThe sizes of the various classes are given in the following table (adapted from\n[Dietterich, 1990, page 262]):'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 33, 'page_label': '34'}, page_content='2.4. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 25\nClass Size of Class\nterms 3n\nclauses 3n\nk-term DNF 2O(kn)\nk-clause CNF 2O(kn)\nk-DNF 2O(nk)\nk-CNF 2O(nk)\nk-DL 2O[nkklog(n)]\nlin sep 2O(n2)\nDNF 22n\n2.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 34, 'page_label': '35'}, page_content='26 CHAPTER 2. BOOLEAN FUNCTIONS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 35, 'page_label': '36'}, page_content='Chapter 3\nUsing Version Spaces for\nLearning\n3.1 Version Spaces and Mistake Bounds\nThe \ufb01rst learning methods we present are based on the concepts of version\nspaces and version graphs. These ideas are most clearly explained for the case\nof Boolean function learning. Given an initial hypothesis set H(a subset of\nall Boolean functions) and the values of f(X) for each X in a training set, \u039e,\nthe version space is that subset of hypotheses, Hv, that is consistent with these\nvalues. A hypothesis, h, is consistent with the values of X in \u039e if and only if\nh(X) = f(X) for all X in \u039e. We say that the hypotheses in Hthat are not\nconsistent with the values in the training set are ruled out by the training set.\nWe could imagine (conceptually only!) that we have devices for implement-\ning every function in H. An incremental training procedure could then be\nde\ufb01ned which presented each pattern in \u039e to each of these functions and then\neliminated those functions whose values for that pattern did not agree with its\ngiven value. At any stage of the process we would then have left some subset\nof functions that are consistent with the patterns presented so far; this subset\nis the version space for the patterns already presented. This idea is illustrated\nin Fig. 3.1.\nConsider the following procedure for classifying an arbitrary input pattern,\nX: the pattern is put in the same class (0 or 1) as are the majority of the\noutputs of the functions in the version space. During the learning procedure,\nif this majority is not equal to the value of the pattern presented, we say a\nmistake is made, and we revise the version space accordinglyeliminating all\nthose (majority of the) functions voting incorrectly. Thus, whenever a mistake\nis made, we rule out at least half of the functions remaining in the version space.\nHow many mistakes can such a procedure make? Obviously, we can make\nno more than log 2(|H|) mistakes, where |H|is the number of hypotheses in the\n27'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 36, 'page_label': '37'}, page_content='28 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nh1\nh2\nhi\nhK\nX\nA Subset, H,  of all\nBoolean Functions\nRule out hypotheses not\nconsistent with training patterns\nhj\nHypotheses not ruled out\nconstitute the version space\nK = |H|\n1 or 0\nFigure 3.1: Implementing the Version Space\noriginal hypothesis set, H. (Note, though, that the number of training patterns\nseen before this maximum number of mistakes is made might be much greater.)\nThis theoretical (and very impractical!) result (due to [Littlestone, 1988]) is an\nexample of a mistake boundan important concept in machine learning theory.\nIt shows that there must exist a learning procedure that makes no more mistakes\nthan this upper bound. Later, well derive other mistake bounds.\nAs a special case, if our bias was to limit Hto terms, we would make no\nmore than log2(3n) = nlog2(3) = 1.585nmistakes before exhausting the version\nspace. This result means that if f were a term, we would make no more than\n1.585nmistakes before learning f, and otherwise we would make no more than\nthat number of mistakes before being able to decide that f is not a term.\nEven if we do not have su\ufb03cient training patterns to reduce the version\nspace to a single function, it may be that there are enough training patterns\nto reduce the version space to a set of functions such that most of them assign\nthe same values to most of the patterns we will see henceforth. We could select\none of the remaining functions at random and be reasonably assured that it\nwill generalize satisfactorily. We next discuss a computationally more feasible\nmethod for representing the version space.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 37, 'page_label': '38'}, page_content='3.2. VERSION GRAPHS 29\n3.2 Version Graphs\nBoolean functions can be ordered by generality. A Boolean function, f1, is more\ngeneral than a function, f2, (and f2 is more speci\ufb01c than f1), if f1 has value 1\nfor all of the arguments for which f2 has value 1, and f1 \u0338= f2. For example, x3\nis more general than x2x3 but is not more general than x3 + x2.\nWe can form a graph with the hypotheses, {hi}, in the version space as\nnodes. A node in the graph, hi, has an arc directed to node, hj, if and only if\nhj is more general than hi. We call such a graph a version graph. In Fig. 3.2,\nwe show an example of a version graph over a 3-dimensional input space for\nhypotheses restricted to terms (with none of them yet ruled out).\n0\nx1 x2x 3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nVersion Graph for Terms\nx1\nx2\nx3\n(for simplicity, only some arcs in the graph are shown)\n(none yet ruled out)\n(k = 1)\n(k = 2)\n(k = 3)\nx1 x3\nFigure 3.2: A Version Graph for Terms\nThat function, denoted here by 1, which has value 1 for all inputs, corre-\nsponds to the node at the top of the graph. (It is more general than any other\nterm.) Similarly, the function 0 is at the bottom of the graph. Just below\n1 is a row of nodes corresponding to all terms having just one literal, and just\nbelow them is a row of nodes corresponding to terms having two literals, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 38, 'page_label': '39'}, page_content='30 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nso on. There are 3 3 = 27 functions altogether (the function 0, included in\nthe graph, is technically not a term). To make our portrayal of the graph less\ncluttered only some of the arcs are shown; each node in the actual graph has an\narc directed to all of the nodes above it that are more general.\nWe use this same example to show how the version graph changes as we\nconsider a set of labeled samples in a training set, \u039e. Suppose we \ufb01rst consider\nthe training pattern (1, 0, 1) with value 0. Some of the functions in the version\ngraph of Fig. 3.2 are inconsistent with this training pattern. These ruled out\nnodes are no longer in the version graph and are shown shaded in Fig. 3.3. We\nalso show there the three-dimensional cube representation in which the vertex\n(1, 0, 1) has value 0.\n0\nx1 x2 x3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nNew Version Graph\n1, 0, 1 has\nvalue 0\nx1x3\nx1x2 x2x3\nx1x2x3\nx1\nx2\nx3\nx1x3\n(only some arcs in the graph are shown)\nruled out nodes\nFigure 3.3: The Version Graph Upon Seeing (1, 0, 1)\nIn a version graph, there are always a set of hypotheses that are maximally\ngeneral and a set of hypotheses that are maximally speci\ufb01c. These are called\nthe general boundary set (gbs) and the speci\ufb01c boundary set (sbs) , respectively.\nIn Fig. 3.4, we have the version graph as it exists after learning that (1,0,1) has\nvalue 0 and (1, 0, 0) has value 1. The gbs and sbs are shown.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 39, 'page_label': '40'}, page_content='3.2. VERSION GRAPHS 31\n0\nx1 x2\nx3\nx2 x3\n1\nx1x2 x3\nx1\nx2x3x1x3\ngeneral boundary set\n(gbs)\nspecific boundary set (sbs)\nx1x2\nmore specific than gbs,\nmore general than sbs\n1, 0, 1 has\nvalue 0\nx1\nx2\nx3\n1, 0, 0 has\nvalue 1\nFigure 3.4: The Version Graph Upon Seeing (1, 0, 1) and (1, 0, 0)\nBoundary sets are important because they provide an alternative to repre-\nsenting the entire version space explicitly, which would be impractical. Given\nonly the boundary sets, it is possible to determine whether or not any hypoth-\nesis (in the prescribed class of Boolean functions we are using) is a member or\nnot of the version space. This determination is possible because of the fact that\nany member of the version space (that is not a member of one of the boundary\nsets) is more speci\ufb01c than some member of the general boundary set and is more\ngeneral than some member of the speci\ufb01c boundary set.\nIf we limit our Boolean functions that can be in the version space to terms,\nit is a simple matter to determine maximally general and maximally speci\ufb01c\nfunctions (assuming that there is some term that is in the version space). A\nmaximally speci\ufb01c one corresponds to a subface of minimal dimension that\ncontains all the members of the training set labelled by a 1 and no members\nlabelled by a 0. A maximally general one corresponds to a subface of maximal\ndimension that contains all the members of the training set labelled by a 1 and\nno members labelled by a 0. Looking at Fig. 3.4, we see that the subface of\nminimal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is just\nthe vertex (1, 0, 0) itselfcorresponding to the function x1x2 x3. The subface'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 40, 'page_label': '41'}, page_content='32 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nof maximal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is\nthe bottom face of the cubecorresponding to the function x3. In Figs. 3.2\nthrough 3.4 the sbs is always singular. Version spaces for terms always have\nsingular speci\ufb01c boundary sets. As seen in Fig. 3.3, however, the gbs of a\nversion space for terms need not be singular.\n3.3 Learning as Search of a Version Space\n[To be written. Relate to term learning algorithm presented in Chapter\nTwo. Also discuss best-\ufb01rst search methods. See Pat Langleys example us-\ning pseudo-cells of how to generate and eliminate hypotheses.]\nSelecting a hypothesis from the version space can be thought of as a search\nproblem. One can start with a very general function and specialize it through\nvarious specialization operators until one \ufb01nds a function that is consistent (or\nadequately so) with a set of training patterns. Such procedures are usually\ncalled top-down methods. Or, one can start with a very special function and\ngeneralize itresulting in bottom-up methods. We shall see instances of both\nstyles of learning in this book.Compare this view of top-down\nversus bottom-up with the\ndivide-and-conquer and the\ncovering (or AQ) methods of\ndecision-tree induction. 3.4 The Candidate Elimination Method\nThe candidate elimination method, is an incremental method for computing the\nboundary sets. Quoting from [Hirsh, 1994, page 6]:\nThe candidate-elimination algorithm manipulates the boundary-set\nrepresentation of a version space to create boundary sets that rep-\nresent a new version space consistent with all the previous instances\nplus the new one. For a positive exmple the algorithm generalizes\nthe elements of the [sbs] as little as possible so that they cover the\nnew instance yet remain consistent with past data, and removes\nthose elements of the [gbs] that do not cover the new instance. For\na negative instance the algorithm specializes elements of the [gbs]\nso that they no longer cover the new instance yet remain consis-\ntent with past data, and removes from the [sbs] those elements that\nmistakenly cover the new, negative instance.\nThe method uses the following de\ufb01nitions (adapted from\n[Genesereth & Nilsson, 1987]):\n a hypothesis is called su\ufb03cient if and only if it has value 1 for all training\nsamples labeled by a 1,\n a hypothesis is called necessary if and only if it has value 0 for all training\nsamples labeled by a 0.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 41, 'page_label': '42'}, page_content='3.4. THE CANDIDATE ELIMINATION METHOD 33\nHere is how to think about these de\ufb01nitions: A hypothesis implements a su\ufb03-\ncient condition that a training sample has value 1 if the hypothesis has value 1\nfor all of the positive instances; a hypothesis implements a necessary condition\nthat a training sample has value 1 if the hypothesis has value 0 for all of the\nnegative instances. A hypothesis is consistent with the training set (and thus is\nin the version space) if and only if it is both su\ufb03cient and necessary.\nWe start (before receiving any members of the training set) with the function\n0 as the singleton element of the speci\ufb01c boundary set and with the function\n1 as the singleton element of the general boundary set. Upon receiving a new\nlabeled input vector, the boundary sets are changed as follows:\na. If the new vector is labelled with a 1:\nThe new general boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not su\ufb03cient. (That is, we exclude any\nelements that have value 0 for the new vector.)\nThe new speci\ufb01c boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least generalizations.\nThe hypothesis hg is a least generalization of h if and only if: a) h is\nmore speci\ufb01c than hg, b) hg is su\ufb03cient, c) no function (including h) that\nis more speci\ufb01c than hg is su\ufb03cient, and d) hg is more speci\ufb01c than some\nmember of the new general boundary set. It might be that hg = h. Also,\nleast generalizations of two di\ufb00erent functions in the speci\ufb01c boundary set\nmay be identical.\nb. If the new vector is labelled with a 0:\nThe new speci\ufb01c boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not necessary. (That is, we exclude\nany elements that have value 1 for the new vector.)\nThe new general boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least specializations.\nThe hypothesis hs is a least specialization of hif and only if: a) his more\ngeneral than hs, b) hs is necessary, c) no function (including h) that is\nmore general than hs is necessary, and d) hs is more general than some\nmember of the new speci\ufb01c boundary set. Again, it might be that hs = h,\nand least specializations of two di\ufb00erent functions in the general boundary\nset may be identical.\nAs an example, suppose we present the vectors in the following order:\nvector label\n(1, 0, 1) 0\n(1, 0, 0) 1\n(1, 1, 1) 0\n(0, 0, 1) 0'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 42, 'page_label': '43'}, page_content='34 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nWe start with general boundary set, 1, and speci\ufb01c boundary set, 0.\nAfter seeing the \ufb01rst sample, (1, 0, 1), labeled with a 0, the speci\ufb01c boundary\nset stays at 0 (it is necessary), and we change the general boundary set to\n{x1,x2,x3}. Each of the functions, x1, x2, and x3, are least specializations of\n1 (they are necessary, 1 is not, they are more general than 0, and there\nare no functions that are more general than they and also necessary).\nThen, after seeing (1, 0, 0), labeled with a 1, the general boundary set\nchanges to {x3}(because x1 and x2 are not su\ufb03cient), and the speci\ufb01c boundary\nset is changed to {x1x2 x3}. This single function is a least generalization of 0\n(it is su\ufb03cient, 0 is more speci\ufb01c than it, no function (including 0) that is\nmore speci\ufb01c than it is su\ufb03cient, and it is more speci\ufb01c than some member of\nthe general boundary set.\nWhen we see (1, 1, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the\ngeneral boundary set either because x3 is still necessary.\nFinally, when we see (0, 0, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the general\nboundary set either because x3 is still necessary.Maybe Ill put in an example of a\nversion graph for non-Boolean\nfunctions.\n3.5 Bibliographical and Historical Remarks\nThe concept of version spaces and their role in learning was \ufb01rst investigated\nby Tom Mitchell [Mitchell, 1982]. Although these ideas are not used in prac-\ntical machine learning procedures, they do provide insight into the nature of\nhypothesis selection. In order to accomodate noisy data, version spaces have\nbeen generalized by [Hirsh, 1994] to allow hypotheses that are not necessarily\nconsistent with the training set.More to be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 43, 'page_label': '44'}, page_content='Chapter 4\nNeural Networks\nIn chapter two we de\ufb01ned several important subsets of Boolean functions. Sup-\npose we decide to use one of these subsets as a hypothesis set for supervised\nfunction learning. We next have the question of how best to implement the\nfunction as a device that gives the outputs prescribed by the function for arbi-\ntrary inputs. In this chapter we describe how networks of non-linear elements\ncan be used to implement various input-output functions and how they can be\ntrained using supervised learning methods.\nNetworks of non-linear elements, interconnected through adjustable weights,\nplay a prominent role in machine learning. They are called neural networks be-\ncause the non-linear elements have as their inputs a weighted sum of the outputs\nof other elementsmuch like networks of biological neurons do. These networks\ncommonly use the threshold element which we encountered in chapter two in\nour study of linearly separable Boolean functions. We begin our treatment of\nneural nets by studying this threshold element and how it can be used in the\nsimplest of all networks, namely ones composed of a single threshold element.\n4.1 Threshold Logic Units\n4.1.1 De\ufb01nitions and Geometry\nLinearly separable (threshold) functions are implemented in a straightforward\nway by summing the weighted inputs and comparing this sum to a threshold\nvalue as shown in Fig. 4.1. This structure we call a threshold logic unit (TLU) .\nIts output is 1 or 0 depending on whether or not the weighted sum of its inputs is\ngreater than or equal to a threshold value, \u03b8. It has also been called an Adaline\n(for ada ptive lin ear e lement) [Widrow, 1962, Widrow & Lehr, 1990], an LTU\n(linear threshold unit), a perceptron, and a neuron. (Although the word per-\nceptron is often used nowadays to refer to a single TLU, Rosenblatt originally\nde\ufb01ned it as a class of networks of threshold elements [Rosenblatt, 1958].)\n35'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 44, 'page_label': '45'}, page_content='36 CHAPTER 4. NEURAL NETWORKS\n!\nx1\nx2\nxn+1 = 1\nxi\nw1\nw2\nwn+1\nwi\nwn\nX\nthreshold weight\nxn\nW threshold  "  = 0\nf\nf = thresh( ! wi xi,  0)\ni = 1\nn+1\nFigure 4.1: A Threshold Logic Unit (TLU)\nThe n-dimensional feature or input vector is denoted by X = (x1,...,x n).\nWhen we want to distinguish among di\ufb00erent feature vectors, we will attach\nsubscripts, such as Xi. The components of X can be any real-valued numbers,\nbut we often specialize to the binary numbers 0 and 1. The weights of a TLU\nare represented by an n-dimensional weight vector , W = ( w1,...,w n). Its\ncomponents are real-valued numbers (but we sometimes specialize to integers).\nThe TLU has output 1 if \u2211n\ni=1 xiwi \u2265 \u03b8; otherwise it has output 0. The\nweighted sum that is calculated by the TLU can be simply represented as a\nvector dot product, XW. (If the pattern and weight vectors are thought of as\ncolumn vectors, this dot product is then sometimes written as XtW, where\nthe row vector Xt is the transpose of X.) Often, the threshold, \u03b8, of the TLU\nis \ufb01xed at 0; in that case, arbitrary thresholds are achieved by using ( n+ 1)-\ndimensional augmented vectors, Y, and V, whose \ufb01rst ncomponents are the\nsame as those of X and W, respectively. The ( n+ 1)-st component, xn+1, of\nthe augmented feature vector, Y, always has value 1; the (n+ 1)-st component,\nwn+1, of the augmented weight vector, V, is set equal to the negative of the\ndesired threshold value. (When we want to emphasize the use of augmented\nvectors, well use the Y,V notation; however when the context of the discussion\nmakes it clear about what sort of vectors we are talking about, well lapse back\ninto the more familiar X,W notation.) In the Y,V notation, the TLU has an\noutput of 1 if YV \u22650. Otherwise, the output is 0.\nWe can give an intuitively useful geometric description of a TLU. A TLU\ndivides the input space by a hyperplane as sketched in Fig. 4.2. The hyperplane\nis the boundary between patterns for which XW + wn+1 > 0 and patterns\nfor which XW + wn+1 < 0. Thus, the equation of the hyperplane itself is\nXW+wn+1 = 0. The unit vector that is normal to the hyperplane is n = W\n|W|,\nwhere |W|=\n\u221a\n(w2\n1 + ... + w2n) is the length of the vector W. (The normal'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 45, 'page_label': '46'}, page_content='4.1. THRESHOLD LOGIC UNITS 37\nform of the hyperplane equation is Xn + W\n|W| = 0.) The distance from the\nhyperplane to the origin is wn+1\n|W|, and the distance from an arbitrary point, X,\nto the hyperplane is XW+wn+1\n|W| . When the distance from the hyperplane to the\norigin is negative (that is, when wn+1 < 0), then the origin is on the negative\nside of the hyperplane (that is, the side for which XW + wn+1 <0).\nX.W + wn+1 > 0\non this side\nW\nX\nW\nn = W\n|W|\nOrigin\nUnit vector normal\nto hyperplane\nW + wn+1 = 0X\nn +           = 0X\nEquations of hyperplane:\nwn+1\n|W|\nwn+1 W + wn+1X\nX.W + wn+1 < 0\non this side\nFigure 4.2: TLU Geometry\nAdjusting the weight vector, W, changes the orientation of the hyperplane;\nadjusting wn+1 changes the position of the hyperplane (relative to the origin).\nThus, training of a TLU can be achieved by adjusting the values of the weights.\nIn this way the hyperplane can be moved so that the TLU implements di\ufb00erent\n(linearly separable) functions of the input.\n4.1.2 Special Cases of Linearly Separable Functions\nTerms\nAny term of size k can be implemented by a TLU with a weight from each of\nthose inputs corresponding to variables occurring in the term. A weight of +1 is\nused from an input corresponding to a positive literal, and a weight of\u22121 is used\nfrom an input corresponding to a negative literal. (Literals not mentioned in\nthe term have weights of zerothat is, no connection at allfrom their inputs.)\nThe threshold, \u03b8, is set equal to kp \u22121/2, where kp is the number of positive\nliterals in the term. Such a TLU implements a hyperplane boundary that is'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 46, 'page_label': '47'}, page_content='38 CHAPTER 4. NEURAL NETWORKS\nparallel to a subface of dimension ( n\u2212k) of the unit hypercube. We show a\nthree-dimensional example in Fig. 4.3. Thus, linearly separable functions are a\nsuperset of terms.\n(1,1,1)\n(1,1,0)\nx2\nx1\nx3 f = x1x2\nx1 + x2 - 3/2 = 0\nEquation of plane is:\nFigure 4.3: Implementing a Term\nClauses\nThe negation of a clause is a term. For example, the negation of the clause\nf = x1 + x2 + x3 is the term f = x1 x2 x3. A hyperplane can be used to\nimplement this term. If we invert the hyperplane, it will implement the\nclause instead. Inverting a hyperplane is done by multiplying all of the TLU\nweightseven wn+1by \u22121. This process simply changes the orientation of the\nhyperplane\ufb02ipping it around by 180 degrees and thus changing its positive\nside. Therefore, linearly separable functions are also a superset of clauses. We\nshow an example in Fig. 4.4.\n4.1.3 Error-Correction Training of a TLU\nThere are several procedures that have been proposed for adjusting the weights\nof a TLU. We present next a family of incremental training procedures with\nparameter c. These methods make adjustments to the weight vector only when\nthe TLU being trained makes an error on a training pattern; they are called\nerror-correction procedures. We use augmented feature and weight vectors in\ndescribing them.\na. We start with a \ufb01nite training set, \u039e, of vectors, Yi , and their binary\nlabels.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 47, 'page_label': '48'}, page_content='4.1. THRESHOLD LOGIC UNITS 39\nf = x1 + x2 + x3\nx1\nx1 + x2 + x3 < 1/2 = 0\nf = x1x2x3\nEquation of plane is:\nx2\nx3\nFigure 4.4: Implementing a Clause\nb. Compose an in\ufb01nite training sequence, \u03a3, of vectors from \u039e and their\nlabels such that each member of \u039e occurs in\ufb01nitely often in \u03a3. Set the\ninitial weight values of an TLU to arbitrary values.\nc. Repeat forever:\nPresent the next vector, Yi, in \u03a3 to the TLU and note its response.\n(a) If the TLU responds correctly, make no change in the weight vector.\n(b) If Yi is supposed to produce an output of 0 and produces an output\nof 1 instead, modify the weight vector as follows:\nV \u2190\u2212V \u2212ciYi\nwhere ci is a positive real number called the learning rate parame-\nter (whose value is di\ufb00ererent in di\ufb00erent instances of this family of\nprocedures and may depend on i).\nNote that after this adjustment the new dot product will be ( V \u2212\nciYi)Yi = VYi\u2212ciYiYi, which is smaller than it was before the\nweight adjustment.\n(c) If Yi is supposed to produce an output of 1 and produces an output\nof 0 instead, modify the weight vector as follows:\nV \u2190\u2212V + ciYi\nIn this case, the new dot product will be ( V + ciYi)Yi = VYi +\nciYiYi, which is larger than it was before the weight adjustment.\nNote that all three of these cases can be combined in the following rule:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 48, 'page_label': '49'}, page_content='40 CHAPTER 4. NEURAL NETWORKS\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere di is the desired response (1 or 0) for Yi , and fi is the actual\nresponse (1 or 0) for Yi.]\nNote also that because the weight vector V now includes the wn+1 thresh-\nold component, the threshold of the TLU is also changed by these adjust-\nments.\nWe identify two versions of this procedure:\n1) In the \ufb01xed-increment procedure, the learning rate parameter, ci, is the\nsame \ufb01xed, positive constant for all i. Depending on the value of this constant,\nthe weight adjustment may or may not correct the response to an erroneously\nclassi\ufb01ed feature vector.\n2) In the fractional-correction procedure, the parameter ci is set to \u03bbYiV\nYiYi\n,\nwhere V is the weight vector before it is changed. Note that if \u03bb = 0, no\ncorrection takes place at all. If \u03bb = 1, the correction is just su\ufb03cient to make\nYiV = 0. If \u03bb> 1, the error will be corrected.\nIt can be proved that if there is some weight vector, V, that produces a\ncorrect output for all of the feature vectors in \u039e, then after a \ufb01nite number\nof feature vector presentations, the \ufb01xed-increment procedure will \ufb01nd such a\nweight vector and thus make no more weight changes. The same result holds\nfor the fractional-correction procedure if 1 <\u03bb \u22642.\nFor additional background, proofs, and examples of error-correction proce-\ndures, see [Nilsson, 1990].See [Maass & Tur´ an, 1994] for a\nhyperplane-\ufb01nding procedure that\nmakes no more than O(n2 log n)\nmistakes.\n4.1.4 Weight Space\nWe can give an intuitive idea about how these procedures work by considering\nwhat happens to the augmented weight vector in weight space as corrections\nare made. We use augmented vectors in our discussion here so that the threshold\nfunction compares the dot product, YiV, against a threshold of 0. A particular\nweight vector, V, then corresponds to a point in ( n+ 1)-dimensional weight\nspace. Now, for any pattern vector, Yi, consider the locus of all points in\nweight space corresponding to weight vectors yielding YiV = 0. This locus is\na hyperplane passing through the origin of the ( n+ 1)-dimensional space. Each\npattern vector will have such a hyperplane corresponding to it. Weight points\nin one of the half-spaces de\ufb01ned by this hyperplane will cause the corresponding\npattern to yield a dot product less than 0, and weight points in the other half-\nspace will cause the corresponding pattern to yield a dot product greater than\n0.\nWe show a schematic representation of such a weight space in Fig. 4.5.\nThere are four pattern hyperplanes, 1, 2, 3, 4 , corresponding to patterns Y1,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 49, 'page_label': '50'}, page_content='4.1. THRESHOLD LOGIC UNITS 41\nY2, Y3, Y4, respectively, and we indicate by an arrow the half-space for each\nin which weight vectors give dot products greater than 0. Suppose we wanted\nweight values that would give positive responses for patterns Y1, Y3, and Y4,\nand a negative response for pattern Y2. The weight point, V, indicated in the\n\ufb01gure is one such set of weight values.\n23\n4\n1\nV\nFigure 4.5: Weight Space\nThe question of whether or not there exists a weight vector that gives desired\nresponses for a given set of patterns can be given a geometric interpretation. To\ndo so involves reversing the polarity of those hyperplanes corresponding to\npatterns for which a negative response is desired. If we do that for our example\nabove, we get the weight space diagram shown in Fig. 4.6.\n23\n4\n1\nV\n0\n1\n1\n23\n2\n3\n4\nFigure 4.6: Solution Region in Weight Space'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 50, 'page_label': '51'}, page_content='42 CHAPTER 4. NEURAL NETWORKS\nIf a weight vector exists that correctly classi\ufb01es a set of patterns, then the\nhalf-spaces de\ufb01ned by the correct responses for these patterns will have a non-\nempty intersection, called the solution region. The solution region will be a\nhyper-wedge region whose vertex is at the origin of weight space and whose\ncross-section increases with increasing distance from the origin. This region\nis shown shaded in Fig. 4.6. (The boxed numbers show, for later purposes,\nthe number of errors made by weight vectors in each of the regions.) The\n\ufb01xed-increment error-correction procedure changes a weight vector by moving it\nnormal to any pattern hyperplane for which that weight vector gives an incorrect\nresponse. Suppose in our example that we present the patterns in the sequence\nY1, Y2, Y3, Y4, and start the process with a weight point V1, as shown in Fig.\n4.7. Starting at V1, we see that it gives an incorrect response for pattern Y1, so\nwe move V1 to V2 in a direction normal to plane 1. (That is what adding Y1 to\nV1 does.) Y2 gives an incorrect response for pattern Y2, and so on. Ultimately,\nthe responses are only incorrect for planes bounding the solution region. Some\nof the subsequent corrections may overshoot the solution region, but eventually\nwe work our way out far enough in the solution region that corrections (for\na \ufb01xed increment size) take us within it. The proofs for convergence of the\n\ufb01xed-increment rule make this intuitive argument precise.\n23\n4\n1\nV\nV1\nV2\nV3\nV4\nV5\nV6\nFigure 4.7: Moving Into the Solution Region\n4.1.5 The Widrow-Ho\ufb00 Procedure\nThe Widrow-Ho\ufb00 procedure (also called the LMS or the delta procedure) at-\ntempts to \ufb01nd weights that minimize a squared-error function between the pat-\ntern labels and the dot product computed by a TLU. For this purpose, the\npattern labels are assumed to be either +1 or \u22121 (instead of 1 or 0). The'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 51, 'page_label': '52'}, page_content='4.1. THRESHOLD LOGIC UNITS 43\nsquared error for a pattern, Xi, with label di (for desired output) is:\n\u03b5i = (di \u2212\nn+1\u2211\nj=1\nxijwj)2\nwhere xij is the j-th component of Xi. The total squared error (over all patterns\nin a training set, \u039e, containing m patterns) is then:\n\u03b5=\nm\u2211\ni=1\n(di \u2212\nn+1\u2211\nj=1\nxijwj)2\nWe want to choose the weightswj to minimize this squared error. One way to\n\ufb01nd such a set of weights is to start with an arbitrary weight vector and move it\nalong the negative gradient of\u03b5as a function of the weights. Since \u03b5is quadratic\nin the wj, we know that it has a global minimum, and thus this steepest descent\nprocedure is guaranteed to \ufb01nd the minimum. Each component of the gradient\nis the partial derivative of \u03b5 with respect to one of the weights. One problem\nwith taking the partial derivative of \u03b5is that \u03b5depends on all the input vectors\nin \u039e. Often, it is preferable to use an incremental procedure in which we try the\nTLU on just one element, Xi, of \u039e at a time, compute the gradient of the single-\npattern squared error, \u03b5i, make the appropriate adjustment to the weights, and\nthen try another member of \u039e. Of course, the results of the incremental version\ncan only approximate those of the batch one, but the approximation is usually\nquite e\ufb00ective. We will be describing the incremental version here.\nThe j-th component of the gradient of the single-pattern error is:\n\u2202\u03b5i\n\u2202wj\n= \u22122(di \u2212\nn+1\u2211\nj=1\nxijwj)xij\nAn adjustment in the direction of the negative gradient would then change each\nweight as follows:\nwj \u2190\u2212wj + ci(di \u2212fi)xij\nwhere fi = \u2211n+1\nj=1 xijwj, and ci governs the size of the adjustment. The entire\nweight vector (in augmented, or V, notation) is thus adjusted according to the\nfollowing rule:\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere, as before, Yi is the i-th augmented pattern vector.\nThe Widrow-Ho\ufb00 procedure makes adjustments to the weight vector when-\never the dot product itself, YiV, does not equal the speci\ufb01ed desired target'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 52, 'page_label': '53'}, page_content='44 CHAPTER 4. NEURAL NETWORKS\nvalue, di (which is either 1 or \u22121). The learning-rate factor, ci, might de-\ncrease with time toward 0 to achieve asymptotic convergence. The Widrow-\nHo\ufb00 formula for changing the weight vector has the same form as the standard\n\ufb01xed-increment error-correction formula. The only di\ufb00erence is that fi is the\nthresholded response of the TLU in the error-correction case while it is the dot\nproduct itself for the Widrow-Ho\ufb00 procedure.\nFinding weight values that give the desired dot products corresponds to solv-\ning a set of linear equalities, and the Widrow-Ho\ufb00 procedure can be interpreted\nas a descent procedure that attempts to minimize the mean-squared-error be-\ntween the actual and desired values of the dot product. (For more on Widrow-\nHo\ufb00 and other related procedures, see [Duda & Hart, 1973, pp. 151\ufb00].)Examples of training curves for\nTLUs; performance on training\nset; performance on test set;\ncumulative number of corrections. 4.1.6 Training a TLU on Non-Linearly-Separable Training\nSets\nWhen the training set is not linearly separable (perhaps because of noise or\nperhaps inherently), it may still be desired to \ufb01nd a best separating hy-\nperplane. Typically, the error-correction procedures will not do well on non-\nlinearly-separable training sets because they will continue to attempt to correct\ninevitable errors, and the hyperplane will never settle into an acceptable place.\nSeveral methods have been proposed to deal with this case. First, we might\nuse the Widrow-Ho\ufb00 procedure, which (although it will not converge to zero\nerror on non-linearly separable problems) will give us a weight vector that min-\nimizes the mean-squared-error. A mean-squared-error criterion often gives un-\nsatisfactory results, however, because it prefers many small errors to a few large\nones. As an alternative, error correction with a continuous decrease toward zero\nof the value of the learning rate constant,c, will result in ever decreasing changes\nto the hyperplane. Duda [Duda, 1966] has suggested keeping track of the average\nvalue of the weight vector during error correction and using this average to give a\nseparating hyperplane that performs reasonably well on non-linearly-separable\nproblems. Gallant [Gallant, 1986] proposed what he called the pocket algo-\nrithm. As described in [Hertz, Krogh, & Palmer, 1991, p. 160]:\n. . . the pocket algorithm . . . consists simply in storing (or putting\nin your pocket) the set of weights which has had the longest un-\nmodi\ufb01ed run of successes so far. The algorithm is stopped after some\nchosen time t . . .\nAfter stopping, the weights in the pocket are used as a set that should give a\nsmall number of errors on the training set. Error-correction proceeds as usual\nwith the ordinary set of weights.Also see methods proposed by\n[John, 1995] and by\n[Marchand & Golea, 1993]. The\nlatter is claimed to outperform the\npocket algorithm. 4.2 Linear Machines\nThe natural generalization of a (two-category) TLU to an R-category classi\ufb01er\nis the structure, shown in Fig. 4.8, called a linear machine. Here, to use more'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 53, 'page_label': '54'}, page_content='4.2. LINEAR MACHINES 45\nfamiliar notation, the Ws and X are meant to be augmented vectors (with an\n(n+1)-st component). Such a structure is also sometimes called a competitive\nnet or a winner-take-all net. The output of the linear machine is one of\nthe numbers, {1,...,R }, corresponding to which dot product is largest. Note\nthat when R = 2, the linear machine reduces to a TLU with weight vector\nW = (W1 \u2212W2).\nX\nW1\nWR\n. . .\nY\nY\nARGMAX\nW1.X\nWR.X\nFigure 4.8: A Linear Machine\nThe diagram in Fig. 4.9 shows the character of the regions in a 2-dimensional\nspace created by a linear machine for R = 5. In n dimensions, every pair of\nregions is either separated by a section of a hyperplane or is non-adjacent.\nR 1\nR 3\nR 4\nR 5\nX.W4  * X.Wi for i & 4\nR 2\nIn this region:\nFigure 4.9: Regions For a Linear Machine\nTo train a linear machine, there is a straightforward generalization of the\n2-category error-correction rule. Assemble the patterns in the training set into\na sequence as before.\na. If the machine classi\ufb01es a pattern correctly, no change is made to any of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 54, 'page_label': '55'}, page_content='46 CHAPTER 4. NEURAL NETWORKS\nthe weight vectors.\nb. If the machine mistakenly classi\ufb01es a category u pattern, Xi, in category\nv (u\u0338= v), then:\nWu \u2190\u2212Wu + ciXi\nand\nWv \u2190\u2212Wv \u2212ciXi\nand all other weight vectors are not changed.\nThis correction increases the value of the u-th dot product and decreases the\nvalue of the v-th dot product. Just as in the 2-category \ufb01xed increment proce-\ndure, this procedure is guaranteed to terminate, for constant ci, if there exists\nweight vectors that make correct separations of the training set. Note that when\nR= 2, this procedure reduces to the ordinary TLU error-correction procedure.\nA proof that this procedure terminates is given in [Nilsson, 1990, pp. 88-90]\nand in [Duda & Hart, 1973, pp. 174-177].\n4.3 Networks of TLUs\n4.3.1 Motivation and Examples\nLayered Networks\nTo classify correctly all of the patterns in non-linearly-separable training sets re-\nquires separating surfaces more complex than hyperplanes. One way to achieve\nmore complex surfaces is with networks of TLUs. Consider, for example, the 2-\ndimensional, even parity function, f = x1x2 + x1 x2. No single line through the\n2-dimensional square can separate the vertices (1,1) and (0,0) from the vertices\n(1,0) and (0,1)the function is not linearly separable and thus cannot be im-\nplemented by a single TLU. But, the network of three TLUs shown in Fig. 4.10\ndoes implement this function. In the \ufb01gure, we show the weight values along\ninput lines to each TLU and the threshold value inside the circle representing\nthe TLU.\nThe function implemented by a network of TLUs depends on its topology\nas well as on the weights of the individual TLUs. Feedforward networks have\nno cycles; in a feedforward network no TLUs input depends (through zero\nor more intermediate TLUs) on that TLUs output. (Networks that are not\nfeedforward are calledrecurrentnetworks). If the TLUs of a feedforward network\nare arranged in layers, with the elements of layer j receiving inputs only from\nTLUs in layer j \u22121, then we say that the network is a layered, feedforward'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 55, 'page_label': '56'}, page_content='4.3. NETWORKS OF TLUS 47\nf\nx1\nx2\n1.5\n-0.5\n0.5\n1\n1-1\n-1 1\n1\nFigure 4.10: A Network for the Even Parity Function\nnetwork. The network shown in Fig. 4.10 is a layered, feedforward network\nhaving two layers (of weights). (Some people count the layers of TLUs and\ninclude the inputs as a layer also; they would call this network a three-layer\nnetwork.) In general, a feedforward, layered network has the structure shown\nin Fig. 4.11. All of the TLUs except the output units are called hidden units\n(they are hidden from the output).\nX\nhidden units\noutput units\nFigure 4.11: A Layered, Feedforward Network\nImplementing DNF Functions by Two-Layer Networks\nWe have already de\ufb01nedk-term DNF functionsthey are DNF functions having\nk terms. A k-term DNF function can be implemented by a two-layer network\nwith k units in the hidden layerto implement the k termsand one output\nunit to implement the disjunction of these terms. Since any Boolean function\nhas a DNF form, any Boolean function can be implemented by some two-layer\nnetwork of TLUs. As an example, consider the function f = x1x2 + x2x3 +\nx1x3. The form of the network that implements this function is shown in Fig.\n4.12. (We leave it to the reader to calculate appropriate values of weights and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 56, 'page_label': '57'}, page_content='48 CHAPTER 4. NEURAL NETWORKS\nthresholds.) The 3-cube representation of the function is shown in Fig. 4.13.\nThe network of Fig. 4.12 can be designed so that each hidden unit implements\none of the planar boundaries shown in Fig. 4.13.\nx\nconjuncts\ndisjunct\nA Feedforward, 2-layer Network\nTLUs\ndisjunction\nof terms\nconjunctions\nof literals\n(terms)\nFigure 4.12: A Two-Layer Network\nx2\nx1\nx3\nf = x1x2 + x2x3 + x1x3\nFigure 4.13: Three Planes Implemented by the Hidden Units\nTo train a two-layer network that implements a k-term DNF function, we\n\ufb01rst note that the output unit implements a disjunction, so the weights in the\n\ufb01nal layer are \ufb01xed. The weights in the \ufb01rst layer (except for the threshold\nweights) can all have values of 1, \u22121, or 0. Later, we will present a training\nprocedure for this \ufb01rst layer of weights.Discuss half-space intersections,\nhalf-space unions, NP-hardness of\noptimal versions,\nsingle-side-error-hypeplane\nmethods, relation to AQ\nmethods.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 57, 'page_label': '58'}, page_content='4.3. NETWORKS OF TLUS 49\nImportant Comment About Layered Networks\nAdding additional layers cannot compensate for an inadequate \ufb01rst layer of\nTLUs. The \ufb01rst layer of TLUs partitions the feature space so that no two dif-\nferently labeled vectors are in the same region (that is, so that no two such\nvectors yield the same set of outputs of the \ufb01rst-layer units). If the \ufb01rst layer\ndoes not partition the feature space in this way, then regardless of what subse-\nquent layers do, the \ufb01nal outputs will not be consistent with the labeled training\nset. Add diagrams showing the\nnon-linear transformation\nperformed by a layered network.\n4.3.2 Madalines\nTwo-Category Networks\nAn interesting example of a layered, feedforward network is the two-layer one\nwhich has an odd number of hidden units, and a vote-taking TLU as the\noutput unit. Such a network was called a Madaline (for m any adalines by\nWidrow. Typically, the response of the vote taking unit is de\ufb01ned to be the\nresponse of the majority of the hidden units, although other output logics are\npossible. Ridgway [Ridgway, 1962] proposed the following error-correction rule\nfor adjusting the weights of the hidden units of a Madaline:\n If the Madaline correctly classi\ufb01es a pattern, Xi, no corrections are made\nto any of the hidden units weight vectors,\n If the Madaline incorrectly classi\ufb01es a pattern, Xi, then determine the\nminimum number of hidden units whose responses need to be changed\n(from 0 to 1 or from 1 to 0depending on the type of error) in order that\nthe Madaline would correctly classify Xi. Suppose that minimum number\nis ki. Of those hidden units voting incorrectly, change the weight vectors\nof those ki of them whose dot products are closest to 0 by using the error\ncorrection rule:\nW \u2190\u2212W + ci(di \u2212fi)Xi\nwhere di is the desired response of the hidden unit (0 or 1) and fi is the\nactual response (0 or 1). (We assume augmented vectors here even though\nwe are using X, W notation.)\nThat is, we perform error-correction on just enough hidden units to correct\nthe vote to a majority voting correctly, and we change those that are easiest to\nchange. There are example problems in which even though a set of weight values\nexists for a given Madaline structure such that it could classify all members of\na training set correctly, this procedure will fail to \ufb01nd them. Nevertheless, the\nprocedure works e\ufb00ectively in most experiments with it.\nWe leave it to the reader to think about how this training procedure could\nbe modi\ufb01ed if the output TLU implemented an or function (or an and function).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 58, 'page_label': '59'}, page_content='50 CHAPTER 4. NEURAL NETWORKS\nR-Category Madalines and Error-Correcting Output Codes\nIf there are k hidden units ( k > 1) in a two-layer network, their responses\ncorrespond to vertices of ak-dimensional hypercube. The ordinary two-category\nMadaline identi\ufb01es two special points in this space, namely the vertex consisting\nof k 1s and the vertex consisting of k 0s. The Madalines response is 1 if the\npoint in hidden-unit-space is closer to the all 1s vertex than it is to the all\n0s vertex. We could design an R-category Madaline by identifying R vertices\nin hidden-unit space and then classifying a pattern according to which of these\nvertices the hidden-unit response is closest to. A machine using that idea was\nimplemented in the early 1960s at SRI [Brain, et al., 1962]. It used the fact\nthat the 2p so-called maximal-length shift-register sequences[Peterson, 1961, pp.\n147\ufb00] in a (2p\u22121)-dimensional Boolean space are mutually equidistant (for any\ninteger p). For similar, more recent work see [Dietterich & Bakiri, 1991].\n4.3.3 Piecewise Linear Machines\nA two-category training set is linearly separable if there exists a threshold func-\ntion that correctly classi\ufb01es all members of the training set. Similarly, we can\nsay that an R-category training set is linearly separable if there exists a linear\nmachine that correctly classi\ufb01es all members of the training set. When an R-\ncategory problem is not linearly separable, we need a more powerful classi\ufb01er.\nA candidate is a structure called a piecewise linear (PWL) machine illustrated\nin Fig. 4.14.\nX\nW1\nW1\n. . .\nY\nY\nMAX\n. . .\nY\nY\nMAX\n. . .\nWR\nWR\nARG\nMAX\n1\nR\n1\nN1\n1\nNR\nFigure 4.14: A Piecewise Linear Machine'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 59, 'page_label': '60'}, page_content='4.3. NETWORKS OF TLUS 51\nThe PWL machine groups its weighted summing units into R banks corre-\nsponding to the R categories. An input vector X is assigned to that category\ncorresponding to the bank with the largest weighted sum. We can use an error-\ncorrection training algorithm similar to that used for a linear machine. If a\npattern is classi\ufb01ed incorrectly, we subtract (a constant times) the pattern vec-\ntor from the weight vector producing the largest dot product (it was incorrectly\nthe largest) and add (a constant times) the pattern vector to that weight vector\nin the correct bank of weight vectors whose dot product is locally largest in\nthat bank. (Again, we use augmented vectors here.) Unfortunately, there are\nexample training sets that are separable by a given PWL machine structure\nbut for which this error-correction training method fails to \ufb01nd a solution. The\nmethod does appear to work well in some situations [Duda & Fossum, 1966], al-\nthough [Nilsson, 1965, page 89] observed that it is probably not a very e\ufb00ective\nmethod for training PWL machines having more than three [weight vectors] in\neach bank.\n4.3.4 Cascade Networks\nAnother interesting class of feedforward networks is that in which all of the TLUs\nare ordered and each TLU receives inputs from all of the pattern components\nand from all TLUs lower in the ordering. Such a network is called a cascade\nnetwork. An example is shown in Fig. 4.15 in which the TLUs are labeled by\nthe linearly separable functions (of their inputs) that they implement. Each\nTLU in the network implements a set of 2 k parallel hyperplanes, where k is\nthe number of TLUs from which it receives inputs. (Each of the k preceding\nTLUs can have an output of 1 or 0; thats 2 k di\ufb00erent combinationsresulting\nin 2k di\ufb00erent positions for the parallel hyperplanes.) We show a 3-dimensional\nsketch for a network of two TLUs in Fig. 4.16. The reader might consider how\nthe n-dimensional parity function might be implemented by a cascade network\nhaving log2 n TLUs.\nx\nL1\nL2\noutput\nL3\nFigure 4.15: A Cascade Network'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 60, 'page_label': '61'}, page_content='52 CHAPTER 4. NEURAL NETWORKS\nL1\nL2\nL2\nFigure 4.16: Planes Implemented by a Cascade Network with Two TLUs\nCascade networks might be trained by \ufb01rst training L1 to do as good a job\nas possible at separating all the training patterns (perhaps by using the pocket\nalgorithm, for example), then training L2 (including the weight from L1 to L2)\nalso to do as good a job as possible at separating all the training patterns,\nand so on until the resulting network classi\ufb01es the patterns in the training set\nsatisfactorily.Also mention the\ncascade-correlation method of\n[Fahlman & Lebiere, 1990].\n4.4 Training Feedforward Networks by Back-\npropagation\n4.4.1 Notation\nThe general problem of training a network of TLUs is di\ufb03cult. Consider, for\nexample, the layered, feedforward network of Fig. 4.11. If such a network makes\nan error on a pattern, there are usually several di\ufb00erent ways in which the error\ncan be corrected. It is di\ufb03cult to assign blame for the error to any particular\nTLU in the network. Intuitively, one looks for weight-adjusting procedures that\nmove the network in the correct direction (relative to the error) by making\nminimal changes. In this spirit, the Widrow-Ho\ufb00 method of gradient descent\nhas been generalized to deal with multilayer networks.\nIn explaining this generalization, we use Fig. 4.17 to introduce some nota-\ntion. This network has only one output unit, but, of course, it is possible to have\nseveral TLUs in the output layereach implementing a di\ufb00erent function. Each\nof the layers of TLUs will have outputs that we take to be the components of\nvectors, just as the input features are components of an input vector. The j-th\nlayer of TLUs (1 \u2264j <k) will have as their outputs the vector X(j). The input\nfeature vector is denoted by X(0), and the \ufb01nal output (of the k-th layer TLU)\nis f. Each TLU in each layer has a weight vector (connecting it to its inputs)\nand a threshold; the i-th TLU in the j-th layer has a weight vector denoted by\nW(j)\ni . (We will assume that the threshold weight is the last component of\nthe associated weight vector; we might have used V notation instead to include'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 61, 'page_label': '62'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION53\nthis threshold component, but we have chosen here to use the familiar X,W\nnotation, assuming that these vectors are augmented as appropriate.) We\ndenote the weighted sum input to the i-th threshold unit in the j-th layer by\ns(j)\ni . (That is, s(j)\ni = X(j\u22121)W(j)\ni .) The number of TLUs in the j-th layer is\ngiven by mj. The vector W(j)\ni has components w(j)\nl,i for l= 1,...,m (j\u22121) + 1.\nX(0)\n. . .\n. . .\n. . .\n. . .\nWi(1)\nW(k)\nX(1)\nm1 TLUs\n. . .\nWi(j)\n. . .\nX(j)\n. . .\nWi(k-1)\nX(k-1)\nmj TLUs m(k-1) TLUs\nwli(j)\nwl(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . .\nf\nsi(1) si(j) si(k-1)\ns(k)\nFigure 4.17: A k-layer Network\n4.4.2 The Backpropagation Method\nA gradient descent method, similar to that used in the Widrow Ho\ufb00 method,\nhas been proposed by various authors for training a multi-layer, feedforward\nnetwork. As before, we de\ufb01ne an error function on the \ufb01nal output of the\nnetwork and we adjust each weight in the network so as to minimize the error.\nIf we have a desired response, di, for the i-th input vector, Xi, in the training\nset, \u039e, we can compute the squared error over the entire training set to be:\n\u03b5=\n\u2211\nXi \u03f5 \u039e\n(di \u2212fi)2\nwhere fi is the actual response of the network for input Xi. To do gradient\ndescent on this squared error, we adjust each weight in the network by an\namount proportional to the negative of the partial derivative of \u03b5 with respect\nto that weight. Again, we use a single-pattern error function so that we can\nuse an incremental weight adjustment procedure. The squared error for a single\ninput vector, X, evoking an output of f when the desired output is d is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 62, 'page_label': '63'}, page_content='54 CHAPTER 4. NEURAL NETWORKS\n\u03b5= (d\u2212f)2\nIt is convenient to take the partial derivatives of\u03b5with respect to the various\nweights in groups corresponding to the weight vectors. We de\ufb01ne a partial\nderivative of a quantity \u03c6, say, with respect to a weight vector, W(j)\ni , thus:\n\u2202\u03c6\n\u2202W(j)\ni\ndef\n=\n[\n\u2202\u03c6\n\u2202w(j)\n1i\n,..., \u2202\u03c6\n\u2202w(j)\nli\n,..., \u2202\u03c6\n\u2202w(j)\nmj\u22121+1,i\n]\nwhere w(j)\nli is the l-th component of W(j)\ni . This vector partial derivative of \u03c6is\ncalled the gradient of \u03c6 with respect to W and is sometimes denoted by \u2207W\u03c6.\nSince \u03b5s dependence on W(j)\ni is entirely through s(j)\ni , we can use the chain\nrule to write:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\n\u2202s(j)\ni\n\u2202W(j)\ni\nBecause s(j)\ni = X(j\u22121)W(j)\ni ,\n\u2202s(j)\ni\n\u2202W(j)\ni\n= X(j\u22121). Substituting yields:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\nX(j\u22121)\nNote that \u2202\u03b5\n\u2202s(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\n. Thus,\n\u2202\u03b5\n\u2202W(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\nX(j\u22121)\nThe quantity (d\u2212f) \u2202f\n\u2202s(j)\ni\nplays an important role in our calculations; we shall\ndenote it by \u03b4(j)\ni . Each of the \u03b4(j)\ni s tells us how sensitive the squared error of\nthe network output is to changes in the input to each threshold function. Since\nwe will be changing weight vectors in directions along their negative gradient,\nour fundamental rule for weight changes throughout the network will be:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nwhere c(j)\ni is the learning rate constant for this weight vector. (Usually, the\nlearning rate constants for all weight vectors in the network are the same.) We\nsee that this rule is quite similar to that used in the error correction procedure'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 63, 'page_label': '64'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION55\nfor a single TLU. A weight vector is changed by the addition of a constant times\nits vector of (unweighted) inputs.\nNow, we must turn our attention to the calculation of the \u03b4(j)\ni s. Using the\nde\ufb01nition, we have:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nWe have a problem, however, in attempting to carry out the partial deriva-\ntives of f with respect to the ss. The network output, f, is not continuously\ndi\ufb00erentiable with respect to the ss because of the presence of the threshold\nfunctions. Most small changes in these sums do not change f at all, and when\nf does change, it changes abruptly from 1 to 0 or vice versa.\nA way around this di\ufb03culty was proposed by Werbos [Werbos, 1974] and\n(perhaps independently) pursued by several other researchers, for example\n[Rumelhart, Hinton, & Williams, 1986]. The trick involves replacing all the\nthreshold functions by di\ufb00erentiable functions called sigmoids.1 The output\nof a sigmoid function, superimposed on that of a threshold function, is shown\nin Fig. 4.18. Usually, the sigmoid function used is f(s) = 1\n1+e\u2212s , where s is\nthe input and f is the output.\nsigmoid\nthreshold function\nf (s)\ns\nf (s) = 1/[1 + e<s]\nFigure 4.18: A Sigmoid Function\n1[Russell & Norvig 1995, page 595] attributes the use of this idea to [Bryson & Ho 1969].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 64, 'page_label': '65'}, page_content='56 CHAPTER 4. NEURAL NETWORKS\nWe show the network containing sigmoid units in place of TLUs in Fig. 4.19.\nThe output of the i-th sigmoid unit in the j-th layer is denoted by f(j)\ni . (That\nis, f(j)\ni = 1\n1+e\u2212s(j)\ni\n.)\nX(0)\n. . .\n. . .\n. . .\n. . .\nWi(1)\nsi(1)\nW(k)\nX(1)\nfi(1)\nm1 sigmoids\n. . .\nWi(j) fi(j)\nsi(j)\n. . .\nX(j)\n. . .\nWi(k-1)\nfi(k-1)\nsi(k-1)\nf(k)\ns(k)\nX(k-1)\nmj sigmoids m(k-1) sigmoids\nwli(j)\nwl(k)\nbi(j)bi(1)\nbi(k-1)\nb(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . .\nFigure 4.19: A Network with Sigmoid Units\n4.4.3 Computing Weight Changes in the Final Layer\nWe \ufb01rst calculate\u03b4(k) in order to compute the weight change for the \ufb01nal sigmoid\nunit:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 65, 'page_label': '66'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION57\n\u03b4(k) = (d\u2212f(k))\u2202f(k)\n\u2202s(k)\nGiven the sigmoid function that we are using, namely f(s) = 1\n1+e\u2212s, we have\nthat \u2202f\n\u2202s = f(1 \u2212f). Substituting gives us:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nRewriting our general rule for weight vector changes, the weight vector in\nthe \ufb01nal layer is changed according to the rule:\nW(k) \u2190W(k) + c(k)\u03b4(k)X(k\u22121)\nwhere \u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nIt is interesting to compare backpropagation to the error-correction rule and\nto the Widrow-Ho\ufb00 rule. The backpropagation weight adjustment for the single\nelement in the \ufb01nal layer can be written as:\nW \u2190\u2212W + c(d\u2212f)f(1 \u2212f)X\nWritten in the same format, the error-correction rule is:\nW \u2190\u2212W + c(d\u2212f)X\nand the Widrow-Ho\ufb00 rule is:\nW \u2190\u2212W + c(d\u2212f)X\nThe only di\ufb00erence (except for the fact that f is not thresholded in Widrow-\nHo\ufb00) is the f(1 \u2212f) term due to the presence of the sigmoid function. With\nthe sigmoid function, f(1 \u2212f) can vary in value from 0 to 1. When f is 0,\nf(1 \u2212f) is also 0; when f is 1, f(1 \u2212f) is 0; f(1 \u2212f) obtains its maximum\nvalue of 1/4 when f is 1/2 (that is, when the input to the sigmoid is 0). The\nsigmoid function can be thought of as implementing a fuzzy hyperplane. For\na pattern far away from this fuzzy hyperplane, f(1 \u2212f) has value close to 0,\nand the backpropagation rule makes little or no change to the weight values\nregardless of the desired output. (Small changes in the weights will have little\ne\ufb00ect on the output for inputs far from the hyperplane.) Weight changes are\nonly made within the region of fuzz surrounding the hyperplane, and these\nchanges are in the direction of correcting the error, just as in the error-correction\nand Widrow-Ho\ufb00 rules.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 66, 'page_label': '67'}, page_content='58 CHAPTER 4. NEURAL NETWORKS\n4.4.4 Computing Changes to the Weights in Intermediate\nLayers\nUsing our expression for the \u03b4s, we can similarly compute how to change each\nof the weight vectors in the network. Recall:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nAgain we use a chain rule. The \ufb01nal output, f, depends on s(j)\ni through\neach of the summed inputs to the sigmoids in the ( j+ 1)-th layer. So:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\n= (d\u2212f)\n[\n\u2202f\n\u2202s(j+1)\n1\n\u2202s(j+1)\n1\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nmj+1\n\u2202s(j+1)\nmj+1\n\u2202s(j)\ni\n]\n=\nmj+1\u2211\nl=1\n(d\u2212f) \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\nIt remains to compute the\n\u2202s(j+1)\nl\n\u2202s(j)\ni\ns. To do that we \ufb01rst write:\ns(j+1)\nl = X(j)W(j+1)\nl\n=\nmj+1\u2211\n\u03bd=1\nf(j)\n\u03bd w(j+1)\n\u03bdl\nAnd then, since the weights do not depend on the ss:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\n\u2202\n[\u2211mj+1\n\u03bd=1 f(j)\n\u03bd w(j+1)\n\u03bdl\n]\n\u2202s(j)\ni\n=\nmj+1\u2211\n\u03bd=1\nw(j+1)\n\u03bdl\n\u2202f(j)\n\u03bd\n\u2202s(j)\ni\nNow, we note that \u2202f(j)\n\u03bd\n\u2202s(j)\ni\n= 0 unless \u03bd = i, in which case \u2202f(j)\n\u03bd\n\u2202s(j)\n\u03bd\n= f(j)\n\u03bd (1 \u2212f(j)\n\u03bd ).\nTherefore:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n= w(j+1)\nil f(j)\ni (1 \u2212f(j)\ni )'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 67, 'page_label': '68'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION59\nWe use this result in our expression for \u03b4(j)\ni to give:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nThe above equation is recursive in the \u03b4s. (It is interesting to note that\nthis expression is independent of the error function; the error function explicitly\na\ufb00ects only the computation of \u03b4(k).) Having computed the \u03b4(j+1)\ni s for layer\nj + 1, we can use this equation to compute the \u03b4(j)\ni s. The base case is \u03b4(k),\nwhich we have already computed:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nWe use this expression for the\u03b4s in our generic weight changing rule, namely:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nAlthough this rule appears complex, it has an intuitively reasonable explanation.\nThe quantity \u03b4(k) = (d\u2212f)f(1 \u2212f) controls the overall amount and sign of all\nweight adjustments in the network. (Adjustments diminish as the \ufb01nal output,\nf, approaches either 0 or 1, because they have vanishing e\ufb00ect on f then.) As\nthe recursion equation for the \u03b4s shows, the adjustments for the weights going\nin to a sigmoid unit in the j-th layer are proportional to the e\ufb00ect that such\nadjustments have on that sigmoid units output (its f(j)(1 \u2212f(j)) factor). They\nare also proportional to a kind of average e\ufb00ect that any change in the output\nof that sigmoid unit will have on the \ufb01nal output. This average e\ufb00ect depends\non the weights going out of the sigmoid unit in the j-th layer (small weights\nproduce little downstream e\ufb00ect) and the e\ufb00ects that changes in the outputs of\n(j+ 1)-th layer sigmoid units will have on the \ufb01nal output (as measured by the\n\u03b4(j+1)s). These calculations can be simply implemented by backpropagating\nthe \u03b4s through the weights in reverse direction (thus, the name backprop for\nthis algorithm).\n4.4.5 Variations on Backprop\n[To be written: problem of local minima, simulated annealing, momemtum\n(Plaut, et al., 1986, see [Hertz, Krogh, & Palmer, 1991]), quickprop, regulariza-\ntion methods]\nSimulated Annealing\nTo apply simulated annealing, the value of the learning rate constant is gradually\ndecreased with time. If we fall early into an error-function valley that is not\nvery deep (a local minimum), it typically will neither be very broad, and soon'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 68, 'page_label': '69'}, page_content='60 CHAPTER 4. NEURAL NETWORKS\na subsequent large correction will jostle us out of it. It is less likely that we will\nmove out of deep valleys, and at the end of the process (with very small values\nof the learning rate constant), we descend to its deepest point. The process\ngets its name by analogy with annealing in metallurgy, in which a materials\ntemperature is gradually decreased allowing its crystalline structure to reach a\nminimal energy state.\n4.4.6 An Application: Steering a Van\nA neural network system called ALVINN (Autonomous Land Vehicle in a Neural\nNetwork) has been trained to steer a Chevy van successfully on ordinary roads\nand highways at speeds of 55 mph [Pomerleau, 1991, Pomerleau, 1993]. The\ninput to the network is derived from a low-resolution (30 x 32) television image.\nThe TV camera is mounted on the van and looks at the road straight ahead.\nThis image is sampled and produces a stream of 960-dimensional input vectors\nto the neural network. The network is shown in Fig. 4.20.\n960 inputs\n30 x 32 retina\n. . .\n5 hidden\nunits connected\nto all 960 inputs\n30 output units\nconnected to all\nhidden units\n. . .\nsharp left\nsharp right\nstraight ahead\ncentroid\nof outputs\nsteers\nvehicle\nFigure 4.20: The ALVINN Network\nThe network has \ufb01ve hidden units in its \ufb01rst layer and 30 output units in the\nsecond layer; all are sigmoid units. The output units are arranged in a linear\norder and control the vans steering angle. If a unit near the top of the array\nof output units has a higher output than most of the other units, the van is\nsteered to the left; if a unit near the bottom of the array has a high output, the\nvan is steered to the right. The centroid of the responses of all of the output'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 69, 'page_label': '70'}, page_content='4.5. SYNERGIES BETWEEN NEURAL NETWORK AND KNOWLEDGE-BASED METHODS61\nunits is computed, and the vans steering angle is set at a corresponding value\nbetween hard left and hard right.\nThe system is trained by a modi\ufb01ed on-line training regime. A driver drives\nthe van, and his actual steering angles are taken as the correct labels for the\ncorresponding inputs. The network is trained incrementally by backprop to\nproduce the driver-speci\ufb01ed steering angles in response to each visual pattern\nas it occurs in real time while driving.\nThis simple procedure has been augmented to avoid two potential problems.\nFirst, since the driver is usually driving well, the network would never get any\nexperience with far-from-center vehicle positions and/or incorrect vehicle orien-\ntations. Also, on long, straight stretches of road, the network would be trained\nfor a long time only to produce straight-ahead steering angles; this training\nwould swamp out earlier training to follow a curved road. We wouldnt want\nto try to avoid these problems by instructing the driver to drive erratically\noccasionally, because the system would learn to mimic this erratic behavior.\nInstead, each original image is shifted and rotated in software to create 14\nadditional images in which the vehicle appears to be situated di\ufb00erently relative\nto the road. Using a model that tells the system what steering angle ought to\nbe used for each of these shifted images, given the driver-speci\ufb01ed steering angle\nfor the original image, the system constructs an additional 14 labeled training\npatterns to add to those encountered during ordinary driver training.\n4.5 Synergies Between Neural Network and\nKnowledge-Based Methods\nTo be written; discuss\nrule-generating procedures (such as\n[Towell & Shavlik, 1992]) and how\nexpert-provided rules can aid\nneural net training and vice-versa\n[Towell, Shavlik, & Noordweier, 1990].\n4.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 70, 'page_label': '71'}, page_content='62 CHAPTER 4. NEURAL NETWORKS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 71, 'page_label': '72'}, page_content='Chapter 5\nStatistical Learning\n5.1 Using Statistical Decision Theory\n5.1.1 Background and General Method\nSuppose the pattern vector, X, is a random variable whose probability distri-\nbution for category 1 is di\ufb00erent than it is for category 2. (The treatment given\nhere can easily be generalized to R-category problems.) Speci\ufb01cally, suppose we\nhave the two probability distributions (perhaps probability density functions),\np(X |1) and p(X |2). Given a pattern, X, we want to use statistical tech-\nniques to determine its categorythat is, to determine from which distribution\nit was drawn. These techniques are based on the idea of minimizing the ex-\npected value of a quantity similar to the error function we used in deriving the\nweight-changing rules for backprop.\nIn developing a decision method, it is necessary to know the relative serious-\nness of the two kinds of mistakes that might be made. (We might decide that a\npattern really in category 1 is in category 2, and vice versa.) We describe this\ninformation by a loss function, \u03bb(i|j), for i,j = 1,2. \u03bb(i|j) represents the loss\nincurred when we decide a pattern is in category i when really it is in category\nj. We assume here that \u03bb(1 |1) and \u03bb(2 |2) are both 0. For any given pattern,\nX, we want to decide its category in such a way that minimizes the expected\nvalue of this loss.\nGiven a pattern, X, if we decide category i, the expected value of the loss\nwill be:\nLX(i) = \u03bb(i|1)p(1 |X) + \u03bb(i|2)p(2 |X)\nwhere p(j |X) is the probability that given a pattern X, its category is j. Our\ndecision rule will be to decide that X belongs to category 1 if LX(1) \u2264LX(2),\nand to decide on category 2 otherwise.\n63'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 72, 'page_label': '73'}, page_content='64 CHAPTER 5. STATISTICAL LEARNING\nWe can use Bayes Rule to get expressions for p(j |X) in terms of p(X |j),\nwhich we assume to be known (or estimatible):\np(j |X) = p(X |j)p(j)\np(X)\nwhere p(j) is the (a priori) probability of category j (one category may be much\nmore probable than the other); and p(X) is the (a priori) probability of pattern\nX being the pattern we are asked to classify. Performing the substitutions given\nby Bayes Rule, our decision rule becomes:\nDecide category 1 i\ufb00:\n\u03bb(1 |1)p(X |1)p(1)\np(X) + \u03bb(1 |2)p(X |2)p(2)\np(X)\n\u2264\u03bb(2 |1)p(X |1)p(1)\np(X) + \u03bb(2 |2)p(X |2)p(2)\np(X)\nUsing the fact that \u03bb(i |i) = 0, and noticing that p(X) is common to both\nexpressions, we obtain,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nIf \u03bb(1 |2) = \u03bb(2 |1) and if p(1) = p(2), then the decision becomes particu-\nlarly simple:\nDecide category 1 i\ufb00:\np(X |2) \u2264p(X |1)\nSince p(X |j) is called the likelihood of j with respect to X, this simple decision\nrule implements what is called a maximum-likelihood decision. More generally,\nif we de\ufb01ne k(i|j) as \u03bb(i|j)p(j), then our decision rule is simply,\nDecide category1 i\ufb00:\nk(1 |2)p(X |2) \u2264k(2 |1)p(X |1)\nIn any case, we need to compare the (perhaps weighted) quantities p(X |i) for\ni= 1 and 2. The exact decision rule depends on the the probability distributions\nassumed. We will treat two interesting distributions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 73, 'page_label': '74'}, page_content='5.1. USING STATISTICAL DECISION THEORY 65\n5.1.2 Gaussian (or Normal) Distributions\nThe multivariate (n-dimensional) Gaussian distribution is given by the proba-\nbility density function:\np(X) = 1\n(2\u03c0)n/2|\u03a3|1/2 e\n\u2212(X\u2212M)t\u03a3\n\u22121\n(X\u2212M)\n2\nwhere nis the dimension of the column vector X, the column vector M is called\nthe mean vector, (X \u2212M)t is the transpose of the vector ( X \u2212M), \u03a3 is the\ncovariance matrix of the distribution (an n×n symmetric, positive de\ufb01nite\nmatrix), \u03a3\u22121 is the inverse of the covariance matrix, and |\u03a3|is the determinant\nof the covariance matrix.\nThe mean vector, M, with components ( m1,...,m n), is the expected value\nof X (using this distribution); that is, M = E[X]. The components of the\ncovariance matrix are given by:\n\u03c32\nij = E[(xi \u2212mi)(xj \u2212mj)]\nIn particular, \u03c32\nii is called the variance of xi.\nAlthough the formula appears complex, an intuitive idea for Gaussian dis-\ntributions can be given when n = 2. We show a two-dimensional Gaussian\ndistribution in Fig. 5.1. A three-dimensional plot of the distribution is shown\nat the top of the \ufb01gure, and contours of equal probability are shown at the bot-\ntom. In this case, the covariance matrix, \u03a3, is such that the elliptical contours\nof equal probability are skewed. If the covariance matrix were diagonal, that is\nif all o\ufb00-diagonal terms were 0, then the major axes of the elliptical contours\nwould be aligned with the coordinate axes. In general the principal axes are\ngiven by the eigenvectors of \u03a3. In any case, the equi-probability contours are\nall centered on the mean vector, M, which in our \ufb01gure happens to be at the\norigin. In general, the formula in the exponent in the Gaussian distribution\nis a positive de\ufb01nite quadratic form (that is, its value is always positive); thus\nequi-probability contours are hyper-ellipsoids in n-dimensional space.\nSuppose we now assume that the two classes of pattern vectors that we\nwant to distinguish are each distributed according to a Gaussian distribution\nbut with di\ufb00erent means and covariance matrices. That is, one class tends to\nhave patterns clustered around one point in the n-dimensional space, and the\nother class tends to have patterns clustered around another point. We show a\ntwo-dimensional instance of this problem in Fig. 5.2. (In that \ufb01gure, we have\nplotted the sum of the two distributions.) What decision rule should we use to\nseparate patterns into the two appropriate categories?\nSubstituting the Gaussian distributions into our maximum likelihood for-\nmula yields:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 74, 'page_label': '75'}, page_content='66 CHAPTER 5. STATISTICAL LEARNING\n-5\n0\n5\n-5\n0\n5\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n-5\n0\n5\n0\n25\n.5\n75\n1\n-6 -4 -2 0 2 4 6\n-6\n-4\n-2\n0\n2\n4\n6\nx1\nx2\np(x1,x2)\n2\n4\n6\n24 6\nx1\nx2\nFigure 5.1: The Two-Dimensional Gaussian Distribution\nDecide category 1 i\ufb00:\n1\n(2\u03c0)n/2|\u03a32|1/2 e\u22121/2(X\u2212M2)t\u03a3\n\u22121\n2 (X\u2212M2)\nis less than or equal to\n1\n(2\u03c0)n/2|\u03a31|1/2 e\u22121/2(X\u2212M1)t\u03a3\n\u22121\n1 (X\u2212M1)\nwhere the category 1 patterns are distributed with mean and covariance M1\nand \u03a31, respectively, and the category 2 patterns are distributed with mean\nand covariance M2 and \u03a32.\nThe result of the comparison isnt changed if we compare logarithms instead.\nAfter some manipulation, our decision rule is then:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 75, 'page_label': '76'}, page_content='5.1. USING STATISTICAL DECISION THEORY 67\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n25\n.5\n75\n1\nx1\nx2\np(x1,x2)\n-5 -2.5 0 2.5 5 7.5 10\n-5\n-2.5\n0\n2.5\n5\n7.5\n10\nFigure 5.2: The Sum of Two Gaussian Distributions\nDecide category 1 i\ufb00:\n(X \u2212M1)t\u03a3\u22121\n1 (X \u2212M1) <(X \u2212M2)t\u03a3\u22121\n2 (X \u2212M2) + B\nwhere B, a constant bias term, incorporates the logarithms of the fractions\npreceding the exponential, etc.\nWhen the quadratic forms are multiplied out and represented in terms of\nthe components xi, the decision rule involves a quadric surface (a hyperquadric)\nin n-dimensional space. The exact shape and position of this hyperquadric is\ndetermined by the means and the covariance matrices. The surface separates\nthe space into two parts, one of which contains points that will be assigned to\ncategory 1 and the other contains points that will be assigned to category 2.\nIt is interesting to look at a special case of this surface. If the covariance\nmatrices for each category are identical and diagonal, with all \u03c3ii equal to each\nother, then the contours of equal probability for each of the two distributions'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 76, 'page_label': '77'}, page_content='68 CHAPTER 5. STATISTICAL LEARNING\nare hyperspherical. The quadric forms then become (1 /|\u03a3|)(X\u2212Mi)t(X\u2212Mi),\nand the decision rule is:\nDecide category 1 i\ufb00:\n(X \u2212M1)t(X \u2212M1) <(X \u2212M2)t(X \u2212M2)\nMultiplying out yields:\nXX \u22122XM1 + M1M1 <XX \u22122XM2 + M2M2\nor \ufb01nally,\nDecide category 1 i\ufb00:\nXM1 \u2265XM2 + Constant\nor\nX(M1 \u2212M2) \u2265Constant\nwhere the constant depends on the lengths of the mean vectors.\nWe see that the optimal decision surface in this special case is a hyperplane.\nIn fact, the hyperplane is perpendicular to the line joining the two means. The\nweights in a TLU implementation are equal to the di\ufb00erence in the mean vectors.\nIf the parameters ( Mi,\u03a3i) of the probability distributions of the categories\nare not known, there are various techniques for estimating them, and then using\nthose estimates in the decision rule. For example, if there are su\ufb03cient training\npatterns, one can use sample means and sample covariance matrices. (Caution:\nthe sample covariance matrix will be singular if the training patterns happen to\nlie on a subspace of the whole n-dimensional spaceas they certainly will, for\nexample, if the number of training patterns is less than n.)\n5.1.3 Conditionally Independent Binary Components\nSuppose the vector X is a random variable having binary (0,1) components.\nWe continue to denote the two probability distributions by p(X |1) and p(X |\n2). Further suppose that the components of these vectors are conditionally\nindependent given the category. By conditional independence in this case, we\nmean that the formulas for the distribution can be expanded as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 77, 'page_label': '78'}, page_content='5.1. USING STATISTICAL DECISION THEORY 69\np(X |i) = p(x1 |i)p(x2 |i) ···p(xn |i)\nfor i= 1,2\nRecall the minimum-average-loss decision rule,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nAssuming conditional independence of the components and that \u03bb(1 |2) = \u03bb(2 |\n1), we obtain,\nDecide category 1 i\ufb00:\np(1)p(x1 |1)p(x2 |1) ···p(xn |1) \u2265p(x1 |2)p(x2 |2) ···p(xn |2)p(2)\nor i\ufb00:\np(x1 |1)p(x2 |1) ...p (xn |1)\np(x1 |2)p(x2 |2) ...p (xn |2) \u2265p(2)\np(1)\nor i\ufb00:\nlog p(x1 |1)\np(x1 |2) + log p(x2 |1)\np(x2 |2) + ··· + log p(xn |1)\np(xn |2) + log p(1)\np(2) \u22650\nLet us de\ufb01ne values of the components of the distribution for speci\ufb01c values of\ntheir arguments, xi :\np(xi = 1 |1) = pi\np(xi = 0 |1) = 1 \u2212pi\np(xi = 1 |2) = qi\np(xi = 0 |2) = 1 \u2212qi\nNow, we note that since xi can only assume the values of 1 or 0:\nlog p(xi |1)\np(xi |2) = xilog pi\nqi\n+ (1 \u2212xi) log (1 \u2212pi)\n(1 \u2212qi)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 78, 'page_label': '79'}, page_content='70 CHAPTER 5. STATISTICAL LEARNING\n= xilog pi(1 \u2212qi)\nqi(1 \u2212pi) + log (1 \u2212pi)\n(1 \u2212qi)\nSubstituting these expressions into our decision rule yields:\nDecide category 1 i\ufb00:\nn\u2211\ni=1\nxilog pi(1 \u2212qi)\nqi(1 \u2212pi) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi) + log p(1)\np(2) \u22650\nWe see that we can achieve this decision with a TLU with weight values as\nfollows:\nwi = log pi(1 \u2212qi)\nqi(1 \u2212pi)\nfor i= 1,...,n , and\nwn+1 = log p(1)\n1 \u2212p(1) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi)\nIf we do not know the pi,qi and p(1), we can use a sample of labeled training\npatterns to estimate these parameters.\n5.2 Learning Belief Networks\nTo be added.\n5.3 Nearest-Neighbor Methods\nAnother class of methods can be related to the statistical ones. These are called\nnearest-neighbor methods or, sometimes, memory-based methods. (A collection\nof papers on this subject is in [Dasarathy, 1991].) Given a training set \u039e of m\nlabeled patterns, a nearest-neighbor procedure decides that some new pattern,\nX, belongs to the same category as do its closest neighbors in \u039e. More precisely,\na k-nearest-neighbor method assigns a new pattern,X, to that category to which\nthe plurality of its k closest neighbors belong. Using relatively large values of\nk decreases the chance that the decision will be unduly in\ufb02uenced by a noisy\ntraining pattern close to X. But large values of k also reduce the acuity of the\nmethod. The k-nearest-neighbor method can be thought of as estimating the\nvalues of the probabilities of the classes given X. Of course the denser are the\npoints around X, and the larger the value of k, the better the estimate.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 79, 'page_label': '80'}, page_content='5.3. NEAREST-NEIGHBOR METHODS 71\nThe distance metric used in nearest-neighbor methods (for numerical at-\ntributes) can be simple Euclidean distance. That is, the distance between two\npatterns (x11,x12,...,x 1n) and (x21,x22,...,x 2n) is\n\u221a\u2211n\nj=1(x1j \u2212x2j)2. This\ndistance measure is often modi\ufb01ed by scaling the features so that the spread of\nattribute values along each dimension is approximately the same. In that case,\nthe distance between the two vectors would be\n\u221a\u2211n\nj=1 a2\nj(x1j \u2212x2j)2, where\naj is the scale factor for dimension j.\nAn example of a nearest-neighbor decision problem is shown in Fig. 5.3. In\nthe \ufb01gure the class of a training pattern is indicated by the number next to it.\nk = 8\nX (a pattern to be classified)\n1\n1\n1 1\n1\n11\n1\n2\n1\n2\n2\n2\n2\n2\n2 2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\ntraining patternclass of training pattern\nfour patterns of category 1\ntwo patterns of category 2\ntwo patterns of category 3\nplurality are in category 1, so\ndecide X is in category 1\nFigure 5.3: An 8-Nearest-Neighbor Decision\nSee [Baum, 1994] for theoretical\nanalysis of error rate as a function\nof the number of training patterns\nfor the case in which points are\nrandomly distributed on the surface\nof a unit sphere and underlying\nfunction is linearly separable.\nNearest-neighbor methods are memory intensive because a large number of\ntraining patterns must be stored to achieve good generalization. Since memory\ncost is now reasonably low, the method and its derivatives have seen several\npractical applications. (See, for example, [Moore, 1992, Moore, et al., 1994].\nAlso, the distance calculations required to \ufb01nd nearest neighbors can often be\ne\ufb03ciently computed by kd-tree methods [Friedman, et al., 1977].\nA theorem by Cover and Hart [Cover & Hart, 1967] relates the performance\nof the 1-nearest-neighbor method to the performance of a minimum-probability-\nof-error classi\ufb01er. As mentioned earlier, the minimum-probability-of-error clas-\nsi\ufb01er would assign a new patternX to that category that maximizedp(i)p(X |i),\nwhere p(i) is the a priori probability of categoryi, and p(X |i) is the probability\n(or probability density function) of X given that X belongs to category i, for\ncategories i= 1,...,R . Suppose the probability of error in classifying patterns\nof such a minimum-probability-of-error classi\ufb01er is \u03b5. The Cover-Hart theo-\nrem states that under very mild conditions (having to do with the smoothness'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 80, 'page_label': '81'}, page_content='72 CHAPTER 5. STATISTICAL LEARNING\nof probability density functions) the probability of error, \u03b5nn, of a 1-nearest-\nneighbor classi\ufb01er is bounded by:\n\u03b5\u2264\u03b5nn \u2264\u03b5\n(\n2 \u2212\u03b5 R\nR\u22121\n)\n\u22642\u03b5\nwhere R is the number of categories.Also see [Aha, 1991].\n5.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 81, 'page_label': '82'}, page_content='Chapter 6\nDecision Trees\n6.1 De\ufb01nitions\nA decision tree (generally de\ufb01ned) is a tree whose internal nodes are tests (on\ninput patterns) and whose leaf nodes are categories (of patterns). We show an\nexample in Fig. 6.1. A decision tree assigns a class number (or output) to an\ninput pattern by \ufb01ltering the pattern down through the tests in the tree. Each\ntest has mutually exclusive and exhaustive outcomes. For example, test T2 in\nthe tree of Fig. 6.1 has three outcomes; the left-most one assigns the input\npattern to class 3, the middle one sends the input pattern down to test T4, and\nthe right-most one assigns the pattern to class 1. We follow the usual convention\nof depicting the leaf nodes by the class number.1 Note that in discussing decision\ntrees we are not limited to implementing Boolean functionsthey are useful for\ngeneral, categorically valued functions.\nThere are several dimensions along which decision trees might di\ufb00er:\na. The tests might be multivariate (testing on several features of the input\nat once) or univariate (testing on only one of the features).\nb. The tests might have two outcomes or more than two. (If all of the tests\nhave two outcomes, we have a binary decision tree.)\nc. The features or attributes might be categorical or numeric. (Binary-valued\nones can be regarded as either.)\n1One of the researchers who has done a lot of work on learning decision trees is Ross\nQuinlan. Quinlan distinguishes between classes and categories. He calls the subsets of patterns\nthat \ufb01lter down to each tip categories and subsets of patterns having the same label classes.\nIn Quinlans terminology, our example tree has nine categories and three classes. We will not\nmake this distinction, however, but will use the words category and class interchangeably\nto refer to what Quinlan calls class.\n73'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 82, 'page_label': '83'}, page_content='74 CHAPTER 6. DECISION TREES\nT1\nT2 T3\nT4\nT4\nT4\n3\n1\n3 2\n1 2 3\n2 1\nFigure 6.1: A Decision Tree\nd. We might have two classes or more than two. If we have two classes and\nbinary inputs, the tree implements a Boolean function, and is called a\nBoolean decision tree.\nIt is straightforward to represent the function implemented by a univariate\nBoolean decision tree in DNF form. The DNF form implemented by such a tree\ncan be obtained by tracing down each path leading to a tip node corresponding\nto an output value of 1, forming the conjunction of the tests along this path,\nand then taking the disjunction of these conjunctions. We show an example in\nFig. 6.2. In drawing univariate decision trees, each non-leaf node is depicted by\na single attribute. If the attribute has value 0 in the input pattern, we branch\nleft; if it has value 1, we branch right.\nThe k-DL class of Boolean functions can be implemented by a multivariate\ndecision tree having the (highly unbalanced) form shown in Fig. 6.3. Each test,\nci, is a term of size k or less. The vi all have values of 0 or 1.\n6.2 Supervised Learning of Univariate Decision\nTrees\nSeveral systems for learning decision trees have been proposed. Prominent\namong these are ID3 and its new version, C4.5 [Quinlan, 1986, Quinlan, 1993],\nand CART [Breiman, et al., 1984] We discuss here only batch methods, al-\nthough incremental ones have also been proposed [Utgo\ufb00, 1989].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 83, 'page_label': '84'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES75\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.2: A Decision Tree Implementing a DNF Function\n6.2.1 Selecting the Type of Test\nAs usual, we have n features or attributes. If the attributes are binary, the\ntests are simply whether the attributes value is 0 or 1. If the attributes are\ncategorical, but non-binary, the tests might be formed by dividing the attribute\nvalues into mutually exclusive and exhaustive subsets. A decision tree with such\ntests is shown in Fig. 6.4. If the attributes are numeric, the tests might involve\ninterval tests, for example 7 \u2264xi \u226413.2.\n6.2.2 Using Uncertainty Reduction to Select Tests\nThe main problem in learning decision trees for the binary-attribute case is\nselecting the order of the tests. For categorical and numeric attributes, we\nmust also decide what the tests should be (besides selecting the order). Several\ntechniques have been tried; the most popular one is at each stage to select that\ntest that maximally reduces an entropy-like measure.\nWe show how this technique works for the simple case of tests with binary\noutcomes. Extension to multiple-outcome tests is straightforward computation-\nally but gives poor results because entropy is always decreased by having more\noutcomes.\nThe entropy or uncertainty still remaining about the class of a pattern\nknowing that it is in some set, \u039e, of patterns is de\ufb01ned as:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 84, 'page_label': '85'}, page_content='76 CHAPTER 6. DECISION TREES\ncq\ncq-1\nci\n1\nvn\nvn-1\nvi\nv1\nFigure 6.3: A Decision Tree Implementing a Decision List\nwhere p(i|\u039e) is the probability that a pattern drawn at random from \u039e belongs\nto class i, and the summation is over all of the classes. We want to select tests at\neach node such that as we travel down the decision tree, the uncertainty about\nthe class of a pattern becomes less and less.\nSince we do not in general have the probabilitiesp(i|\u039e), we estimate them by\nsample statistics. Although these estimates might be errorful, they are never-\ntheless useful in estimating uncertainties. Let p(i|\u039e) be the number of patterns\nin \u039e belonging to class idivided by the total number of patterns in \u039e. Then an\nestimate of the uncertainty is:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)\nFor simplicity, from now on well drop the hats and use sample statistics as\nif they were real probabilities.\nIf we perform a test, T, having k possible outcomes on the patterns in \u039e, we\nwill create ksubsets, \u039e1,\u039e2,..., \u039ek. Suppose that ni of the patterns in \u039e are in\n\u039ei for i= 1,...,k . (Some ni may be 0.) If we knew that T applied to a pattern\nin \u039e resulted in the j-th outcome (that is, we knew that the pattern was in \u039e j),\nthe uncertainty about its class would be:\nH(\u039ej) = \u2212\n\u2211\ni\np(i|\u039ej) log2 p(i|\u039ej)\nand the reduction in uncertainty (beyond knowing only that the pattern was in\n\u039e) would be:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 85, 'page_label': '86'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES77\nx3 = a, b, c, or d \n{a, c} {b}\nx1 = e, b, or d \n{e,b} {d}\nx4 = a, e, f, or g\n{a, g} {e, f}\nx2 = a, or g\n{a} {g}\n1\n2 1\n1 2\n{d}\n2\nFigure 6.4: A Decision Tree with Categorical Attributes\nH(\u039e) \u2212H(\u039ej)\nOf course we cannot say that the test T is guaranteed always to produce that\namount of reduction in uncertainty because we dont know that the result of\nthe test will be the j-th outcome. But we can estimate the average uncertainty\nover all the \u039ej, by:\nE[HT(\u039e)] =\n\u2211\nj\np(\u039ej)H(\u039ej)\nwhere by HT(\u039e) we mean the average uncertainty after performing test T on\nthe patterns in \u039e, p(\u039ej) is the probability that the test has outcome j, and the\nsum is taken from 1 to k. Again, we dont know the probabilities p(\u039ej), but we\ncan use sample values. The estimate p(\u039ej) of p(\u039ej) is just the number of those\npatterns in \u039e that have outcome j divided by the total number of patterns in\n\u039e. The average reduction in uncertainty achieved by test T (applied to patterns\nin \u039e) is then:\nRT(\u039e) = H(\u039e) \u2212E[HT(\u039e)]\nAn important family of decision tree learning algorithms selects for the root\nof the tree that test that gives maximum reduction of uncertainty, and then\napplies this criterion recursively until some termination condition is met (which\nwe shall discuss in more detail later). The uncertainty calculations are particu-\nlarly simple when the tests have binary outcomes and when the attributes have'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 86, 'page_label': '87'}, page_content='78 CHAPTER 6. DECISION TREES\nbinary values. Well give a simple example to illustrate how the test selection\nmechanism works in that case.\nSuppose we want to use the uncertainty-reduction method to build a decision\ntree to classify the following patterns:\npattern class\n(0, 0, 0) 0\n(0, 0, 1) 0\n(0, 1, 0) 0\n(0, 1, 1) 0\n(1, 0, 0) 0\n(1, 0, 1) 1\n(1, 1, 0) 0\n(1, 1, 1) 1\nWhat single test, x1, x2, or x3, should be performed \ufb01rst? The illustration in\nFig. 6.5 gives geometric intuition about the problem.\nx1\nx2\nx3\nThe test x1\nFigure 6.5: Eight Patterns to be Classi\ufb01ed by a Decision Tree\nThe initial uncertainty for the set, \u039e, containing all eight points is:\nH(\u039e) = \u2212(6/8) log2(6/8) \u2212(2/8) log2(2/8) = 0.81\nNext, we calculate the uncertainty reduction if we perform x1 \ufb01rst. The left-\nhand branch has only patterns belonging to class 0 (we call them the set \u039el), and\nthe right-hand-branch (\u039er) has two patterns in each class. So, the uncertainty\nof the left-hand branch is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 87, 'page_label': '88'}, page_content='6.3. NETWORKS EQUIVALENT TO DECISION TREES 79\nHx1 (\u039el) = \u2212(4/4) log2(4/4) \u2212(0/4) log2(0/4) = 0\nAnd the uncertainty of the right-hand branch is:\nHx1 (\u039er) = \u2212(2/4) log2(2/4) \u2212(2/4) log2(2/4) = 1\nHalf of the patterns go left and half go right on test x1. Thus, the average\nuncertainty after performing the x1 test is:\n1/2Hx1 (\u039el) + 1/2Hx1 (\u039er) = 0.5\nTherefore the uncertainty reduction on \u039e achieved by x1 is:\nRx1 (\u039e) = 0.81 \u22120.5 = 0.31\nBy similar calculations, we see that the test x3 achieves exactly the same\nuncertainty reduction, but x2 achieves no reduction whatsoever. Thus, our\ngreedy algorithm for selecting a \ufb01rst test would select eitherx1 or x3. Suppose\nx1 is selected. The uncertainty-reduction procedure would select x3 as the next\ntest. The decision tree that this procedure creates thus implements the Boolean\nfunction: f = x1x3. See [Quinlan, 1986, sect. 4] for\nanother example.\n6.2.3 Non-Binary Attributes\nIf the attributes are non-binary, we can still use the uncertainty-reduction tech-\nnique to select tests. But now, in addition to selecting an attribute, we must\nselect a test on that attribute. Suppose for example that the value of an at-\ntribute is a real number and that the test to be performed is to set a threshold\nand to test to see if the number is greater than or less than that threshold. In\nprinciple, given a set of labeled patterns, we can measure the uncertainty reduc-\ntion for each test that is achieved by every possible threshold (there are only\na \ufb01nite number of thresholds that give di\ufb00erent test results if there are only\na \ufb01nite number of training patterns). Similarly, if an attribute is categorical\n(with a \ufb01nite number of categories), there are only a \ufb01nite number of mutually\nexclusive and exhaustive subsets into which the values of the attribute can be\nsplit. We can calculate the uncertainty reduction for each split.\n6.3 Networks Equivalent to Decision Trees\nSince univariate Boolean decision trees are implementations of DNF functions,\nthey are also equivalent to two-layer, feedforward neural networks. We show\nan example in Fig. 6.6. The decision tree at the left of the \ufb01gure implements'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 88, 'page_label': '89'}, page_content='80 CHAPTER 6. DECISION TREES\nthe same function as the network at the right of the \ufb01gure. Of course, when\nimplemented as a network, all of the features are evaluated in parallel for any\ninput pattern, whereas when implemented as a decision tree only those features\non the branch traveled down by the input pattern need to be evaluated. The\ndecision-tree induction methods discussed in this chapter can thus be thought of\nas particular ways to establish the structure and the weight values for networks.\nX\nx1\nx2\nx3\nx4\nterms\n-1\n+1\ndisjunction\nx3x2\nx3x4x1\n+1\n-1\n+1\nf\n1.5\n0.5\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.6: A Univariate Decision Tree and its Equivalent Network\nMultivariate decision trees with linearly separable functions at each node can\nalso be implemented by feedforward networksin this case three-layer ones. We\nshow an example in Fig. 6.7 in which the linearly separable functions, each im-\nplemented by a TLU, are indicated by L1,L2,L3, and L4. Again, the \ufb01nal layer\nhas \ufb01xed weights, but the weights in the \ufb01rst two layers must be trained. Dif-\nferent approaches to training procedures have been discussed by [Brent, 1990],\nby [John, 1995], and (for a special case) by [Marchand & Golea, 1993].\n6.4 Over\ufb01tting and Evaluation\n6.4.1 Over\ufb01tting\nIn supervised learning, we must choose a function to \ufb01t the training set from\namong a set of hypotheses. We have already showed that generalization is\nimpossible without bias. When we know a priori that the function we are\ntrying to guess belongs to a small subset of all possible functions, then, even\nwith an incomplete set of training samples, it is possible to reduce the subset\nof functions that are consistent with the training set su\ufb03ciently to make useful\nguesses about the value of the function for inputs not in the training set. And,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 89, 'page_label': '90'}, page_content='6.4. OVERFITTING AND EVALUATION 81\nL1\nL2 L3\nL4\n10\n1\n1\n0 0\n0\n1\n1\n0\n0\n1 0\nX\nL1\nL2\nL3\nL4\nconjunctions\nL1L2\nL1 L3 L4\n<\n+\n++\ndisjunction\n<\nf\nFigure 6.7: A Multivariate Decision Tree and its Equivalent Network\nthe larger the training set, the more likely it is that even a randomly selected\nconsistent function will have appropriate outputs for patterns not yet seen.\nHowever, even with bias, if the training set is not su\ufb03ciently large compared\nwith the size of the hypothesis space, there will still be too many consistent\nfunctions for us to make useful guesses, and generalization performance will be\npoor. When there are too many hypotheses that are consistent with the training\nset, we say that we are over\ufb01tting the training data. Over\ufb01tting is a problem\nthat we must address for all learning methods.\nSince a decision tree of su\ufb03cient size can implement any Boolean function\nthere is a danger of over\ufb01ttingespecially if the training set is small. That\nis, even if the decision tree is synthesized to classify all the members of the\ntraining set correctly, it might perform poorly on new patterns that were not\nused to build the decision tree. Several techniques have been proposed to avoid\nover\ufb01tting, and we shall examine some of them here. They make use of methods\nfor estimating how well a given decision tree might generalizemethods we shall\ndescribe next.\n6.4.2 Validation Methods\nThe most straightforward way to estimate how well a hypothesized function\n(such as a decision tree) performs on a test set is to test it on the test set! But,\nif we are comparing several learning systems (for example, if we are comparing\ndi\ufb00erent decision trees) so that we can select the one that performs the best on\nthe test set, then such a comparison amounts to training on the test data.\nTrue, training on the test data enlarges the training set, with a consequent ex-\npected improvement in generalization, but there is still the danger of over\ufb01tting\nif we are comparing several di\ufb00erent learning systems. Another technique is to'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 90, 'page_label': '91'}, page_content='82 CHAPTER 6. DECISION TREES\nsplit the training setusing (say) two-thirds for training and the other third\nfor estimating generalization performance. But splitting reduces the size of the\ntraining set and thereby increases the possibility of over\ufb01tting. We next describe\nsome validation techniques that attempt to avoid these problems.\nCross-Validation\nIn cross-validation, we divide the training set \u039e into K mutually exclusive and\nexhaustive equal-sized subsets: \u039e 1,..., \u039eK. For each subset, \u039e i, train on the\nunion of all of the other subsets, and empirically determine the error rate, \u03b5i,\non \u039ei. (The error rate is the number of classi\ufb01cation errors made on \u039e i divided\nby the number of patterns in \u039e i.) An estimate of the error rate that can be\nexpected on new patterns of a classi\ufb01er trained on all the patterns in \u039e is then\nthe average of the \u03b5i.\nLeave-one-out Validation\nLeave-one-out validation is the same as cross validation for the special case in\nwhich K equals the number of patterns in \u039e, and each \u039e i consists of a single\npattern. When testing on each \u039e i, we simply note whether or not a mistake\nwas made. We count the total number of mistakes and divide by K to get\nthe estimated error rate. This type of validation is, of course, more expensive\ncomputationally, but useful when a more accurate estimate of the error rate for\na classi\ufb01er is needed.Describe bootstrapping also\n[Efron, 1982].\n6.4.3 Avoiding Over\ufb01tting in Decision Trees\nNear the tips of a decision tree there may be only a few patterns per node.\nFor these nodes, we are selecting a test based on a very small sample, and thus\nwe are likely to be over\ufb01tting. This problem can be dealt with by terminating\nthe test-generating procedure before all patterns are perfectly split into their\nseparate categories. That is, a leaf node may contain patterns of more than one\nclass, but we can decide in favor of the most numerous class. This procedure\nwill result in a few errors but often accepting a small number of errors on the\ntraining set results in fewer errors on a testing set.\nThis behavior is illustrated in Fig. 6.8.\nOne can use cross-validation techniques to determine when to stop splitting\nnodes. If the cross validation error increases as a consequence of a node split,\nthen dont split. One has to be careful about when to stop, though, because\nunder\ufb01tting usually leads to more errors on test sets than does over\ufb01tting. There\nis a general rule that the lowest error-rate attainable by a sub-tree of a fully\nexpanded tree can be no less than 1/2 of the error rate of the fully expanded\ntree [Weiss & Kulikowski, 1991, page 126].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 91, 'page_label': '92'}, page_content='6.4. OVERFITTING AND EVALUATION 83\n(From Weiss, S., and Kulikowski, C., Computer Systems that Learn,\nMorgan Kaufmann, 1991)\ntraining errors\nvalidation errors\n1 2 34 5 6 78 9\n0.2\n0.4\n0.6\n0.8\n1.0\n0\n0\nError Rate\nNumber of Terminal\nNodes\nIris Data Decision Tree\nFigure 6.8: Determining When Over\ufb01tting Begins\nRather than stopping the growth of a decision tree, one might grow it to\nits full size and then prune away leaf nodes and their ancestors until cross-\nvalidation accuracy no longer increases. This technique is called post-pruning.\nVarious techniques for pruning are discussed in [Weiss & Kulikowski, 1991].\n6.4.4 Minimum-Description Length Methods\nAn important tree-growing and pruning technique is based on the minimum-\ndescription-length (MDL) principle. (MDL is an important idea that extends\nbeyond decision-tree methods [Rissanen, 1978].) The idea is that the simplest\ndecision tree that can predict the classes of the training patterns is the best\none. Consider the problem of transmitting just the labels of a training set of\npatterns, assuming that the receiver of this information already has the ordered\nset of patterns. If there are m patterns, each labeled by one of R classes,\none could transmit a list of m R-valued numbers. Assuming equally probable\nclasses, this transmission would require mlog2 Rbits. Or, one could transmit a\ndecision tree that correctly labelled all of the patterns. The number of bits that\nthis transmission would require depends on the technique for encoding decision\ntrees and on the size of the tree. If the tree is small and accurately classi\ufb01es\nall of the patterns, it might be more economical to transmit the tree than to\ntransmit the labels directly. In between these extremes, we might transmit a\ntree plus a list of labels of all the patterns that the tree misclassi\ufb01es.\nIn general, the number of bits (or description length of the binary encoded\nmessage) is t+ d, where t is the length of the message required to transmit\nthe tree, and d is the length of the message required to transmit the labels of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 92, 'page_label': '93'}, page_content='84 CHAPTER 6. DECISION TREES\nthe patterns misclassi\ufb01ed by the tree. In a sense, that tree associated with the\nsmallest value of t+ d is the best or most economical tree. The MDL method\nis one way of adhering to the Occams razor principle.\nQuinlan and Rivest [Quinlan & Rivest, 1989] have proposed techniques for\nencoding decision trees and lists of exception labels and for calculating the\ndescription length (t+d) of these trees and labels. They then use the description\nlength as a measure of quality of a tree in two ways:\na. In growing a tree, they use the reduction in description length to select\ntests (instead of reduction in uncertainty).\nb. In pruning a tree after it has been grown to zero error, they prune away\nthose nodes (starting at the tips) that achieve a decrease in the description\nlength.\nThese techniques compare favorably with the uncertainty-reduction method,\nalthough they are quite sensitive to the coding schemes used.\n6.4.5 Noise in Data\nNoise in the data means that one must inevitably accept some number of\nerrorsdepending on the noise level. Refusal to tolerate errors on the training\nset when there is noise leads to the problem of \ufb01tting the noise. Dealing with\nnoise, then, requires accepting some errors at the leaf nodes just as does the\nfact that there are a small number of patterns at leaf nodes.\n6.5 The Problem of Replicated Subtrees\nDecision trees are not the most economical means of implementing some Boolean\nfunctions. Consider, for example, the function f = x1x2 +x3x4. A decision tree\nfor this function is shown in Fig. 6.9. Notice the replicated subtrees shown\ncircled. The DNF-form equivalent to the function implemented by this decision\ntree is f = x1x2 + x1x2x3x4 + x1x3x4. This DNF form is non-minimal (in the\nnumber of disjunctions) and is equivalent to f = x1x2 + x3x4.\nThe need for replication means that it takes longer to learn the tree and\nthat subtrees replicated further down the tree must be learned using a smaller\ntraining subset. This problem is sometimes called the fragmentation problem.\nSeveral approaches might be suggested for dealing with fragmenta-\ntion. One is to attempt to build a decision graph instead of a tree\n[Oliver, Dowe, & Wallace, 1992, Kohavi, 1994]. A decision graph that imple-\nments the same decisions as that of the decision tree of Fig. 6.9 is shown in Fig.\n6.10.\nAnother approach is to use multivariate (rather than univariate tests at each\nnode). In our example of learning f = x1x2 + x3x4, if we had a test for x1x2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 93, 'page_label': '94'}, page_content='6.6. THE PROBLEM OF MISSING ATTRIBUTES 85\nx1\nx3 x2\n10\nx4\n0 1\nx3\n0\nx4\n0 1\nFigure 6.9: A Decision Tree with Subtree Replication\nand a test for x3x4, the decision tree could be much simpli\ufb01ed, as shown in Fig.\n6.11. Several researchers have proposed techniques for learning decision trees in\nwhich the tests at each node are linearly separable functions. [John, 1995] gives\na nice overview (with several citations) of learning suchlinear discriminant trees\nand presents a method based on soft entropy.\nA third method for dealing with the replicated subtree problem involves ex-\ntracting propositional rules from the decision tree. The rules will have as an-\ntecedents the conjunctions that lead down to the leaf nodes, and as consequents\nthe name of the class at the corresponding leaf node. An example rule from the\ntree with the repeating subtree of our example would be: x1 \u2227¬x2 \u2227x3 \u2227x4 \u22831.\nQuinlan [Quinlan, 1987] discusses methods for reducing a set of rules to a sim-\npler set by 1) eliminating from the antecedent of each rule any unnecessary\nconjuncts, and then 2) eliminating unnecessary rules. A conjunct or rule is\ndetermined to be unnecessary if its elimination has little e\ufb00ect on classi\ufb01cation\naccuracyas determined by a chi-square test, for example. After a rule set is\nprocessed, it might be the case that more than one rule is active for any given\npattern, and care must be taken that the active rules do not con\ufb02ict in their\ndecision about the class of a pattern.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 94, 'page_label': '95'}, page_content='86 CHAPTER 6. DECISION TREES\nx1\nx3\nx2\n1\n0\nx4\n0 1\nFigure 6.10: A Decision Graph\n6.6 The Problem of Missing Attributes\nTo be added.\n6.7 Comparisons\nSeveral experimenters have compared decision-tree, neural-net, and nearest-\nneighbor classi\ufb01ers on a wide variety of problems. For a comparison of\nneural nets versus decision trees, for example, see [Dietterich, et al., 1990,\nShavlik, Mooney, & Towell, 1991, Quinlan, 1994]. In their StatLog project,\n[Taylor, Michie, & Spiegalhalter, 1994] give thorough comparisons of several\nmachine learning algorithms on several di\ufb00erent types of problems. There seems\nx1x2\n1\n0\nx3x4\n1\nFigure 6.11: A Multivariate Decision Tree'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 95, 'page_label': '96'}, page_content='6.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 87\nto be no single type of classi\ufb01er that is best for all problems. And, there do\nnot seem to be any general conclusions that would enable one to say which\nclassi\ufb01er method is best for which sorts of classi\ufb01cation problems, although\n[Quinlan, 1994] does provide some intuition about properties of problems that\nmight render them ill suited for decision trees, on the one hand, or backpropa-\ngation, on the other.\n6.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 96, 'page_label': '97'}, page_content='88 CHAPTER 6. DECISION TREES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 97, 'page_label': '98'}, page_content='Chapter 7\nInductive Logic\nProgramming\nThere are many di\ufb00erent representational forms for functions of input vari-\nables. So far, we have seen (Boolean) algebraic expressions, decision trees, and\nneural networks, plus other computational mechanisms such as techniques for\ncomputing nearest neighbors. Of course, the representation most important\nin computer science is a computer program. For example, a Lisp predicate of\nbinary-valued inputs computes a Boolean function of those inputs. Similarly, a\nlogic program (whose ordinary application is to compute bindings for variables)\ncan also be used simply to decide whether or not a predicate has value True\n(T) or False (F). For example, the Boolean exclusive-or (odd parity) function\nof two variables can be computed by the following logic program:\nParity(x,y) :- True(x), ¬ True(y)\n:- True(y), ¬ True(x)\nWe follow Prolog syntax (see, for example, [Mueller & Page, 1988]), except that\nour convention is to write variables as strings beginning with lower-case letters\nand predicates as strings beginning with upper-case letters. The unary function\nTrue returns T if and only if the value of its argument is T. (We now think\nof Boolean functions and arguments as having values of T and F instead of 0\nand 1.) Programs will be written in  typewriter font.\nIn this chapter, we consider the matter of learning logic programs given\na set of variable values for which the logic program should return T (the\npositive instances ) and a set of variable values for which it should return\nF (the negative instances). The subspecialty of machine learning that deals\nwith learning logic programs is called inductive logic programming (ILP)\n[Lavra\u02c7 c & D\u02c7 zeroski, 1994]. As with any learning problem, this one can be quite\ncomplex and intractably di\ufb03cult unless we constrain it with biases of some sort.\n89'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 98, 'page_label': '99'}, page_content='90 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nIn ILP, there are a variety of possible biases (calledlanguage biases). One might\nrestrict the program to Horn clauses, not allow recursion, not allow functions,\nand so on.\nAs an example of an ILP problem, suppose we are trying to induce a func-\ntion Nonstop(x,y), that is to have value T for pairs of cities connected by a\nnon-stop air \ufb02ight and F for all other pairs of cities. We are given a training set\nconsisting of positive and negative examples. As positive examples, we might\nhave (A,B), (A, A1), and some other pairs; as negative examples, we might\nhave (A1, A2), and some other pairs. In ILP, we usually have additional infor-\nmation about the examples, called background knowledge. In our air-\ufb02ight\nproblem, the background information might be such ground facts as Hub(A),\nHub(B), Satellite(A1,A), plus others. ( Hub(A) is intended to mean that the\ncity denoted by A is a hub city, and Satellite(A1,A) is intended to mean that\nthe city denoted by A1 is a satellite of the city denoted by A.) From these train-\ning facts, we want to induce a program Nonstop(x,y), written in terms of the\nbackground relations Hub and Satellite, that has value T for all the positive\ninstances and has value F for all the negative instances. Depending on the exact\nset of examples, we might induce the program:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nwhich would have value T if both of the two cities were hub cities or if one were\na satellite of the other. As with other learning problems, we want the induced\nprogram to generalize well; that is, if presented with arguments not represented\nin the training set (but for which we have the needed background knowledge),\nwe would like the function to guess well.\n7.1 Notation and De\ufb01nitions\nIn evaluating logic programs in ILP, we implicitly append the background facts\nto the program and adopt the usual convention that a program has value T for\na set of inputs if and only if the program interpreter returns T when actually\nrunning the program (with background facts appended) on those inputs; oth-\nerwise it has value F. Using the given background facts, the program above\nwould return T for input (A, A1), for example. If a logic program, \u03c0, returns\nT for a set of arguments X, we say that the program covers the arguments and\nwrite covers(\u03c0,X). Following our terminology introduced in connection with\nversion spaces, we will say that a program is su\ufb03cient if it covers all of the\npositive instances and that it is necessary if it does not cover any of the neg-\native instances. (That is, a program implements a su\ufb03cient condition that a\ntraining instance is positive if it covers all of the positive training instances; it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 99, 'page_label': '100'}, page_content='7.2. A GENERIC ILP ALGORITHM 91\nimplements a necessary condition if it covers none of the negative instances.) In\nthe noiseless case, we want to induce a program that is both su\ufb03cient and nec-\nessary, in which case we will call it consistent. With imperfect (noisy) training\nsets, we might relax this criterion and settle for a program that covers all but\nsome fraction of the positive instances while allowing it to cover some fraction\nof the negative instances. We illustrate these de\ufb01nitions schematically in Fig.\n7.1.\n<\n<\n<\n<<\n<\n<\n/1 is a necessary program\n/2 is a sufficient program\n/3 is a consistent program\n+\n+\n+\n+\n+ +\n+\n+\n+\n+\n<\n<\nA positive instance\n covered by /2 and /3\nFigure 7.1: Su\ufb03cient, Necessary, and Consistent Programs\nAs in version spaces, if a program is su\ufb03cient but not necessary it can be\nmade to cover fewer examples by specializing it. Conversely, if it is necessary\nbut not su\ufb03cient, it can be made to cover more examples by generalizing it.\nSuppose we are attempting to induce a logic program to compute the relation\n\u03c1. The most general logic program, which is certainly su\ufb03cient, is the one that\nhas value T for all inputs, namely a single clause with an empty body, [ \u03c1 :-\n], which is called a fact in Prolog. The most special logic program, which is\ncertainly necessary, is the one that has value F for all inputs, namely [ \u03c1 :-\nF ]. Two of the many di\ufb00erent ways to search for a consistent logic program\nare: 1) start with [ \u03c1 :- ] and specialize until the program is consistent, or 2)\nstart with [ \u03c1 :- F ] and generalize until the program is consistent. We will\nbe discussing a method that starts with [ \u03c1 :- ], specializes until the program\nis necessary (but might no longer be su\ufb03cient), then reachieves su\ufb03ciency in\nstages by generalizingensuring within each stage that the program remains\nnecessary (by specializing).\n7.2 A Generic ILP Algorithm\nSince the primary operators in our search for a consistent program are special-\nization and generalization, we must next discuss those operations. There are'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 100, 'page_label': '101'}, page_content='92 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nthree major ways in which a logic program might be generalized:\na. Replace some terms in a program clause by variables. (Readers familiar\nwith substitutions in the predicate calculus will note that this process is\nthe inverse of substitution.)\nb. Remove literals from the body of a clause.\nc. Add a clause to the program\nAnalogously, there are three ways in which a logic program might be specialized:\na. Replace some variables in a program clause by terms (a substitution).\nb. Add literals to the body of a clause.\nc. Remove a clause from the program\nWe will be presenting an ILP learning method that adds clauses to a program\nwhen generalizing and that adds literals to the body of a clause when special-\nizing. When we add a clause, we will always add the clause [ \u03c1 :- ] and then\nspecialize it by adding literals to the body. Thus, we need only describe the\nprocess for adding literals.\nClauses can be partially ordered by the specialization relation. In general,\nclause c1 is more special than clause c2 if c2 |= c1. A special case, which is what\nwe use here, is that a clause c1 is more special than a clause c2 if the set of\nliterals in the body of c2 is a subset of those in c1. This ordering relation can\nbe used in a structure of partially ordered clauses, called the re\ufb01nement graph,\nthat is similar to a version space. Clause c1 is an immediate successor of clause\nc2 in this graph if and only if clause c1 can be obtained from clause c2 by adding\na literal to the body of c2. A re\ufb01nement graph then tells us the ways in which\nwe can specialize a clause by adding a literal to it.\nOf course there are unlimited possible literals we might add to the body of\na clause. Practical ILP systems restrict the literals in various ways. Typical\nallowed additions are:\na. Literals used in the background knowledge.\nb. Literals whose arguments are a subset of those in the head of the clause.\nc. Literals that introduce a new distinct variable di\ufb00erent from those in the\nhead of the clause.\nd. A literal that equates a variable in the head of the clause with another\nsuch variable or with a term mentioned in the background knowledge.\n(This possibility is equivalent to forming a specialization by making a\nsubstitution.)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 101, 'page_label': '102'}, page_content='7.2. A GENERIC ILP ALGORITHM 93\ne. A literal that is the same (except for its arguments) as that in the head\nof the clause. (This possibility admits recursive programs, which are dis-\nallowed in some systems.)\nWe can illustrate these possibilities using our air-\ufb02ight example. We start\nwith the program [ Nonstop(x,y) :- ]. The literals used in the background\nknowledge are Hub and Satellite. Thus the literals that we might consider\nadding are:\nHub(x)\nHub(y)\nHub(z)\nSatellite(x,y)\nSatellite(y,x)\nSatellite(x,z)\nSatellite(z,y)\n(x = y)\n(If recursive programs are allowed, we could also add the literals Nonstop(x,z)\nand Nonstop(z,y).) These possibilities are among those illustrated in the re-\n\ufb01nement graph shown in Fig. 7.2. Whatever restrictions on additional literals\nare imposed, they are all syntactic ones from which the successors in the re\ufb01ne-\nment graph are easily computed. ILP programs that follow the approach we\nare discussing (of specializing clauses by adding a literal) thus have well de\ufb01ned\nmethods of computing the possible literals to add to a clause.\nNow we are ready to write down a simple generic algorithm for inducing a\nlogic program, \u03c0 for inducing a relation \u03c1. We are given a training set, \u039e of\nargument sets some known to be in the relation \u03c1 and some not in \u03c1; \u039e+ are\nthe positive instances, and \u039e \u2212 are the negative instances. The algorithm has\nan outer loop in which it successively adds clauses to make \u03c0 more and more\nsu\ufb03cient. It has an inner loop for constructing a clause, c, that is more and\nmore necessary and in which it refers only to a subset, \u039e cur, of the training\ninstances. (The positive instances in \u039e cur will be denoted by \u039e +\ncur, and the\nnegative ones by \u039e \u2212\ncur.) The algorithm is also given background relations and\nthe means for adding literals to a clause. It uses a logic program interpreter to\ncompute whether or not the program it is inducing covers training instances.\nThe algorithm can be written as follows:\nGeneric ILP Algorithm\n(Adapted from [Lavra\u02c7 c & D\u02c7 zeroski, 1994, p. 60].)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 102, 'page_label': '103'}, page_content='94 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nNonstop(x,y) :-\nNonstop(x,y) :-\n   Hub(x)\nNonstop(x,y) :-\n   Satellite(x,y)\nNonstop(x,y) :-\n   (x = y)\n. . .\n. . .\n. . . . . .\nNonstop(x,y) :- Hub(x), Hub(y)\n. . .\n. . .\n. . .\nFigure 7.2: Part of a Re\ufb01nement Graph\nInitialize \u039ecur := \u039e.\nInitialize \u03c0:= empty set of clauses.\nrepeat [The outer loop works to make \u03c0 su\ufb03cient.]\nInitialize c := \u03c1 : \u2212.\nrepeat [The inner loop makes c necessary.]\nSelect a literal l to add to c. [This is a nondeterministic choice point.]\nAssign c:= c,l.\nuntil c is necessary. [That is, until c covers no negative instances in \u039e cur.]\nAssign \u03c0:= \u03c0,c. [We add the clause c to the program.]\nAssign \u039ecur := \u039ecur \u2212(the positive instances in \u039e cur covered by \u03c0).\nuntil \u03c0 is su\ufb03cient.\n(The termination tests for the inner and outer loops can be relaxed as appro-\npriate for the case of noisy instances.)\n7.3 An Example\nWe illustrate how the algorithm works by returning to our example of airline\n\ufb02ights. Consider the portion of an airline route map, shown in Fig. 7.3. Cities\nA, B, and C are hub cities, and we know that there are nonstop \ufb02ights between\nall hub cities (even those not shown on this portion of the route map). The other'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 103, 'page_label': '104'}, page_content='7.3. AN EXAMPLE 95\ncities are satellites of one of the hubs, and we know that there are nonstop\n\ufb02ights between each satellite city and its hub. The learning program is given a\nset of positive instances, \u039e +, of pairs of cities between which there are nonstop\n\ufb02ights and a set of negative instances, \u039e\u2212, of pairs of cities between which there\nare not nonstop \ufb02ights. \u039e + contains just the pairs:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nFor our example, we will assume that \u039e\u2212contains all those pairs of cities shown\nin Fig. 7.3 that are not in \u039e + (a type of closed-world assumption). These are:\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<B,C 1 >,<B,C 2 >,\n<B,A 1 >,<B,A 2 >,<C,A 1 >,<C,A 2 >,<C,B 1 >,<C,B 2 >,\n<B 1,A>,<B 2,A>,<C 1,A>,<C 2,A>,<C 1,B >,<C 2,B >,\n<A1,B >,<A2,B >,<A1,C >,<A2,C >,<B 1,C >,<B 2,C >}\nThere may be other cities not shown on this map, so the training set does not\nnecessarily exhaust all the cities.\nA\nB\nC\nC1\nC2\nB1 B2\nA1\nA2\nFigure 7.3: Part of an Airline Route Map\nWe want the learning program to induce a program for computing the value\nof the relation Nonstop. The training set, \u039e, can be thought of as a partial'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 104, 'page_label': '105'}, page_content='96 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\ndescription of this relation in extensional formit explicitly names some pairs\nin the relation and some pairs not in the relation. We desire to learn the\nNonstop relation as a logic program in terms of the background relations, Hub\nand Satellite, which are also given in extensional form. Doing so will give us\na more compact, intensional, description of the relation, and this description\ncould well generalize usefully to other cities not mentioned in the map.\nWe assume the learning program has the following extensional de\ufb01nitions of\nthe relations Hub and Satellite:\nHub\n{<A>,<B >,<C > }\nAll other cities mentioned in the map are assumed not in the relation Hub. We\nwill use the notation Hub(x) to express that the city named xis in the relation\nHub.\nSatellite\n{<A1,A,>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nAll other pairs of cities mentioned in the map are not in the relation Satellite.\nWe will use the notation Satellite(x,y) to express that the pair < x,y >is\nin the relation Satellite.\nKnowing that the predicate Nonstop is a two-place predicate, the inner loop\nof our algorithm initializes the \ufb01rst clause to Nonstop(x,y) :- . This clause\nis not necessary because it covers all the negative examples (since it covers all\nexamples). So we must add a literal to its (empty) body. Suppose (selecting\na literal from the re\ufb01nement graph) the algorithm adds Hub(x). The following\npositive instances in \u039e are covered by Nonstop(x,y) :- Hub(x):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}\nTo compute this covering, we interpret the logic program Nonstop(x,y) :-\nHub(x) for all pairs of cities in \u039e, using the pairs given in the background\nrelation Hub as ground facts. The following negative instances are also covered:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 105, 'page_label': '106'}, page_content='7.3. AN EXAMPLE 97\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<C,A 1 >,<C,A 2 >,\n<C,B 1 >,<C,B 2 >,<B,A 1 >,<B,A 2 >,<B,C 1 >,<B,C 2 >}\nThus, the clause is not yet necessary and another literal must be added. Sup-\npose we next add Hub(y). The following positive instances are covered by\nNonstop(x,y) :- Hub(x), Hub(y):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B > }\nThere are no longer any negative instances in \u039e covered so the clause\nNonstop(x,y) :- Hub(x), Hub(y) is necessary, and we can terminate the \ufb01rst\npass through the inner loop.\nBut the program, \u03c0, consisting of just this clause is not su\ufb03cient. These\npositive instances are not covered by the clause:\n{<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nThe positive instances that were covered byNonstop(x,y) :- Hub(x), Hub(y)\nare removed from \u039e to form the \u039e cur to be used in the next pass through the\ninner loop. \u039e cur consists of all the negative instances in \u039e plus the positive\ninstances (listed above) that are not yet covered. In order to attempt to cover\nthem, the inner loop creates another clause c, initially set to Nonstop(x,y)\n:- . This clause covers all the negative instances, and so we must add liter-\nals to make it necessary. Suppose we add the literal Satellite(x,y). The\nclause Nonstop(x,y) :- Satellite(x,y) covers no negative instances, so it is\nnecessary. It does cover the following positive instances in \u039e cur:\n{<A1,A>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nThese instances are removed from \u039ecur for the next pass through the inner loop.\nThe program now contains two clauses:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\nThis program is not yet su\ufb03cient since it does not cover the following positive\ninstances:\n{<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 106, 'page_label': '107'}, page_content='98 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nDuring the next pass through the inner loop, we add the clauseNonstop(x,y)\n:- Satellite(y,x). This clause is necessary, and since the program containing\nall three clauses is now su\ufb03cient, the procedure terminates with:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nSince each clause is necessary, and the whole program is su\ufb03cient, the pro-\ngram is also consistent with all instances of the training set. Note that this\nprogram can be applied (perhaps with good generalization) to other cities be-\nsides those in our partial mapso long as we can evaluate the relations Hub and\nSatellite for these other cities. In the next section, we show how the technique\ncan be extended to use recursion on the relation we are inducing. With that\nextension, the method can be used to induce more general logic programs.\n7.4 Inducing Recursive Programs\nTo induce a recursive program, we allow the addition of a literal having the\nsame predicate letter as that in the head of the clause. Various mechanisms\nmust be used to ensure that such a program will terminate; one such is to make\nsure that the new literal has di\ufb00erent variables than those in the head literal.\nThe process is best illustrated with another example. Our example continues\nthe one using the airline map, but we make the map somewhat simpler in order\nto reduce the size of the extensional relations used. Consider the map shown\nin Fig. 7.4. Again, B and C are hub cities, B1 and B2 are satellites of B, C1\nand C2 are satellites of C. We have introduced two new cities, B3 and C3. No\n\ufb02ights exist between these cities and any other citiesperhaps there are only\nbus routes as shown by the grey lines in the map.\nWe now seek to learn a program for Canfly(x,y) that covers only those\npairs of cities that can be reached by one or more nonstop \ufb02ights. The relation\nCanfly is satis\ufb01ed by the following pairs of postive instances:\n{<B 1,B >,<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,\n<B,B 1 >,<B 2,B1 >,<C,B 1 >,<C 1,B1 >,<C 2,B1 >,\n<B 2,B >,<B 2,C >,<B 2,C1 >,<B 2,C2 >,<B,B 2 >,\n<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C >,<B,C 1 >,\n<B,C 2 >,<C,B >,<C 1,B >,<C 2,B >,<C,C 1 >,\n<C,C 2 >,<C 1,C >,<C 2,C >,<C 1,C2 >,<C 2,C1 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 107, 'page_label': '108'}, page_content='7.4. INDUCING RECURSIVE PROGRAMS 99\nB\nC\nC1\nC2\nB1\nB2\nB3\nC3\nFigure 7.4: Another Airline Route Map\nUsing a closed-world assumption on our map, we take the negative instances of\nCanfly to be:\n{<B 3,B2 >,<B 3,B >,<B 3,B1 >,<B 3,C >,<B 3,C1 >,\n<B 3,C2 >,<B 3,C3 >,<B 2,B3 >,<B,B 3 >,<B 1,B3 >,\n<C,B 3 >,<C 1,B3 >,<C 2,B3 >,<C 3,B3 >,<C 3,B2 >,\n<C 3,B >,<C 3,B1 >,<C 3,C >,<C 3,C1 >,<C 3,C2 >,\n<B 2,C3 >,<B,C 3 >,<B 1,C3 >,<C,C 3 >,<C 1,C3 >,\n<C 2,C3 >}\nWe will induce Canfly(x,y) using the extensionally de\ufb01ned background\nrelation Nonstop given earlier (modi\ufb01ed as required for our reduced airline map)\nand Canfly itself (recursively).\nAs before, we start with the empty program and proceed to the inner loop\nto construct a clause that is necessary. Suppose that the inner loop adds the\nbackground literal Nonstop(x,y). The clause Canfly(x,y) :- Nonstop(x,y)\nis necessary; it covers no negative instances. But it is not su\ufb03cient because it\ndoes not cover the following positive instances:\n{<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,<B 2,B1 >,\n<C,B 1 >,<C 1,B1 >,<C 2,B1 >,<B 2,C >,<B 2,C1 >,\n<B 2,C2 >,<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C 1 >,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 108, 'page_label': '109'}, page_content='100 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n<B,C 2 >,<C 1,B >,<C 2,B >,<C 1,C2 >,<C 2,C1 >}\nThus, we must add another clause to the program. In the inner loop, we \ufb01rst\ncreate the clause Canfly(x,y) :- Nonstop(x,z) which introduces the new\nvariable z. We digress brie\ufb02y to describe how a program containing a clause\nwith unbound variables in its body is interpreted. Suppose we try to inter-\npret it for the positive instance Canfly(B1,B2). The interpreter attempts to\nestablish Nonstop(B1,z) for some z. Since Nonstop(B1, B), for example, is\na background fact, the interpreter returns Twhich means that the instance\n< B1,B2 > is covered. Suppose now, we attempt to interpret the clause\nfor the negative instance Canfly(B3,B). The interpreter attempts to estab-\nlish Nonstop(B3,z) for some z. There are no background facts that match, so\nthe clause does not cover < B3,B >. Using the interpreter, we see that the\nclause Canfly(x,y) :- Nonstop(x,z) covers all of the positive instances not\nalready covered by the \ufb01rst clause, but it also covers many negative instances\nsuch as <B 2,B3 >, and <B,B 3 >. So the inner loop must add another literal.\nThis time, suppose it adds Canfly(z,y) to yield the clause Canfly(x,y) :-\nNonstop(x,z), Canfly(z,y). This clause is necessary; no negative instances\nare covered. The program is now su\ufb03cient and consistent; it is:\nCanfly(x,y) :- Nonstop(x,y)\n:- Nonstop(x,z), Canfly(z,y)\n7.5 Choosing Literals to Add\nOne of the \ufb01rst practical ILP systems was Quinlans FOIL [Quinlan, 1990]. A\nmajor problem involves deciding how to select a literal to add in the inner loop\n(from among the literals that are allowed). In FOIL, Quinlan suggested that\ncandidate literals can be compared using an information-like measuresimilar\nto the measures used in inducing decision trees. A measure that gives the same\ncomparison as does Quinlans is based on the amount by which adding a literal\nincreases the odds that an instance drawn at random from those covered by the\nnew clause is a positive instance beyond what these odds were before adding\nthe literal.\nLet p be an estimate of the probability that an instance drawn at random\nfrom those covered by a clause before adding the literal is a positive instance.\nThat is, p=(number of positive instances covered by the clause)/(total number\nof instances covered by the clause). It is convenient to express this probability\nin odds form. The odds, o, that a covered instance is positive is de\ufb01ned to\nbe o = p/(1 \u2212p). Expressing the probability in terms of the odds, we obtain\np= o/(1 + o).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 109, 'page_label': '110'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION101\nAfter selecting a literal, l, to add to a clause, some of the instances previously\ncovered are still covered; some of these are positive and some are negative. Let\npl denote the probability that an instance drawn at random from the instances\ncovered by the new clause (with l added) is positive. The odds will be denoted\nby ol. We want to select a literal, l, that gives maximal increase in these\nodds. That is, if we de\ufb01ne \u03bbl = ol/o, we want a literal that gives a high\nvalue of \u03bbl. Specializing the clause in such a way that it fails to cover many of\nthe negative instances previously covered but still covers most of the positive\ninstances previously covered will result in a high value of \u03bbl. (It turns out that\nthe value of Quinlans information theoretic measure increases monotonically\nwith \u03bbl, so we could just as well use the latter instead.)\nBesides \ufb01nding a literal with a high value of \u03bbl, Quinlans FOIL system also\nrestricts the choice to literals that:\na) contain at least one variable that has already been used,\nb) place further restrictions on the variables if the literal selected has the\nsame predicate letter as the literal being induced (in order to prevent in\ufb01nite\nrecursion), and\nc) survive a pruning test based on the values of \u03bbl for those literals selected\nso far.\nWe refer the reader to Quinlans paper for further discussion of these points.\nQuinlan also discusses post-processing pruning methods and presents experi-\nmental results of the method applied to learning recursive relations on lists, on\nlearning rules for chess endgames and for the card game Eleusis, and for some\nother standard tasks mentioned in the machine learning literature.\nThe reader should also refer to [Pazzani & Kibler, 1992,\nLavra\u02c7 c & D\u02c7 zeroski, 1994, Muggleton, 1991, Muggleton, 1992]. Discuss preprocessing,\npostprocessing, bottom-up\nmethods, and LINUS.\n7.6 Relationships Between ILP and Decision\nTree Induction\nThe generic ILP algorithm can also be understood as a type of decision tree\ninduction. Recall the problem of inducing decision trees when the values of\nattributes are categorical. When splitting on a single variable, the split at\neach node involves asking to which of several mutually exclusive and exhaustive\nsubsets the value of a variable belongs. For example, if a node tested the variable\nxi, and if xi could have values drawn from {A,B,C,D,E,F }, then one possible\nsplit (among many) might be according to whether the value of xi had as value\none of {A,B,C }or one of {D,E,F }.\nIt is also possible to make a multi-variate splittesting the values of two or\nmore variables at a time. With categorical variables, an n-variable split would\nbe based on which of several n-ary relations the values of the variables satis\ufb01ed.\nFor example, if a node tested the variables xi and xj, and if xi and xj both\ncould have values drawn from {A,B,C,D,E,F }, then one possible binary split'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 110, 'page_label': '111'}, page_content='102 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n(among many) might be according to whether or not < xi,xj > satis\ufb01ed the\nrelation {<A,C >,<C,D> }. (Note that our subset method of forming single-\nvariable splits could equivalently have been framed using 1-ary relationswhich\nare usually called properties.)\nIn this framework, the ILP problem is as follows: We are given a training set,\n\u039e, of positively and negatively labeled patterns whose components are drawn\nfrom a set of variables {x,y,z,... }. The positively labeled patterns in \u039e form an\nextensional de\ufb01nition of a relation, R. We are also given background relations,\nR1,...,R k, on various subsets of these variables. (That is, we are given sets\nof tuples that are in these relations.) We desire to construct an intensional\nde\ufb01nition of Rin terms of the R1,...,R k, such that all of the positively labeled\npatterns in \u039e are satis\ufb01ed by R and none of the negatively labeled patterns\nare. The intensional de\ufb01nition will be in terms of a logic program in which the\nrelation R is the head of a set of clauses whose bodies involve the background\nrelations.\nThe generic ILP algorithm can be understood as decision tree induction,\nwhere each node of the decision tree is itself a sub-decision tree, and each sub-\ndecision tree consists of nodes that make binary splits on several variables using\nthe background relations, Ri. Thus we will speak of a top-level decision tree\nand various sub-decision trees. (Actually, our decision trees will be decision\nlistsa special case of decision trees, but we will refer to them as trees in our\ndiscussions.)\nIn broad outline, the method for inducing an intensional version of the rela-\ntion R is illustrated by considering the decision tree shown in Fig. 7.5. In this\ndiagram, the patterns in \u039e are \ufb01rst \ufb01ltered through the decision tree in top-\nlevel node 1. The background relation R1 is satis\ufb01ed by some of these patterns;\nthese are \ufb01ltered to the right (to relation R2), and the rest are \ufb01ltered to the\nleft (more on what happens to these later). Right-going patterns are \ufb01ltered\nthrough a sequence of relational tests until only positively labeled patterns sat-\nisfy the last relationin this case R3. That is, the subset of patterns satisfying\nall the relations, R1, R2, and R3 contains only positive instances from \u039e. (We\nmight say that this combination of tests is necessary. They correspond to the\nclause created in the \ufb01rst pass through the inner loop of the generic ILP algo-\nrithm.) Let us call the subset of patterns satisfying these relations, \u039e 1; these\nsatisfy Node 1 at the top level. All other patterns, that is {\u039e \u2212\u039e1}= \u039e2 are\n\ufb01ltered to the left by Node 1.\n\u039e2 is then \ufb01ltered by top-level Node 2 in much the same manner, so that\nNode 2 is satis\ufb01ed only by the positively labeled samples in \u039e 2. We continue\n\ufb01ltering through top-level nodes until only the negatively labeled patterns fail to\nsatisfy a top node. In our example, \u039e 4 contains only negatively labeled patterns\nand the union of \u039e 1 and \u039e3 contains all the positively labeled patterns. The\nrelation, R, that distinguishes positive from negative patterns in \u039e is then given\nin terms of the following logic program:\nR :- R1, R2, R3'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 111, 'page_label': '112'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION103\nR1\nR2\nR3\nT\nT\nT\nF\nF\nF\nT\nF\nR4\nR5\nT\nT\nF\nF\nTF\nU\nU1\nU2 = U < U1\nU3U4= U2 < U3\nNode 1\nNode 2\n(only positive\ninstances\nsatisfy all three\ntests)\n(only positivel\ninstances satisfy\nthese two tests)\n(only negative\ninstances)\nFigure 7.5: A Decision Tree for ILP\n:- R4, R5\nIf we apply this sort of decision-tree induction procedure to the problem\nof generating a logic program for the relation Nonstop (refer to Fig. 7.3), we\nobtain the decision tree shown in Fig. 7.6. The logic program resulting from\nthis decision tree is the same as that produced by the generic ILP algorithm.\nIn setting up the problem, the training set, \u039e can be expressed as a set of 2-\ndimensional vectors with components xand y. The values of these components\nrange over the cities {A,B,C,A 1,A2,B1,B2,C1,C2}except (for simplicity)\nwe do not allow patterns in which x and y have the same value. As before, the\nrelation, Nonstop, contains the following pairs of cities, which are the positive\ninstances:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nAll other pairs of cities named in the map of Fig. 7.3 (using the closed world\nassumption) are not in the relation Nonstop and thus are negative instances.\nBecause the values of xand y are categorical, decision-tree induction would\nbe a very di\ufb03cult taskinvolving as it does the need to invent relations on'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 112, 'page_label': '113'}, page_content='104 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nx and y to be used as tests. But with the background relations, Ri (in this\ncase Hub and Satellite), the problem is made much easier. We select these\nrelations in the same way that we select literals; from among the available tests,\nwe make a selection based on which leads to the largest value of \u03bbRi.\n7.7 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 113, 'page_label': '114'}, page_content='7.7. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 105\nHub(x) T\nF\nU\nNode 1\n(top level)\n{<A,B>, <A,C>,\n<B,C>, <B,A>,\n<C,A>, <C,B>}\nHub(y) T\nT\nFNode 2\n(top level)\nSatellite(x,y)\nF T\nT {<A1,A>, <A2,A>, <B1,B>,\n<B2,B>, <C1,C>, <C2,C>}\nF\n{<A,A1>, <A,A2>,<B,B1>,\n<B,B2>,  <C,C1>, <C,C2>}\nSatellite(y,x)\nF\nF\nT\nNode 3\n(top level)\nT\n{Only negative instances}\n(Only positive instances)\n(Only positive instances)\n(Only positive instances)\nF\nFigure 7.6: A Decision Tree for the Airline Route Problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 114, 'page_label': '115'}, page_content='106 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 115, 'page_label': '116'}, page_content='Chapter 8\nComputational Learning\nTheory\nIn chapter one we posed the problem of guessing a function given a set of\nsample inputs and their values. We gave some intuitive arguments to support\nthe claim that after seeing only a small fraction of the possible inputs (and\ntheir values) that we could guess almost correctly the values of most subsequent\ninputsif we knew that the function we were trying to guess belonged to an\nappropriately restricted subset of functions. That is, a given training set of\nsample patterns might be adequate to allow us to select a function, consistent\nwith the labeled samples , from among a restricted set of hypotheses such that\nwith high probability the function we select will be approximately correct (small\nprobability of error) on subsequent samples drawn at random according to the\nsame distribution from which the labeled samples were drawn. This insight\nled to the theory of probably approximately correct (PAC) learninginitially\ndeveloped by Leslie Valiant [Valiant, 1984]. We present here a brief description\nof the theory for the case of Boolean functions. [Dietterich, 1990, Haussler, 1988,\nHaussler, 1990] give nice surveys of the important results. Other overviews?\n8.1 Notation and Assumptions for PAC Learn-\ning Theory\nWe assume a training set \u039e of n-dimensional vectors, Xi, i = 1 ,...,m , each\nlabeled (by 1 or 0) according to a target function, f, which is unknown to\nthe learner. The probability of any given vector X being in \u039e, or later being\npresented to the learner, is P(X). The probability distribution, P, can be\narbitrary. (In the literature of PAC learning theory, the target function is usually\ncalled the target concept and is denoted by c, but to be consistent with our\nprevious notation we will continue to denote it by f.) Our problem is to guess\n107'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 116, 'page_label': '117'}, page_content='108 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\na function, h(X), based on the labeled samples in \u039e. In PAC theory such a\nguessed function is called the hypothesis. We assume that the target function\nis some element of a set of functions, C. We also assume that the hypothesis,\nh, is an element of a set, H, of hypotheses, which includes the set, C, of target\nfunctions. His called the hypothesis space.\nIn general, h wont be identical to f, but we can strive to have the value of\nh(X) = the value of f(X) for most Xs. That is, we want hto be approximately\ncorrect. To quantify this notion, we de\ufb01ne the error of h, \u03b5h, as the probability\nthat an X drawn randomly according to P will be misclassi\ufb01ed:\n\u03b5h =\n\u2211\n[X:h(X)\u0338=f(X)]\nP(X)\nBoldface symbols need to be\nsmaller when they are subscripts in\nmath environments. We say that h is approximately (except for \u03b5 ) correct if \u03b5h \u2264\u03b5, where \u03b5 is the\naccuracy parameter.\nSuppose we are able to \ufb01nd anhthat classi\ufb01es all mrandomly drawn training\nsamples correctly; that is, h is consistent with this randomly selected training\nset, \u039e. If m is large enough, will such an h be approximately correct (and\nfor what value of \u03b5)? On some training occasions, using m randomly drawn\ntraining samples, such an h might turn out to be approximately correct (for a\ngiven value of \u03b5), and on others it might not. We say that his probably (except\nfor \u03b4) approximately correct (PAC) if the probability that it is approximately\ncorrect is greater than 1\u2212\u03b4, where \u03b4is the con\ufb01dence parameter. We shall show\nthat if m is greater than some bound whose value depends on \u03b5 and \u03b4, such an\nh is guaranteed to be probably approximately correct.\nIn general, we say that a learning algorithm PAC-learns functions from Cin\nterms of Hi\ufb00 for every function f\u03f5 C, it outputs a hypothesis h\u03f5 H, such that\nwith probability at least (1 \u2212\u03b4), \u03b5h \u2264\u03b5. Such a hypothesis is called probably\n(except for \u03b4) approximately (except for \u03b5) correct.\nWe want learning algorithms that are tractable, so we want an algorithm\nthat PAC-learns functions in polynomial time. This can only be done for certain\nclasses of functions. If there are a \ufb01nite number of hypotheses in a hypothesis\nset (as there are for many of the hypothesis sets we have considered), we could\nalways produce a consistent hypothesis from this set by testing all of them\nagainst the training data. But if there are an exponential number of hypotheses,\nthat would take exponential time. We seek training methods that produce\nconsistent hypotheses in less time. The time complexities for various hypothesis\nsets have been determined, and these are summarized in a table to be presented\nlater.\nA class, C, is polynomially PAC learnable in terms of Hprovided there exists\na polynomial-time learning algorithm (polynomial in the number of samples\nneeded, m, in the dimension, n, in 1 /\u03b5, and in 1 /\u03b4) that PAC-learns functions\nin Cin terms of H.\nInitial work on PAC assumed H= C, but it was later shown that some func-\ntions cannot be polynomially PAC-learned under such an assumption (assuming'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 117, 'page_label': '118'}, page_content='8.2. PAC LEARNING 109\nP \u0338= NP)but can be polynomially PAC-learned if His a strict superset of C!\nAlso our de\ufb01nition does not specify the distribution, P, from which patterns\nare drawn nor does it say anything about the properties of the learning algo-\nrithm. Since Cand Hdo not have to be identical, we have the further restrictive\nde\ufb01nition:\nA properly PAC-learnableclass is a classCfor which there exists an algorithm\nthat polynomially PAC-learns functions from Cin terms of C.\n8.2 PAC Learning\n8.2.1 The Fundamental Theorem\nSuppose our learning algorithm selects some hrandomly from among those that\nare consistent with the values of f on the mtraining patterns. The probability\nthat the error of this randomly selected his greater than some \u03b5, with hconsis-\ntent with the values of f(X) for minstances of X (drawn according to arbitrary\nP), is less than or equal to |H|e\u2212\u03b5m, where |H|is the number of hypotheses in\nH. We state this result as a theorem [Blumer, et al., 1987]:\nTheorem 8.1 (Blumer, et al.) Let Hbe any set of hypotheses, \u039e be a set of\nm \u22651 training examples drawn independently according to some distribution\nP, f be any classi\ufb01cation function in H, and \u03b5> 0. Then, the probability that\nthere exists a hypothesis hconsistent with f for the members of \u039e but with error\ngreater than \u03b5 is at most |H|e\u2212\u03b5m.\nProof:\nConsider the set of all hypotheses, {h1,h2,...,h i,...,h S}, in H, where S =\n|H|. The error for hi is \u03b5hi= the probability that hi will classify a pattern in\nerror (that is, di\ufb00erently than f would classify it). The probability that hi will\nclassify a pattern correctly is (1\u2212\u03b5hi). A subset, HB, of Hwill have error greater\nthan \u03b5. We will call the hypotheses in this subset bad. The probability that any\nparticular one of these bad hypotheses, sayhb, would classify a pattern correctly\nis (1\u2212\u03b5hb). Since \u03b5hb >\u03b5, the probability that hb (or any other bad hypothesis)\nwould classify a pattern correctly is less than (1 \u2212\u03b5). The probability that it\nwould classify all m independently drawn patterns correctly is then less than\n(1 \u2212\u03b5)m.\nThat is,\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB] \u2264(1 \u2212\u03b5)m.\nprob[some h \u03f5HB classi\ufb01es all m patterns correctly]\n= \u2211\nhb \u03f5 HB\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB]\n\u2264K(1 \u2212\u03b5)m, where K = |HB|.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 118, 'page_label': '119'}, page_content='110 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nThat is,\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n\u2264K(1 \u2212\u03b5)m.\nSince K \u2264|H| and (1 \u2212\u03b5)m \u2264e\u2212\u03b5m, we have:\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n= prob[there is a hypothesis with error >\u03b5 and that classi\ufb01es all mpatterns\ncorrectly] \u2264|H|e\u2212\u03b5m.\nQED\nA corollary of this theorem is:\nCorollary 8.2 Given m \u2265 (1/\u03b5)(ln |H|+ ln(1/\u03b4)) independent samples, the\nprobability that there exists a hypothesis in Hthat is consistent with f on these\nsamples and has error greater than \u03b5 is at most \u03b4.\nProof: We are to \ufb01nd a bound on m that guarantees that\nprob[there is a hypothesis with error > \u03b5and that classi\ufb01es all m patterns\ncorrectly] \u2264 \u03b4. Thus, using the result of the theorem, we must show that\n|H|e\u2212\u03b5m \u2264\u03b4. Taking the natural logarithm of both sides yields:\nln |H|\u2212\u03b5m\u2264ln \u03b4\nor\nm\u2265(1/\u03b5)(ln |H|+ ln(1/\u03b4))\nQED\nThis corollary is important for two reasons. First it clearly states that we\ncan select any hypothesis consistent with the m samples and be assured that\nwith probability (1 \u2212\u03b4) its error will be less than \u03b5. Also, it shows that in\norder for mto increase no more than polynomially with n, |H|can be no larger\nthan 2O(nk). No class larger than that can be guaranteed to be properly PAC\nlearnable.\nHere is a possible point of confusion: The bound given in the corollary is\nan upper bound on the value of mneeded to guarantee polynomial probably ap-\nproximately correct learning. Values of mgreater than that bound are su\ufb03cient\n(but might not be necessary). We will present a lower (necessary) bound later\nin the chapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 119, 'page_label': '120'}, page_content='8.2. PAC LEARNING 111\n8.2.2 Examples\nTerms\nLet Hbe the set of terms (conjunctions of literals). Then, |H|= 3n, and\nm\u2265(1/\u03b5)(ln(3n) + ln(1/\u03b4))\n\u2265(1/\u03b5)(1.1n+ ln(1/\u03b4))\nNote that the bound on m increases only polynomially with n, 1/\u03b5, and 1/\u03b4.\nFor n= 50, \u03b5= 0.01 and \u03b4= 0.01, m\u22655,961 guarantees PAC learnability.\nIn order to show that terms are properly PAC learnable , we additionally\nhave to show that one can \ufb01nd in time polynomial in m and n a hypothesis\nh consistent with a set of m patterns labeled by the value of a term. The\nfollowing procedure for \ufb01nding such a consistent hypothesis requires O(nm)\nsteps (adapted from [Dietterich, 1990, page 268]):\nWe are given a training sequence, \u039e, of m examples. Find the \ufb01rst pattern,\nsay X1, in that list that is labeled with a 1. Initialize a Boolean function,\nh, to the conjunction of the n literals corresponding to the values of the n\ncomponents of X1. (Components with value 1 will have corresponding positive\nliterals; components with value 0 will have corresponding negative literals.) If\nthere are no patterns labeled by a 1, we exit with the null concept ( h \u22610 for\nall patterns). Then, for each additional pattern, Xi, that is labeled with a 1,\nwe delete from h any Boolean variables appearing in Xi with a sign di\ufb00erent\nfrom their sign in h. After processing all the patterns labeled with a 1, we check\nall of the patterns labeled with a 0 to make sure that none of them is assigned\nvalue 1 by h. If, at any stage of the algorithm, any patterns labeled with a 0\nare assigned a 1 by h, then there exists no term that consistently classi\ufb01es the\npatterns in \u039e, and we exit with failure. Otherwise, we exit with h. Change this paragraph if this\nalgorithm was presented in Chapter\nThree.As an example, consider the following patterns, all labeled with a 1 (from\n[Dietterich, 1990]):\n(0,1,1,0)\n(1,1,1,0)\n(1,1,0,0)\nAfter processing the \ufb01rst pattern, we have h = x1x2x3x4; after processing the\nsecond pattern, we have h = x2x3x4; \ufb01nally, after the third pattern, we have\nh= x2x4.\nLinearly Separable Functions\nLet Hbe the set of all linearly separable functions. Then, |H|\u2264 2n2\n, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 120, 'page_label': '121'}, page_content='112 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nm\u2265(1/\u03b5)\n(\nn2 ln 2 + ln(1/\u03b4)\n)\nAgain, note that the bound on m increases only polynomially with n, 1/\u03b5, and\n1/\u03b4.\nFor n= 50, \u03b5= 0.01 and \u03b4 = 0.01, m\u2265173,748 guarantees PAC learnabil-\nity.\nTo show that linearly separable functions are properly PAC learnable , we\nwould have additionally to show that one can \ufb01nd in time polynomial in mand\nna hypothesis hconsistent with a set of mlabeled linearly separable patterns.Linear programming is polynomial.\n8.2.3 Some Properly PAC-Learnable Classes\nSome properly PAC-learnable classes of functions are given in the following\ntable. (Adapted from [Dietterich, 1990, pages 262 and 268] which also gives\nreferences to proofs of some of the time complexities.)\nH |H| Time Complexity P. Learnable?\nterms 3n polynomial yes\nk-term DNF 2O(kn) NP-hard no\n(k disjunctive terms)\nk-DNF 2O(nk) polynomial yes\n(a disjunction of k-sized terms)\nk-CNF 2O(nk) polynomial yes\n(a conjunction of k-sized clauses)\nk-DL 2O(nkklg n) polynomial yes\n(decision lists with k-sized terms)\nlin. sep. 2O(n2) polynomial yes\nlin. sep. with (0,1) weights ? NP-hard no\nk-2NN ? NP-hard no\nDNF 22n\npolynomial no\n(all Boolean functions)\n(Members of the class k-2NN are two-layer, feedforward neural networks with\nexactly k hidden units and one output unit.)\nSummary: In order to show that a class of functions is Properly PAC-\nLearnable :\na. Show that there is an algorithm that produces a consistent hypothesis on\nm n-dimensional samples in time polynomial in m and n.\nb. Show that the sample size, m, needed to ensure PAC learnability is polyno-\nmial (or better) in (1/\u03b5), (1/\u03b4), and nby showing that ln|H|is polynomial\nor better in the number of dimensions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 121, 'page_label': '122'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 113\nAs hinted earlier, sometimes enlarging the class of hypotheses makes learning\neasier. For example, the table above shows that k-CNF is PAC learnable, but\nk-term-DNF is not. And yet, k-term-DNF is a subclass of k-CNF! So, even if\nthe target function were in k-term-DNF, one would be able to \ufb01nd a hypothesis\nin k-CNF that is probably approximately correct for the target function. Sim-\nilarly, linearly separable functions implemented by TLUs whose weight values\nare restricted to 0 and 1 are not properly PAC learnable, whereas unrestricted\nlinearly separable functions are. It is possible that enlarging the space of hy-\npotheses makes \ufb01nding one that is consistent with the training examples easier.\nAn interesting question is whether or not the class of functions ink-2NN is poly-\nnomially PAC learnable if the hypotheses are drawn from k\u2032-2NN with k\u2032>k .\n(At the time of writing, this matter is still undecided.)\nAlthough PAC learning theory is a powerful analytic tool, it (like complexity\ntheory) deals mainly with worst-case results. The fact that the class of two-\nlayer, feedforward neural networks is not polynomially PAC learnable is more an\nattack on the theory than it is on the networks, which have had many successful\napplications. As [Baum, 1994, page 416-17] says:  ... humans are capable of\nlearning in the natural world. Therefore, a proof within some model of learning\nthat learning is not feasible is an indictment of the model. We should examine\nthe model to see what constraints can be relaxed and made more realistic.\n8.3 The Vapnik-Chervonenkis Dimension\n8.3.1 Linear Dichotomies\nConsider a set, H, of functions, and a set, \u039e, of (unlabeled) patterns. One\nmeasure of the expressive power of a set of hypotheses, relative to \u039e, is its\nability to make arbitrary classi\ufb01cations of the patterns in \u039e. 1 If there are m\npatterns in \u039e, there are 2 m di\ufb00erent ways to divide these patterns into two\ndisjoint and exhaustive subsets. We say there are 2 m di\ufb00erent dichotomies of\n\u039e. If \u039e were to include all of the 2 n Boolean patterns, for example, there are\n22n\nways to dichotomize them, and (of course) the set of all possible Boolean\nfunctions dichotomizes them in all of these ways. But a subset,H, of the Boolean\nfunctions might not be able to dichotomize an arbitrary set, \u039e, of m Boolean\npatterns in all 2 m ways. In general (that is, even in the non-Boolean case), we\nsay that if a subset, H, of functions can dichotomize a set, \u039e, of m patterns in\nall 2m ways, then Hshatters \u039e.\nAs an example, consider a set \u039e of m patterns in the n-dimensional space,\nRn. (That is, the ncomponents of these patterns are real numbers.) We de\ufb01ne\na linear dichotomy as one implemented by an (n\u22121)-dimensional hyperplane in\nthe n-dimensional space. How many linear dichotomies of m patterns in n di-\nmensions are there? For example, as shown in Fig. 8.1, there are 14 dichotomies\n1And, of course, if a hypothesis drawn from a set that could make arbitrary classi\ufb01cations\nof a set of training patterns, there is little likelihood that such a hypothesis will generalize\nwell beyond the training set.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 122, 'page_label': '123'}, page_content='114 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nof four points in two dimensions (each separating line yields two dichotomies\ndepending on whether the points on one side of the line are classi\ufb01ed as 1 or 0).\n(Note that even though there are an in\ufb01nite number of hyperplanes, there are,\nnevertheless, only a \ufb01nite number of ways in which hyperplanes can dichotomize\na \ufb01nite number of patterns. Small movements of a hyperplane typically do not\nchange the classi\ufb01cations of any patterns.)\n12\n3\n4\n14 dichotomies of 4 points in 2 dimensions\n5\n6\n7\nFigure 8.1: Dichotomizing Points in Two Dimensions\nThe number of dichotomies achievable by hyperplanes depends on how the\npatterns are disposed. For the maximum number of linear dichotomies, the\npoints must be in what is called general position. For m>n , we say that a set\nof m points is in general position in an n-dimensional space if and only if no\nsubset of (n+1) points lies on an (n\u22121)-dimensional hyperplane. When m\u2264n,\na set of m points is in general position if no ( m\u22122)-dimensional hyperplane\ncontains the set. Thus, for example, a set of m\u22654 points is in general position\nin a three-dimensional space if no four of them lie on a (two-dimensional) plane.\nWe will denote the number of linear dichotomies of mpoints in general position\nin an n-dimensional space by the expression \u03a0 L(m,n).\nIt is not too di\ufb03cult to verify that:Include the derivation.\n\u03a0L(m,n) = 2\nn\u2211\ni=0\nC(m\u22121,i) for m>n, and\n= 2m for m\u2264n'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 123, 'page_label': '124'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 115\nwhere C(m\u22121,i) is the binomial coe\ufb03cient (m\u22121)!\n(m\u22121\u2212i)!i! .\nThe table below shows some values for \u03a0 L(m,n).\nm n\n(no. of patterns) (dimension)\n1 2 3 4 5\n1 2 2 2 2 2\n2 4 4 4 4 4\n3 6 8 8 8 8\n4 8 14 16 16 16\n5 10 22 30 32 32\n6 12 32 52 62 64\n7 14 44 84 114 126\n8 16 58 128 198 240\nNote that the class of linear dichotomies shatters the m patterns if m\u2264n+ 1.\nThe bold-face entries in the table correspond to the highest values of m for\nwhich linear dichotomies shatter m patterns in n dimensions.\n8.3.2 Capacity\nLet Pm,n = \u03a0L(m,n)\n2m = the probability that a randomly selected dichotomy (out\nof the 2 m possible dichotomies of m patterns in n dimensions) will be linearly\nseparable. In Fig. 8.2 we plot P\u03bb(n+1),n versus \u03bb and n, where \u03bb= m/(n+ 1).\nNote that for large n (say n >30) how quickly Pm,n falls from 1 to 0 as\nm goes above 2( n+ 1). For m <2(n+ 1), any dichotomy of the m points is\nalmost certainly linearly separable. But for m> 2(n+ 1), a randomly selected\ndichotomy of the m points is almost certainly not linearly separable. For this\nreason m= 2(n+ 1) is called the capacity of a TLU [Cover, 1965]. Unless the\nnumber of training patterns exceeds the capacity, the fact that a TLU separates\nthose training patterns according to their labels means nothing in terms of how\nwell that TLU will generalize to new patterns. There is nothing special about\na separation found for m <2(n+ 1) patternsalmost any dichotomy of those\npatterns would have been linearly separable. To make sure that the separation\nfound is forced by the training set and thus generalizes well, it has to be the\ncase that there are very few linearly separable functions that would separate\nthe m training patterns.\nAnalogous results about the generalizing abilities of neural networks have\nbeen developed by [Baum & Haussler, 1989] and given intuitive and experimen-\ntal justi\ufb01cation in [Baum, 1994, page 438]:\nThe results seemed to indicate the following heuristic rule holds. If\nM examples [can be correctly classi\ufb01ed by] a net withW weights (for\nM >>W), the net will make a fraction \u03b5of errors on new examples\nchosen from the same [uniform] distribution where \u03b5= W/M.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 124, 'page_label': '125'}, page_content='116 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n0.25\n0.5\n0.75\n1\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n25\n.5\n75\n1\nPh(n + 1), n\nh\nn\nFigure 8.2: Probability that a Random Dichotomy is Linearly Separable\n8.3.3 A More General Capacity Result\nCorollary 7.2 gave us an expression for the number of training patterns su\ufb03cient\nto guarantee a required level of generalizationassuming that the function we\nwere guessing was a function belonging to a class of known and \ufb01nite cardinality.\nThe capacity result just presented applies to linearly separable functions for non-\nbinary patterns. We can extend these ideas to general dichotomies of non-binary\npatterns.\nIn general, let us denote the maximum number of dichotomies of any set\nof m n-dimensional patterns by hypotheses in Has \u03a0H(m,n). The number of\ndichotomies will, of course, depend on the disposition of the m points in the\nn-dimensional space; we take \u03a0 H(m,n) to be the maximum over all possible\narrangements of the m points. (In the case of the class of linearly separable\nfunctions, the maximum number is achieved when the m points are in general\nposition.) For each class, H, there will be some maximum value of mfor which\n\u03a0H(m,n) = 2m, that is, for which Hshatters the m patterns. This maximum\nnumber is called the Vapnik-Chervonenkis (VC) dimension and is denoted by\nVCdim(H) [Vapnik & Chervonenkis, 1971].\nWe saw that for the class of linear dichotomies, VCdim( Linear) = (n+ 1).\nAs another example, let us calculate the VC dimension of the hypothesis space\nof single intervals on the real lineused to classify points on the real line. We\nshow an example of how points on the line might be dichotomized by a single\ninterval in Fig. 8.3. The set \u039e could be, for example, {0.5, 2.5, - 2.3, 3.14}, and\none of the hypotheses in our set would be [1, 4.5]. This hypothesis would label\nthe points 2.5 and 3.14 with a 1 and the points - 2.3 and 0.5 with a 0. This'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 125, 'page_label': '126'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 117\nset of hypotheses (single intervals on the real line) can arbitrarily classify any\ntwo points. But no single interval can classify three points such that the outer\ntwo are classi\ufb01ed as 1 and the inner one as 0. Therefore the VC dimension of\nsingle intervals on the real line is 2. As soon as we have many more than 2\ntraining patterns on the real line and provided we know that the classi\ufb01cation\nfunction we are trying to guess is a single interval, then we begin to have good\ngeneralization.\nFigure 8.3: Dichotomizing Points by an Interval\nThe VC dimension is a useful measure of the expressive power of a hypothesis\nset. Since any dichotomy of VCdim(H) or fewer patterns in general position inn\ndimensions can be achieved by some hypothesis in H, we must have many more\nthan VCdim(H) patterns in the training set in order that a hypothesis consistent\nwith the training set is su\ufb03ciently constrained to imply good generalization.\nOur examples have shown that the concept of VC dimension is not restricted\nto Boolean functions.\n8.3.4 Some Facts and Speculations About the VC Dimen-\nsion\n If there are a \ufb01nite number, |H|, of hypotheses in H, then:\nVCdim(H) \u2264log(|H|)\n The VC dimension of terms in n dimensions is n.\n Suppose we generalize our example that used a hypothesis set of single\nintervals on the real line. Now let us consider an n-dimensional feature\nspace and tests of the form Li \u2264xi \u2264Hi. We allow only one such test per\ndimension. A hypothesis space consisting of conjunctions of these tests\n(called axis-parallel hyper-rectangles) has VC dimension bounded by:\nn\u2264 VCdim \u22642n\n As we have already seen, TLUs with n inputs have a VC dimension of\nn+ 1.\n [Baum, 1994, page 438] gives experimental evidence for the proposition\nthat  ... multilayer [neural] nets have a VC dimension roughly equal to\ntheir total number of [adjustable] weights.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 126, 'page_label': '127'}, page_content='118 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n8.4 VC Dimension and PAC Learning\nThere are two theorems that connect the idea of VC dimension with PAC learn-\ning [Blumer, et al., 1990]. We state these here without proof.\nTheorem 8.3 (Blumer, et al.) A hypothesis space His PAC learnable i\ufb00 it\nhas \ufb01nite VC dimension.\nTheorem 8.4 A set of hypotheses, H, is properly PAC learnable if:\na. m\u2265(1/\u03b5) max [4 lg(2/\u03b4), 8 VCdim lg(13 /\u03b5)], and\nb. if there is an algorithm that outputs a hypothesis h\u03f5 Hconsistent with the\ntraining set in polynomial (in m and n) time.\nThe second of these two theorems improves the bound on the number of\ntraining patterns needed for linearly separable functions to one that is linear\nin n. In our previous example of how many training patterns were needed to\nensure PAC learnability of a linearly separable function if n= 50, \u03b5= 0.01, and\n\u03b4 = 0.01, we obtained m \u2265173,748. Using the Blumer, et al. result we would\nget m\u226552,756.\nAs another example of the second theorem, let us take Hto be the set of\nclosed intervals on the real line. The VC dimension is 2 (as shown previously).\nWith n= 50, \u03b5= 0.01, and \u03b4= 0.01, m\u226516,551 ensures PAC learnability.\nThere is also a theorem that gives a lower (necessary) bound on the number\nof training patterns required for PAC learning [Ehrenfeucht, et al., 1988]:\nTheorem 8.5 Any PAC learning algorithm must examine at least\n\u2126(1/\u03b5lg(1/\u03b4) + VCdim(H)) training patterns.\nThe di\ufb00erence between the lower and upper bounds is\nO(log(1/\u03b5)VCdim(H)/\u03b5).\n8.5 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 127, 'page_label': '128'}, page_content='Chapter 9\nUnsupervised Learning\n9.1 What is Unsupervised Learning?\nConsider the various sets of points in a two-dimensional space illustrated in Fig.\n9.1. The \ufb01rst set (a) seems naturally partitionable into two classes, while the\nsecond (b) seems di\ufb03cult to partition at all, and the third (c) is problematic.\nUnsupervised learning uses procedures that attempt to \ufb01nd natural partitions\nof patterns. There are two stages:\n Form an R-way partition of a set \u039e of unlabeled training patterns (where\nthe value of R, itself, may need to be induced from the patterns). The\npartition separates \u039e into R mutually exclusive and exhaustive subsets,\n\u039e1,..., \u039eR, called clusters.\n Design a classi\ufb01er based on the labels assigned to the training patterns by\nthe partition.\nWe will explain shortly various methods for deciding how many clusters there\nshould be and for separating a set of patterns into that many clusters. We can\nbase some of these methods, and their motivation, on minimum-description-\nlength (MDL) principles. In that setting, we assume that we want to encode\na description of a set of points, \u039e, into a message of minimal length. One\nencoding involves a description of each point separately; other, perhaps shorter,\nencodings might involve a description of clusters of points together with how\neach point in a cluster can be described given the cluster it belongs to. The\nspeci\ufb01c techniques described in this chapter do not explicitly make use of MDL\nprinciples, but the MDL method has been applied with success. One of the\nMDL-based methods, Autoclass II [Cheeseman, et al., 1988] discovered a new\nclassi\ufb01cation of stars based on the properties of infrared sources.\nAnother type of unsupervised learning involves \ufb01nding hierarchies of par-\ntitionings or clusters of clusters. A hierarchical partition is one in which \u039e is\n119'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 128, 'page_label': '129'}, page_content='120 CHAPTER 9. UNSUPERVISED LEARNING\na)  two clusters\nb) one cluster\nc) ?\nFigure 9.1: Unlabeled Patterns\ndivided into mutually exclusive and exhaustive subsets, \u039e 1,..., \u039eR; each set,\n\u039ei, ( i = 1 ,...,R ) is divided into mutually exclusive and exhaustive subsets,\nand so on. We show an example of such a hierarchical partition in Fig. 9.2.\nThe hierarchical form is best displayed as a tree, as shown in Fig. 9.3. The tip\nnodes of the tree can further be expanded into their individual pattern elements.\nOne application of such hierarchical partitions is in organizing individuals into\ntaxonomic hierarchies such as those used in botany and zoology.\n9.2 Clustering Methods\n9.2.1 A Method Based on Euclidean Distance\nMost of the unsupervised learning methods use a measure of similarity between\npatterns in order to group them into clusters. The simplest of these involves\nde\ufb01ning a distance between patterns. For patterns whose features are numeric,\nthe distance measure can be ordinary Euclidean distance between two points in\nan n-dimensional space.\nThere is a simple, iterative clustering method based on distance. It can\nbe described as follows. Suppose we have R randomly chosen cluster seekers,\nC1,..., CR. These are points in an n-dimensional space that we want to adjust\nso that they each move toward the center of one of the clusters of patterns.\nWe present the (unlabeled) patterns in the training set, \u039e, to the algorithm'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 129, 'page_label': '130'}, page_content='9.2. CLUSTERING METHODS 121\nU11\nU12\nU21\nU22\nU23\nU31\nU32\nU11 F U12 = U1\nU21 F U22 F U23 = U2\nU31 F U32 = U3\nU1 F U2 F U3 = U\nFigure 9.2: A Hierarchy of Clusters\none-by-one. For each pattern, Xi, presented, we \ufb01nd that cluster seeker, Cj,\nthat is closest to Xi and move it closer to Xi:\nCj \u2190\u2212(1 \u2212\u03b1j)Cj + \u03b1jXi\nwhere \u03b1j is a learning rate parameter for the j-th cluster seeker; it determines\nhow far Cj is moved toward Xi.\nRe\ufb01nements on this procedure make the cluster seekers move less far as\ntraining proceeds. Suppose each cluster seeker, Cj, has a mass, mj, equal to\nthe number of times that it has moved. As a cluster seekers mass increases it\nmoves less far towards a pattern. For example, we might set \u03b1j = 1/(1 + mj)\nand use the above rule together with mj \u2190\u2212mj+1. With this adjustment rule,\na cluster seeker is always at the center of gravity (sample mean) of the set of\npatterns toward which it has so far moved. Intuitively, if a cluster seeker ever\ngets within some reasonably well clustered set of patterns (and if that cluster\nseeker is the only one so located), it will converge to the center of gravity of\nthat cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 130, 'page_label': '131'}, page_content='122 CHAPTER 9. UNSUPERVISED LEARNING\nU\nU2\nU11 U12 U31 U32 U21 U22 U23\nU1 U3\nFigure 9.3: Displaying a Hierarchy as a Tree\nOnce the cluster seekers have converged, the classi\ufb01er implied by the now-\nlabeled patterns in \u039e can be based on a Voronoi partitioning of the space (based\non distances to the various cluster seekers). This kind of classi\ufb01cation, an ex-\nample of which is shown in Fig. 9.4, can be implemented by a linear machine.\nGeorgy Fedoseevich Voronoi, was a\nRussian mathematician who lived\nfrom 1868 to 1909. When basing partitioning on distance, we seek clusters whose patterns are\nas close together as possible. We can measure the badness, V, of a cluster of\npatterns, {Xi}, by computing its sample variance de\ufb01ned by:\nV = (1/K)\n\u2211\ni\n(Xi \u2212M)2\nwhere M is the sample mean of the cluster, which is de\ufb01ned to be:\nM = (1/K)\n\u2211\ni\nXi\nand K is the number of points in the cluster.\nWe would like to partition a set of patterns into clusters such that the sum of\nthe sample variances (badnesses) of these clusters is small. Of course if we have\none cluster for each pattern, the sample variances will all be zero, so we must\narrange that our measure of the badness of a partition must increase with the\nnumber of clusters. In this way, we can seek a trade-o\ufb00 between the variances of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 131, 'page_label': '132'}, page_content='9.2. CLUSTERING METHODS 123\nC1\nC2\nC3\nSeparating boundaries\nFigure 9.4: Minimum-Distance Classi\ufb01cation\nthe clusters and the number of them in a way somewhat similar to the principle\nof minimal description length discussed earlier.\nElaborations of our basic cluster-seeking procedure allow the number of clus-\nter seekers to vary depending on the distances between them and depending on\nthe sample variances of the clusters. For example, if the distance, dij, between\ntwo cluster seekers, Ci and Cj, ever falls below some threshold \u03b5, then we can\nreplace them both by a single cluster seeker placed at their center of gravity\n(taking into account their respective masses). In this way we can decrease the\noverall badness of a partition by reducing the number of clusters for compara-\ntively little penalty in increased variance.\nOn the other hand, if any of the cluster seekers, say Ci, de\ufb01nes a cluster\nwhose sample variance is larger than some amount \u03b4, then we can place a new\ncluster seeker, Cj, at some random location somewhat adjacent to Ci and reset\nthe masses of both Ci and Cj to zero. In this way the badness of the par-\ntition might ultimately decrease by decreasing the total sample variance with\ncomparatively little penalty for the additional cluster seeker. The values of the\nparameters \u03b5 and \u03b4 are set depending on the relative weights given to sample\nvariances and numbers of clusters.\nIn distance-based methods, it is important to scale the components of the\npattern vectors. The variation of values along some dimensions of the pattern\nvector may be much di\ufb00erent than that of other dimensions. One commonly\nused technique is to compute the standard deviation (i.e., the square root of the\nvariance) of each of the components over the entire training set and normalize\nthe values of the components so that their adjusted standard deviations are\nequal.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 132, 'page_label': '133'}, page_content='124 CHAPTER 9. UNSUPERVISED LEARNING\n9.2.2 A Method Based on Probabilities\nSuppose we have a partition of the training set, \u039e, into R mutually exclusive\nand exhaustive clusters, C1,...,C R. We can decide to which of these clusters\nsome arbitrary pattern, X, should be assigned by selecting the Ci for which\nthe probability, p(Ci|X), is largest, providing p(Ci|X) is larger than some \ufb01xed\nthreshold, \u03b4. As we saw earlier, we can use Bayes rule and base our decision on\nmaximizing p(X|Ci)p(Ci). Assuming conditional independence of the pattern\ncomponents, xi, the quantity to be maximized is:\nS(X,Ci) = p(x1|Ci)p(x2|Ci) ···p(xn|Ci)p(Ci)\nThe p(xj|Ci) can be estimated from the sample statistics of the patterns in the\nclusters and then used in the above expression. (Recall the linear form that this\nformula took in the case of binary-valued components.)\nWe call S(X,Ci) the similarity of X to a cluster, Ci, of patterns. Thus, we\nassign X to the cluster to which it is most similar, providing the similarity is\nlarger than \u03b4.\nJust as before, we can de\ufb01ne the sample mean of a cluster, Ci, to be:\nMi = (1/Ki)\n\u2211\nXj\u03f5 Ci\nXj\nwhere Ki is the number of patterns in Ci.\nWe can base an iterative clustering algorithm on this measure of similarity\n[Mahadevan & Connell, 1992]. It can be described as follows:\na. Begin with a set of unlabeled patterns \u039e and an empty list, L, of clusters.\nb. For the next pattern, X, in \u039e, compute S(X,Ci) for each cluster, Ci.\n(Initially, these similarities are all zero.) Suppose the largest of these\nsimilarities is S(X,Cmax).\n(a) If S(X,Cmax) >\u03b4, assign X to Cmax. That is,\nCmax \u2190\u2212Cmax \u222a{X}\nUpdate the sample statisticsp(x1|Cmax),p(x2|Cmax),...,p (xn|Cmax),\nand p(Cmax) to take the new pattern into account. Go to 3.\n(b) If S(X,Cmax) \u2264\u03b4, create a new cluster, Cnew = {X}and add Cnew\nto L. Go to 3.\nc. Merge any existing clusters, Ci and Cj if ( Mi \u2212Mj)2 < \u03b5. Compute\nnew sample statistics p(x1|Cmerge),p(x2|Cmerge),...,p (xn|Cmerge), and\np(Cmerge) for the merged cluster, Cmerge = Ci \u222aCj.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 133, 'page_label': '134'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 125\nd. If the sample statistics of the clusters have not changed during an entire\niteration through \u039e, then terminate with the clusters in L; otherwise go\nto 2.\nThe value of the parameter \u03b4 controls the number of clusters. If \u03b4 is high,\nthere will be a large number of clusters with few patterns in each cluster. For\nsmall values of \u03b4, there will be a small number of clusters with many patterns in\neach cluster. Similarly, the larger the value of \u03b5, the smaller the number clusters\nthat will be found.\nDesigning a classi\ufb01er based on the patterns labeled by the partitioning is\nstraightforward. We assign any pattern, X, to that category that maximizes\nS(X,Ci). Mention k-means and EM\nmethods.\n9.3 Hierarchical Clustering Methods\n9.3.1 A Method Based on Euclidean Distance\nSuppose we have a set, \u039e, of unlabeled training patterns. We can form a hi-\nerarchical classi\ufb01cation of the patterns in \u039e by a simple agglomerative method.\n(The description of this algorithm is based on an unpublished manuscript by\nPat Langley.) Our description here gives the general idea; we leave it to the\nreader to generate a precise algorithm.\nWe \ufb01rst compute the Euclidean distance between all pairs of patterns in \u039e.\n(Again, appropriate scaling of the dimensions is assumed.) Suppose the smallest\ndistance is between patterns Xi and Xj. We collect Xi and Xj into a cluster,\nC, eliminate Xi and Xj from \u039e and replace them by a cluster vector, C, equal\nto the average of Xi and Xj. Next we compute the Euclidean distance again\nbetween all pairs of points in \u039e. If the smallest distance is between pairs of\npatterns, we form a new cluster, C, as before and replace the pair of patterns\nin \u039e by their average. If the shortest distance is between a pattern, Xi, and\na cluster vector, Cj (representing a cluster, Cj), we form a new cluster, C,\nconsisting of the union of Cj and {Xi}. In this case, we replace Cj and Xi\nin \u039e by their (appropriately weighted) average and continue. If the shortest\ndistance is between two cluster vectors, Ci and Cj, we form a new cluster, C,\nconsisting of the union of Ci and Cj. In this case, we replace Ci and Cj by their\n(appropriately weighted) average and continue. Since we reduce the number of\npoints in \u039e by one each time, we ultimately terminate with a tree of clusters\nrooted in the cluster containing all of the points in the original training set.\nAn example of how this method aggregates a set of two dimensional patterns\nis shown in Fig. 9.5. The numbers associated with each cluster indicate the order\nin which they were formed. These clusters can be organized hierarchically in a\nbinary tree with cluster 9 as root, clusters 7 and 8 as the two descendants of the\nroot, and so on. A ternary tree could be formed instead if one searches for the\nthree points in \u039e whose triangle de\ufb01ned by those patterns has minimal area.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 134, 'page_label': '135'}, page_content='126 CHAPTER 9. UNSUPERVISED LEARNING\n1\n2 3\n5\n4\n6\n7\n8\n9\nFigure 9.5: Agglommerative Clustering\n9.3.2 A Method Based on Probabilities\nA probabilistic quality measure for partitions\nWe can develop a measure of the goodness of a partitioning based on how\naccurately we can guess a pattern given only what partition it is in. Suppose\nwe are given a partitioning of \u039e into R classes, C1,...,C R. As before, we can\ncompute the sample statistics p(xi|Ck) which give probability values for each\ncomponent given the class assigned to it by the partitioning. Suppose each\ncomponent xi of X can take on the values vij, where the index j steps over the\ndomain of that component. We use the notation pi(vij|Ck) = probability(xi =\nvij|Ck).\nSuppose we use the following probabilistic guessing rule about the values\nof the components of a vector X given only that it is in class k. Guess that\nxi = vij with probability pi(vij|Ck). Then, the probability that we guess the\ni-th component correctly is:\n\u2211\nj\nprobability(guess is vij)pi(vij|Ck) =\n\u2211\nj\n[pi(vij|Ck)]2\nThe average number of (the n) components whose values are guessed correctly\nby this method is then given by the sum of these probabilities over all of the\ncomponents of X:\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 135, 'page_label': '136'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 127\nGiven our partitioning into R classes, the goodness measure, G, of this parti-\ntioning is the average of the above expression over all classes:\nG=\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nwhere p(Ck) is the probability that a pattern is in class Ck. In order to penalize\nthis measure for having a large number of classes, we divide it by R to get an\noverall quality measure of a partitioning:\nZ = (1/R)\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nWe give an example of the use of this measure for a trivially simple\nclustering of the four three-dimensional patterns shown in Fig. 9.6. There\nare several di\ufb00erent partitionings. Lets evaluate Z values for the follow-\ning ones: P1 = {a,b,c,d }, P2 = {{a,b},{c,d}}, P3 = {{a,c},{b,d}}, and\nP4 = {{a},{b},{c},{d}}. The \ufb01rst, P1, puts all of the patterns into a single\ncluster. The sample probabilities pi(vi1 = 1) and pi(vi0 = 0) are all equal to 1/2\nfor each of the three components. Summing over the values of the components\n(0 and 1) gives (1 /2)2 + (1/2)2 = 1 /2. Summing over the three components\ngives 3/2. Averaging over all of the clusters (there is just one) also gives 3 /2.\nFinally, dividing by the number of clusters produces the \ufb01nal Z value of this\npartition, Z(P1) = 3/2.\nThe second partition, P2, gives the following sample probabilities:\np1(v11 = 1|C1) = 1\np2(v21 = 1|C1) = 1/2\np3(v31 = 1|C1) = 1\nSumming over the values of the components (0 and 1) gives (1) 2 + (0)2 = 1 for\ncomponent 1, (1 /2)2 + (1/2)2 = 1/2 for component 2, and (1) 2 + (0)2 = 1 for\ncomponent 3. Summing over the three components gives 2 1 /2 for class 1. A\nsimilar calculation also gives 2 1 /2 for class 2. Averaging over the two clusters\nalso gives 2 1 /2. Finally, dividing by the number of clusters produces the \ufb01nal\nZ value of this partition, Z(P2) = 1 1/4, not quite as high as Z(P1).\nSimilar calculations yield Z(P3) = 1 and Z(P4) = 3 /4, so this method of\nevaluating partitions would favor placing all patterns in a single cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 136, 'page_label': '137'}, page_content='128 CHAPTER 9. UNSUPERVISED LEARNING\nx2\nx3\nx1\nab\ncd\nFigure 9.6: Patterns in 3-Dimensional Space\nAn iterative method for hierarchical clustering\nEvaluating all partitionings of mpatterns and then selecting the best would be\ncomputationally intractable. The following iterative method is based on a hi-\nerarchical clustering procedure called COBWEB [Fisher, 1987]. The procedure\ngrows a tree each node of which is labeled by a set of patterns. At the end\nof the process, the root node contains all of the patterns in \u039e. The successors\nof the root node will contain mutually exclusive and exhaustive subsets of \u039e.\nIn general, the successors of a node, \u03b7, are labeled by mutually exclusive and\nexhaustive subsets of the pattern set labelling node \u03b7. The tips of the tree will\ncontain singleton sets. The method uses Z values to place patterns at the vari-\nous nodes; sample statistics are used to update the Z values whenever a pattern\nis placed at a node. The algorithm is as follows:\na. We start with a tree whose root node contains all of the patterns in \u039e\nand a single empty successor node. We arrange that at all times dur-\ning the process every non-empty node in the tree has (besides any other\nsuccessors) exactly one empty successor.\nb. Select a pattern Xi in \u039e (if there are no more patterns to select, terminate).\nc. Set µ to the root node.\nd. For each of the successors of µ(including the empty successor!), calculate\nthe best host for Xi. A best host is determined by tentatively placing\nXi in one of the successors and calculating the resulting Z value for each'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 137, 'page_label': '138'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 129\none of these ways of accomodating Xi. The best host corresponds to the\nassignment with the highest Z value.\ne. If the best host is an empty node, \u03b7, we place Xi in \u03b7, generate an empty\nsuccessor node of \u03b7, generate an empty sibling node of \u03b7, and go to 2.\nf. If the best host is a non-empty, singleton (tip) node, \u03b7, we place Xi in \u03b7,\ncreate one successor node of \u03b7 containing the singleton pattern that was\nin \u03b7, create another successor node of \u03b7 containing Xi, create an empty\nsuccessor node of \u03b7, create empty successor nodes of the new non-empty\nsuccessors of \u03b7, and go to 2.\ng. If the best host is a non-empty, non-singleton node, \u03b7, we place Xi in \u03b7,\nset µ to \u03b7, and go to 4.\nThis process is rather sensitive to the order in which patterns are presented.\nTo make the \ufb01nal classi\ufb01cation tree less order dependent, the COBWEB proce-\ndure incorporates node merging and splitting.\nNode merging:\nIt may happen that two nodes having the same parent could be merged with\nan overall increase in the quality of the resulting classi\ufb01cation performed by the\nsuccessors of that parent. Rather than try all pairs to merge, a good heuristic\nis to attempt to merge the two best hosts. When such a merging improves the\nZ value, a new node containing the union of the patterns in the merged nodes\nreplaces the merged nodes, and the two nodes that were merged are installed\nas successors of the new node.\nNode splitting:\nA heuristic for node splitting is to consider replacing the best host among a\ngroup of siblings by that hosts successors. This operation is performed only if\nit increases the Z value of the classi\ufb01cation performed by a group of siblings.\nExample results from COBWEB\nWe mention two experiments with COBWEB. In the \ufb01rst, the program at-\ntempted to \ufb01nd two categories (we will call them Class 1 and Class 2) of United\nStates Senators based on their votes ( yes or no) on six issues. After the clus-\nters were established, the majority vote in each class was computed. These are\nshown in the table below.\nIssue Class 1 Class 2\nToxic Waste yes no\nBudget Cuts yes no\nSDI Reduction no yes\nContra Aid yes no\nLine-Item Veto yes no\nMX Production yes no'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 138, 'page_label': '139'}, page_content='130 CHAPTER 9. UNSUPERVISED LEARNING\nIn the second experiment, the program attempted to classify soybean dis-\neases based on various characteristics. COBWEB grouped the diseases in the\ntaxonomy shown in Fig. 9.7.\nN0\nsoybean\ndiseases\nN1\n  Diaporthe\nStem Canker\nN2\nCharcoal\n     Rot\nN3\nN31\nRhizoctonia\n       Rot\nN32\nPhytophthora\n       Rot\nFigure 9.7: Taxonomy Induced for Soybean Diseases\n9.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 139, 'page_label': '140'}, page_content='Chapter 10\nTemporal-Di\ufb00erence\nLearning\n10.1 Temporal Patterns and Prediction Prob-\nlems\nIn this chapter, we consider problems in which we wish to learn to predict the\nfuture value of some quantity, say z, from an n-dimensional input pattern, X.\nIn many of these problems, the patterns occur in temporal sequence, X1, X2,\n. . ., Xi, Xi+1, ... , Xm, and are generated by a dynamical process. The\ncomponents of Xi are features whose values are available at time, t = i. We\ndistinguish two kinds of prediction problems. In one, we desire to predict the\nvalue of z at time t = i+ 1 based on input Xi for every i. For example, we\nmight wish to predict some aspects of tomorrows weather based on a set of\nmeasurements made today. In the other kind of prediction problem, we desire\nto make a sequence of predictions about the value of z at some \ufb01xed time, say\nt= m+ 1, based on each of the Xi, i= 1,...,m . For example, we might wish\nto make a series of predictions about some aspect of the weather on next New\nYears Day, based on measurements taken every day before New Years. Sutton\n[Sutton, 1988] has called this latter problem, multi-step prediction, and that is\nthe problem we consider here. In multi-step prediction, we might expect that\nthe prediction accuracy should get better and better as i increases toward m.\n10.2 Supervised and Temporal-Di\ufb00erence Meth-\nods\nA training method that naturally suggests itself is to use the actual value of\nz at time m+ 1 (once it is known) in a supervised learning procedure using a\n131'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 140, 'page_label': '141'}, page_content='132 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nsequence of training patterns, {X1, X2, ... , Xi, Xi+1, ... , Xm}. That is, we\nseek to learn a function, f, such that f(Xi) is as close as possible to zfor each i.\nTypically, we would need a training set, \u039e, consisting of several such sequences.\nWe will show that a method that is better than supervised learning for some\nimportant problems is to base learning on the di\ufb00erence between f(Xi+1) and\nf(Xi) rather than on the di\ufb00erence between zand f(Xi). Such methods involve\nwhat is called temporal-di\ufb00erence (TD) learning.\nWe assume that our prediction, f(X), depends on a vector of modi\ufb01able\nweights, W. To make that dependence explicit, we write f(X,W). For su-\npervised learning, we consider procedures of the following type: For each Xi,\nthe prediction f(Xi,W) is computed and compared to z, and the learning rule\n(whatever it is) computes the change, (\u2206 Wi), to be made to W. Then, taking\ninto account the weight changes for each pattern in a sequence all at once after\nhaving made all of the predictions with the old weight vector, we change W as\nfollows:\nW \u2190\u2212W +\nm\u2211\ni=1\n(\u2206W)i\nWhenever we are attempting to minimize the squared error between z and\nf(Xi,W) by gradient descent, the weight-changing rule for each pattern is:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nwhere c is a learning rate parameter, fi is our prediction of z, f(Xi,W),\nat time t = i, and \u2202fi\n\u2202W is, by de\ufb01nition, the vector of partial derivatives\n( \u2202fi\n\u2202w1\n,..., \u2202fi\n\u2202wi\n,..., \u2202fi\n\u2202wn\n) in which the wi are the individual components of W.\n(The expression \u2202fi\n\u2202W is sometimes written \u2207Wfi.) The reader will recall that\nwe used an equivalent expression for (\u2206 W)i in deriving the backpropagation\nformulas used in training multi-layer neural networks.\nThe Widrow-Ho\ufb00 rule results when f(X,W) = X W. Then:\n(\u2206W)i = c(z\u2212fi)Xi\nAn interesting form for (\u2206 W)i can be developed if we note that\n(z\u2212fi) =\nm\u2211\nk=i\n(fk+1 \u2212fk)\nwhere we de\ufb01ne fm+1 = z. Substituting in our formula for (\u2206 W)i yields:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 141, 'page_label': '142'}, page_content='10.2. SUPERVISED AND TEMPORAL-DIFFERENCE METHODS 133\n= c\u2202fi\n\u2202W\nm\u2211\nk=i\n(fk+1 \u2212fk)\nIn this form, instead of using the di\ufb00erence between a prediction and the value\nof z, we use the di\ufb00erences between successive predictionsthus the phrase\ntemporal-di\ufb00erence (TD) learning.\nIn the case when f(X,W) = X W, the temporal di\ufb00erence form of the\nWidrow-Ho\ufb00 rule is:\n(\u2206W)i = cXi\nm\u2211\nk=i\n(fk+1 \u2212fk)\nOne reason for writing (\u2206 W)i in temporal-di\ufb00erence form is to permit an\ninteresting generalization as follows:\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nwhere 0 < \u03bb\u22641. Here, the \u03bb term gives exponentially decreasing weight to\ndi\ufb00erences later in time than t = i. When \u03bb = 1, we have the same rule with\nwhich we beganweighting all di\ufb00erences equally, but as\u03bb\u21920, we weight only\nthe (fi+1 \u2212fi) di\ufb00erence. With the \u03bb term, the method is called TD( \u03bb).\nIt is interesting to compare the two extreme cases:\nFor TD(0):\n(\u2206W)i = c(fi+1 \u2212fi) \u2202fi\n\u2202W\nFor TD(1):\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nBoth extremes can be handled by the same learning mechanism; only the error\nterm is di\ufb00erent. In TD(0), the error is the di\ufb00erence between successive predic-\ntions, and in TD(1), the error is the di\ufb00erence between the \ufb01nally revealed value\nof z and the prediction. Intermediate values of \u03bb take into account di\ufb00erently\nweighted di\ufb00erences between future pairs of successive predictions.\nOnly TD(1) can be considered a puresupervised learning procedure, sensitive\nto the \ufb01nal value ofzprovided by the teacher. For\u03bb< 1, we have various degrees\nof unsupervised learning, in which the prediction function strives to make each\nprediction more like successive ones (whatever they might be). We shall soon\nsee that these unsupervised procedures result in better learning than do the\nsupervised ones for an important class of problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 142, 'page_label': '143'}, page_content='134 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n10.3 Incremental Computation of the (\u2206W)i\nWe can rewrite our formula for (\u2206 W)i, namely\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nto allow a type of incremental computation. First we write the expression for\nthe weight change rule that takes into account all of the (\u2206 W)i:\nW \u2190\u2212W +\nm\u2211\ni=1\nc\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nInterchanging the order of the summations yields:\nW \u2190\u2212W +\nm\u2211\nk=1\nc\nk\u2211\ni=1\n\u03bb(k\u2212i)(fk+1 \u2212fk) \u2202fi\n\u2202W\n= W +\nm\u2211\nk=1\nc(fk+1 \u2212fk)\nk\u2211\ni=1\n\u03bb(k\u2212i) \u2202fi\n\u2202W\nInterchanging the indices k and i \ufb01nally yields:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nIf, as earlier, we want to use an expression of the formW \u2190\u2212W+\u2211m\ni=1(\u2206W)i,\nwe see that we can write:\n(\u2206W)i = c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nNow, if we let ei = \u2211i\nk=1 \u03bb(i\u2212k) \u2202fk\n\u2202W , we can develop a computationally e\ufb03cient\nrecurrence equation for ei+1 as follows:\nei+1 =\ni+1\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W\n= \u2202fi+1\n\u2202W +\ni\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 143, 'page_label': '144'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 135\n= \u2202fi+1\n\u2202W + \u03bbei\nRewriting (\u2206W)i in these terms, we obtain:\n(\u2206W)i = c(fi+1 \u2212fi)ei\nwhere:\ne1 = \u2202f1\n\u2202W\ne2 = \u2202f2\n\u2202W + \u03bbe1\netc.\nQuoting Sutton [Sutton, 1988, page 15] (about a di\ufb00erent equation, but the\nquote applies equally well to this one):\n... this equation can be computed incrementally, because each\n(\u2206W)i depends only on a pair of successive predictions and on the\n[weighted] sum of all past values for \u2202fi\n\u2202W . This saves substantially on\nmemory, because it is no longer necessary to individually remember\nall past values of \u2202fi\n\u2202W .\n10.4 An Experiment with TD Methods\nTD prediction methods [especially TD(0)] are well suited to situations in which\nthe patterns are generated by a dynamic process. In that case, sequences of\ntemporally presented patterns contain important information that is ignored\nby a conventional supervised method such as the Widrow-Ho\ufb00 rule. Sutton\n[Sutton, 1988, page 19] gives an interesting example involving a random walk,\nwhich we repeat here. In Fig. 10.1, sequences of vectors, X, are generated as\nfollows: We start with vector XD; the next vector in the sequence is equally\nlikely to be one of the adjacent vectors in the diagram. If the next vector is\nXC (or XE), the next one after that is equally likely to be one of the vectors\nadjacent to XC (or XE). When XB is in the sequence, it is equally likely that\nthe sequence terminates with z = 0 or that the next vector is XC. Similarly,\nwhen XF is in the sequence, it is equally likely that the sequence terminates\nwith z= 1 or that the next vector is XE. Thus the sequences are random, but\nthey always start with XD. Some sample sequences are shown in the \ufb01gure.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 144, 'page_label': '145'}, page_content='136 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\nz = 0 z = 1\nXB XC XD XE XF\nTypical Sequences:\nXDXCXDXEXF  1\nXDXCXBXCXDXEXDXEXF  1\nXDXEXDXCXB  0\nFigure 10.1: A Markov Process\nThis random walk is an example of a Markov process; transitions from state i\nto state j occur with probabilities that depend only on i and j.\nGiven a set of sequences generated by this process as a training set, we want\nto be able to predict the value of z for each X in a test sequence. We assume\nthat the learning system does not know the transition probabilities.\nFor his experiments with this process, Sutton used a linear predictor, that\nis f(X,W) = X W. The learning problem is to \ufb01nd a weight vector, W, that\nminimizes the mean-squared error betweenzand the predicted value of z. Given\nthe \ufb01ve di\ufb00erent values that X can take on, we have the following predictions:\nf(XB) = w1, f(XC) = w2, f(XD) = w3, f(XE) = w4, f(XF) = w5, where\nwi is the i-th component of the weight vector. (Note that the values of the\npredictions are not limited to 1 or 0even though z can only have one of\nthose valuesbecause we are minimizing mean-squared error.) After training,\nthese predictions will be compared with the optimal onesgiven the transition\nprobabilities.\nThe experimental setup was as follows: ten random sequences were generated\nusing the transition probabilities. Each of these sequences was presented in turn\nto a TD(\u03bb) method for various values of \u03bb. Weight vector increments, (\u2206 W)i,\nwere computed after each pattern presentation but no weight changes were\nmade until all ten sequences were presented. The weight vector increments were\nsummed after all ten sequences were presented, and this sum was used to change\nthe weight vector to be used for the next pass through the ten sequences. This\nprocess was repeated over and over (using the same training sequences) until\n(quoting Sutton) the procedure no longer produced any signi\ufb01cant changes in\nthe weight vector. For small c, the weight vector always converged in this way,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 145, 'page_label': '146'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 137\nand always to the same \ufb01nal value [for 100 di\ufb00erent training sets of ten random\nsequences], independent of its initial value. (Even though, for \ufb01xed, small c,\nthe weight vector always converged to the same vector, it might converge to a\nsomewhat di\ufb00erent vector for di\ufb00erent values of c.)\nAfter convergence, the predictions made by the \ufb01nal weight vector are com-\npared with the optimal predictions made using the transition probabilities.\nThese optimal predictions are simply p(z= 1|X). We can compute these proba-\nbilities to be 1/6, 1/3, 1/2, 2/3, and 5/6 forXB, XC, XD, XE, XF, respectively.\nThe root-mean-squared di\ufb00erences between the best learned predictions (over\nall c) and these optimal ones are plotted in Fig. 10.2 for seven di\ufb00erent values\nof \u03bb. (For each data point, the standard error is approximately \u03c3= 0.01.)\n0.10\n0.12\n0.14\n0.16\n0.18\n0.20\n0.0 0.1 0.3 0.5 0.7 0.9 1.0\nh\nError using\nbest c\nWidrow-Hoff\nTD(1)\nTD(0)\n(Adapted from Sutton, p. 20, 1988)\nFigure 10.2: Prediction Errors for TD( \u03bb)\nNotice that the Widrow-Ho\ufb00 procedure does not perform as well as other\nversions of TD(\u03bb) for \u03bb< 1! Quoting [Sutton, 1988, page 21]:\nThis result contradicts conventional wisdom. It is well known that,\nunder repeated presentations, the Widrow-Ho\ufb00 procedure minimizes\nthe RMS error between its predictions and the actual outcomes in\nthe training set ([Widrow & Stearns, 1985]). How can it be that this\noptimal method peformed worse than all the TD methods for \u03bb <\n1? The answer is that the Widrow-Ho\ufb00 procedure only minimizes\nerror on the training set ; it does not necessarily minimize error for\nfuture experience. [Later] we prove that in fact it is linear TD(0)\nthat converges to what can be considered the optimal estimates for'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 146, 'page_label': '147'}, page_content='138 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nmatching future experiencethose consistent with the maximum-\nlikelihood estimate of the underlying Markov process.\n10.5 Theoretical Results\nIt is possible to analyze the performance of the linear-prediction TD(\u03bb) methods\non Markov processes. We state some theorems here without proof.\nTheorem 10.1 (Sutton, page 24, 1988) For any absorbing Markov chain,\nand for any linearly independent set of observation vectors {Xi}for the non-\nterminal states, there exists an \u03b5> 0 such that for all positive c<\u03b5 and for any\ninitial weight vector, the predictions of linear TD(0) (with weight updates after\neach sequence) converge in expected value to the optimal (maximum likelihood)\npredictions of the true process.\nEven though the expected values of the predictions converge, the predictions\nthemselves do not converge but vary around their expected values depending on\ntheir most recent experience. Sutton conjectures that if c is made to approach\n0 as training progresses, the variance of the predictions will approach 0 also.\nDayan [Dayan, 1992] has extended the result of Theorem 9.1 to TD( \u03bb) for\narbitrary \u03bb between 0 and 1. (Also see [Dayan & Sejnowski, 1994].)\n10.6 Intra-Sequence Weight Updating\nOur standard weight updating rule for TD( \u03bb) methods is:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere the weight update occurs after an entire sequence is observed. To make\nthe method truly incremental (in analogy with weight updating rules for neural\nnets), it would be desirable to change the weight vector after every pattern\npresentation. The obvious extension is:\nWi+1 \u2190\u2212Wi + c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere fi+1 is computed before making the weight change; that is, fi+1 =\nf(Xi+1,Wi). But that would make fi = f(Xi,Wi\u22121), and such a rule would\nmake the prediction di\ufb00erence, namely ( fi+1 \u2212fi), sensitive both to changes in\nX and changes in W and could lead to instabilities. Instead, we modify the rule\nso that, for every pair of predictions, fi+1 = f(Xi+1,Wi) and fi = f(Xi,Wi).\nThis version of the rule has been used in practice with excellent results.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 147, 'page_label': '148'}, page_content='10.6. INTRA-SEQUENCE WEIGHT UPDATING 139\nFor TD(0) and linear predictors, the rule is:\nWi+1 = Wi + c(fi+1 \u2212fi)Xi\nThe rule is implemented as follows:\na. Initialize the weight vector, W, arbitrarily.\nb. For i= 1,...,m , do:\n(a) fi \u2190\u2212Xi W\n(We compute fi anew each time through rather than use the value\nof fi+1 the previous time through.)\n(b) fi+1 \u2190\u2212Xi+1 W\n(c) di+1 \u2190\u2212fi+1 \u2212fi\n(d) W \u2190\u2212W + c di+1Xi\n(If fi were computed again with this changed weight vector, its value\nwould be closer to fi+1 as desired.)\nThe linear TD(0) method can be regarded as a technique for training a\nvery simple network consisting of a single dot product unit (and no threshold\nor sigmoid function). TD methods can also be used in combination with back-\npropagation to train neural networks. For TD(0) we change the network weights\naccording to the expression:\nWi+1 = Wi + c(fi+1 \u2212fi) \u2202fi\n\u2202W\nThe only change that must be made to the standard backpropagation weight-\nchanging rule is that the di\ufb00erence term between the desired output and the\noutput of the unit in the \ufb01nal ( k-th) layer, namely (d\u2212f(k)), must be replaced\nby a di\ufb00erence term between successive outputs, ( fi+1 \u2212fi). This change has a\ndirect e\ufb00ect only on the expression for \u03b4(k) which becomes:\n\u03b4(k) = 2(f\u2032(k) \u2212f(k))f(k)(1 \u2212f(k))\nwhere f\u2032(k) and f(k) are two successive outputs of the network.\nThe weight changing rule for the i-th weight vector in the j-th layer of weights\nhas the same form as before, namely:\nW(j)\ni \u2190\u2212W(j)\ni + c\u03b4(j)\ni X(j\u22121)\nwhere the \u03b4(j)\ni are given recursively by:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nand w(j+1)\nil is the l-th component of the i-th weight vector in the (j+1)-th layer\nof weights. Of course, here also it is assumed that f\u2032(k) and f(k) are computed\nusing the same weights and then the weights are changed. In the next section\nwe shall see an interesting example of this application of TD learning.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 148, 'page_label': '149'}, page_content='140 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n10.7 An Example Application: TD-gammon\nA program called TD-gammon [Tesauro, 1992] learns to play backgammon by\ntraining a neural network via temporal-di\ufb00erence methods. The structure of\nthe neural net, and its coding is as shown in Fig. 10.3. The network is trained\nto minimize the error between actual payo\ufb00 and estimated payo\ufb00, where the\nactual payo\ufb00 is de\ufb01ned to be df = p1 + 2p2 \u2212p3 \u22122p4, and the pi are the actual\nprobabilities of the various outcomes as de\ufb01ned in the \ufb01gure.\n. . . p3 = pr(black wins)\np4 = pr(black gammons)\np1 = pr(white wins)\np2 = pr(white gammons)\nestimated payoff:\nd = p1 + 2p2 < p3 < 2p4\nno. of white\non cell 1\nno. on bar,\noff board,\nand who\nmoves\n198 inputs\n1\n2\n3\n# > 3\n. . .\nup to 40 hidden units\n2 x 24\ncells\n4 output units\nhidden and output units are sigmoids\nlearning rate:  c = 0.1; initial weights chosen\nrandomly between <0.5 and +0.5.\nestimated probabilities:\nFigure 10.3: The TD-gammon Network\nTD-gammon learned by using the network to select that move that results\nin the best predicted payo\ufb00. That is, at any stage of the game some \ufb01nite set of\nmoves is possible and these lead to the set, {X}, of new board positions. Each\nmember of this set is evaluated by the network, and the one with the largest'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 149, 'page_label': '150'}, page_content='10.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 141\npredicted payo\ufb00 is selected if it is whites move (and the smallest if it is blacks).\nThe move is made, and the network weights are adjusted to make the predicted\npayo\ufb00 from the original position closer to that of the resulting position.\nThe weight adjustment procedure combines temporal-di\ufb00erence (TD( \u03bb))\nlearning with backpropagation. If dt is the networks estimate of the payo\ufb00\nat time t (before a move is made), and dt+1 is the estimate at time t+ 1 (after\na move is made), the weight adjustment rule is:\n\u2206Wt = c(dt+1 \u2212dt)\nt\u2211\nk=1\n\u03bbt\u2212k \u2202dk\n\u2202W\nwhere Wt is a vector of all weights in the network at time t, and \u2202dk\n\u2202W is the\ngradient of dk in this weight space. (For a layered, feedforward network, such\nas that of TD-gammon, the weight changes for the weight vectors in each layer\ncan be expressed in the usual manner.)\nTo make the special cases clear, recall that for TD(0), the network would be\ntrained so that, for all t, its output, dt, for input Xt tended toward its expected\noutput, dt+1, for input Xt+1. For TD(1), the network would be trained so that,\nfor all t, its output, dt, for input Xt tended toward the expected \ufb01nal payo\ufb00,\ndf, given that input. The latter case is the same as the Widrow-Ho\ufb00 rule.\nAfter about 200,000 games the following results were obtained. TD-gammon\n(with 40 hidden units, \u03bb= 0.7, and c= 0.1) won 66.2% of 10,000 games against\nSUN Microsystems Gammontool and 55% of 10,000 games against a neural\nnetwork trained using expert moves. Commenting on a later version of TD-\ngammon, incorporating special features as inputs, Tesauro said: It appears to\nbe the strongest program ever seen by this author.\n10.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 150, 'page_label': '151'}, page_content='142 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 151, 'page_label': '152'}, page_content='Chapter 11\nDelayed-Reinforcement\nLearning\n11.1 The General Problem\nImagine a robot that exists in an environment in which it can sense and act.\nSuppose (as an extreme case) that it has no idea about the e\ufb00ects of its actions.\nThat is, it doesnt know how acting will change its sensory inputs. Along with\nits sensory inputs are rewards, which it occasionally receives. How should it\nchoose its actions so as to maximize its rewards over the long run? To maximize\nrewards, it will need to be able to predict how actions change inputs, and in\nparticular, how actions lead to rewards.\nWe formalize the problem in the following way: The robot exists in an\nenvironment consisting of a set,S, of states. We assume that the robots sensory\napparatus constructs an input vector, X, from the environment, which informs\nthe robot about which state the environment is in. For the moment, we will\nassume that the mapping from states to vectors is one-to-one, and, in fact, will\nuse the notation X to refer to the state of the environment as well as to the\ninput vector. When presented with an input vector, the robot decides which\naction from a set, A, of actions to perform. Performing the action produces an\ne\ufb00ect on the environmentmoving it to a new state. The new state results in\nthe robot perceiving a new input vector, and the cycle repeats. We assume a\ndiscrete time model; the input vector at time t = i is Xi, the action taken at\nthat time is ai, and the expected reward, ri, received at t = i depends on the\naction taken and on the state, that is ri = r(Xi,ai). The learners goal is to \ufb01nd\na policy, \u03c0(X), that maps input vectors to actions in such a way that maximizes\nrewards accumulated over time. This type of learning is called reinforcement\nlearning. The learner must \ufb01nd the policy by trial and error; it has no initial\nknowledge of the e\ufb00ects of its actions. The situation is as shown in Fig. 11.1.\n143'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 152, 'page_label': '153'}, page_content='144 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nXi\nri\nLearner\nEnvironment\n(reward)\n(state)\n(action)\nai\nFigure 11.1: Reinforcement Learning\n11.2 An Example\nA grid world, such as the one shown in Fig. 11.2 is often used to illustrate\nreinforcement learning. Imagine a robot initially in cell (2,3). The robot receives\ninput vector ( x1,x2) telling it what cell it is in; it is capable of four actions,\nn,e,s,w moving the robot one cell up, right, down, or left, respectively. It is\nrewarded one negative unit whenever it bumps into the wall or into the blocked\ncells. For example, if the input to the robot is (1,3), and the robot chooses\naction w, the next input to the robot is still (1,3) and it receives a reward of\n\u22121. If the robot lands in the cell marked G (for goal), it receives a reward of\n+10. Lets suppose that whenever the robot lands in the goal cell and gets its\nreward, it is immediately transported out to some random cell, and the quest\nfor reward continues.\nA policy for our robot is a speci\ufb01cation of what action to take for every one\nof its inputs, that is, for every one of the cells in the grid. For example, a com-\nponent of such a policy would be when in cell (3,1), move right. An optimal\npolicy is a policy that maximizes long-term reward. One way of displaying a\npolicy for our grid-world robot is by an arrow in each cell indicating the direc-\ntion the robot should move when in that cell. In Fig. 11.3, we show an optimal\npolicy displayed in this manner. In this chapter we will describe methods for\nlearning optimal policies based on reward values received by the learner.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 153, 'page_label': '154'}, page_content='11.3. TEMPORAL DISCOUNTING AND OPTIMAL POLICIES 145\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.2: A Grid World\n11.3 Temporal Discounting and Optimal Poli-\ncies\nIn delayed reinforcement learning, one often assumes that rewards in the distant\nfuture are not as valuable as are more immediate rewards. This preference can\nbe accomodated by a temporal discount factor, 0 \u2264\u03b3 <1. The present value of\na reward, ri, occuring i time units in the future, is taken to be \u03b3iri. Suppose\nwe have a policy \u03c0(X) that maps input vectors into actions, and let r\u03c0(X)\ni be\nthe reward that will be received on the i-th time step after one begins executing\npolicy \u03c0 starting in state X. Then the total reward accumulated over all time\nsteps by policy \u03c0 beginning in state X is:\nV\u03c0(X) =\n\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\nOne reason for using a temporal discount factor is so that the above sum will\nbe \ufb01nite. An optimal policy is one that maximizes V\u03c0(X) for all inputs, X.\nIn general, we want to consider the case in which the rewards,ri, are random\nvariables and in which the e\ufb00ects of actions on environmental states are random.\nIn Markovian environments, for example, the probability that action a in state\nXi will lead to state Xj is given by a transition probability p[Xj|Xi,a]. Then,\nwe will want to maximize expected future reward and would de\ufb01ne V\u03c0(X) as:\nV\u03c0(X) = E\n[\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\n]\nIn either case, we call V\u03c0(X) the value of policy \u03c0 for input X.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 154, 'page_label': '155'}, page_content='146 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.3: An Optimal Policy in the Grid World\nIf the action prescribed by \u03c0 taken in state X leads to state X\u2032 (randomly\naccording to the transition probabilities), then we can write V\u03c0(X) in terms of\nV\u03c0(X\u2032) as follows:\nV\u03c0(X) = r[X,\u03c0(X)] + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,\u03c0(X)]V\u03c0(X\u2032)\nwhere (in summary):\n\u03b3 = the discount factor,\nV\u03c0(X) = the value of state X under policy \u03c0,\nr[X,\u03c0(X)] = the expected immediate reward received when we execute the\naction prescribed by \u03c0 in state X, and\np[X\u2032|X,\u03c0(X)] = the probability that the environment transitions to state\nX\u2032when we execute the action prescribed by \u03c0 in state X.\nIn other words, the value of state X under policy \u03c0 is the expected value of\nthe immediate reward received when executing the action recommended by \u03c0\nplus the average value (under \u03c0) of all of the states accessible from X.\nFor an optimal policy, \u03c0\u2217(and no others!), we have the famous optimality\nequation:\nV\u03c0\u2217\n(X) = max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nThe theory of dynamic programming (DP) [Bellman, 1957, Ross, 1983] assures\nus that there is at least one optimal policy, \u03c0\u2217, that satis\ufb01es this equation. DP'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 155, 'page_label': '156'}, page_content='11.4. Q-LEARNING 147\nalso provides methods for calculating V\u03c0\u2217\n(X) and at least one \u03c0\u2217, assuming\nthat we know the average rewards and the transition probabilities. If we knew\nthe transition probabilities, the average rewards, and V\u03c0\u2217\n(X) for all X and a,\nthen it would be easy to implement an optimal policy. We would simply select\nthat a that maximizes r(X,a) + \u03b3\u2211\nX\u2032p[X\u2032|X,a]V\u03c0\u2217\n(X\u2032). That is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nBut, of course, we are assuming that we do not know these average rewards nor\nthe transition probabilities, so we have to \ufb01nd a method that e\ufb00ectively learns\nthem.\nIf we had a model of actions, that is, if we knew for every state, X, and\naction a, which state, X\u2032 resulted, then we could use a method called value\niteration to \ufb01nd an optimal policy. Value iteration works as follows: We begin\nby assigning, randomly, an estimated value V(X) to every state, X. On the i-th\nstep of the process, suppose we are at state Xi (that is, our input on the i-th\nstep is Xi), and that the estimated value of state Xi on the i-th step is Vi(Xi).\nWe then select that actionathat maximizes the estimated value of the predicted\nsubsequent state. Suppose this subsequent state having the highest estimated\nvalue is X\u2032\ni. Then we update the estimated value, Vi(Xi), of state Xi as follows:\nVi(X) = (1 \u2212ci) Vi\u22121(X) + ci\n[\nri + \u03b3Vi\u22121(X\u2032\ni)\n]\nif X = Xi,\n= Vi\u22121(X)\notherwise.\nWe see that this adjustment moves the value ofVi(Xi) an increment (depend-\ning on ci) closer to\n[\nri + \u03b3Vi(X\u2032\ni)\n]\n. Assuming that Vi(X\u2032\ni) is a good estimate for\nVi(X\u2032\ni), then this adjustment helps to make the two estimates more consistent.\nProviding that 0 < ci < 1 and that we visit each state in\ufb01nitely often, this\nprocess of value iteration will converge to the optimal values. Discuss synchronous dynamic\nprogramming, asynchronous\ndynamic programming, and policy\niteration.\n11.4 Q-Learning\nWatkins [Watkins, 1989] has proposed a technique that he calls incremental\ndynamic programming. Let a; \u03c0 stand for the policy that chooses action aonce,\nand thereafter chooses actions according to policy \u03c0. We de\ufb01ne:\nQ\u03c0(X,a) = Va;\u03c0(X)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 156, 'page_label': '157'}, page_content='148 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nThen the optimal value from state X is given by:\nV\u03c0\u2217\n(X) = max\na\nQ\u03c0\u2217\n(X,a)\nThis equation holds only for an optimal policy, \u03c0\u2217. The optimal policy is given\nby:\n\u03c0\u2217(X) = arg max\na\nQ\u03c0\u2217\n(X,a)\nNote that if an actionamakes Q\u03c0(X,a) larger than V\u03c0(X), then we can improve\n\u03c0 by changing it so that \u03c0(X) = a. Making such a change is the basis for a\npowerful learning rule that we shall describe shortly.\nSuppose action ain state X leads to state X\u2032. Then using the de\ufb01nitions of\nQ and V, it is easy to show that:\nQ\u03c0(X,a) = r(X,a) + \u03b3E[V\u03c0(X\u2032)]\nwhere r(X,a) is the average value of the immediate reward received when we\nexecute action a in state X. For an optimal policy (and no others), we have\nanother version of the optimality equation in terms of Q values:\nQ\u03c0\u2217\n(X,a) = max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nfor all actions, a, and states, X. Now, if we had the optimal Q values (for all\na and X), then we could implement an optimal policy simply by selecting that\naction that maximized r(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]\n.\nThat is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nWatkins proposal amounts to a TD(0) method of learning the Q values.\nWe quote (with minor notational changes) from [Watkins & Dayan, 1992, page\n281]:\nIn Q-Learning, the agents experience consists of a sequence of dis-\ntinct stages or episodes. In the i-th episode, the agent:\n observes its current state Xi,\n selects [using the method described below] and performs an\naction ai,\n observes the subsequent state X\u2032\ni,\n receives an immediate reward ri, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 157, 'page_label': '158'}, page_content='11.4. Q-LEARNING 149\n adjusts its Qi\u22121 values using a learning factor ci, according to:\nQi(X,a) = (1 \u2212ci)Qi\u22121(X,a) + ci[ri + \u03b3Vi\u22121(X\u2032\ni)]\nif X = Xi and a= ai,\n= Qi\u22121(X,a)\notherwise,\nwhere\nVi\u22121(X\u2032) = max\nb\n[Qi\u22121(X\u2032,b)]\nis the best the agent thinks it can do from state X\u2032. ... The\ninitial Qvalues, Q0(X,a), for all states and actions are assumed\ngiven.\nUsing the current Q values, Qi(X,a), the agent always selects that action\nthat maximizes Qi(X,a). Note that only the Q value corresponding to the\nstate just exited and the action just taken is adjusted. And that Q value is\nadjusted so that it is closer (by an amount determined by ci) to the sum of\nthe immediate reward plus the discounted maximum (over all actions) of the Q\nvalues of the state just entered. If we imagine the Qvalues to be predictions of\nultimate (in\ufb01nite horizon) total reward, then the learning procedure described\nabove is exactly a TD(0) method of learning how to predict these Q values.\nQ learning strengthens the usual TD methods, however, because TD (applied\nto reinforcement problems using value iteration) requires a one-step lookahead,\nusing a model of the e\ufb00ects of actions, whereas Q learning does not.\nA convenient notation (proposed by [Schwartz, 1993]) for representing the\nchange in Q value is:\nQ(X,a)\n\u03b2\n\u2190\u2212r+ \u03b3V(X\u2032)\nwhere Q(X,a) is the new Qvalue for input X and action a, r is the immediate\nreward when action a is taken in response to input X, V(X\u2032) is the maximum\n(over all actions) of the Qvalue of the state next reached when action ais taken\nfrom state X, and \u03b2 is the fraction of the way toward which the new Q value,\nQ(X,a), is adjusted to equal r+ \u03b3V(X\u2032).\nWatkins and Dayan [Watkins & Dayan, 1992] prove that, under certain con-\nditions, the Q values computed by this learning procedure converge to optimal\nones (that is, to ones on which an optimal policy can be based).\nWe de\ufb01ne ni(X,a) as the index (episode number) of thei-th time that action\na is tried in state X. Then, we have:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 158, 'page_label': '159'}, page_content='150 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nTheorem 11.1 (Watkins and Dayan) For Markov problems with states{X}\nand actions {a}, and given bounded rewards |rn|\u2264 R, learning rates 0 \u2264cn <1,\nand\n\u221e\u2211\ni=0\ncni(X,a) = \u221e,\n\u221e\u2211\ni=0\n[\ncni(X,a)\n]2\n<\u221e\nfor all X and a, then\nQn(X,a) \u2192Q\u2217\nn(X,a) as n \u2192\u221e, for all X and a, with probability 1, where\nQ\u2217\nn(X,a) corresponds to the Q values of an optimal policy.\nAgain, we quote from [Watkins & Dayan, 1992, page 281]:\nThe most important condition implicit in the convergence theorem\n... is that the sequence of episodes that forms the basis of learning\nmust include an in\ufb01nite number of episodes for each starting state\nand action. This may be considered a strong condition on the way\nstates and actions are selectedhowever, under the stochastic con-\nditions of the theorem, no method could be guaranteed to \ufb01nd an\noptimal policy under weaker conditions. Note, however, that the\nepisodes need not form a continuous sequencethat is the X\u2032of one\nepisode need not be the X of the next episode.\nThe relationships among Q learning, dynamic programming, and control\nare very well described in [Barto, Bradtke, & Singh, 1994]. Q learning is best\nthought of as a stochastic approximation method for calculating the Q values.\nAlthough the de\ufb01nition of the optimalQvalues for any state depends recursively\non expected values of the Q values for subsequent states (and on the expected\nvalues of rewards), no expected values are explicitly computed by the procedure.\nInstead, these values are approximated by iterative sampling using the actual\nstochastic mechanism that produces successor states.\n11.5 Discussion, Limitations, and Extensions of\nQ-Learning\n11.5.1 An Illustrative Example\nThe Q-learning procedure requires that we maintain a table of Q(X,a) values\nfor all state-action pairs. In the grid world that we described earlier, such a\ntable would not be excessively large. We might start with random entries in the\ntable; a portion of such an intial table might be as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 159, 'page_label': '160'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING151\nX a Q(X,a) r(X,a)\n(2,3) w 7 0\n(2,3) n 4 0\n(2,3) e 3 0\n(2,3) s 6 0\n(1,3) w 4 -1\n(1,3) n 5 0\n(1,3) e 2 0\n(1,3) s 4 0\nSuppose the robot is in cell (2,3). The maximumQvalue occurs fora= w, so the\nrobot moves west to cell (1,3)receiving no immediate reward. The maximum\nQ value in cell (1,3) is 5, and the learning mechanism attempts to make the\nvalue of Q((2,3),w) closer to the discounted value of 5 plus the immediate\nreward (which was 0 in this case). With a learning rate parameter c = 0 .5\nand \u03b3 = 0.9, the Q value of Q((2,3),w) is adjusted from 7 to 5.75. No other\nchanges are made to the table at this episode. The reader might try this learning\nprocedure on the grid world with a simple computer program. Notice that an\noptimal policy might not be discovered if some cells are not visited nor some\nactions not tried frequently enough.\nThe learning problem faced by the agent is to associate speci\ufb01c actions with\nspeci\ufb01c input patterns. Q learning gradually reinforces those actions that con-\ntribute to positive rewards by increasing the associated Q values. Typically, as\nin this example, rewards occur somewhat after the actions that lead to them\nhence the phrase delayed-reinforcement learning. One can imagine that better\nand better approximations to the optimal Q values gradually propagate back\nfrom states producing rewards toward all of the other states that the agent fre-\nquently visits. With random Qvalues to begin, the agents actions amount to a\nrandom walk through its space of states. Only when this random walk happens\nto stumble into rewarding states does Q learning begin to produce Q values\nthat are useful, and, even then, the Q values have to work their way outward\nfrom these rewarding states. The general problem of associating rewards with\nstate-action pairs is called the temporal credit assignment problemhow should\ncredit for a reward be apportioned to the actions leading up to it? Qlearning is,\nto date, the most successful technique for temporal credit assignment, although\na related method, called the bucket brigade algorithm , has been proposed by\n[Holland, 1986].\nLearning problems similar to that faced by the agent in our grid world have\nbeen thoroughly studied by Sutton who has proposed an architecture, called\nDYNA, for solving them [Sutton, 1990]. DYNA combines reinforcement learning\nwith planning. Sutton characterizes planning as learning in a simulated world\nthat models the world that the agent inhabits. The agents model of the world\nis obtained by Q learning in its actual world, and planning is accomplished by\nQ learning in its model of the world.\nWe should note that the learning problem faced by our grid-world robot'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 160, 'page_label': '161'}, page_content='152 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\ncould be modi\ufb01ed to have several places in the grid that give positive rewards.\nThis possibility presents an interesting way to generalize the classical notion of\na goal in AI planning systemseven in those that do no learning. Instead of\nrepresenting a goal as a condition to be achieved, we represent a goal struc-\nture as a set of rewards to be given for achieving various conditions. Then,\nthe generalized goal becomes maximizing discounted future reward instead of\nsimply achieving some particular condition. This generalization can be made to\nencompass so-called goals of maintenance and goals of avoidance. The exam-\nple presented above included avoiding bumping into the grid-world boundary.\nA goal of maintenance, of a particular state, could be expressed in terms of a\nreward that was earned whenever the agent was in that state and performed an\naction that transitioned back to that state in one step.\n11.5.2 Using Random Actions\nWhen the next pattern presentation in a sequence of patterns is the one caused\nby the agents own action in response to the last pattern, we have what is called\nan on-line learning method. In Watkins and Dayans terminology, in on-line\nlearning the episodes form a continous sequence. As already mentioned, the\nconvergence theorem for Q learning does not require on-line learning; indeed,\nspecial precautions must be taken to ensure that on-line learning meets the\nconditions of the theorem. If on-line learning discovers some good paths to\nrewards, the agent may \ufb01xate on these and never discover a policy that leads\nto a possibly greater long-term reward. In reinforcement learning phraseology,\nthis problem is referred to as the problem of exploitation (of already learned\nbehavior) versus exploration (of possibly better behavior).\nOne way to force exploration is to perform occasional random actions (in-\nstead of that single action prescribed by the current Q values). For example,\nin the grid-world problem, one could imagine selecting an action randomly ac-\ncording to a probability distribution over the actions ( n,e,s, and w). This\ndistribution, in turn, could depend on the Q values. For example, we might\n\ufb01rst \ufb01nd that action prescribed by the Q values and then choose that action\nwith probability 1/2, choose the two orthogonal actions with probability 3/16\neach, and choose the opposite action with probability 1/8. This policy might be\nmodi\ufb01ed by simulated annealing which would gradually increase the probabil-\nity of the action prescribed by theQvalues more and more as time goes on. This\nstrategy would favor exploration at the beginning of learning and exploitation\nlater.\nOther methods, also, have been proposed for dealing with exploration, in-\ncluding making unvisited states intrinsically rewarding and using an interval\nestimate, which is related to the uncertainty in the estimate of a states value\n[Kaelbling, 1993].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 161, 'page_label': '162'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING153\n11.5.3 Generalizing Over Inputs\nFor large problems it would be impractical to maintain a table like that used\nin our grid-world example. Various researchers have suggested mechanisms for\ncomputing Q values, given pattern inputs and actions. One method that sug-\ngests itself is to use a neural network. For example, consider the simple linear\nmachine shown in Fig. 11.4.\nX\n. . .\n. . .\nY\nY\nY\ntrainable weights\nY\nWi\nR dot product units\nQ(ai, X) = X . Wi\nQ(a1, X)\nQ(a2, X)\nQ(aR, X)\nFigure 11.4: A Net that Computes Q Values\nSuch a neural net could be used by an agent that has R actions to select\nfrom. The Qvalues (as a function of the input pattern X and the action ai) are\ncomputed as dot products of weight vectors (one for each action) and the input\nvector. Weight adjustments are made according to a TD(0) procedure to bring\nthe Qvalue for the action last selected closer to the sum of the immediate reward\n(if any) and the (discounted) maximum Q value for the next input pattern.\nIf the optimum Qvalues for the problem (whatever they might be) are more\ncomplex than those that can be computed by a linear machine, a layered neural\nnetwork might be used. Sigmoid units in the \ufb01nal layer would compute Qvalues\nin the range 0 to 1. The TD(0) method for updatingQvalues would then have to\nbe combined with a multi-layer weight-changing rule, such as backpropagation.\nNetworks of this sort are able to aggregate di\ufb00erent input vectors into regions\nfor which the same action should be performed. This kind of aggregation is an\nexample of what has been calledstructural credit assignment. Combining TD(\u03bb)\nand backpropagation is a method for dealing with both the temporal and the\nstructural credit assignment problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 162, 'page_label': '163'}, page_content='154 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nInteresting examples of delayed-reinforcement training of simulated and\nactual robots requiring structural credit assignment have been reported by\n[Lin, 1992, Mahadevan & Connell, 1992].\n11.5.4 Partially Observable States\nSo far, we have identi\ufb01ed the input vector, X, with the actual state of the envi-\nronment. When the input vector results from an agents perceptual apparatus\n(as we assume it does), there is no reason to suppose that it uniquely identi\ufb01es\nthe environmental state. Because of inevitable perceptual limitations, several\ndi\ufb00erent environmental states might give rise to the same input vector. This\nphenomenon has been referred to as perceptual aliasing. With perceptual alias-\ning, we can no longer guarantee that Qlearning will result in even useful action\npolicies, let alone optimal ones. Several researchers have attempted to deal with\nthis problem using a variety of methods including attempting to model hid-\nden states by using internal memory [Lin, 1993]. That is, if some aspect of\nthe environment cannot be sensed currently, perhaps it was sensed once and\ncan be remembered by the agent. When such is the case, we no longer have a\nMarkov problem; that is, the next X vector, given any action, may depend on\na sequence of previous ones rather than just the immediately preceding one. It\nmight be possible to reinstate a Markov framework (over the Xs) if X includes\nnot only current sensory precepts but information from the agents memory.\n11.5.5 Scaling Problems\nSeveral di\ufb03culties have so far prohibited wide application of reinforcement learn-\ning to large problems. (The TD-gammon program, mentioned in the last chap-\nter, is probably unique in terms of success on a high-dimensional problem.)\nWe have already touched on some di\ufb03culties; these and others are summarized\nbelow with references to attempts to overcome them.\na. Exploration versus exploitation.\n use random actions\n favor states not visited recently\n separate the learning phase from the use phase\n employ a teacher to guide exploration\nb. Slow time to convergence\n combine learning with prior knowledge; use estimates of Q values\n(rather than random values) initially\n use a hierarchy of actions; learn primitive actions \ufb01rst and freeze the\nuseful sequences into macros and then learn how to use the macros'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 163, 'page_label': '164'}, page_content='11.6. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 155\n employ a teacher; use graded lessonsstarting near the rewards\nand then backing away, and use examples of good behavior [Lin, 1992]\n use more e\ufb03cient computations; e.g. do several updates per episode\n[Moore & Atkeson, 1993]\nc. Large state spaces\n use hand-coded features\n use neural networks\n use nearest-neighbor methods [Moore, 1990]\nd. Temporal discounting problems. Using small \u03b3 can make the learner too\ngreedy for present rewards and indi\ufb00erent to the future; but using large \u03b3\nslows down learning.\n use a learning method based on average rewards [Schwartz, 1993]\ne. No transfer of learning . What is learned depends on the reward struc-\nture; if the rewards change, learning has to start over.\n Separate the learning into two parts: learn an action model which\npredicts how actions change states (and is constant over all prob-\nlems), and then learn the values of states by reinforcement learn-\ning for each di\ufb00erent set of rewards. Sometimes the reinforcement\nlearning part can be replaced by a planner that uses the action\nmodel to produce plans to achieve goals.\nAlso see other articles in the special issue on reinforcement learning:Machine\nLearning, 8, May, 1992.\n11.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 164, 'page_label': '165'}, page_content='156 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 165, 'page_label': '166'}, page_content='Chapter 12\nExplanation-Based\nLearning\n12.1 Deductive Learning\nIn the learning methods studied so far, typically the training set does not ex-\nhaust the version space. Using logical terminology, we could say that the classi-\n\ufb01ers output does not logically follow from the training set. In this sense, these\nmethods are inductive. In logic, a deductive system is one whose conclusions\nlogically follow from a set of input facts, if the system is sound. 1\nTo contrast inductive with deductive systems in a logical setting, suppose\nwe have a set of facts (the training set) that includes the following formulas:\n{Round(Obj1),Round(Obj2),Round(Obj3),Round(Obj4),\nBall(Obj1),Ball(Obj2),Ball(Obj3),Ball(Obj4)}\nA learning system that forms the conclusion ( \u2200x)[Ball(x) \u2283Round(x)] is in-\nductive. This conclusion may be useful (if there are no facts of the form\nBall(\u03c3) \u2227¬Round(\u03c3)), but it does not logically follow from the facts. On the\nother hand, if we had the facts Green(Obj5) and Green(Obj5) \u2283Round(Obj5),\nthen we could logically conclude Round(Obj5). Making this conclusion and sav-\ning it is an instance of deductive learninga topic we study in this chapter.\nSuppose that some logical proposition, \u03c6, logically follows from some set of\nfacts, \u2206. Under what circumstances might we say that the process of deducing\n\u03c6 from \u2206 results in our learning \u03c6? In a sense, we implicitly knew \u03c6 all along,\nsince it was inherent in knowing \u2206. Yet, \u03c6 might not be obvious given \u2206, and\n1Logical reasoning systems that are not sound, for example those using non-monotonic\nreasoning, themselves might produce inductive conclusions that do not logically follow from\nthe input facts.\n157'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 166, 'page_label': '167'}, page_content='158 CHAPTER 12. EXPLANATION-BASED LEARNING\nthe deduction process to establish \u03c6might have been arduous. Rather than have\nto deduce \u03c6 again, we might want to save it, perhaps along with its deduction,\nin case it is needed later. Shouldnt that process count as learning? Dietterich\n[Dietterich, 1990] has called this type of learning speed-up learning.\nStrictly speaking, speed-up learning does not result in a system being able to\nmake decisions that, in principle, could not have been made before the learning\ntook place. Speed-up learning simply makes it possible to make those decisions\nmore e\ufb03ciently. But, in practice, this type of learning might make possible\ncertain decisions that might otherwise have been infeasible.\nTo take an extreme case, a chess player can be said to learn chess even though\noptimal play is inherent in the rules of chess. On the surface, there seems to be\nno real di\ufb00erence between the experience-based hypotheses that a chess player\nmakes about what constitutes good play and the kind of learning we have been\nstudying so far.\nAs another example, suppose we are given some theorems about geometry\nand are asked to prove that the sum of the angles of a right triangle is 180\ndegrees. Let us further suppose that the proof we constructed did not depend\non the given triangle being a right triangle; in that case we can learn a more\ngeneral fact. The learning technique that we are going to study next is related\nto this example. It is called explanation-based learning (EBL) . EBL can be\nthought of as a process in which implicit knowledge is converted into explicit\nknowledge.\nIn EBL, we specialize parts of a domain theory to explain a particular ex-\nample, then we generalize the explanation to produce another element of the\ndomain theory that will be useful on similar examples. This process is illustrated\nin Fig. 12.1.\n12.2 Domain Theories\nTwo types of information were present in the inductive methods we have studied:\nthe information inherent in the training samples and the information about the\ndomain that is implied by the bias (for example, the hypothesis set from which\nwe choose functions). The learning methods are successful only if the hypothesis\nset is appropriate for the problem. Typically, the smaller the hypothesis set (that\nis, the more a priori information we have about the function being sought), the\nless dependent we are on information being supplied by a training set (that\nis, fewer samples). A priori information about a problem can be expressed in\nseveral ways. The methods we have studied so far restrict the hypotheses in a\nrather direct way. A less direct method involves making assertions in a logical\nlanguage about the property we are trying to learn. A set of such assertions is\nusually called a domain theory.\nSuppose, for example, that we wanted to classify people according to whether\nor not they were good credit risks. We might represent a person by a set of\nproperties (income, marital status, type of employment, etc.), assemble such'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 167, 'page_label': '168'}, page_content='12.3. AN EXAMPLE 159\nDomain\nTheory\nExample\n(X is P) Prove: X is P\nspecialize\nExplanation\n(Proof)\ngeneralize\nA New Domain Rule:\nThings "like" X are P\nY is like X\nComplex Proof\nProcess\nTrivial  Proof\nY is P\nFigure 12.1: The EBL Process\ndata about people who are known to be good and bad credit risks and train a\nclassi\ufb01er to make decisions. Or, we might go to a loan o\ufb03cer of a bank, ask him\nor her what sorts of things s/he looks for in making a decision about a loan,\nencode this knowledge into a set of rules for an expert system, and then use\nthe expert system to make decisions. The knowledge used by the loan o\ufb03cer\nmight have originated as a set of policies (the domain theory), but perhaps the\napplication of these policies were specialized and made more e\ufb03cient through\nexperience with the special cases of loans made in his or her district.\n12.3 An Example\nTo make our discussion more concrete, lets consider the following fanciful exam-\nple. We want to \ufb01nd a way to classify robots as robust or not. The attributes\nthat we use to represent a robot might include some that are relevant to this\ndecision and some that are not.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 168, 'page_label': '169'}, page_content='160 CHAPTER 12. EXPLANATION-BASED LEARNING\nSuppose we have a domain theory of logical sentences that taken together,\nhelp to de\ufb01ne whether or not a robot can be classi\ufb01ed as robust. (The same\ndomain theory may be useful for several other purposes also, but among other\nthings, it describes the concept robust.)\nIn this example, lets suppose that our domain theory includes the sentences:\nFixes(u,u) \u2283Robust(u)\n(An individual that can \ufb01x itself is robust.)\nSees(x,y) \u2227Habile(x) \u2283Fixes(x,y)\n(A habile individual that can see another entity can \ufb01x that entity.)\nRobot(w) \u2283Sees(w,w)\n(All robots can see themselves.)\nR2D2(x) \u2283Habile(x)\n(R2D2-class individuals are habile.)\nC3PO(x) \u2283Habile(x)\n(C3PO-class individuals are habile.)\n...\n(By convention, variables are assumed to be universally quanti\ufb01ed.) We could\nuse theorem-proving methods operating on this domain theory to conclude\nwhether certain robots are robust. These methods might be computationally\nquite expensive because extensive search may have to be performed to derive a\nconclusion. But after having found a proof for some particular robot, we might\nbe able to derive some new sentence whose use allows a much faster conclusion.\nWe next show how such a new rule might be derived in this example. Suppose\nwe are given a number of facts about Num5, such as:\nRobot(Num5)\nR2D2(Num5)\nAge(Num5,5)\nManufacturer(Num5,GR)\n...'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 169, 'page_label': '170'}, page_content='12.3. AN EXAMPLE 161\nFixes(u, u) => Robust(u)\nRobust(Num5)\nFixes(Num5, Num5)\nSees(Num5,Num5) Habile(Num5)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nRobot(w)\n     => Sees(w,w)\nRobot(Num5)\nR2D2(x)\n         => Habile(x)\nR2D2(Num5)\nFigure 12.2: A Proof Tree\nWe are also told that Robust(Num5) is true, but we nevertheless attempt to\n\ufb01nd a proof of that assertion using these facts about Num5 and the domain\ntheory. The facts about Num5 correspond to the features that we might use\nto represent Num5. In this example, not all of them are relevant to a decision\nabout Robust(Num5). The relevant ones are those used or needed in proving\nRobust(Num5) using the domain theory. The proof tree in Fig. 12.2 is one that\na typical theorem-proving system might produce.\nIn the language of EBL, this proof is an explanation for the fact\nRobust(Num5). We see from this explanation that the only facts about Num5\nthat were used were Robot(Num5) and R2D2(Num5). In fact, we could con-\nstruct the following rule from this explanation:\nRobot(Num5) \u2227R2D2(Num5) \u2283Robust(Num5)\nThe explanation has allowed us to prune some attributes about Num5 that are\nirrelevant (at least for decidingRobust(Num5)). This type of pruning is the \ufb01rst\nsense in which an explanation is used to generalize the classi\ufb01cation problem.\n([DeJong & Mooney, 1986] call this aspect of explanation-based learning feature\nelimination.) But the rule we extracted from the explanation applies only to\nNum5. There might be little value in learning that rule since it is so speci\ufb01c.\nCan it be generalized so that it can be applied to other individuals as well?'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 170, 'page_label': '171'}, page_content='162 CHAPTER 12. EXPLANATION-BASED LEARNING\nExamination of the proof shows that the same proof structure, using the\nsame sentences from the domain theory, could be used independently of whether\nwe are talking about Num5 or some other individual. We can generalize the\nproof by a process that replaces constants in the tip nodes of the proof tree\nwith variables and works upwardusing uni\ufb01cation to constrain the values of\nvariables as needed to obtain a proof.\nIn this example, we replace Robot(Num5) by Robot(r) and R2D2(Num5)\nby R2D2(s) and redo the proofusing the explanation proof as a template.\nNote that we use di\ufb00erent values for the two di\ufb00erent occurrences of Num5 at\nthe tip nodes. Doing so sometimes results in more general, but nevertheless\nvalid rules. We now apply the rules used in the proof in the forward direction,\nkeeping track of the substitutions imposed by the most general uni\ufb01ers used in\nthe proof. (Note that we always substitute terms that are already in the tree for\nvariables in rules.) This process results in the generalized proof tree shown in\nFig. 12.3. Note that the occurrence of Sees(r,r) as a node in the tree forces the\nuni\ufb01cation of xwith yin the domain rule, Sees(x,y)\u2227Habile(y) \u2283Fixes(x,y).\nThe substitutions are then applied to the variables in the tip nodes and the root\nnode to yield the general rule: Robot(r) \u2227R2D2(r) \u2283Robust(r).\nThis rule is the end result of EBL for this example. The process\nby which Num5 in this example was generalized to a variable is what\n[DeJong & Mooney, 1986] call identity elimination (the precise identity of Num5\nturned out to be irrelevant). (The generalization process described in this ex-\nample is based on that of [DeJong & Mooney, 1986] and di\ufb00ers from that of\n[Mitchell, et al., 1986]. It is also similar to that used in [Fikes, et al., 1972].)\nClearly, under certain assumptions, this general rule is more easily used to con-\nclude Robust about an individual than the original proof process was.\nIt is important to note that we could have derived the general rule from the\ndomain theory without using the example. (In the literature, doing so is called\nstatic analysis [Etzioni, 1991].) In fact, the example told us nothing new other\nthan what it told us about Num5. The sole role of the example in this instance\nof EBL was to provide a template for a proof to help guide the generalization\nprocess. Basing the generalization process on examples helps to insure that we\nlearn rules matched to the distribution of problems that occur.\nThere are a number of quali\ufb01cations and elaborations about EBL that need\nto be mentioned.\n12.4 Evaluable Predicates\nThe domain theory includes a number of predicates other than the one occuring\nin the formula we are trying to prove and other than those that might custom-\narily be used to describe an individual. One might note, for example, that if we\nused Habile(Num5) to describe Num5, the proof would have been shorter. Why\ndidnt we? The situation is analogous to that of using a data base augmented\nby logical rules. In the latter application, the formulas in the actual data base'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 171, 'page_label': '172'}, page_content='12.4. EVALUABLE PREDICATES 163\nRobust(r)\nFixes(r, r)\nSees(r,r) Habile(s)\nRobot(r) R2D2(s)\n{r/w}\n{s/x}\n{r/x, r/y, r/s}\n{r/u}\nRobot(w)\n     => Sees(w,w)\nR2D2(x)\n         => Habile(x)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nFixes(u, u) => Robust(u)\nbecomes R2D2(r) after\napplying {r/s}\nFigure 12.3: A Generalized Proof Tree\nare extensional, and those in the logical rules are intensional. This usage\nre\ufb02ects the fact that the predicates in the data base part are de\ufb01ned by their\nextensionwe explicitly list all the tuples sastisfying a relation. The logical\nrules serve to connect the data base predicates with higher level abstractions\nthat are described (if not de\ufb01ned) by the rules. We typically cannot look up\nthe truth values of formulas containing these intensional predicates; they have\nto be derived using the rules and the database.\nThe EBL process assumes something similar. The domain theory is useful\nfor connecting formulas that we might want to prove with those whose truth\nvalues can be looked up or otherwise evaluated. In the EBL literature, such\nformulas satisfy what is called the operationality criterion. Perhaps another\nanalogy might be to neural networks. The evaluable predicates correspond to\nthe components of the input pattern vector; the predicates in the domain theory\ncorrespond to the hidden units. Finding the new rule corresponds to \ufb01nding a\nsimpler expression for the formula to be proved in terms only of the evaluable\npredicates.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 172, 'page_label': '173'}, page_content='164 CHAPTER 12. EXPLANATION-BASED LEARNING\n12.5 More General Proofs\nExamining the domain theory for our example reveals that an alternative rule\nmight have been: Robot(u) \u2227C3PO(u) \u2283 Robust(u). Such a rule might\nhave resulted if we were given {C3PO(Num6),Robot(Num6),... }and proved\nRobust(Num6). After considering these two examples (Num5 and Num6),\nthe question arises, do we want to generalize the two rules to something like:\nRobot(u)\u2227[C3PO(u)\u2228R2D2(u)] \u2283Robust(u)? Doing so is an example of what\n[DeJong & Mooney, 1986] call structural generalization (via disjunctive augmen-\ntation ).\nAdding disjunctions for every alternative proof can soon become cumbersome\nand destroy any e\ufb03ciency advantage of EBL. In our example, the e\ufb03ciency\nmight be retrieved if there were another evaluable predicate, say,Bionic(u) such\nthat the domain theory also contained R2D2(x) \u2283Bionic(x) and C3PO(x) \u2283\nBionic(x). After seeing a number of similar examples, we might be willing to\ninduce the formula Bionic(u) \u2283[C3PO(u) \u2228R2D2(u)] in which case the rule\nwith the disjunction could be replaced with Robot(u) \u2227Bionic(u) \u2283Robust(u).\n12.6 Utility of EBL\nIt is well known in theorem proving that the complexity of \ufb01nding a proof\ndepends both on the number of formulas in the domain theory and on the depth\nof the shortest proof. Adding a new rule decreases the depth of the shortest\nproof but it also increases the number of formulas in the domain theory. In\nrealistic applications, the added rules will be relevant for some tasks and not for\nothers. Thus, it is unclear whether the overall utility of the new rules will turn\nout to be positive. EBL methods have been applied in several settings, usually\nwith positive utility. (See [Minton, 1990] for an analysis).\n12.7 Applications\nThere have been several applications of EBL methods. We mention two here,\nnamely the formation of macro-operators in automatic plan generation and\nlearning how to control search.\n12.7.1 Macro-Operators in Planning\nIn automatic planning systems, e\ufb03ciency can sometimes be enhanced by chain-\ning together a sequence of operators into macro-operators. We show an exam-\nple of a process for creating macro-operators based on techniques explored by\n[Fikes, et al., 1972].\nReferring to Fig. 12.4, consider the problem of \ufb01nding a plan for a robot in\nroom R1 to fetch a box, B1, by going to an adjacent room, R2, and pushing it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 173, 'page_label': '174'}, page_content='12.7. APPLICATIONS 165\nback to R1. The goal for the robot is INROOM (B1,R1), and the facts that\nare true in the initial state are listed in the \ufb01gure.\nR1 R2\nR3\nD1\nD2\nB1\nInitial State:\nINROOM(ROBOT, R1)\nINROOM(B1,R2)\nCONNECTS(D1,R1,R2)\nCONNECTS(D1,R2,R1)\n. . .\nFigure 12.4: Initial State of a Robot Problem\nWe will construct the plan from a set of STRIPS operators that include:\nGOTHRU(d,r1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2)\nDelete list: INROOM (ROBOT,r 1)\nAdd list: INROOM (ROBOT,r 2)\nPUSHTHRU(b,d,r 1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2),INROOM (b,r1)\nDelete list: INROOM (ROBOT,r 1),INROOM (b,r1)\nAdd list: INROOM (ROBOT,r 2),INROOM (b,r2)\nA backward-reasoning STRIPS system might produce the plan shown in\nFig. 12.5. We show there the main goal and the subgoals along a solution path.\n(The conditions in each subgoal that are true in the initial state are shown\nunderlined.) The preconditions for this plan, true in the initial state, are:\nINROOM (ROBOT,R 1)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 174, 'page_label': '175'}, page_content='166 CHAPTER 12. EXPLANATION-BASED LEARNING\nCONNECTS (D1,R1,R2)\nCONNECTS (D1,R2,R1)\nINROOM (B1,R2)\nSaving this speci\ufb01c plan, valid only for the speci\ufb01c constants it mentions, would\nnot be as useful as would be saving a more general one. We \ufb01rst generalize\nthese preconditions by substituting variables for constants. We then follow the\nstructure of the speci\ufb01c plan to produce the generalized plan shown in Fig. 12.6\nthat achievesINROOM (b1,r4). Note that the generalized plan does not require\npushing the box back to the place where the robot started. The preconditions\nfor the generalized plan are:\nINROOM (ROBOT,r 1)\nCONNECTS (d1,r1,r2)\nCONNECTS (d2,r2,r4)\nINROOM (b,r4)\nINROOM(B1,R1)\nPUSHTHRU(B1,d,r1,R1)\nINROOM(ROBOT, r1),\nCONNECTS(d, r1, R1),\nINROOM(B1, r1)\nINROOM(ROBOT, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2){R2/r1,\nD1/d}\nGOTHRU(d2, r3, R2)\nINROOM(ROBOT, r3),\nCONNECTS(d2, r3, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\n{R1/r3, D1/d2}\nINROOM(ROBOT, R1),\nCONNECTS(D1, R1, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\nR1 R2\nR3\nD1\nD2\nGOTHRU(D1,R1,R2)\nPUSHTHRU(B1,D1,R2,R1)\nB1\nPLAN:\nFigure 12.5: A Plan for the Robot Problem\nAnother related technique that chains together sequences of operators to\nform more general ones is the chunking mechanism in Soar [Laird, et al., 1986].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 175, 'page_label': '176'}, page_content='12.7. APPLICATIONS 167\nINROOM(b1,r4)\nPUSHTHRU(b1,d2,r2,r4)\nINROOM(ROBOT, r2),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nGOTHRU(d1, r1, r2)\nINROOM(ROBOT, r1),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nFigure 12.6: A Generalized Plan\n12.7.2 Learning Search Control Knowledge\nBesides their use in creating macro-operators, EBL methods can be used to\nimprove the e\ufb03ciency of planning in another way also. In his system called\nPRODIGY, Minton proposed using EBL to learn e\ufb00ective ways to control\nsearch [Minton, 1988]. PRODIGY is a STRIPS-like system that solves planning\nproblems in the blocks-world, in a simple mobile robot world, and in job-shop\nscheduling. PRODIGY has a domain theory involving both the domain of the\nproblem and a simple (meta) theory about planning. Its meta theory includes\nstatements about whether a control choice about a subgoal to work on, an oper-\nator to apply, etc. either succeedsor fails. After producing a plan, it analyzes its\nsuccessful and its unsuccessful choices and attempts to explain them in terms\nof its domain theory. Using an EBL-like process, it is able to produce useful\ncontrol rules such as:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 176, 'page_label': '177'}, page_content='168 CHAPTER 12. EXPLANATION-BASED LEARNING\nIF (AND (CURRENT \u2212NODE node)\n(CANDIDATE \u2212GOAL node (ON x y))\n(CANDIDATE \u2212GOAL node (ON y z)))\nTHEN (PREFER GOAL (ON y z) TO (ON x y))\nPRODIGY keeps statistics on how often these learned rules are used, their\nsavings (in time to \ufb01nd plans), and their cost of application. It saves only the\nrules whose utility, thus measured, is judged to be high. Minton [Minton, 1990]\nhas shown that there is an overall advantage of using these rules (as against not\nhaving any rules and as against hand-coded search control rules).\n12.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 177, 'page_label': '178'}, page_content='Bibliography\n[Acorn & Walden, 1992] Acorn, T., and Walden, S., SMART: Support Man-\nagement Automated Reasoning Technology for COMPAQ Customer Ser-\nvice, Proc. Fourth Annual Conf. on Innovative Applications of Arti\ufb01cial\nIntelligence, Menlo Park, CA: AAAI Press, 1992.\n[Aha, 1991] Aha, D., Kibler, D., and Albert, M., Instance-Based Learning\nAlgorithms, Machine Learning, 6, 37-66, 1991.\n[Anderson & Bower, 1973] Anderson, J. R., and Bower, G. H., Human Asso-\nciative Memory, Hillsdale, NJ: Erlbaum, 1973.\n[Anderson, 1958] Anderson, T. W., An Introduction to Multivariate Statistical\nAnalysis, New York: John Wiley, 1958.\n[Barto, Bradtke, & Singh, 1994] Barto, A., Bradtke, S., and Singh, S., Learn-\ning to Act Using Real-Time Dynamic Programming, to appear in Ar-\nti\ufb01cial Intelligence, 1994.\n[Baum & Haussler, 1989] Baum, E, and Haussler, D., What Size Net Gives\nValid Generalization? Neural Computation, 1, pp. 151-160, 1989.\n[Baum, 1994] Baum, E., When Are k-Nearest Neighbor and Backpropagation\nAccurate for Feasible-Sized Sets of Examples? in Hanson, S., Drastal,\nG., and Rivest, R., (eds.), Computational Learning Theory and Natural\nLearning Systems, Volume 1: Constraints and Prospects , pp. 415-442,\nCambridge, MA: MIT Press, 1994.\n[Bellman, 1957] Bellman, R. E., Dynamic Programming, Princeton: Princeton\nUniversity Press, 1957.\n[Blumer, et al., 1987] Blumer, A., et al., Occams Razor, Info. Process. Lett.,\nvol 24, pp. 377-80, 1987.\n[Blumer, et al., 1990] Blumer, A., et al ., Learnability and the Vapnik-\nChervonenkis Dimension, JACM, 1990.\n[Bollinger & Du\ufb03e, 1988] Bollinger, J., and Du\ufb03e, N., Computer Control of\nMachines and Processes, Reading, MA: Addison-Wesley, 1988.\n169'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 178, 'page_label': '179'}, page_content='170 BIBLIOGRAPHY\n[Brain, et al., 1962] Brain, A. E., et al. , Graphical Data Processing Research\nStudy and Experimental Investigation, Report No. 8 (pp. 9-13) and No.\n9 (pp. 3-10), Contract DA 36-039 SC-78343, SRI International, Menlo\nPark, CA, June 1962 and September 1962.\n[Breiman, et al., 1984] Breiman, L., Friedman, J., Olshen, R., and Stone, C.,\nClassi\ufb01cation and Regression Trees, Monterey, CA: Wadsworth, 1984.\n[Brent, 1990] Brent, R. P., Fast Training Algorithms for Multi-Layer Neural\nNets, Numerical Analysis Project Manuscript NA-90-03, Computer Sci-\nence Department, Stanford University, Stanford, CA 94305, March 1990.\n[Bryson & Ho 1969] Bryson, A., and Ho, Y.-C., Applied Optimal Control, New\nYork: Blaisdell.\n[Buchanan & Wilkins, 1993] Buchanan, B. and Wilkins, D., (eds.), Readings in\nKnowledge Acquisition and Learning, San Francisco: Morgan Kaufmann,\n1993.\n[Carbonell, 1983] Carbonell, J., Learning by Analogy, in Machine Learning:\nAn Arti\ufb01cial Intelligence Approach , Michalski, R., Carbonell, J., and\nMitchell, T., (eds.), San Francisco: Morgan Kaufmann, 1983.\n[Cheeseman, et al., 1988] Cheeseman, P., et al., AutoClass: A Bayesian Clas-\nsi\ufb01cation System, Proc. Fifth Intl. Workshop on Machine Learning ,\nMorgan Kaufmann, San Mateo, CA, 1988. Reprinted in Shavlik, J. and\nDietterich, T., Readings in Machine Learning , Morgan Kaufmann, San\nFrancisco, pp. 296-306, 1990.\n[Cover & Hart, 1967] Cover, T., and Hart, P., Nearest Neighbor Pattern Clas-\nsi\ufb01cation, IEEE Trans. on Information Theory , 13, 21-27, 1967.\n[Cover, 1965] Cover, T., Geometrical and Statistical Properties of Systems\nof Linear Inequalities with Applications in Pattern Recognition, IEEE\nTrans. Elec. Comp., EC-14, 326-334, June, 1965.\n[Dasarathy, 1991] Dasarathy, B. V., Nearest Neighbor Pattern Classi\ufb01cation\nTechniques, IEEE Computer Society Press, 1991.\n[Dayan & Sejnowski, 1994] Dayan, P., and Sejnowski, T.,  TD(\u03bb) Converges\nwith Probability 1, Machine Learning, 14, pp. 295-301, 1994.\n[Dayan, 1992] Dayan, P., The Convergence of TD( \u03bb) for General \u03bb, Machine\nLearning, 8, 341-362, 1992.\n[DeJong & Mooney, 1986] DeJong, G., and Mooney, R., Explanation-Based\nLearning: An Alternative View, Machine Learning, 1:145-176, 1986.\nReprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 452-467.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 179, 'page_label': '180'}, page_content='BIBLIOGRAPHY 171\n[Dietterich & Bakiri, 1991] Dietterich, T. G., and Bakiri, G., Error-Correcting\nOutput Codes: A General Method for Improving Multiclass Induc-\ntive Learning Programs, Proc. Ninth Nat. Conf. on A.I. , pp. 572-577,\nAAAI-91, MIT Press, 1991.\n[Dietterich, et al., 1990] Dietterich, T., Hild, H., and Bakiri, G., A Compara-\ntive Study of ID3 and Backpropagation for English Text-to-Speech Map-\nping, Proc. Seventh Intl. Conf. Mach. Learning, Porter, B. and Mooney,\nR. (eds.), pp. 24-31, San Francisco: Morgan Kaufmann, 1990.\n[Dietterich, 1990] Dietterich, T., Machine Learning, Annu. Rev. Comput.\nSci., 4:255-306, Palo Alto: Annual Reviews Inc., 1990.\n[Duda & Fossum, 1966] Duda, R. O., and Fossum, H., Pattern Classi\ufb01cation\nby Iteratively Determined Linear and Piecewise Linear Discriminant\nFunctions, IEEE Trans. on Elect. Computers , vol. EC-15, pp. 220-232,\nApril, 1966.\n[Duda & Hart, 1973] Duda, R. O., and Hart, P.E., Pattern Classi\ufb01cation and\nScene Analysis, New York: Wiley, 1973.\n[Duda, 1966] Duda, R. O., Training a Linear Machine on Mislabeled Patterns,\nSRI Tech. Report prepared for ONR under Contract 3438(00), SRI In-\nternational, Menlo Park, CA, April 1966.\n[Efron, 1982] Efron, B., The Jackknife, the Bootstrap and Other Resampling\nPlans, Philadelphia: SIAM, 1982.\n[Ehrenfeucht, et al., 1988] Ehrenfeucht, A., et al., A General Lower Bound on\nthe Number of Examples Needed for Learning, in Proc. 1988 Workshop\non Computational Learning Theory, pp. 110-120, San Francisco: Morgan\nKaufmann, 1988.\n[Etzioni, 1991] Etzioni, O., STATIC: A Problem-Space Compiler for\nPRODIGY, Proc. of Ninth National Conf. on Arti\ufb01cial Intelligence ,\npp. 533-540, Menlo Park: AAAI Press, 1991.\n[Etzioni, 1993] Etzioni, O., A Structural Theory of Explanation-Based Learn-\ning, Arti\ufb01cial Intelligence, 60:1, pp. 93-139, March, 1993.\n[Evans & Fisher, 1992] Evans, B., and Fisher, D., Process Delay Analyses Using\nDecision-Tree Induction, Tech. Report CS92-06, Department of Com-\nputer Science, Vanderbilt University, TN, 1992.\n[Fahlman & Lebiere, 1990] Fahlman, S., and Lebiere, C., The Cascade-\nCorrelation Learning Architecture, in Touretzky, D., (ed.), Advances in\nNeural Information Processing Systems, 2 , pp. 524-532, San Francisco:\nMorgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 180, 'page_label': '181'}, page_content='172 BIBLIOGRAPHY\n[Fayyad, et al., 1993] Fayyad, U. M., Weir, N., and Djorgovski, S., SKICAT:\nA Machine Learning System for Automated Cataloging of Large Scale\nSky Surveys, in Proc. Tenth Intl. Conf. on Machine Learning , pp. 112-\n119, San Francisco: Morgan Kaufmann, 1993. (For a longer version of\nthis paper see: Fayyad, U. Djorgovski, G., and Weir, N., Automating\nthe Analysis and Cataloging of Sky Surveys, in Fayyad, U., et al.(eds.),\nAdvances in Knowledge Discovery and Data Mining , Chapter 19, pp.\n471\ufb00., Cambridge: The MIT Press, March, 1996.)\n[Feigenbaum, 1961] Feigenbaum, E. A., The Simulation of Verbal Learning Be-\nhavior, Proceedings of the Western Joint Computer Conference, 19:121-\n132, 1961.\n[Fikes, et al., 1972] Fikes, R., Hart, P., and Nilsson, N., Learning and Execut-\ning Generalized Robot Plans, Arti\ufb01cial Intelligence, pp 251-288, 1972.\nReprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 468-486.\n[Fisher, 1987] Fisher, D., Knowledge Acquisition via Incremental Conceptual\nClustering, Machine Learning, 2:139-172, 1987. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 267283.\n[Friedman, et al., 1977] Friedman, J. H., Bentley, J. L., and Finkel, R. A., An\nAlgorithm for Finding Best Matches in Logarithmic Expected Time,\nACM Trans. on Math. Software , 3(3):209-226, September 1977.\n[Fu, 1994] Fu, L., Neural Networks in Arti\ufb01cial Intelligence , New York:\nMcGraw-Hill, 1994.\n[Gallant, 1986] Gallant, S. I., Optimal Linear Discriminants, in Eighth Inter-\nnational Conf. on Pattern Recognition , pp. 849-852, New York: IEEE,\n1986.\n[Genesereth & Nilsson, 1987] Genesereth, M., and Nilsson, N., Logical Founda-\ntions of Arti\ufb01cial Intelligence , San Francisco: Morgan Kaufmann, 1987.\n[Gluck & Rumelhart, 1989] Gluck, M. and Rumelhart, D., Neuroscience and\nConnectionist Theory, The Developments in Connectionist Theory, Hills-\ndale, NJ: Erlbaum Associates, 1989.\n[Hammerstrom, 1993] Hammerstrom, D., Neural Networks at Work, IEEE\nSpectrum, pp. 26-32, June 1993.\n[Haussler, 1988] Haussler, D., Quantifying Inductive Bias: AI Learning Al-\ngorithms and Valiants Learning Framework, Arti\ufb01cial Intelligence ,\n36:177-221, 1988. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96-107.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 181, 'page_label': '182'}, page_content='BIBLIOGRAPHY 173\n[Haussler, 1990] Haussler, D., Probably Approximately Correct Learning,\nProc. Eighth Nat. Conf. on AI , pp. 1101-1108. Cambridge, MA: MIT\nPress, 1990.\n[Hebb, 1949] Hebb, D. O., The Organization of Behaviour , New York: John\nWiley, 1949.\n[Hertz, Krogh, & Palmer, 1991] Hertz, J., Krogh, A, and Palmer, R., Introduc-\ntion to the Theory of Neural Computation , Lecture Notes, vol. 1, Santa\nFe Inst. Studies in the Sciences of Complexity, New York: Addison-\nWesley, 1991.\n[Hirsh, 1994] Hirsh, H., Generalizing Version Spaces, Machine Learning, 17,\n5-45, 1994.\n[Holland, 1975] Holland, J., Adaptation in Natural and Arti\ufb01cial Systems , Ann\nArbor: The University of Michigan Press, 1975. (Second edition printed\nin 1992 by MIT Press, Cambridge, MA.)\n[Holland, 1986] Holland, J. H., Escaping Brittleness; The Possibilities of\nGeneral-Purpose Learning Algorithms Applied to Parallel Rule-Based\nSystems. In Michalski, R., Carbonell, J., and Mitchell, T. (eds.) , Ma-\nchine Learning: An Arti\ufb01cial Intelligence Approach, Volume 2 , chapter\n20, San Francisco: Morgan Kaufmann, 1986.\n[Hunt, Marin, & Stone, 1966] Hunt, E., Marin, J., and Stone, P., Experiments\nin Induction, New York: Academic Press, 1966.\n[Jabbour, K., et al., 1987] Jabbour, K., et al. , ALFA: Automated Load Fore-\ncasting Assistant, Proc. of the IEEE Pwer Engineering Society Summer\nMeeting, San Francisco, CA, 1987.\n[John, 1995] John, G., Robust Linear Discriminant Trees, Proc. of the Conf.\non Arti\ufb01cial Intelligence and Statistics , Ft. Lauderdale, FL, January,\n1995.\n[Kaelbling, 1993] Kaelbling, L. P., Learning in Embedded Systems, Cambridge,\nMA: MIT Press, 1993.\n[Kohavi, 1994] Kohavi, R., Bottom-Up Induction of Oblivious Read-Once De-\ncision Graphs, Proc. of European Conference on Machine Learning\n(ECML-94), 1994.\n[Kolodner, 1993] Kolodner, J., Case-Based Reasoning, San Francisco: Morgan\nKaufmann, 1993.\n[Koza, 1992] Koza, J., Genetic Programming: On the Programming of Comput-\ners by Means of Natural Selection , Cambridge, MA: MIT Press, 1992.\n[Koza, 1994] Koza, J., Genetic Programming II: Automatic Discovery of\nReusable Programs, Cambridge, MA: MIT Press, 1994.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 182, 'page_label': '183'}, page_content='174 BIBLIOGRAPHY\n[Laird, et al., 1986] Laird, J., Rosenbloom, P., and Newell, A., Chunking in\nSoar: The Anatomy of a General Learning Mechanism, Machine Learn-\ning, 1, pp. 11-46, 1986. Reprinted in Buchanan, B. and Wilkins, D.,\n(eds.), Readings in Knowledge Acquisition and Learning , pp. 518-535,\nMorgan Kaufmann, San Francisco, CA, 1993.\n[Langley, 1992] Langley, P., Areas of Application for Machine Learning,Proc.\nof Fifth Intl. Symp. on Knowledge Engineering , Sevilla, 1992.\n[Langley, 1996] Langley, P., Elements of Machine Learning , San Francisco:\nMorgan Kaufmann, 1996.\n[Lavra\u02c7 c & D\u02c7 zeroski, 1994] Lavra\u02c7 c, N., and D\u02c7 zeroski, S.,Inductive Logic Pro-\ngramming, Chichester, England: Ellis Horwood, 1994.\n[Lin, 1992] Lin, L., Self-Improving Reactive Agents Based on Reinforcement\nLearning, Planning, and Teaching, Machine Learning, 8, 293-321, 1992.\n[Lin, 1993] Lin, L., Scaling Up Reinforcement Learning for Robot Control,\nProc. Tenth Intl. Conf. on Machine Learning, pp. 182-189, San Francisco:\nMorgan Kaufmann, 1993.\n[Littlestone, 1988] Littlestone, N., Learning Quickly When Irrelevant At-\ntributes Abound: A New Linear-Threshold Algorithm, Machine Learn-\ning 2: 285-318, 1988.\n[Maass & Tur´ an, 1994] Maass, W., and Tur´ an, G., How Fast Can a Thresh-\nold Gate Learn?, in Hanson, S., Drastal, G., and Rivest, R., (eds.),\nComputational Learning Theory and Natural Learning Systems, Volume\n1: Constraints and Prospects , pp. 381-414, Cambridge, MA: MIT Press,\n1994.\n[Mahadevan & Connell, 1992] Mahadevan, S., and Connell, J., Automatic\nProgramming of Behavior-Based Robots Using Reinforcement Learn-\ning, Arti\ufb01cial Intelligence, 55, pp. 311-365, 1992.\n[Marchand & Golea, 1993] Marchand, M., and Golea, M., On Learning Sim-\nple Neural Concepts: From Halfspace Intersections to Neural Decision\nLists, Network, 4:67-85, 1993.\n[McCulloch & Pitts, 1943] McCulloch, W. S., and Pitts, W. H., A Logical Cal-\nculus of the Ideas Immanent in Nervous Activity, Bulletin of Mathe-\nmatical Biophysics, Vol. 5, pp. 115-133, Chicago: University of Chicago\nPress, 1943.\n[Michie, 1992] Michie, D., Some Directions in Machine Intelligence, unpub-\nlished manuscript, The Turing Institute, Glasgow, Scotland, 1992.\n[Minton, 1988] Minton, S., Learning Search Control Knowledge: An\nExplanation-Based Approach , Kluwer Academic Publishers, Boston,\nMA, 1988.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 183, 'page_label': '184'}, page_content='BIBLIOGRAPHY 175\n[Minton, 1990] Minton, S., Quantitative Results Concerning the Utility of\nExplanation-Based Learning, Arti\ufb01cial Intelligence , 42, pp. 363-392,\n1990. Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine\nLearning, San Francisco: Morgan Kaufmann, 1990, pp. 573-587.\n[Mitchell, et al., 1986] Mitchell, T., et al., Explanation-Based Generalization:\nA Unifying View, Machine Learning, 1:1, 1986. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 435-451.\n[Mitchell, 1982] Mitchell, T., Generalization as Search, Arti\ufb01cial Intelligence,\n18:203-226, 1982. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96107.\n[Moore & Atkeson, 1993] Moore, A., and Atkeson, C., Prioritized Sweeping:\nReinforcement Learning with Less Data and Less Time,Machine Learn-\ning, 13, pp. 103-130, 1993.\n[Moore, et al., 1994] Moore, A. W., Hill, D. J., and Johnson, M. P., An Em-\npirical Investigation of Brute Force to Choose Features, Smoothers, and\nFunction Approximators, in Hanson, S., Judd, S., and Petsche, T.,\n(eds.), Computational Learning Theory and Natural Learning Systems ,\nVol. 3, Cambridge: MIT Press, 1994.\n[Moore, 1990] Moore, A., E\ufb03cient Memory-based Learning for Robot Control ,\nPhD. Thesis; Technical Report No. 209, Computer Laboratory, Univer-\nsity of Cambridge, October, 1990.\n[Moore, 1992] Moore, A., Fast, Robust Adaptive Control by Learning Only\nForward Models, in Moody, J., Hanson, S., and Lippman, R., (eds.),\nAdvances in Neural Information Processing Systems 4 , San Francisco:\nMorgan Kaufmann, 1992.\n[Mueller & Page, 1988] Mueller, R. and Page, R., Symbolic Computing with\nLisp and Prolog, New York: John Wiley & Sons, 1988.\n[Muggleton, 1991] Muggleton, S., Inductive Logic Programming, New Gen-\neration Computing, 8, pp. 295-318, 1991.\n[Muggleton, 1992] Muggleton, S., Inductive Logic Programming, London: Aca-\ndemic Press, 1992.\n[Muroga, 1971] Muroga, S., Threshold Logic and its Applications , New York:\nWiley, 1971.\n[Natarjan, 1991] Natarajan, B., Machine Learning: A Theoretical Approach ,\nSan Francisco: Morgan Kaufmann, 1991.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 184, 'page_label': '185'}, page_content='176 BIBLIOGRAPHY\n[Nilsson, 1965] Nilsson, N. J., Theoretical and Experimental Investigations in\nTrainable Pattern-Classifying Systems, Tech. Report No. RADC-TR-\n65-257, Final Report on Contract AF30(602)-3448, Rome Air Develop-\nment Center (Now Rome Laboratories), Gri\ufb03ss Air Force Base, New\nYork, September, 1965.\n[Nilsson, 1990] Nilsson, N. J., The Mathematical Foundations of Learning Ma-\nchines, San Francisco: Morgan Kaufmann, 1990. (This book is a reprint\nof Learning Machines: Foundations of Trainable Pattern-Classifying\nSystems, New York: McGraw-Hill, 1965.)\n[Oliver, Dowe, & Wallace, 1992] Oliver, J., Dowe, D., and Wallace, C., Infer-\nring Decision Graphs using the Minimum Message Length Principle,\nProc. 1992 Australian Arti\ufb01cial Intelligence Conference , 1992.\n[Pagallo & Haussler, 1990] Pagallo, G. and Haussler, D., Boolean Feature Dis-\ncovery in Empirical Learning, Machine Learning, vol.5, no.1, pp. 71-99,\nMarch 1990.\n[Pazzani & Kibler, 1992] Pazzani, M., and Kibler, D., The Utility of Knowl-\nedge in Inductive Learning, Machine Learning, 9, 57-94, 1992.\n[Peterson, 1961] Peterson, W., Error Correcting Codes, New York: John Wiley,\n1961.\n[Pomerleau, 1991] Pomerleau, D., Rapidly Adapting Arti\ufb01cial Neural Net-\nworks for Autonomous Navigation, in Lippmann, P., et al. (eds.), Ad-\nvances in Neural Information Processing Systems, 3 , pp. 429-435, San\nFrancisco: Morgan Kaufmann, 1991.\n[Pomerleau, 1993] Pomerleau, D, Neural Network Perception for Mobile Robot\nGuidance, Boston: Kluwer Academic Publishers, 1993.\n[Quinlan & Rivest, 1989] Quinlan, J. Ross, and Rivest, Ron, Inferring Deci-\nsion Trees Using the Minimum Description Length Principle, Informa-\ntion and Computation , 80:227248, March, 1989.\n[Quinlan, 1986] Quinlan, J. Ross, Induction of Decision Trees, Machine\nLearning, 1:81106, 1986. Reprinted in Shavlik, J. and Dietterich, T.,\nReadings in Machine Learning, San Francisco: Morgan Kaufmann, 1990,\npp. 5769.\n[Quinlan, 1987] Quinlan, J. R., Generating Production Rules from Decision\nTrees, In IJCAI-87: Proceedings of the Tenth Intl. Joint Conf. on Ar-\nti\ufb01cial Intelligence, pp. 304-7, San Francisco: Morgan-Kaufmann, 1987.\n[Quinlan, 1990] Quinlan, J. R., Learning Logical De\ufb01nitions from Relations,\nMachine Learning, 5, 239-266, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 185, 'page_label': '186'}, page_content='BIBLIOGRAPHY 177\n[Quinlan, 1993] Quinlan, J. Ross, C4.5: Programs for Machine Learning , San\nFrancisco: Morgan Kaufmann, 1993.\n[Quinlan, 1994] Quinlan, J. R., Comparing Connectionist and Symbolic Learn-\ning Methods, in Hanson, S., Drastal, G., and Rivest, R., (eds.), Com-\nputational Learning Theory and Natural Learning Systems, Volume 1:\nConstraints and Prospects , pp. 445-456,, Cambridge, MA: MIT Press,\n1994.\n[Ridgway, 1962] Ridgway, W. C., An Adaptive Logic System with Generalizing\nProperties, PhD thesis, Tech. Rep. 1556-1, Stanford Electronics Labs.,\nStanford, CA, April 1962.\n[Rissanen, 1978] Rissanen, J., Modeling by Shortest Data Description, Auto-\nmatica, 14:465-471, 1978.\n[Rivest, 1987] Rivest, R. L., Learning Decision Lists, Machine Learning, 2,\n229-246, 1987.\n[Rosenblatt, 1958] Rosenblatt, F., Principles of Neurodynamics , Washington:\nSpartan Books, 1961.\n[Ross, 1983] Ross, S., Introduction to Stochastic Dynamic Programming , New\nYork: Academic Press, 1983.\n[Rumelhart, Hinton, & Williams, 1986] Rumelhart, D. E., Hinton, G. E., and\nWilliams, R. J., Learning Internal Representations by Error Propa-\ngation, In Rumelhart, D. E., and McClelland, J. L., (eds.) Parallel\nDistributed Processing, Vol 1, 318362, 1986.\n[Russell & Norvig 1995] Russell, S., and Norvig, P., Arti\ufb01cial Intelligence: A\nModern Approach, Englewood Cli\ufb00s, NJ: Prentice Hall, 1995.\n[Samuel, 1959] Samuel, A., Some Studies in Machine Learning Using the Game\nof Checkers,IBM Journal of Research and Development, 3:211-229, July\n1959.\n[Schwartz, 1993] Schwartz, A., A Reinforcement Learning Method for Max-\nimizing Undiscounted Rewards, Proc. Tenth Intl. Conf. on Machine\nLearning, pp. 298-305, San Francisco: Morgan Kaufmann, 1993.\n[Sejnowski, Koch, & Churchland, 1988] Sejnowski, T., Koch, C., and Church-\nland, P., Computational Neuroscience, Science, 241: 1299-1306, 1988.\n[Shavlik, Mooney, & Towell, 1991] Shavlik, J., Mooney, R., and Towell, G.,\nSymbolic and Neural Learning Algorithms: An Experimental Compar-\nison, Machine Learning, 6, pp. 111-143, 1991.\n[Shavlik & Dietterich, 1990] Shavlik, J. and Dietterich, T., Readings in Ma-\nchine Learning, San Francisco: Morgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 186, 'page_label': '187'}, page_content='178 BIBLIOGRAPHY\n[Sutton & Barto, 1987] Sutton, R. S., and Barto, A. G., A Temporal-\nDi\ufb00erence Model of Classical Conditioning, in Proceedings of the Ninth\nAnnual Conference of the Cognitive Science Society , Hillsdale, NJ: Erl-\nbaum, 1987.\n[Sutton, 1988] Sutton, R. S., Learning to Predict by the Methods of Temporal\nDi\ufb00erences, Machine Learning 3: 9-44, 1988.\n[Sutton, 1990] Sutton, R., Integrated Architectures for Learning, Planning,\nand Reacting Based on Approximating Dynamic Programming,Proc. of\nthe Seventh Intl. Conf. on Machine Learning, pp. 216-224, San Francisco:\nMorgan Kaufmann, 1990.\n[Taylor, Michie, & Spiegalhalter, 1994] Taylor, C., Michie, D., and Spiegal-\nhalter, D., Machine Learning, Neural and Statistical Classi\ufb01cation ,\nParamount Publishing International.\n[Tesauro, 1992] Tesauro, G., Practical Issues in Temporal Di\ufb00erence Learn-\ning, Machine Learning, 8, nos. 3/4, pp. 257-277, 1992.\n[Towell & Shavlik, 1992] Towell G., and Shavlik, J., Interpretation of Arti\ufb01-\ncial Neural Networks: Mapping Knowledge-Based Neural Networks into\nRules, in Moody, J., Hanson, S., and Lippmann, R., (eds.), Advances in\nNeural Information Processing Systems, 4 , pp. 977-984, San Francisco:\nMorgan Kaufmann, 1992.\n[Towell, Shavlik, & Noordweier, 1990] Towell, G., Shavlik, J., and Noordweier,\nM., Re\ufb01nement of Approximate Domain Theories by Knowledge-Based\nArti\ufb01cial Neural Networks, Proc. Eighth Natl., Conf. on Arti\ufb01cial In-\ntelligence, pp. 861-866, 1990.\n[Unger, 1989] Unger, S., The Essence of Logic Circuits , Englewood Cli\ufb00s, NJ:\nPrentice-Hall, 1989.\n[Utgo\ufb00, 1989] Utgo\ufb00, P., Incremental Induction of Decision Trees, Machine\nLearning, 4:161186, Nov., 1989.\n[Valiant, 1984] Valiant, L., A Theory of the Learnable, Communications of\nthe ACM, Vol. 27 , pp. 1134-1142, 1984.\n[Vapnik & Chervonenkis, 1971] Vapnik, V., and Chervonenkis, A., On the\nUniform Convergence of Relative Frequencies, Theory of Probability and\nits Applications, Vol. 16 , No. 2, pp. 264-280, 1971.\n[Various Editors, 1989-1994] Advances in Neural Information Processing Sys-\ntems, vols 1 through 6, San Francisco: Morgan Kaufmann, 1989 -1994.\n[Watkins & Dayan, 1992] Watkins, C. J. C. H., and Dayan, P., Technical Note:\nQ-Learning, Machine Learning, 8, 279-292, 1992.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 187, 'page_label': '188'}, page_content='BIBLIOGRAPHY 179\n[Watkins, 1989] Watkins, C. J. C. H., Learning From Delayed Rewards , PhD\nThesis, University of Cambridge, England, 1989.\n[Weiss & Kulikowski, 1991] Weiss, S., and Kulikowski, C., Computer Systems\nthat Learn, San Francisco: Morgan Kaufmann, 1991.\n[Werbos, 1974] Werbos, P., Beyond Regression: New Tools for Prediction and\nAnalysis in the Behavioral Sciences , Ph.D. Thesis, Harvard University,\n1974.\n[Widrow & Lehr, 1990] Widrow, B., and Lehr, M. A., 30 Years of Adaptive\nNeural Networks: Perceptron, Madaline and Backpropagation, Proc.\nIEEE, vol. 78, no. 9, pp. 1415-1442, September, 1990.\n[Widrow & Stearns, 1985] Widrow, B., and Stearns, S., Adaptive Signal Pro-\ncessing, Englewood Cli\ufb00s, NJ: Prentice-Hall.\n[Widrow, 1962] Widrow, B., Generalization and Storage in Networks of Ada-\nline Neurons, in Yovits, Jacobi, and Goldstein (eds.), Self-organizing\nSystems1962, pp. 435-461, Washington, DC: Spartan Books, 1962.\n[Winder, 1961] Winder, R., Single Stage Threshold Logic, Proc. of the AIEE\nSymp. on Switching Circuits and Logical Design , Conf. paper CP-60-\n1261, pp. 321-332, 1961.\n[Winder, 1962] Winder, R., Threshold Logic, PhD Dissertation, Princeton Uni-\nversity, Princeton, NJ, 1962.\n[Wnek, et al., 1990] Wnek, J., et al., Comparing Learning Paradigms via Di-\nagrammatic Visualization, in Proc. Fifth Intl. Symp. on Methodologies\nfor Intelligent Systems , pp. 428-437, 1990. (Also Tech. Report MLI90-2,\nUniversity of Illinois at Urbana-Champaign.)')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 401 Unauthorized"
ERROR:root:Error indexing document: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************zh0A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
INFO:root:File ID: 3, Temp file path: temp_MLpdf.pdf
INFO:root:File ID: 3, file path: temp_MLpdf.pdf
INFO:root:PDF file loaded: temp_MLpdf.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 0, 'page_label': '1'}, page_content='INTRODUCTION\nTO\nMACHINE LEARNING\nAN EARLY DRAFT OF A PROPOSED\nTEXTBOOK\nNils J. Nilsson\nRobotics Laboratory\nDepartment of Computer Science\nStanford University\nStanford, CA 94305\ne-mail: nilsson@cs.stanford.edu\nNovember 3, 1998\nCopyright c\u20dd2005 Nils J. Nilsson\nThis material may not be copied, reproduced, or distributed without the\nwritten permission of the copyright holder.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 1, 'page_label': '2'}, page_content='ii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='Contents\n1 Preliminaries 1\n1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1.1 What is Machine Learning? . . . . . . . . . . . . . . . . . 1\n1.1.2 Wellsprings of Machine Learning . . . . . . . . . . . . . . 3\n1.1.3 Varieties of Machine Learning . . . . . . . . . . . . . . . . 4\n1.2 Learning Input-Output Functions . . . . . . . . . . . . . . . . . . 5\n1.2.1 Types of Learning . . . . . . . . . . . . . . . . . . . . . . 5\n1.2.2 Input Vectors . . . . . . . . . . . . . . . . . . . . . . . . . 7\n1.2.3 Outputs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.4 Training Regimes . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.5 Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.2.6 Performance Evaluation . . . . . . . . . . . . . . . . . . . 9\n1.3 Learning Requires Bias . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.4 Sample Applications . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.5 Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 13\n2 Boolean Functions 15\n2.1 Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1.1 Boolean Algebra . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1.2 Diagrammatic Representations . . . . . . . . . . . . . . . 16\n2.2 Classes of Boolean Functions . . . . . . . . . . . . . . . . . . . . 17\n2.2.1 Terms and Clauses . . . . . . . . . . . . . . . . . . . . . . 17\n2.2.2 DNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.2.3 CNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.2.4 Decision Lists . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.2.5 Symmetric and Voting Functions . . . . . . . . . . . . . . 23\n2.2.6 Linearly Separable Functions . . . . . . . . . . . . . . . . 23\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 25\niii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='3 Using Version Spaces for Learning 27\n3.1 Version Spaces and Mistake Bounds . . . . . . . . . . . . . . . . 27\n3.2 Version Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n3.3 Learning as Search of a Version Space . . . . . . . . . . . . . . . 32\n3.4 The Candidate Elimination Method . . . . . . . . . . . . . . . . 32\n3.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 34\n4 Neural Networks 35\n4.1 Threshold Logic Units . . . . . . . . . . . . . . . . . . . . . . . . 35\n4.1.1 De\ufb01nitions and Geometry . . . . . . . . . . . . . . . . . . 35\n4.1.2 Special Cases of Linearly Separable Functions . . . . . . . 37\n4.1.3 Error-Correction Training of a TLU . . . . . . . . . . . . 38\n4.1.4 Weight Space . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4.1.5 The Widrow-Ho\ufb00 Procedure . . . . . . . . . . . . . . . . . 42\n4.1.6 Training a TLU on Non-Linearly-Separable Training Sets 44\n4.2 Linear Machines . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.3 Networks of TLUs . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n4.3.1 Motivation and Examples . . . . . . . . . . . . . . . . . . 46\n4.3.2 Madalines . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.3.3 Piecewise Linear Machines . . . . . . . . . . . . . . . . . . 50\n4.3.4 Cascade Networks . . . . . . . . . . . . . . . . . . . . . . 51\n4.4 Training Feedforward Networks by Backpropagation . . . . . . . 52\n4.4.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.4.2 The Backpropagation Method . . . . . . . . . . . . . . . . 53\n4.4.3 Computing Weight Changes in the Final Layer . . . . . . 56\n4.4.4 Computing Changes to the Weights in Intermediate Layers 58\n4.4.5 Variations on Backprop . . . . . . . . . . . . . . . . . . . 59\n4.4.6 An Application: Steering a Van . . . . . . . . . . . . . . . 60\n4.5 Synergies Between Neural Network and Knowledge-Based Methods 61\n4.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 61\n5 Statistical Learning 63\n5.1 Using Statistical Decision Theory . . . . . . . . . . . . . . . . . . 63\n5.1.1 Background and General Method . . . . . . . . . . . . . . 63\n5.1.2 Gaussian (or Normal) Distributions . . . . . . . . . . . . 65\n5.1.3 Conditionally Independent Binary Components . . . . . . 68\n5.2 Learning Belief Networks . . . . . . . . . . . . . . . . . . . . . . 70\n5.3 Nearest-Neighbor Methods . . . . . . . . . . . . . . . . . . . . . . 70\n5.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 72\niv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='6 Decision Trees 73\n6.1 De\ufb01nitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n6.2 Supervised Learning of Univariate Decision Trees . . . . . . . . . 74\n6.2.1 Selecting the Type of Test . . . . . . . . . . . . . . . . . . 75\n6.2.2 Using Uncertainty Reduction to Select Tests . . . . . . . 75\n6.2.3 Non-Binary Attributes . . . . . . . . . . . . . . . . . . . . 79\n6.3 Networks Equivalent to Decision Trees . . . . . . . . . . . . . . . 79\n6.4 Over\ufb01tting and Evaluation . . . . . . . . . . . . . . . . . . . . . 80\n6.4.1 Over\ufb01tting . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n6.4.2 Validation Methods . . . . . . . . . . . . . . . . . . . . . 81\n6.4.3 Avoiding Over\ufb01tting in Decision Trees . . . . . . . . . . . 82\n6.4.4 Minimum-Description Length Methods . . . . . . . . . . . 83\n6.4.5 Noise in Data . . . . . . . . . . . . . . . . . . . . . . . . . 84\n6.5 The Problem of Replicated Subtrees . . . . . . . . . . . . . . . . 84\n6.6 The Problem of Missing Attributes . . . . . . . . . . . . . . . . . 86\n6.7 Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n6.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 87\n7 Inductive Logic Programming 89\n7.1 Notation and De\ufb01nitions . . . . . . . . . . . . . . . . . . . . . . . 90\n7.2 A Generic ILP Algorithm . . . . . . . . . . . . . . . . . . . . . . 91\n7.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n7.4 Inducing Recursive Programs . . . . . . . . . . . . . . . . . . . . 98\n7.5 Choosing Literals to Add . . . . . . . . . . . . . . . . . . . . . . 100\n7.6 Relationships Between ILP and Decision Tree Induction . . . . . 101\n7.7 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 104\n8 Computational Learning Theory 107\n8.1 Notation and Assumptions for PAC Learning Theory . . . . . . . 107\n8.2 PAC Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n8.2.1 The Fundamental Theorem . . . . . . . . . . . . . . . . . 109\n8.2.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n8.2.3 Some Properly PAC-Learnable Classes . . . . . . . . . . . 112\n8.3 The Vapnik-Chervonenkis Dimension . . . . . . . . . . . . . . . . 113\n8.3.1 Linear Dichotomies . . . . . . . . . . . . . . . . . . . . . . 113\n8.3.2 Capacity . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n8.3.3 A More General Capacity Result . . . . . . . . . . . . . . 116\n8.3.4 Some Facts and Speculations About the VC Dimension . 117\n8.4 VC Dimension and PAC Learning . . . . . . . . . . . . . . . . . 118\n8.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 118\nv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='9 Unsupervised Learning 119\n9.1 What is Unsupervised Learning? . . . . . . . . . . . . . . . . . . 119\n9.2 Clustering Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n9.2.1 A Method Based on Euclidean Distance . . . . . . . . . . 120\n9.2.2 A Method Based on Probabilities . . . . . . . . . . . . . . 124\n9.3 Hierarchical Clustering Methods . . . . . . . . . . . . . . . . . . 125\n9.3.1 A Method Based on Euclidean Distance . . . . . . . . . . 125\n9.3.2 A Method Based on Probabilities . . . . . . . . . . . . . . 126\n9.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 130\n10 Temporal-Di\ufb00erence Learning 131\n10.1 Temporal Patterns and Prediction Problems . . . . . . . . . . . . 131\n10.2 Supervised and Temporal-Di\ufb00erence Methods . . . . . . . . . . . 131\n10.3 Incremental Computation of the (\u2206 W)i . . . . . . . . . . . . . . 134\n10.4 An Experiment with TD Methods . . . . . . . . . . . . . . . . . 135\n10.5 Theoretical Results . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n10.6 Intra-Sequence Weight Updating . . . . . . . . . . . . . . . . . . 138\n10.7 An Example Application: TD-gammon . . . . . . . . . . . . . . . 140\n10.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 141\n11 Delayed-Reinforcement Learning 143\n11.1 The General Problem . . . . . . . . . . . . . . . . . . . . . . . . 143\n11.2 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n11.3 Temporal Discounting and Optimal Policies . . . . . . . . . . . . 145\n11.4 Q-Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n11.5 Discussion, Limitations, and Extensions of Q-Learning . . . . . . 150\n11.5.1 An Illustrative Example . . . . . . . . . . . . . . . . . . . 150\n11.5.2 Using Random Actions . . . . . . . . . . . . . . . . . . . 152\n11.5.3 Generalizing Over Inputs . . . . . . . . . . . . . . . . . . 153\n11.5.4 Partially Observable States . . . . . . . . . . . . . . . . . 154\n11.5.5 Scaling Problems . . . . . . . . . . . . . . . . . . . . . . . 154\n11.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 155\nvi'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='12 Explanation-Based Learning 157\n12.1 Deductive Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 157\n12.2 Domain Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n12.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n12.4 Evaluable Predicates . . . . . . . . . . . . . . . . . . . . . . . . . 162\n12.5 More General Proofs . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.6 Utility of EBL . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.7 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.7.1 Macro-Operators in Planning . . . . . . . . . . . . . . . . 164\n12.7.2 Learning Search Control Knowledge . . . . . . . . . . . . 167\n12.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 168\nvii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 7, 'page_label': '8'}, page_content='viii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 8, 'page_label': '9'}, page_content='Preface\nThese notes are in the process of becoming a textbook. The process is quite\nun\ufb01nished, and the author solicits corrections, criticisms, and suggestions from\nstudents and other readers. Although I have tried to eliminate errors, some un-\ndoubtedly remaincaveat lector. Many typographical infelicities will no doubt\npersist until the \ufb01nal version. More material has yet to be added. Please let Some of my plans for additions and\nother reminders are mentioned in\nmarginal notes.me have your suggestions about topics that are too important to be left out.\nI hope that future versions will cover Hop\ufb01eld nets, Elman nets and other re-\ncurrent nets, radial basis functions, grammar and automata learning, genetic\nalgorithms, and Bayes networks ... . I am also collecting exercises and project\nsuggestions which will appear in future versions.\nMy intention is to pursue a middle ground between a theoretical textbook\nand one that focusses on applications. The book concentrates on the important\nideas in machine learning. I do not give proofs of many of the theorems that I\nstate, but I do give plausibility arguments and citations to formal proofs. And, I\ndo not treat many matters that would be of practical importance in applications;\nthe book is not a handbook of machine learning practice. Instead, my goal is\nto give the reader su\ufb03cient preparation to make the extensive literature on\nmachine learning accessible.\nStudents in my Stanford courses on machine learning have already made\nseveral useful suggestions, as have my colleague, Pat Langley, and my teaching\nassistants, Ron Kohavi, Karl P\ufb02eger, Robert Allen, and Lise Getoor.\nix'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 9, 'page_label': '10'}, page_content='Chapter 1\nPreliminaries\n1.1 Introduction\n1.1.1 What is Machine Learning?\nLearning, like intelligence, covers such a broad range of processes that it is dif-\n\ufb01cult to de\ufb01ne precisely. A dictionary de\ufb01nition includes phrases such as to\ngain knowledge, or understanding of, or skill in, by study, instruction, or expe-\nrience, and modi\ufb01cation of a behavioral tendency by experience. Zoologists\nand psychologists study learning in animals and humans. In this book we fo-\ncus on learning in machines. There are several parallels between animal and\nmachine learning. Certainly, many techniques in machine learning derive from\nthe e\ufb00orts of psychologists to make more precise their theories of animal and\nhuman learning through computational models. It seems likely also that the\nconcepts and techniques being explored by researchers in machine learning may\nilluminate certain aspects of biological learning.\nAs regards machines, we might say, very broadly, that a machine learns\nwhenever it changes its structure, program, or data (based on its inputs or in\nresponse to external information) in such a manner that its expected future\nperformance improves. Some of these changes, such as the addition of a record\nto a data base, fall comfortably within the province of other disciplines and are\nnot necessarily better understood for being called learning. But, for example,\nwhen the performance of a speech-recognition machine improves after hearing\nseveral samples of a persons speech, we feel quite justi\ufb01ed in that case to say\nthat the machine has learned.\nMachine learning usually refers to the changes in systems that perform tasks\nassociated with arti\ufb01cial intelligence (AI) . Such tasks involve recognition, diag-\nnosis, planning, robot control, prediction, etc. The changes might be either\nenhancements to already performing systems or ab initio synthesis of new sys-\ntems. To be slightly more speci\ufb01c, we show the architecture of a typical AI\n1'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 10, 'page_label': '11'}, page_content='2 CHAPTER 1. PRELIMINARIES\nagent in Fig. 1.1. This agent perceives and models its environment and com-\nputes appropriate actions, perhaps by anticipating their e\ufb00ects. Changes made\nto any of the components shown in the \ufb01gure might count as learning. Di\ufb00erent\nlearning mechanisms might be employed depending on which subsystem is being\nchanged. We will study several di\ufb00erent learning methods in this book.\nSensory signals\nPerception\nActions\nAction\nComputation\nModel\nPlanning and\nReasoning\nGoals\nFigure 1.1: An AI System\nOne might ask Why should machines have to learn? Why not design ma-\nchines to perform as desired in the \ufb01rst place? There are several reasons why\nmachine learning is important. Of course, we have already mentioned that the\nachievement of learning in machines might help us understand how animals and\nhumans learn. But there are important engineering reasons as well. Some of\nthese are:\n Some tasks cannot be de\ufb01ned well except by example; that is, we might be\nable to specify input/output pairs but not a concise relationship between\ninputs and desired outputs. We would like machines to be able to adjust\ntheir internal structure to produce correct outputs for a large number of\nsample inputs and thus suitably constrain their input/output function to\napproximate the relationship implicit in the examples.\n It is possible that hidden among large piles of data are important rela-\ntionships and correlations. Machine learning methods can often be used\nto extract these relationships ( data mining).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 11, 'page_label': '12'}, page_content='1.1. INTRODUCTION 3\n Human designers often produce machines that do not work as well as\ndesired in the environments in which they are used. In fact, certain char-\nacteristics of the working environment might not be completely known\nat design time. Machine learning methods can be used for on-the-job\nimprovement of existing machine designs.\n The amount of knowledge available about certain tasks might be too large\nfor explicit encoding by humans. Machines that learn this knowledge\ngradually might be able to capture more of it than humans would want to\nwrite down.\n Environments change over time. Machines that can adapt to a changing\nenvironment would reduce the need for constant redesign.\n New knowledge about tasks is constantly being discovered by humans.\nVocabulary changes. There is a constant stream of new events in the\nworld. Continuing redesign of AI systems to conform to new knowledge is\nimpractical, but machine learning methods might be able to track much\nof it.\n1.1.2 Wellsprings of Machine Learning\nWork in machine learning is now converging from several sources. These dif-\nferent traditions each bring di\ufb00erent methods and di\ufb00erent vocabulary which\nare now being assimilated into a more uni\ufb01ed discipline. Here is a brief listing\nof some of the separate disciplines that have contributed to machine learning;\nmore details will follow in the the appropriate chapters:\n Statistics: A long-standing problem in statistics is how best to use sam-\nples drawn from unknown probability distributions to help decide from\nwhich distribution some new sample is drawn. A related problem is how\nto estimate the value of an unknown function at a new point given the\nvalues of this function at a set of sample points. Statistical methods\nfor dealing with these problems can be considered instances of machine\nlearning because the decision and estimation rules depend on a corpus of\nsamples drawn from the problem environment. We will explore some of\nthe statistical methods later in the book. Details about the statistical the-\nory underlying these methods can be found in statistical textbooks such\nas [Anderson, 1958].\n Brain Models: Non-linear elements with weighted inputs\nhave been suggested as simple models of biological neu-\nrons. Networks of these elements have been studied by sev-\neral researchers including [McCulloch & Pitts, 1943, Hebb, 1949,\nRosenblatt, 1958] and, more recently by [Gluck & Rumelhart, 1989,\nSejnowski, Koch, & Churchland, 1988]. Brain modelers are interested\nin how closely these networks approximate the learning phenomena of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 12, 'page_label': '13'}, page_content='4 CHAPTER 1. PRELIMINARIES\nliving brains. We shall see that several important machine learning\ntechniques are based on networks of nonlinear elementsoften called\nneural networks . Work inspired by this school is sometimes called\nconnectionism, brain-style computation, or sub-symbolic processing.\n Adaptive Control Theory: Control theorists study the problem of con-\ntrolling a process having unknown parameters which must be estimated\nduring operation. Often, the parameters change during operation, and the\ncontrol process must track these changes. Some aspects of controlling a\nrobot based on sensory inputs represent instances of this sort of problem.\nFor an introduction see [Bollinger & Du\ufb03e, 1988].\n Psychological Models: Psychologists have studied the performance of\nhumans in various learning tasks. An early example is the EPAM net-\nwork for storing and retrieving one member of a pair of words when\ngiven another [Feigenbaum, 1961]. Related work led to a number of\nearly decision tree [Hunt, Marin, & Stone, 1966] and semantic network\n[Anderson & Bower, 1973] methods. More recent work of this sort has\nbeen in\ufb02uenced by activities in arti\ufb01cial intelligence which we will be pre-\nsenting.\nSome of the work in reinforcement learning can be traced to e\ufb00orts to\nmodel how reward stimuli in\ufb02uence the learning of goal-seeking behavior in\nanimals [Sutton & Barto, 1987]. Reinforcement learning is an important\ntheme in machine learning research.\n Arti\ufb01cial Intelligence: From the beginning, AI research has been con-\ncerned with machine learning. Samuel developed a prominent early pro-\ngram that learned parameters of a function for evaluating board posi-\ntions in the game of checkers [Samuel, 1959]. AI researchers have also\nexplored the role of analogies in learning [Carbonell, 1983] and how fu-\nture actions and decisions can be based on previous exemplary cases\n[Kolodner, 1993]. Recent work has been directed at discovering rules\nfor expert systems using decision-tree methods [Quinlan, 1990] and in-\nductive logic programming [Muggleton, 1991, Lavra\u02c7 c & D\u02c7 zeroski, 1994].\nAnother theme has been saving and generalizing the results of prob-\nlem solving using explanation-based learning [DeJong & Mooney, 1986,\nLaird, et al., 1986, Minton, 1988, Etzioni, 1993].\n Evolutionary Models:\nIn nature, not only do individual animals learn to perform better, but\nspecies evolve to be better \ufb01t in their individual niches. Since the distinc-\ntion between evolving and learning can be blurred in computer systems,\ntechniques that model certain aspects of biological evolution have been\nproposed as learning methods to improve the performance of computer\nprograms. Genetic algorithms [Holland, 1975] and genetic programming\n[Koza, 1992, Koza, 1994] are the most prominent computational tech-\nniques for evolution.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 13, 'page_label': '14'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 5\n1.1.3 Varieties of Machine Learning\nOrthogonal to the question of the historical source of any learning technique is\nthe more important question of what is to be learned. In this book, we take it\nthat the thing to be learned is a computational structure of some sort. We will\nconsider a variety of di\ufb00erent computational structures:\n Functions\n Logic programs and rule sets\n Finite-state machines\n Grammars\n Problem solving systems\nWe will present methods both for the synthesis of these structures from examples\nand for changing existing structures. In the latter case, the change to the\nexisting structure might be simply to make it more computationally e\ufb03cient\nrather than to increase the coverage of the situations it can handle. Much of\nthe terminology that we shall be using throughout the book is best introduced\nby discussing the problem of learning functions, and we turn to that matter\n\ufb01rst.\n1.2 Learning Input-Output Functions\nWe use Fig. 1.2 to help de\ufb01ne some of the terminology used in describing the\nproblem of learning a function. Imagine that there is a function, f, and the task\nof the learner is to guess what it is. Our hypothesis about the function to be\nlearned is denoted by h. Both f and h are functions of a vector-valued input\nX = (x1,x2,...,x i,...,x n) which has n components. We think of h as being\nimplemented by a device that has X as input and h(X) as output. Both f and\nh themselves may be vector-valued. We assume a priori that the hypothesized\nfunction, h, is selected from a class of functions H. Sometimes we know that\nf also belongs to this class or to a subset of this class. We select h based on a\ntraining set, \u039e, of minput vector examples. Many important details depend on\nthe nature of the assumptions made about all of these entities.\n1.2.1 Types of Learning\nThere are two major settings in which we wish to learn a function. In one,\ncalled supervised learning, we know (sometimes only approximately) the values\nof f for the m samples in the training set, \u039e. We assume that if we can \ufb01nd\na hypothesis, h, that closely agrees with f for the members of \u039e, then this\nhypothesis will be a good guess for fespecially if \u039e is large.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 14, 'page_label': '15'}, page_content='6 CHAPTER 1. PRELIMINARIES\nh(X)\nh\nU = {X1, X2, . . . Xi, . . ., Xm}\nTraining Set:\nX =\nx1\n.\n.\n.\nxi\n.\n.\n.\nxn h D H\nFigure 1.2: An Input-Output Function\nCurve-\ufb01tting is a simple example of supervised learning of a function. Sup-\npose we are given the values of a two-dimensional function,f, at the four sample\npoints shown by the solid circles in Fig. 1.3. We want to \ufb01t these four points\nwith a function, h, drawn from the set, H, of second-degree functions. We show\nthere a two-dimensional parabolic surface above the x1, x2 plane that \ufb01ts the\npoints. This parabolic function, h, is our hypothesis about the function, f, that\nproduced the four samples. In this case, h= f at the four samples, but we need\nnot have required exact matches.\nIn the other setting, termed unsupervised learning, we simply have a train-\ning set of vectors without function values for them. The problem in this case,\ntypically, is to partition the training set into subsets, \u039e 1, . . . , \u039eR, in some ap-\npropriate way. (We can still regard the problem as one of learning a function;\nthe value of the function is the name of the subset to which an input vector be-\nlongs.) Unsupervised learning methods have application in taxonomic problems\nin which it is desired to invent ways to classify data into meaningful categories.\nWe shall also describe methods that are intermediate between supervised\nand unsupervised learning.\nWe might either be trying to \ufb01nd a new function, h, or to modify an existing\none. An interesting special case is that of changing an existing function into an\nequivalent one that is computationally more e\ufb03cient. This type of learning is\nsometimes called speed-uplearning. A very simple example of speed-up learning\ninvolves deduction processes. From the formulas A \u2283B and B \u2283C, we can\ndeduce C if we are given A. From this deductive process, we can create the\nformula A\u2283Ca new formula but one that does not sanction any more con-'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 15, 'page_label': '16'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 7\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n500\n1000\n1500\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n00\n00\n0\nx1\nx2\nh sample f-value\nFigure 1.3: A Surface that Fits Four Points\nclusions than those that could be derived from the formulas that we previously\nhad. But with this new formula we can derive C more quickly, given A, than\nwe could have done before. We can contrast speed-up learning with methods\nthat create genuinely new functionsones that might give di\ufb00erent results after\nlearning than they did before. We say that the latter methods involve inductive\nlearning. As opposed to deduction, there are no correct inductionsonly useful\nones.\n1.2.2 Input Vectors\nBecause machine learning methods derive from so many di\ufb00erent traditions, its\nterminology is rife with synonyms, and we will be using most of them in this\nbook. For example, the input vector is called by a variety of names. Some\nof these are: input vector, pattern vector, feature vector, sample, example, and\ninstance. The components, xi, of the input vector are variously called features,\nattributes, input variables, and components.\nThe values of the components can be of three main types. They might\nbe real-valued numbers, discrete-valued numbers, or categorical values. As an\nexample illustrating categorical values, information about a student might be\nrepresented by the values of the attributes class, major, sex, adviser . A par-\nticular student would then be represented by a vector such as: (sophomore,\nhistory, male, higgins). Additionally, categorical values may be ordered (as in\n{small, medium, large}) or unordered (as in the example just given). Of course,\nmixtures of all these types of values are possible.\nIn all cases, it is possible to represent the input in unordered form by listing\nthe names of the attributes together with their values. The vector form assumes\nthat the attributes are ordered and given implicitly by a form. As an example\nof an attribute-value representation, we might have: (major: history, sex: male,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 16, 'page_label': '17'}, page_content='8 CHAPTER 1. PRELIMINARIES\nclass: sophomore, adviser: higgins, age: 19). We will be using the vector form\nexclusively.\nAn important specialization uses Boolean values, which can be regarded as\na special case of either discrete numbers (1,0) or of categorical variables ( True,\nFalse).\n1.2.3 Outputs\nThe output may be a real number, in which case the process embodying the\nfunction, h, is called a function estimator , and the output is called an output\nvalue or estimate.\nAlternatively, the output may be a categorical value, in which case the pro-\ncess embodying h is variously called a classi\ufb01er, a recognizer, or a categorizer,\nand the output itself is called a label, a class, a category, or a decision. Classi-\n\ufb01ers have application in a number of recognition problems, for example in the\nrecognition of hand-printed characters. The input in that case is some suitable\nrepresentation of the printed character, and the classi\ufb01er maps this input into\none of, say, 64 categories.\nVector-valued outputs are also possible with components being real numbers\nor categorical values.\nAn important special case is that of Boolean output values. In that case,\na training pattern having value 1 is called a positive instance, and a training\nsample having value 0 is called a negative instance. When the input is also\nBoolean, the classi\ufb01er implements a Boolean function. We study the Boolean\ncase in some detail because it allows us to make important general points in\na simpli\ufb01ed setting. Learning a Boolean function is sometimes called concept\nlearning, and the function is called a concept.\n1.2.4 Training Regimes\nThere are several ways in which the training set, \u039e, can be used to produce a\nhypothesized function. In the batch method, the entire training set is available\nand used all at once to compute the function, h. A variation of this method\nuses the entire training set to modify a current hypothesis iteratively until an\nacceptable hypothesis is obtained. By contrast, in the incremental method, we\nselect one member at a time from the training set and use this instance alone\nto modify a current hypothesis. Then another member of the training set is\nselected, and so on. The selection method can be random (with replacement)\nor it can cycle through the training set iteratively. If the entire training set\nbecomes available one member at a time, then we might also use an incremental\nmethodselecting and using training set members as they arrive. (Alterna-\ntively, at any stage all training set members so far available could be used in a\nbatch process.) Using the training set members as they become available is\ncalled an online method. Online methods might be used, for example, when the'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 17, 'page_label': '18'}, page_content='1.3. LEARNING REQUIRES BIAS 9\nnext training instance is some function of the current hypothesis and the previ-\nous instanceas it would be when a classi\ufb01er is used to decide on a robots next\naction given its current set of sensory inputs. The next set of sensory inputs\nwill depend on which action was selected.\n1.2.5 Noise\nSometimes the vectors in the training set are corrupted by noise. There are two\nkinds of noise. Class noise randomly alters the value of the function; attribute\nnoise randomly alters the values of the components of the input vector. In either\ncase, it would be inappropriate to insist that the hypothesized function agree\nprecisely with the values of the samples in the training set.\n1.2.6 Performance Evaluation\nEven though there is no correct answer in inductive learning, it is important\nto have methods to evaluate the result of learning. We will discuss this matter\nin more detail later, but, brie\ufb02y, in supervised learning the induced function is\nusually evaluated on a separate set of inputs and function values for them called\nthe testing set . A hypothesized function is said to generalize when it guesses\nwell on the testing set. Both mean-squared-error and the total number of errors\nare common measures.\n1.3 Learning Requires Bias\nLong before now the reader has undoubtedly asked why is learning a function\npossible at all? Certainly, for example, there are an uncountable number of\ndi\ufb00erent functions having values that agree with the four samples shown in Fig.\n1.3. Why would a learning procedure happen to select the quadratic one shown\nin that \ufb01gure? In order to make that selection we had at least to limit a priori\nthe set of hypotheses to quadratic functions and then to insist that the one we\nchose passed through all four sample points. This kind of a priori information\nis called bias, and useful learning without bias is impossible.\nWe can gain more insight into the role of bias by considering the special case\nof learning a Boolean function of n dimensions. There are 2 n di\ufb00erent Boolean\ninputs possible. Suppose we had no bias; that is His the set of all 22n\nBoolean\nfunctions, and we have no preference among those that \ufb01t the samples in the\ntraining set. In this case, after being presented with one member of the training\nset and its value we can rule out precisely one-half of the members of Hthose\nBoolean functions that would misclassify this labeled sample. The remaining\nfunctions constitute what is called a version space; well explore that concept\nin more detail later. As we present more members of the training set, the graph\nof the number of hypotheses not yet ruled out as a function of the number of\ndi\ufb00erent patterns presented is as shown in Fig. 1.4. At any stage of the process,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 18, 'page_label': '19'}, page_content='10 CHAPTER 1. PRELIMINARIES\nhalf of the remaining Boolean functions have value 1 and half have value 0 for\nany training pattern not yet seen. No generalization is possible in this case\nbecause the training patterns give no clue about the value of a pattern not yet\nseen. Only memorization is possible here, which is a trivial sort of learning.\nlog2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n2n < j\n(generalization is not possible)\n|Hv| = no. of functions not ruled out\nFigure 1.4: Hypotheses Remaining as a Function of Labeled Patterns Presented\nBut suppose we limited Hto some subset, Hc, of all Boolean functions.\nDepending on the subset and on the order of presentation of training patterns,\na curve of hypotheses not yet ruled out might look something like the one\nshown in Fig. 1.5. In this case it is even possible that after seeing fewer than\nall 2 n labeled samples, there might be only one hypothesis that agrees with\nthe training set. Certainly, even if there is more than one hypothesis remaining,\nmost of them may have the same value formost of the patterns not yet seen! The\ntheory of Probably Approximately Correct (PAC) learning makes this intuitive\nidea precise. Well examine that theory later.\nLets look at a speci\ufb01c example of how bias aids learning. A Boolean function\ncan be represented by a hypercube each of whose vertices represents a di\ufb00erent\ninput pattern. We show a 3-dimensional version in Fig. 1.6. There, we show a\ntraining set of six sample patterns and have marked those having a value of 1 by\na small square and those having a value of 0 by a small circle. If the hypothesis\nset consists of just the linearly separable functionsthose for which the positive\nand negative instances can be separated by a linear surface, then there is only\none function remaining in this hypothsis set that is consistent with the training\nset. So, in this case, even though the training set does not contain all possible\npatterns, we can already pin down what the function must begiven the bias.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 19, 'page_label': '20'}, page_content='1.4. SAMPLE APPLICATIONS 11\nlog2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n|Hv| = no. of functions not ruled out\ndepends on order\nof presentation\nlog2|Hc|\nFigure 1.5: Hypotheses Remaining From a Restricted Subset\nMachine learning researchers have identi\ufb01ed two main varieties of bias, ab-\nsolute and preference. In absolute bias (also called restricted hypothesis-space\nbias), one restricts Hto a de\ufb01nite subset of functions. In our example of Fig. 1.6,\nthe restriction was to linearly separable Boolean functions. In preference bias,\none selects that hypothesis that is minimal according to some ordering scheme\nover all hypotheses. For example, if we had some way of measuring thecomplex-\nity of a hypothesis, we might select the one that was simplest among those that\nperformed satisfactorily on the training set. The principle of Occams razor,\nused in science to prefer simple explanations to more complex ones, is a type\nof preference bias. (William of Occam, 1285-?1349, was an English philosopher\nwho said:  non sunt multiplicanda entia praeter necessitatem , which means\nentities should not be multiplied unnecessarily.)\n1.4 Sample Applications\nOur main emphasis in this book is on the concepts of machine learningnot\non its applications. Nevertheless, if these concepts were irrelevant to real-world\nproblems they would probably not be of much interest. As motivation, we give\na short summary of some areas in which machine learning techniques have been\nsuccessfully applied. [Langley, 1992] cites some of the following applications and\nothers:\na. Rule discovery using a variant of ID3 for a printing industry problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 20, 'page_label': '21'}, page_content='12 CHAPTER 1. PRELIMINARIES\nx1\nx2\nx3\nFigure 1.6: A Training Set That Completely Determines a Linearly Separable\nFunction\n[Evans & Fisher, 1992].\nb. Electric power load forecasting using a k-nearest-neighbor rule system\n[Jabbour, K., et al., 1987].\nc. Automatic help desk assistant using a nearest-neighbor system\n[Acorn & Walden, 1992].\nd. Planning and scheduling for a steel mill using ExpertEase, a marketed\n(ID3-like) system [Michie, 1992].\ne. Classi\ufb01cation of stars and galaxies [Fayyad, et al., 1993].\nMany application-oriented papers are presented at the annual conferences\non Neural Information Processing Systems. Among these are papers on: speech\nrecognition, dolphin echo recognition, image processing, bio-engineering, diag-\nnosis, commodity trading, face recognition, music composition, optical character\nrecognition, and various control applications [Various Editors, 1989-1994].\nAs additional examples, [Hammerstrom, 1993] mentions:\na. Sharps Japanese kanji character recognition system processes 200 char-\nacters per second with 99+% accuracy. It recognizes 3000+ characters.\nb. NeuroForecasting Centres (London Business School and University Col-\nlege London) trading strategy selection network earned an average annual\npro\ufb01t of 18% against a conventional systems 12.3%.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 21, 'page_label': '22'}, page_content='1.5. SOURCES 13\nc. Fujitsus (plus a partners) neural network for monitoring a continuous\nsteel casting operation has been in successful operation since early 1990.\nIn summary, it is rather easy nowadays to \ufb01nd applications of machine learn-\ning techniques. This fact should come as no surprise inasmuch as many machine\nlearning techniques can be viewed as extensions of well known statistical meth-\nods which have been successfully applied for many years.\n1.5 Sources\nBesides the rich literature in machine learning (a small part of\nwhich is referenced in the Bibliography), there are several text-\nbooks that are worth mentioning [Hertz, Krogh, & Palmer, 1991,\nWeiss & Kulikowski, 1991, Natarjan, 1991, Fu, 1994, Langley, 1996].\n[Shavlik & Dietterich, 1990, Buchanan & Wilkins, 1993] are edited vol-\numes containing some of the most important papers. A survey paper by\n[Dietterich, 1990] gives a good overview of many important topics. There are\nalso well established conferences and publications where papers are given and\nappear including:\n The Annual Conferences on Advances in Neural Information Processing\nSystems\n The Annual Workshops on Computational Learning Theory\n The Annual International Workshops on Machine Learning\n The Annual International Conferences on Genetic Algorithms\n(The Proceedings of the above-listed four conferences are published by\nMorgan Kaufmann.)\n The journal Machine Learning (published by Kluwer Academic Publish-\ners).\nThere is also much information, as well as programs and datasets, available over\nthe Internet through the World Wide Web.\n1.6 Bibliographical and Historical Remarks\nTo be added. Every chapter will\ncontain a brief survey of the history\nof the material covered in that\nchapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 22, 'page_label': '23'}, page_content='14 CHAPTER 1. PRELIMINARIES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 23, 'page_label': '24'}, page_content='Chapter 2\nBoolean Functions\n2.1 Representation\n2.1.1 Boolean Algebra\nMany important ideas about learning of functions are most easily presented\nusing the special case of Boolean functions. There are several important sub-\nclasses of Boolean functions that are used as hypothesis classes for function\nlearning. Therefore, we digress in this chapter to present a review of Boolean\nfunctions and their properties. (For a more thorough treatment see, for example,\n[Unger, 1989].)\nA Boolean function, f(x1,x2,...,x n) maps an n-tuple of (0,1) values to\n{0,1}. Boolean algebra is a convenient notation for representing Boolean func-\ntions. Boolean algebra uses the connectives ·, +, and . For example, the and\nfunction of two variables is written x1 ·x2. By convention, the connective,  ·\nis usually suppressed, and the and function is written x1x2. x1x2 has value 1 if\nand only if both x1 and x2 have value 1; if either x1 or x2 has value 0, x1x2 has\nvalue 0. The (inclusive) or function of two variables is written x1 + x2. x1 + x2\nhas value 1 if and only if either or both of x1 or x2 has value 1; if both x1 and\nx2 have value 0, x1 + x2 has value 0. The complement or negation of a variable,\nx, is written x. xhas value 1 if and only if xhas value 0; if xhas value 1, xhas\nvalue 0.\nThese de\ufb01nitions are compactly given by the following rules for Boolean\nalgebra:\n1 + 1 = 1, 1 + 0 = 1, 0 + 0 = 0,\n1 ·1 = 1, 1 ·0 = 0, 0 ·0 = 0, and\n1 = 0, 0 = 1.\nSometimes the arguments and values of Boolean functions are expressed in\nterms of the constants T (True) and F (False) instead of 1 and 0, respectively.\n15'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 24, 'page_label': '25'}, page_content='16 CHAPTER 2. BOOLEAN FUNCTIONS\nThe connectives ·and + are each commutative and associative. Thus, for\nexample, x1(x2x3) = ( x1x2)x3, and both can be written simply as x1x2x3.\nSimilarly for +.\nA Boolean formula consisting of a single variable, such as x1 is called an\natom. One consisting of either a single variable or its complement, such as x1,\nis called a literal.\nThe operators ·and + do not commute between themselves. Instead, we\nhave DeMorgans laws (which can be veri\ufb01ed by using the above de\ufb01nitions):\nx1x2 = x1 + x2, and\nx1 + x2 = x1 x2.\n2.1.2 Diagrammatic Representations\nWe saw in the last chapter that a Boolean function could be represented by\nlabeling the vertices of a cube. For a function of n variables, we would need\nan n-dimensional hypercube. In Fig. 2.1 we show some 2- and 3-dimensional\nexamples. Vertices having value 1 are labeled with a small square, and vertices\nhaving value 0 are labeled with a small circle.\nx1\nx2\nx1\nx2\nx1\nx2\nand or\nxor (exclusive or)\nx1x2 x1 + x2\nx1x2  +  x1x2\neven parity functionx1\nx2\nx3\nx1x2x3  +  x1x2x3\n+ x1x2x3 + x1x2x3\nFigure 2.1: Representing Boolean Functions on Cubes\nUsing the hypercube representations, it is easy to see how many Boolean\nfunctions of n dimensions there are. A 3-dimensional cube has 2 3 = 8 vertices,\nand each may be labeled in two di\ufb00erent ways; thus there are 2 (23) = 256'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 25, 'page_label': '26'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 17\ndi\ufb00erent Boolean functions of 3 variables. In general, there are 2 2n\nBoolean\nfunctions of n variables.\nWe will be using 2- and 3-dimensional cubes later to provide some intuition\nabout the properties of certain Boolean functions. Of course, we cannot visualize\nhypercubes (for n > 3), and there are many surprising properties of higher\ndimensional spaces, so we must be careful in using intuitions gained in low\ndimensions. One diagrammatic technique for dimensions slightly higher than\n3 is the Karnaugh map . A Karnaugh map is an array of values of a Boolean\nfunction in which the horizontal rows are indexed by the values of some of\nthe variables and the vertical columns are indexed by the rest. The rows and\ncolumns are arranged in such a way that entries that are adjacent in the map\ncorrespond to vertices that are adjacent in the hypercube representation. We\nshow an example of the 4-dimensional even parity function in Fig. 2.2. (An\neven parity function is a Boolean function that has value 1 if there are an even\nnumber of its arguments that have value 1; otherwise it has value 0.) Note\nthat all adjacent cells in the table correspond to inputs di\ufb00ering in only one\ncomponent. Also describe general logic\ndiagrams, [Wnek, et al., 1990].\n00 01 1011\n00\n01\n10\n11\n11\n1\n1\n11\n1\n10\n00\n0\n0\n0\n0\n0\nx1,x2\nx3,x4\nFigure 2.2: A Karnaugh Map\n2.2 Classes of Boolean Functions\n2.2.1 Terms and Clauses\nTo use absolute bias in machine learning, we limit the class of hypotheses. In\nlearning Boolean functions, we frequently use some of the common sub-classes of\nthose functions. Therefore, it will be important to know about these subclasses.\nOne basic subclass is called terms. A term is any function written in the\nform l1l2 ···lk, where the li are literals. Such a form is called a conjunction of\nliterals. Some example terms are x1x7 and x1x2x4. The size of a term is the\nnumber of literals it contains. The examples are of sizes 2 and 3, respectively.\n(Strictly speaking, the class of conjunctions of literals is called the monomials,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 26, 'page_label': '27'}, page_content='18 CHAPTER 2. BOOLEAN FUNCTIONS\nand a conjunction of literals itself is called a term. This distinction is a \ufb01ne one\nwhich we elect to blur here.)\nIt is easy to show that there are exactly 3 n possible terms of n variables.\nThe number of terms of size kor less is bounded from above by \u2211k\ni=0 C(2n,i) =\nO(nk), where C(i,j) = i!\n(i\u2212j)!j! is the binomial coe\ufb03cient.Probably Ill put in a simple\nterm-learning algorithm hereso\nwe can get started on learning!\nAlso for DNF functions and\ndecision listsas they are de\ufb01ned\nin the next few pages.\nA clause is any function written in the form l1 +l2 +···+lk, where the li are\nliterals. Such a form is called a disjunction of literals. Some example clauses\nare x3 + x5 + x6 and x1 + x4. The size of a clause is the number of literals it\ncontains. There are 3 n possible clauses and fewer than \u2211k\ni=0 C(2n,i) clauses of\nsize k or less. If f is a term, then (by De Morgans laws) f is a clause, and vice\nversa. Thus, terms and clauses are duals of each other.\nIn psychological experiments, conjunctions of literals seem easier for humans\nto learn than disjunctions of literals.\n2.2.2 DNF Functions\nA Boolean function is said to be in disjunctive normal form (DNF) if it can be\nwritten as adisjunction of terms. Some examples in DNF are: f = x1x2+x2x3x4\nand f = x1x3 + x2 x3 + x1x2x3. A DNF expression is called a k-term DNF\nexpression if it is a disjunction of k terms; it is in the class k-DNF if the size of\nits largest term is k. The examples above are 2-term and 3-term expressions,\nrespectively. Both expressions are in the class 3-DNF.\nEach term in a DNF expression for a function is called an implicant because\nit implies the function (if the term has value 1, so does the function). In\ngeneral, a term, t, is an implicant of a function, f, if f has value 1 whenever\nt does. A term, t, is a prime implicant of f if the term, t\u2032, formed by taking\nany literal out of an implicant t is no longer an implicant of f. (The implicant\ncannot be divided by any term and remain an implicant.)\nThus, both x2x3 and x1 x3 are prime implicants off = x2x3+x1 x3+x2x1x3,\nbut x2x1x3 is not.\nThe relationship between implicants and prime implicants can be geometri-\ncally illustrated using the cube representation for Boolean functions. Consider,\nfor example, the function f = x2x3 + x1 x3 + x2x1x3. We illustrate it in Fig.\n2.3. Note that each of the three planes in the \ufb01gure cuts o\ufb00 a group of\nvertices having value 1, but none cuts o\ufb00 any vertices having value 0. These\nplanes are pictorial devices used to isolate certain lower dimensional subfaces\nof the cube. Two of them isolate one-dimensional edges, and the third isolates\na zero-dimensional vertex. Each group of vertices on a subface corresponds to\none of the implicants of the function, f, and thus each implicant corresponds\nto a subface of some dimension. A k-dimensional subface corresponds to an\n(n\u2212k)-size implicant term. The function is written as the disjunction of the\nimplicantscorresponding to the union of all the vertices cut o\ufb00 by all of the\nplanes. Geometrically, an implicant is prime if and only if its corresponding\nsubface is the largest dimensional subface that includes all of its vertices and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 27, 'page_label': '28'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 19\nno other vertices having value 0. Note that the term x2x1x3 is not a prime\nimplicant of f. (In this case, we dont even have to include this term in the\nfunction because the vertex cut o\ufb00 by the plane corresponding to x2x1x3 is\nalready cut o\ufb00 by the plane corresponding to x2x3.) The other two implicants\nare prime because their corresponding subfaces cannot be expanded without\nincluding vertices having value 0.\nx2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x2x1x3\n   = x2x3 + x1x3\nx2x3 and  x1x3 are prime implicants\nFigure 2.3: A Function and its Implicants\nNote that all Boolean functions can be represented in DNFtrivially by\ndisjunctions of terms of size nwhere each term corresponds to one of the vertices\nwhose value is 1. Whereas there are 22n\nfunctions of ndimensions in DNF (since\nany Boolean function can be written in DNF), there are just 2 O(nk) functions\nin k-DNF.\nAll Boolean functions can also be represented in DNF in which each term is\na prime implicant, but that representation is not unique, as shown in Fig. 2.4.\nIf we can express a function in DNF form, we can use the consensus method\nto \ufb01nd an expression for the function in which each term is a prime implicant.\nThe consensus method relies on two results: We may replace this section with\none describing the\nQuine-McCluskey method instead. Consensus:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 28, 'page_label': '29'}, page_content='20 CHAPTER 2. BOOLEAN FUNCTIONS\nx2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x1x2\n   = x1x2 + x1x3\nAll of the terms are prime implicants, but there\nis not a unique representation\nFigure 2.4: Non-Uniqueness of Representation by Prime Implicants\nxi ·f1 + xi ·f2 = xi ·f1 + xi ·f2 + f1 ·f2\nwhere f1 and f2 are terms such that no literal appearing in f1 appears\ncomplemented in f2. f1 ·f2 is called the consensus of xi ·f1 and xi ·\nf2. Readers familiar with the resolution rule of inference will note that\nconsensus is the dual of resolution.\nExamples: x1 is the consensus of x1x2 and x1x2. The terms x1x2 and x1x2\nhave no consensus since each term has more than one literal appearing\ncomplemented in the other.\n Subsumption:\nxi ·f1 + f1 = f1\nwhere f1 is a term. We say that f1 subsumes xi ·f1.\nExample: x1 x4x5 subsumes x1 x4 x2x5'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 29, 'page_label': '30'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 21\nThe consensus method for \ufb01nding a set of prime implicants for a function,\nf, iterates the following operations on the terms of a DNF expression for f until\nno more such operations can be applied:\na. initialize the process with the set, T, of terms in the DNF expression of\nf,\nb. compute the consensus of a pair of terms in T and add the result to T,\nc. eliminate any terms in T that are subsumed by other terms in T.\nWhen this process halts, the terms remaining in T are all prime implicants of\nf.\nExample: Let f = x1x2 + x1 x2x3 + x1 x2 x3 x4x5. We show a derivation of\na set of prime implicants in the consensus tree of Fig. 2.5. The circled numbers\nadjoining the terms indicate the order in which the consensus and subsumption\noperations were performed. Shaded boxes surrounding a term indicate that it\nwas subsumed. The \ufb01nal form of the function in which all terms are prime\nimplicants is: f = x1x2 + x1x3 + x1 x4x5. Its terms are all of the non-subsumed\nterms in the consensus tree.\n x1x2 x1x2x3 x1x2x3x4x5\n x1x3\nx1x2x4x5\nx1x4x5\nf =  x1x2 + + x1x3 x1x4x5\n1\n2\n6\n4\n5\n3\nFigure 2.5: A Consensus Tree\n2.2.3 CNF Functions\nDisjunctive normal form has a dual: conjunctive normal form (CNF). A Boolean\nfunction is said to be in CNF if it can be written as a conjunction of clauses.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 30, 'page_label': '31'}, page_content='22 CHAPTER 2. BOOLEAN FUNCTIONS\nAn example in CNF is: f = (x1 +x2)(x2 +x3 +x4). A CNF expression is called\na k-clause CNF expression if it is a conjunction of k clauses; it is in the class\nk-CNF if the size of its largest clause is k. The example is a 2-clause expression\nin 3-CNF. If f is written in DNF, an application of De Morgans law renders f\nin CNF, and vice versa. Because CNF and DNF are duals, there are also 2 O(nk)\nfunctions in k-CNF.\n2.2.4 Decision Lists\nRivest has proposed a class of Boolean functions calleddecision lists [Rivest, 1987].\nA decision list is written as an ordered list of pairs:\n(tq,vq)\n(tq\u22121,vq\u22121)\n···\n(ti,vi)\n···\n(t2,v2)\n(T,v1)\nwhere the vi are either 0 or 1, the ti are terms in ( x1,...,x n), and T is a term\nwhose value is 1 (regardless of the values of the xi). The value of a decision list\nis the value of vi for the \ufb01rst ti in the list that has value 1. (At least one ti will\nhave value 1, because the last one does; v1 can be regarded as a default value of\nthe decision list.) The decision list is of size k, if the size of the largest term in\nit is k. The class of decision lists of size k or less is called k-DL.\nAn example decision list is:\nf =\n(x1x2,1)\n(x1 x2x3,0)\nx2x3,1)\n(1,0)\nf has value 0 for x1 = 0, x2 = 0, and x3 = 1. It has value 1 for x1 = 1, x2 = 0,\nand x3 = 1. This function is in 3-DL.\nIt has been shown that the class k-DL is a strict superset of the union of\nk-DNF and k-CNF. There are 2 O[nkklog(n)] functions in k-DL [Rivest, 1987].\nInteresting generalizations of decision lists use other Boolean functions in\nplace of the terms, ti. For example we might use linearly separable functions in\nplace of the ti (see below and [Marchand & Golea, 1993]).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 31, 'page_label': '32'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 23\n2.2.5 Symmetric and Voting Functions\nA Boolean function is called symmetric if it is invariant under permutations\nof the input variables. For example, any function that is dependent only on\nthe number of input variables whose values are 1 is a symmetric function. The\nparity functions, which have value 1 depending on whether or not the number\nof input variables with value 1 is even or odd is a symmetric function. (The\nexclusive or function, illustrated in Fig. 2.1, is an odd-parity function of two\ndimensions. The or and and functions of two dimensions are also symmetric.)\nAn important subclass of the symmetric functions is the class of voting func-\ntions (also called m-of-nfunctions). A k-voting function has value 1 if and only\nif k or more of its n inputs has value 1. If k= 1, a voting function is the same\nas an n-sized clause; if k= n, a voting function is the same as an n-sized term;\nif k = (n+ 1)/2 for n odd or k = 1 + n/2 for n even, we have the majority\nfunction.\n2.2.6 Linearly Separable Functions\nThe linearly separable functions are those that can be expressed as follows:\nf = thresh(\nn\u2211\ni=1\nwixi,\u03b8)\nwhere wi, i= 1,...,n , are real-valued numbers called weights, \u03b8is a real-valued\nnumber called the threshold, and thresh( \u03c3,\u03b8) is 1 if \u03c3 \u2265\u03b8 and 0 otherwise.\n(Note that the concept of linearly separable functions can be extended to non-\nBoolean inputs.) The k-voting functions are all members of the class of linearly\nseparable functions in which the weights all have unit value and the threshold\ndepends on k. Thus, terms and clauses are special cases of linearly separable\nfunctions.\nA convenient way to write linearly separable functions uses vector notation:\nf = thresh(X ·W,\u03b8)\nwhere X = ( x1,...,x n) is an n-dimensional vector of input variables, W =\n(w1,...,w n) is an n-dimensional vector of weight values, and X ·W is the dot\n(or inner) product of the two vectors. Input vectors for which f has value 1 lie\nin a half-space on one side of (and on) a hyperplane whose orientation is normal\nto W and whose position (with respect to the origin) is determined by \u03b8. We\nsaw an example of such a separating plane in Fig. 1.6. With this idea in mind,\nit is easy to see that two of the functions in Fig. 2.1 are linearly separable, while\ntwo are not. Also note that the terms in Figs. 2.3 and 2.4 are linearly separable\nfunctions as evidenced by the separating planes shown.\nThere is no closed-form expression for the number of linearly separable func-\ntions of n dimensions, but the following table gives the numbers for n up to 6.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 32, 'page_label': '33'}, page_content='24 CHAPTER 2. BOOLEAN FUNCTIONS\nn Boolean Linearly Separable\nFunctions Functions\n1 4 4\n2 16 14\n3 256 104\n4 65,536 1,882\n5 \u22484.3 ×109 94,572\n6 \u22481.8 ×1019 15,028,134\n[Muroga, 1971] has shown that (for n> 1) there are no more than 2 n2\nlinearly\nseparable functions of n dimensions. (See also [Winder, 1961, Winder, 1962].)\n2.3 Summary\nThe diagram in Fig. 2.6 shows some of the set inclusions of the classes of Boolean\nfunctions that we have considered. We will be confronting these classes again\nin later chapters.\nDNF\n(All)\nk-DLk-DNFk-size-\nterms\nterms\nlin sep\nFigure 2.6: Classes of Boolean Functions\nThe sizes of the various classes are given in the following table (adapted from\n[Dietterich, 1990, page 262]):'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 33, 'page_label': '34'}, page_content='2.4. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 25\nClass Size of Class\nterms 3n\nclauses 3n\nk-term DNF 2O(kn)\nk-clause CNF 2O(kn)\nk-DNF 2O(nk)\nk-CNF 2O(nk)\nk-DL 2O[nkklog(n)]\nlin sep 2O(n2)\nDNF 22n\n2.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 34, 'page_label': '35'}, page_content='26 CHAPTER 2. BOOLEAN FUNCTIONS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 35, 'page_label': '36'}, page_content='Chapter 3\nUsing Version Spaces for\nLearning\n3.1 Version Spaces and Mistake Bounds\nThe \ufb01rst learning methods we present are based on the concepts of version\nspaces and version graphs. These ideas are most clearly explained for the case\nof Boolean function learning. Given an initial hypothesis set H(a subset of\nall Boolean functions) and the values of f(X) for each X in a training set, \u039e,\nthe version space is that subset of hypotheses, Hv, that is consistent with these\nvalues. A hypothesis, h, is consistent with the values of X in \u039e if and only if\nh(X) = f(X) for all X in \u039e. We say that the hypotheses in Hthat are not\nconsistent with the values in the training set are ruled out by the training set.\nWe could imagine (conceptually only!) that we have devices for implement-\ning every function in H. An incremental training procedure could then be\nde\ufb01ned which presented each pattern in \u039e to each of these functions and then\neliminated those functions whose values for that pattern did not agree with its\ngiven value. At any stage of the process we would then have left some subset\nof functions that are consistent with the patterns presented so far; this subset\nis the version space for the patterns already presented. This idea is illustrated\nin Fig. 3.1.\nConsider the following procedure for classifying an arbitrary input pattern,\nX: the pattern is put in the same class (0 or 1) as are the majority of the\noutputs of the functions in the version space. During the learning procedure,\nif this majority is not equal to the value of the pattern presented, we say a\nmistake is made, and we revise the version space accordinglyeliminating all\nthose (majority of the) functions voting incorrectly. Thus, whenever a mistake\nis made, we rule out at least half of the functions remaining in the version space.\nHow many mistakes can such a procedure make? Obviously, we can make\nno more than log 2(|H|) mistakes, where |H|is the number of hypotheses in the\n27'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 36, 'page_label': '37'}, page_content='28 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nh1\nh2\nhi\nhK\nX\nA Subset, H,  of all\nBoolean Functions\nRule out hypotheses not\nconsistent with training patterns\nhj\nHypotheses not ruled out\nconstitute the version space\nK = |H|\n1 or 0\nFigure 3.1: Implementing the Version Space\noriginal hypothesis set, H. (Note, though, that the number of training patterns\nseen before this maximum number of mistakes is made might be much greater.)\nThis theoretical (and very impractical!) result (due to [Littlestone, 1988]) is an\nexample of a mistake boundan important concept in machine learning theory.\nIt shows that there must exist a learning procedure that makes no more mistakes\nthan this upper bound. Later, well derive other mistake bounds.\nAs a special case, if our bias was to limit Hto terms, we would make no\nmore than log2(3n) = nlog2(3) = 1.585nmistakes before exhausting the version\nspace. This result means that if f were a term, we would make no more than\n1.585nmistakes before learning f, and otherwise we would make no more than\nthat number of mistakes before being able to decide that f is not a term.\nEven if we do not have su\ufb03cient training patterns to reduce the version\nspace to a single function, it may be that there are enough training patterns\nto reduce the version space to a set of functions such that most of them assign\nthe same values to most of the patterns we will see henceforth. We could select\none of the remaining functions at random and be reasonably assured that it\nwill generalize satisfactorily. We next discuss a computationally more feasible\nmethod for representing the version space.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 37, 'page_label': '38'}, page_content='3.2. VERSION GRAPHS 29\n3.2 Version Graphs\nBoolean functions can be ordered by generality. A Boolean function, f1, is more\ngeneral than a function, f2, (and f2 is more speci\ufb01c than f1), if f1 has value 1\nfor all of the arguments for which f2 has value 1, and f1 \u0338= f2. For example, x3\nis more general than x2x3 but is not more general than x3 + x2.\nWe can form a graph with the hypotheses, {hi}, in the version space as\nnodes. A node in the graph, hi, has an arc directed to node, hj, if and only if\nhj is more general than hi. We call such a graph a version graph. In Fig. 3.2,\nwe show an example of a version graph over a 3-dimensional input space for\nhypotheses restricted to terms (with none of them yet ruled out).\n0\nx1 x2x 3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nVersion Graph for Terms\nx1\nx2\nx3\n(for simplicity, only some arcs in the graph are shown)\n(none yet ruled out)\n(k = 1)\n(k = 2)\n(k = 3)\nx1 x3\nFigure 3.2: A Version Graph for Terms\nThat function, denoted here by 1, which has value 1 for all inputs, corre-\nsponds to the node at the top of the graph. (It is more general than any other\nterm.) Similarly, the function 0 is at the bottom of the graph. Just below\n1 is a row of nodes corresponding to all terms having just one literal, and just\nbelow them is a row of nodes corresponding to terms having two literals, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 38, 'page_label': '39'}, page_content='30 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nso on. There are 3 3 = 27 functions altogether (the function 0, included in\nthe graph, is technically not a term). To make our portrayal of the graph less\ncluttered only some of the arcs are shown; each node in the actual graph has an\narc directed to all of the nodes above it that are more general.\nWe use this same example to show how the version graph changes as we\nconsider a set of labeled samples in a training set, \u039e. Suppose we \ufb01rst consider\nthe training pattern (1, 0, 1) with value 0. Some of the functions in the version\ngraph of Fig. 3.2 are inconsistent with this training pattern. These ruled out\nnodes are no longer in the version graph and are shown shaded in Fig. 3.3. We\nalso show there the three-dimensional cube representation in which the vertex\n(1, 0, 1) has value 0.\n0\nx1 x2 x3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nNew Version Graph\n1, 0, 1 has\nvalue 0\nx1x3\nx1x2 x2x3\nx1x2x3\nx1\nx2\nx3\nx1x3\n(only some arcs in the graph are shown)\nruled out nodes\nFigure 3.3: The Version Graph Upon Seeing (1, 0, 1)\nIn a version graph, there are always a set of hypotheses that are maximally\ngeneral and a set of hypotheses that are maximally speci\ufb01c. These are called\nthe general boundary set (gbs) and the speci\ufb01c boundary set (sbs) , respectively.\nIn Fig. 3.4, we have the version graph as it exists after learning that (1,0,1) has\nvalue 0 and (1, 0, 0) has value 1. The gbs and sbs are shown.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 39, 'page_label': '40'}, page_content='3.2. VERSION GRAPHS 31\n0\nx1 x2\nx3\nx2 x3\n1\nx1x2 x3\nx1\nx2x3x1x3\ngeneral boundary set\n(gbs)\nspecific boundary set (sbs)\nx1x2\nmore specific than gbs,\nmore general than sbs\n1, 0, 1 has\nvalue 0\nx1\nx2\nx3\n1, 0, 0 has\nvalue 1\nFigure 3.4: The Version Graph Upon Seeing (1, 0, 1) and (1, 0, 0)\nBoundary sets are important because they provide an alternative to repre-\nsenting the entire version space explicitly, which would be impractical. Given\nonly the boundary sets, it is possible to determine whether or not any hypoth-\nesis (in the prescribed class of Boolean functions we are using) is a member or\nnot of the version space. This determination is possible because of the fact that\nany member of the version space (that is not a member of one of the boundary\nsets) is more speci\ufb01c than some member of the general boundary set and is more\ngeneral than some member of the speci\ufb01c boundary set.\nIf we limit our Boolean functions that can be in the version space to terms,\nit is a simple matter to determine maximally general and maximally speci\ufb01c\nfunctions (assuming that there is some term that is in the version space). A\nmaximally speci\ufb01c one corresponds to a subface of minimal dimension that\ncontains all the members of the training set labelled by a 1 and no members\nlabelled by a 0. A maximally general one corresponds to a subface of maximal\ndimension that contains all the members of the training set labelled by a 1 and\nno members labelled by a 0. Looking at Fig. 3.4, we see that the subface of\nminimal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is just\nthe vertex (1, 0, 0) itselfcorresponding to the function x1x2 x3. The subface'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 40, 'page_label': '41'}, page_content='32 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nof maximal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is\nthe bottom face of the cubecorresponding to the function x3. In Figs. 3.2\nthrough 3.4 the sbs is always singular. Version spaces for terms always have\nsingular speci\ufb01c boundary sets. As seen in Fig. 3.3, however, the gbs of a\nversion space for terms need not be singular.\n3.3 Learning as Search of a Version Space\n[To be written. Relate to term learning algorithm presented in Chapter\nTwo. Also discuss best-\ufb01rst search methods. See Pat Langleys example us-\ning pseudo-cells of how to generate and eliminate hypotheses.]\nSelecting a hypothesis from the version space can be thought of as a search\nproblem. One can start with a very general function and specialize it through\nvarious specialization operators until one \ufb01nds a function that is consistent (or\nadequately so) with a set of training patterns. Such procedures are usually\ncalled top-down methods. Or, one can start with a very special function and\ngeneralize itresulting in bottom-up methods. We shall see instances of both\nstyles of learning in this book.Compare this view of top-down\nversus bottom-up with the\ndivide-and-conquer and the\ncovering (or AQ) methods of\ndecision-tree induction. 3.4 The Candidate Elimination Method\nThe candidate elimination method, is an incremental method for computing the\nboundary sets. Quoting from [Hirsh, 1994, page 6]:\nThe candidate-elimination algorithm manipulates the boundary-set\nrepresentation of a version space to create boundary sets that rep-\nresent a new version space consistent with all the previous instances\nplus the new one. For a positive exmple the algorithm generalizes\nthe elements of the [sbs] as little as possible so that they cover the\nnew instance yet remain consistent with past data, and removes\nthose elements of the [gbs] that do not cover the new instance. For\na negative instance the algorithm specializes elements of the [gbs]\nso that they no longer cover the new instance yet remain consis-\ntent with past data, and removes from the [sbs] those elements that\nmistakenly cover the new, negative instance.\nThe method uses the following de\ufb01nitions (adapted from\n[Genesereth & Nilsson, 1987]):\n a hypothesis is called su\ufb03cient if and only if it has value 1 for all training\nsamples labeled by a 1,\n a hypothesis is called necessary if and only if it has value 0 for all training\nsamples labeled by a 0.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 41, 'page_label': '42'}, page_content='3.4. THE CANDIDATE ELIMINATION METHOD 33\nHere is how to think about these de\ufb01nitions: A hypothesis implements a su\ufb03-\ncient condition that a training sample has value 1 if the hypothesis has value 1\nfor all of the positive instances; a hypothesis implements a necessary condition\nthat a training sample has value 1 if the hypothesis has value 0 for all of the\nnegative instances. A hypothesis is consistent with the training set (and thus is\nin the version space) if and only if it is both su\ufb03cient and necessary.\nWe start (before receiving any members of the training set) with the function\n0 as the singleton element of the speci\ufb01c boundary set and with the function\n1 as the singleton element of the general boundary set. Upon receiving a new\nlabeled input vector, the boundary sets are changed as follows:\na. If the new vector is labelled with a 1:\nThe new general boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not su\ufb03cient. (That is, we exclude any\nelements that have value 0 for the new vector.)\nThe new speci\ufb01c boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least generalizations.\nThe hypothesis hg is a least generalization of h if and only if: a) h is\nmore speci\ufb01c than hg, b) hg is su\ufb03cient, c) no function (including h) that\nis more speci\ufb01c than hg is su\ufb03cient, and d) hg is more speci\ufb01c than some\nmember of the new general boundary set. It might be that hg = h. Also,\nleast generalizations of two di\ufb00erent functions in the speci\ufb01c boundary set\nmay be identical.\nb. If the new vector is labelled with a 0:\nThe new speci\ufb01c boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not necessary. (That is, we exclude\nany elements that have value 1 for the new vector.)\nThe new general boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least specializations.\nThe hypothesis hs is a least specialization of hif and only if: a) his more\ngeneral than hs, b) hs is necessary, c) no function (including h) that is\nmore general than hs is necessary, and d) hs is more general than some\nmember of the new speci\ufb01c boundary set. Again, it might be that hs = h,\nand least specializations of two di\ufb00erent functions in the general boundary\nset may be identical.\nAs an example, suppose we present the vectors in the following order:\nvector label\n(1, 0, 1) 0\n(1, 0, 0) 1\n(1, 1, 1) 0\n(0, 0, 1) 0'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 42, 'page_label': '43'}, page_content='34 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nWe start with general boundary set, 1, and speci\ufb01c boundary set, 0.\nAfter seeing the \ufb01rst sample, (1, 0, 1), labeled with a 0, the speci\ufb01c boundary\nset stays at 0 (it is necessary), and we change the general boundary set to\n{x1,x2,x3}. Each of the functions, x1, x2, and x3, are least specializations of\n1 (they are necessary, 1 is not, they are more general than 0, and there\nare no functions that are more general than they and also necessary).\nThen, after seeing (1, 0, 0), labeled with a 1, the general boundary set\nchanges to {x3}(because x1 and x2 are not su\ufb03cient), and the speci\ufb01c boundary\nset is changed to {x1x2 x3}. This single function is a least generalization of 0\n(it is su\ufb03cient, 0 is more speci\ufb01c than it, no function (including 0) that is\nmore speci\ufb01c than it is su\ufb03cient, and it is more speci\ufb01c than some member of\nthe general boundary set.\nWhen we see (1, 1, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the\ngeneral boundary set either because x3 is still necessary.\nFinally, when we see (0, 0, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the general\nboundary set either because x3 is still necessary.Maybe Ill put in an example of a\nversion graph for non-Boolean\nfunctions.\n3.5 Bibliographical and Historical Remarks\nThe concept of version spaces and their role in learning was \ufb01rst investigated\nby Tom Mitchell [Mitchell, 1982]. Although these ideas are not used in prac-\ntical machine learning procedures, they do provide insight into the nature of\nhypothesis selection. In order to accomodate noisy data, version spaces have\nbeen generalized by [Hirsh, 1994] to allow hypotheses that are not necessarily\nconsistent with the training set.More to be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 43, 'page_label': '44'}, page_content='Chapter 4\nNeural Networks\nIn chapter two we de\ufb01ned several important subsets of Boolean functions. Sup-\npose we decide to use one of these subsets as a hypothesis set for supervised\nfunction learning. We next have the question of how best to implement the\nfunction as a device that gives the outputs prescribed by the function for arbi-\ntrary inputs. In this chapter we describe how networks of non-linear elements\ncan be used to implement various input-output functions and how they can be\ntrained using supervised learning methods.\nNetworks of non-linear elements, interconnected through adjustable weights,\nplay a prominent role in machine learning. They are called neural networks be-\ncause the non-linear elements have as their inputs a weighted sum of the outputs\nof other elementsmuch like networks of biological neurons do. These networks\ncommonly use the threshold element which we encountered in chapter two in\nour study of linearly separable Boolean functions. We begin our treatment of\nneural nets by studying this threshold element and how it can be used in the\nsimplest of all networks, namely ones composed of a single threshold element.\n4.1 Threshold Logic Units\n4.1.1 De\ufb01nitions and Geometry\nLinearly separable (threshold) functions are implemented in a straightforward\nway by summing the weighted inputs and comparing this sum to a threshold\nvalue as shown in Fig. 4.1. This structure we call a threshold logic unit (TLU) .\nIts output is 1 or 0 depending on whether or not the weighted sum of its inputs is\ngreater than or equal to a threshold value, \u03b8. It has also been called an Adaline\n(for ada ptive lin ear e lement) [Widrow, 1962, Widrow & Lehr, 1990], an LTU\n(linear threshold unit), a perceptron, and a neuron. (Although the word per-\nceptron is often used nowadays to refer to a single TLU, Rosenblatt originally\nde\ufb01ned it as a class of networks of threshold elements [Rosenblatt, 1958].)\n35'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 44, 'page_label': '45'}, page_content='36 CHAPTER 4. NEURAL NETWORKS\n!\nx1\nx2\nxn+1 = 1\nxi\nw1\nw2\nwn+1\nwi\nwn\nX\nthreshold weight\nxn\nW threshold  "  = 0\nf\nf = thresh( ! wi xi,  0)\ni = 1\nn+1\nFigure 4.1: A Threshold Logic Unit (TLU)\nThe n-dimensional feature or input vector is denoted by X = (x1,...,x n).\nWhen we want to distinguish among di\ufb00erent feature vectors, we will attach\nsubscripts, such as Xi. The components of X can be any real-valued numbers,\nbut we often specialize to the binary numbers 0 and 1. The weights of a TLU\nare represented by an n-dimensional weight vector , W = ( w1,...,w n). Its\ncomponents are real-valued numbers (but we sometimes specialize to integers).\nThe TLU has output 1 if \u2211n\ni=1 xiwi \u2265 \u03b8; otherwise it has output 0. The\nweighted sum that is calculated by the TLU can be simply represented as a\nvector dot product, XW. (If the pattern and weight vectors are thought of as\ncolumn vectors, this dot product is then sometimes written as XtW, where\nthe row vector Xt is the transpose of X.) Often, the threshold, \u03b8, of the TLU\nis \ufb01xed at 0; in that case, arbitrary thresholds are achieved by using ( n+ 1)-\ndimensional augmented vectors, Y, and V, whose \ufb01rst ncomponents are the\nsame as those of X and W, respectively. The ( n+ 1)-st component, xn+1, of\nthe augmented feature vector, Y, always has value 1; the (n+ 1)-st component,\nwn+1, of the augmented weight vector, V, is set equal to the negative of the\ndesired threshold value. (When we want to emphasize the use of augmented\nvectors, well use the Y,V notation; however when the context of the discussion\nmakes it clear about what sort of vectors we are talking about, well lapse back\ninto the more familiar X,W notation.) In the Y,V notation, the TLU has an\noutput of 1 if YV \u22650. Otherwise, the output is 0.\nWe can give an intuitively useful geometric description of a TLU. A TLU\ndivides the input space by a hyperplane as sketched in Fig. 4.2. The hyperplane\nis the boundary between patterns for which XW + wn+1 > 0 and patterns\nfor which XW + wn+1 < 0. Thus, the equation of the hyperplane itself is\nXW+wn+1 = 0. The unit vector that is normal to the hyperplane is n = W\n|W|,\nwhere |W|=\n\u221a\n(w2\n1 + ... + w2n) is the length of the vector W. (The normal'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 45, 'page_label': '46'}, page_content='4.1. THRESHOLD LOGIC UNITS 37\nform of the hyperplane equation is Xn + W\n|W| = 0.) The distance from the\nhyperplane to the origin is wn+1\n|W|, and the distance from an arbitrary point, X,\nto the hyperplane is XW+wn+1\n|W| . When the distance from the hyperplane to the\norigin is negative (that is, when wn+1 < 0), then the origin is on the negative\nside of the hyperplane (that is, the side for which XW + wn+1 <0).\nX.W + wn+1 > 0\non this side\nW\nX\nW\nn = W\n|W|\nOrigin\nUnit vector normal\nto hyperplane\nW + wn+1 = 0X\nn +           = 0X\nEquations of hyperplane:\nwn+1\n|W|\nwn+1 W + wn+1X\nX.W + wn+1 < 0\non this side\nFigure 4.2: TLU Geometry\nAdjusting the weight vector, W, changes the orientation of the hyperplane;\nadjusting wn+1 changes the position of the hyperplane (relative to the origin).\nThus, training of a TLU can be achieved by adjusting the values of the weights.\nIn this way the hyperplane can be moved so that the TLU implements di\ufb00erent\n(linearly separable) functions of the input.\n4.1.2 Special Cases of Linearly Separable Functions\nTerms\nAny term of size k can be implemented by a TLU with a weight from each of\nthose inputs corresponding to variables occurring in the term. A weight of +1 is\nused from an input corresponding to a positive literal, and a weight of\u22121 is used\nfrom an input corresponding to a negative literal. (Literals not mentioned in\nthe term have weights of zerothat is, no connection at allfrom their inputs.)\nThe threshold, \u03b8, is set equal to kp \u22121/2, where kp is the number of positive\nliterals in the term. Such a TLU implements a hyperplane boundary that is'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 46, 'page_label': '47'}, page_content='38 CHAPTER 4. NEURAL NETWORKS\nparallel to a subface of dimension ( n\u2212k) of the unit hypercube. We show a\nthree-dimensional example in Fig. 4.3. Thus, linearly separable functions are a\nsuperset of terms.\n(1,1,1)\n(1,1,0)\nx2\nx1\nx3 f = x1x2\nx1 + x2 - 3/2 = 0\nEquation of plane is:\nFigure 4.3: Implementing a Term\nClauses\nThe negation of a clause is a term. For example, the negation of the clause\nf = x1 + x2 + x3 is the term f = x1 x2 x3. A hyperplane can be used to\nimplement this term. If we invert the hyperplane, it will implement the\nclause instead. Inverting a hyperplane is done by multiplying all of the TLU\nweightseven wn+1by \u22121. This process simply changes the orientation of the\nhyperplane\ufb02ipping it around by 180 degrees and thus changing its positive\nside. Therefore, linearly separable functions are also a superset of clauses. We\nshow an example in Fig. 4.4.\n4.1.3 Error-Correction Training of a TLU\nThere are several procedures that have been proposed for adjusting the weights\nof a TLU. We present next a family of incremental training procedures with\nparameter c. These methods make adjustments to the weight vector only when\nthe TLU being trained makes an error on a training pattern; they are called\nerror-correction procedures. We use augmented feature and weight vectors in\ndescribing them.\na. We start with a \ufb01nite training set, \u039e, of vectors, Yi , and their binary\nlabels.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 47, 'page_label': '48'}, page_content='4.1. THRESHOLD LOGIC UNITS 39\nf = x1 + x2 + x3\nx1\nx1 + x2 + x3 < 1/2 = 0\nf = x1x2x3\nEquation of plane is:\nx2\nx3\nFigure 4.4: Implementing a Clause\nb. Compose an in\ufb01nite training sequence, \u03a3, of vectors from \u039e and their\nlabels such that each member of \u039e occurs in\ufb01nitely often in \u03a3. Set the\ninitial weight values of an TLU to arbitrary values.\nc. Repeat forever:\nPresent the next vector, Yi, in \u03a3 to the TLU and note its response.\n(a) If the TLU responds correctly, make no change in the weight vector.\n(b) If Yi is supposed to produce an output of 0 and produces an output\nof 1 instead, modify the weight vector as follows:\nV \u2190\u2212V \u2212ciYi\nwhere ci is a positive real number called the learning rate parame-\nter (whose value is di\ufb00ererent in di\ufb00erent instances of this family of\nprocedures and may depend on i).\nNote that after this adjustment the new dot product will be ( V \u2212\nciYi)Yi = VYi\u2212ciYiYi, which is smaller than it was before the\nweight adjustment.\n(c) If Yi is supposed to produce an output of 1 and produces an output\nof 0 instead, modify the weight vector as follows:\nV \u2190\u2212V + ciYi\nIn this case, the new dot product will be ( V + ciYi)Yi = VYi +\nciYiYi, which is larger than it was before the weight adjustment.\nNote that all three of these cases can be combined in the following rule:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 48, 'page_label': '49'}, page_content='40 CHAPTER 4. NEURAL NETWORKS\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere di is the desired response (1 or 0) for Yi , and fi is the actual\nresponse (1 or 0) for Yi.]\nNote also that because the weight vector V now includes the wn+1 thresh-\nold component, the threshold of the TLU is also changed by these adjust-\nments.\nWe identify two versions of this procedure:\n1) In the \ufb01xed-increment procedure, the learning rate parameter, ci, is the\nsame \ufb01xed, positive constant for all i. Depending on the value of this constant,\nthe weight adjustment may or may not correct the response to an erroneously\nclassi\ufb01ed feature vector.\n2) In the fractional-correction procedure, the parameter ci is set to \u03bbYiV\nYiYi\n,\nwhere V is the weight vector before it is changed. Note that if \u03bb = 0, no\ncorrection takes place at all. If \u03bb = 1, the correction is just su\ufb03cient to make\nYiV = 0. If \u03bb> 1, the error will be corrected.\nIt can be proved that if there is some weight vector, V, that produces a\ncorrect output for all of the feature vectors in \u039e, then after a \ufb01nite number\nof feature vector presentations, the \ufb01xed-increment procedure will \ufb01nd such a\nweight vector and thus make no more weight changes. The same result holds\nfor the fractional-correction procedure if 1 <\u03bb \u22642.\nFor additional background, proofs, and examples of error-correction proce-\ndures, see [Nilsson, 1990].See [Maass & Tur´ an, 1994] for a\nhyperplane-\ufb01nding procedure that\nmakes no more than O(n2 log n)\nmistakes.\n4.1.4 Weight Space\nWe can give an intuitive idea about how these procedures work by considering\nwhat happens to the augmented weight vector in weight space as corrections\nare made. We use augmented vectors in our discussion here so that the threshold\nfunction compares the dot product, YiV, against a threshold of 0. A particular\nweight vector, V, then corresponds to a point in ( n+ 1)-dimensional weight\nspace. Now, for any pattern vector, Yi, consider the locus of all points in\nweight space corresponding to weight vectors yielding YiV = 0. This locus is\na hyperplane passing through the origin of the ( n+ 1)-dimensional space. Each\npattern vector will have such a hyperplane corresponding to it. Weight points\nin one of the half-spaces de\ufb01ned by this hyperplane will cause the corresponding\npattern to yield a dot product less than 0, and weight points in the other half-\nspace will cause the corresponding pattern to yield a dot product greater than\n0.\nWe show a schematic representation of such a weight space in Fig. 4.5.\nThere are four pattern hyperplanes, 1, 2, 3, 4 , corresponding to patterns Y1,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 49, 'page_label': '50'}, page_content='4.1. THRESHOLD LOGIC UNITS 41\nY2, Y3, Y4, respectively, and we indicate by an arrow the half-space for each\nin which weight vectors give dot products greater than 0. Suppose we wanted\nweight values that would give positive responses for patterns Y1, Y3, and Y4,\nand a negative response for pattern Y2. The weight point, V, indicated in the\n\ufb01gure is one such set of weight values.\n23\n4\n1\nV\nFigure 4.5: Weight Space\nThe question of whether or not there exists a weight vector that gives desired\nresponses for a given set of patterns can be given a geometric interpretation. To\ndo so involves reversing the polarity of those hyperplanes corresponding to\npatterns for which a negative response is desired. If we do that for our example\nabove, we get the weight space diagram shown in Fig. 4.6.\n23\n4\n1\nV\n0\n1\n1\n23\n2\n3\n4\nFigure 4.6: Solution Region in Weight Space'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 50, 'page_label': '51'}, page_content='42 CHAPTER 4. NEURAL NETWORKS\nIf a weight vector exists that correctly classi\ufb01es a set of patterns, then the\nhalf-spaces de\ufb01ned by the correct responses for these patterns will have a non-\nempty intersection, called the solution region. The solution region will be a\nhyper-wedge region whose vertex is at the origin of weight space and whose\ncross-section increases with increasing distance from the origin. This region\nis shown shaded in Fig. 4.6. (The boxed numbers show, for later purposes,\nthe number of errors made by weight vectors in each of the regions.) The\n\ufb01xed-increment error-correction procedure changes a weight vector by moving it\nnormal to any pattern hyperplane for which that weight vector gives an incorrect\nresponse. Suppose in our example that we present the patterns in the sequence\nY1, Y2, Y3, Y4, and start the process with a weight point V1, as shown in Fig.\n4.7. Starting at V1, we see that it gives an incorrect response for pattern Y1, so\nwe move V1 to V2 in a direction normal to plane 1. (That is what adding Y1 to\nV1 does.) Y2 gives an incorrect response for pattern Y2, and so on. Ultimately,\nthe responses are only incorrect for planes bounding the solution region. Some\nof the subsequent corrections may overshoot the solution region, but eventually\nwe work our way out far enough in the solution region that corrections (for\na \ufb01xed increment size) take us within it. The proofs for convergence of the\n\ufb01xed-increment rule make this intuitive argument precise.\n23\n4\n1\nV\nV1\nV2\nV3\nV4\nV5\nV6\nFigure 4.7: Moving Into the Solution Region\n4.1.5 The Widrow-Ho\ufb00 Procedure\nThe Widrow-Ho\ufb00 procedure (also called the LMS or the delta procedure) at-\ntempts to \ufb01nd weights that minimize a squared-error function between the pat-\ntern labels and the dot product computed by a TLU. For this purpose, the\npattern labels are assumed to be either +1 or \u22121 (instead of 1 or 0). The'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 51, 'page_label': '52'}, page_content='4.1. THRESHOLD LOGIC UNITS 43\nsquared error for a pattern, Xi, with label di (for desired output) is:\n\u03b5i = (di \u2212\nn+1\u2211\nj=1\nxijwj)2\nwhere xij is the j-th component of Xi. The total squared error (over all patterns\nin a training set, \u039e, containing m patterns) is then:\n\u03b5=\nm\u2211\ni=1\n(di \u2212\nn+1\u2211\nj=1\nxijwj)2\nWe want to choose the weightswj to minimize this squared error. One way to\n\ufb01nd such a set of weights is to start with an arbitrary weight vector and move it\nalong the negative gradient of\u03b5as a function of the weights. Since \u03b5is quadratic\nin the wj, we know that it has a global minimum, and thus this steepest descent\nprocedure is guaranteed to \ufb01nd the minimum. Each component of the gradient\nis the partial derivative of \u03b5 with respect to one of the weights. One problem\nwith taking the partial derivative of \u03b5is that \u03b5depends on all the input vectors\nin \u039e. Often, it is preferable to use an incremental procedure in which we try the\nTLU on just one element, Xi, of \u039e at a time, compute the gradient of the single-\npattern squared error, \u03b5i, make the appropriate adjustment to the weights, and\nthen try another member of \u039e. Of course, the results of the incremental version\ncan only approximate those of the batch one, but the approximation is usually\nquite e\ufb00ective. We will be describing the incremental version here.\nThe j-th component of the gradient of the single-pattern error is:\n\u2202\u03b5i\n\u2202wj\n= \u22122(di \u2212\nn+1\u2211\nj=1\nxijwj)xij\nAn adjustment in the direction of the negative gradient would then change each\nweight as follows:\nwj \u2190\u2212wj + ci(di \u2212fi)xij\nwhere fi = \u2211n+1\nj=1 xijwj, and ci governs the size of the adjustment. The entire\nweight vector (in augmented, or V, notation) is thus adjusted according to the\nfollowing rule:\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere, as before, Yi is the i-th augmented pattern vector.\nThe Widrow-Ho\ufb00 procedure makes adjustments to the weight vector when-\never the dot product itself, YiV, does not equal the speci\ufb01ed desired target'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 52, 'page_label': '53'}, page_content='44 CHAPTER 4. NEURAL NETWORKS\nvalue, di (which is either 1 or \u22121). The learning-rate factor, ci, might de-\ncrease with time toward 0 to achieve asymptotic convergence. The Widrow-\nHo\ufb00 formula for changing the weight vector has the same form as the standard\n\ufb01xed-increment error-correction formula. The only di\ufb00erence is that fi is the\nthresholded response of the TLU in the error-correction case while it is the dot\nproduct itself for the Widrow-Ho\ufb00 procedure.\nFinding weight values that give the desired dot products corresponds to solv-\ning a set of linear equalities, and the Widrow-Ho\ufb00 procedure can be interpreted\nas a descent procedure that attempts to minimize the mean-squared-error be-\ntween the actual and desired values of the dot product. (For more on Widrow-\nHo\ufb00 and other related procedures, see [Duda & Hart, 1973, pp. 151\ufb00].)Examples of training curves for\nTLUs; performance on training\nset; performance on test set;\ncumulative number of corrections. 4.1.6 Training a TLU on Non-Linearly-Separable Training\nSets\nWhen the training set is not linearly separable (perhaps because of noise or\nperhaps inherently), it may still be desired to \ufb01nd a best separating hy-\nperplane. Typically, the error-correction procedures will not do well on non-\nlinearly-separable training sets because they will continue to attempt to correct\ninevitable errors, and the hyperplane will never settle into an acceptable place.\nSeveral methods have been proposed to deal with this case. First, we might\nuse the Widrow-Ho\ufb00 procedure, which (although it will not converge to zero\nerror on non-linearly separable problems) will give us a weight vector that min-\nimizes the mean-squared-error. A mean-squared-error criterion often gives un-\nsatisfactory results, however, because it prefers many small errors to a few large\nones. As an alternative, error correction with a continuous decrease toward zero\nof the value of the learning rate constant,c, will result in ever decreasing changes\nto the hyperplane. Duda [Duda, 1966] has suggested keeping track of the average\nvalue of the weight vector during error correction and using this average to give a\nseparating hyperplane that performs reasonably well on non-linearly-separable\nproblems. Gallant [Gallant, 1986] proposed what he called the pocket algo-\nrithm. As described in [Hertz, Krogh, & Palmer, 1991, p. 160]:\n. . . the pocket algorithm . . . consists simply in storing (or putting\nin your pocket) the set of weights which has had the longest un-\nmodi\ufb01ed run of successes so far. The algorithm is stopped after some\nchosen time t . . .\nAfter stopping, the weights in the pocket are used as a set that should give a\nsmall number of errors on the training set. Error-correction proceeds as usual\nwith the ordinary set of weights.Also see methods proposed by\n[John, 1995] and by\n[Marchand & Golea, 1993]. The\nlatter is claimed to outperform the\npocket algorithm. 4.2 Linear Machines\nThe natural generalization of a (two-category) TLU to an R-category classi\ufb01er\nis the structure, shown in Fig. 4.8, called a linear machine. Here, to use more'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 53, 'page_label': '54'}, page_content='4.2. LINEAR MACHINES 45\nfamiliar notation, the Ws and X are meant to be augmented vectors (with an\n(n+1)-st component). Such a structure is also sometimes called a competitive\nnet or a winner-take-all net. The output of the linear machine is one of\nthe numbers, {1,...,R }, corresponding to which dot product is largest. Note\nthat when R = 2, the linear machine reduces to a TLU with weight vector\nW = (W1 \u2212W2).\nX\nW1\nWR\n. . .\nY\nY\nARGMAX\nW1.X\nWR.X\nFigure 4.8: A Linear Machine\nThe diagram in Fig. 4.9 shows the character of the regions in a 2-dimensional\nspace created by a linear machine for R = 5. In n dimensions, every pair of\nregions is either separated by a section of a hyperplane or is non-adjacent.\nR 1\nR 3\nR 4\nR 5\nX.W4  * X.Wi for i & 4\nR 2\nIn this region:\nFigure 4.9: Regions For a Linear Machine\nTo train a linear machine, there is a straightforward generalization of the\n2-category error-correction rule. Assemble the patterns in the training set into\na sequence as before.\na. If the machine classi\ufb01es a pattern correctly, no change is made to any of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 54, 'page_label': '55'}, page_content='46 CHAPTER 4. NEURAL NETWORKS\nthe weight vectors.\nb. If the machine mistakenly classi\ufb01es a category u pattern, Xi, in category\nv (u\u0338= v), then:\nWu \u2190\u2212Wu + ciXi\nand\nWv \u2190\u2212Wv \u2212ciXi\nand all other weight vectors are not changed.\nThis correction increases the value of the u-th dot product and decreases the\nvalue of the v-th dot product. Just as in the 2-category \ufb01xed increment proce-\ndure, this procedure is guaranteed to terminate, for constant ci, if there exists\nweight vectors that make correct separations of the training set. Note that when\nR= 2, this procedure reduces to the ordinary TLU error-correction procedure.\nA proof that this procedure terminates is given in [Nilsson, 1990, pp. 88-90]\nand in [Duda & Hart, 1973, pp. 174-177].\n4.3 Networks of TLUs\n4.3.1 Motivation and Examples\nLayered Networks\nTo classify correctly all of the patterns in non-linearly-separable training sets re-\nquires separating surfaces more complex than hyperplanes. One way to achieve\nmore complex surfaces is with networks of TLUs. Consider, for example, the 2-\ndimensional, even parity function, f = x1x2 + x1 x2. No single line through the\n2-dimensional square can separate the vertices (1,1) and (0,0) from the vertices\n(1,0) and (0,1)the function is not linearly separable and thus cannot be im-\nplemented by a single TLU. But, the network of three TLUs shown in Fig. 4.10\ndoes implement this function. In the \ufb01gure, we show the weight values along\ninput lines to each TLU and the threshold value inside the circle representing\nthe TLU.\nThe function implemented by a network of TLUs depends on its topology\nas well as on the weights of the individual TLUs. Feedforward networks have\nno cycles; in a feedforward network no TLUs input depends (through zero\nor more intermediate TLUs) on that TLUs output. (Networks that are not\nfeedforward are calledrecurrentnetworks). If the TLUs of a feedforward network\nare arranged in layers, with the elements of layer j receiving inputs only from\nTLUs in layer j \u22121, then we say that the network is a layered, feedforward'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 55, 'page_label': '56'}, page_content='4.3. NETWORKS OF TLUS 47\nf\nx1\nx2\n1.5\n-0.5\n0.5\n1\n1-1\n-1 1\n1\nFigure 4.10: A Network for the Even Parity Function\nnetwork. The network shown in Fig. 4.10 is a layered, feedforward network\nhaving two layers (of weights). (Some people count the layers of TLUs and\ninclude the inputs as a layer also; they would call this network a three-layer\nnetwork.) In general, a feedforward, layered network has the structure shown\nin Fig. 4.11. All of the TLUs except the output units are called hidden units\n(they are hidden from the output).\nX\nhidden units\noutput units\nFigure 4.11: A Layered, Feedforward Network\nImplementing DNF Functions by Two-Layer Networks\nWe have already de\ufb01nedk-term DNF functionsthey are DNF functions having\nk terms. A k-term DNF function can be implemented by a two-layer network\nwith k units in the hidden layerto implement the k termsand one output\nunit to implement the disjunction of these terms. Since any Boolean function\nhas a DNF form, any Boolean function can be implemented by some two-layer\nnetwork of TLUs. As an example, consider the function f = x1x2 + x2x3 +\nx1x3. The form of the network that implements this function is shown in Fig.\n4.12. (We leave it to the reader to calculate appropriate values of weights and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 56, 'page_label': '57'}, page_content='48 CHAPTER 4. NEURAL NETWORKS\nthresholds.) The 3-cube representation of the function is shown in Fig. 4.13.\nThe network of Fig. 4.12 can be designed so that each hidden unit implements\none of the planar boundaries shown in Fig. 4.13.\nx\nconjuncts\ndisjunct\nA Feedforward, 2-layer Network\nTLUs\ndisjunction\nof terms\nconjunctions\nof literals\n(terms)\nFigure 4.12: A Two-Layer Network\nx2\nx1\nx3\nf = x1x2 + x2x3 + x1x3\nFigure 4.13: Three Planes Implemented by the Hidden Units\nTo train a two-layer network that implements a k-term DNF function, we\n\ufb01rst note that the output unit implements a disjunction, so the weights in the\n\ufb01nal layer are \ufb01xed. The weights in the \ufb01rst layer (except for the threshold\nweights) can all have values of 1, \u22121, or 0. Later, we will present a training\nprocedure for this \ufb01rst layer of weights.Discuss half-space intersections,\nhalf-space unions, NP-hardness of\noptimal versions,\nsingle-side-error-hypeplane\nmethods, relation to AQ\nmethods.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 57, 'page_label': '58'}, page_content='4.3. NETWORKS OF TLUS 49\nImportant Comment About Layered Networks\nAdding additional layers cannot compensate for an inadequate \ufb01rst layer of\nTLUs. The \ufb01rst layer of TLUs partitions the feature space so that no two dif-\nferently labeled vectors are in the same region (that is, so that no two such\nvectors yield the same set of outputs of the \ufb01rst-layer units). If the \ufb01rst layer\ndoes not partition the feature space in this way, then regardless of what subse-\nquent layers do, the \ufb01nal outputs will not be consistent with the labeled training\nset. Add diagrams showing the\nnon-linear transformation\nperformed by a layered network.\n4.3.2 Madalines\nTwo-Category Networks\nAn interesting example of a layered, feedforward network is the two-layer one\nwhich has an odd number of hidden units, and a vote-taking TLU as the\noutput unit. Such a network was called a Madaline (for m any adalines by\nWidrow. Typically, the response of the vote taking unit is de\ufb01ned to be the\nresponse of the majority of the hidden units, although other output logics are\npossible. Ridgway [Ridgway, 1962] proposed the following error-correction rule\nfor adjusting the weights of the hidden units of a Madaline:\n If the Madaline correctly classi\ufb01es a pattern, Xi, no corrections are made\nto any of the hidden units weight vectors,\n If the Madaline incorrectly classi\ufb01es a pattern, Xi, then determine the\nminimum number of hidden units whose responses need to be changed\n(from 0 to 1 or from 1 to 0depending on the type of error) in order that\nthe Madaline would correctly classify Xi. Suppose that minimum number\nis ki. Of those hidden units voting incorrectly, change the weight vectors\nof those ki of them whose dot products are closest to 0 by using the error\ncorrection rule:\nW \u2190\u2212W + ci(di \u2212fi)Xi\nwhere di is the desired response of the hidden unit (0 or 1) and fi is the\nactual response (0 or 1). (We assume augmented vectors here even though\nwe are using X, W notation.)\nThat is, we perform error-correction on just enough hidden units to correct\nthe vote to a majority voting correctly, and we change those that are easiest to\nchange. There are example problems in which even though a set of weight values\nexists for a given Madaline structure such that it could classify all members of\na training set correctly, this procedure will fail to \ufb01nd them. Nevertheless, the\nprocedure works e\ufb00ectively in most experiments with it.\nWe leave it to the reader to think about how this training procedure could\nbe modi\ufb01ed if the output TLU implemented an or function (or an and function).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 58, 'page_label': '59'}, page_content='50 CHAPTER 4. NEURAL NETWORKS\nR-Category Madalines and Error-Correcting Output Codes\nIf there are k hidden units ( k > 1) in a two-layer network, their responses\ncorrespond to vertices of ak-dimensional hypercube. The ordinary two-category\nMadaline identi\ufb01es two special points in this space, namely the vertex consisting\nof k 1s and the vertex consisting of k 0s. The Madalines response is 1 if the\npoint in hidden-unit-space is closer to the all 1s vertex than it is to the all\n0s vertex. We could design an R-category Madaline by identifying R vertices\nin hidden-unit space and then classifying a pattern according to which of these\nvertices the hidden-unit response is closest to. A machine using that idea was\nimplemented in the early 1960s at SRI [Brain, et al., 1962]. It used the fact\nthat the 2p so-called maximal-length shift-register sequences[Peterson, 1961, pp.\n147\ufb00] in a (2p\u22121)-dimensional Boolean space are mutually equidistant (for any\ninteger p). For similar, more recent work see [Dietterich & Bakiri, 1991].\n4.3.3 Piecewise Linear Machines\nA two-category training set is linearly separable if there exists a threshold func-\ntion that correctly classi\ufb01es all members of the training set. Similarly, we can\nsay that an R-category training set is linearly separable if there exists a linear\nmachine that correctly classi\ufb01es all members of the training set. When an R-\ncategory problem is not linearly separable, we need a more powerful classi\ufb01er.\nA candidate is a structure called a piecewise linear (PWL) machine illustrated\nin Fig. 4.14.\nX\nW1\nW1\n. . .\nY\nY\nMAX\n. . .\nY\nY\nMAX\n. . .\nWR\nWR\nARG\nMAX\n1\nR\n1\nN1\n1\nNR\nFigure 4.14: A Piecewise Linear Machine'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 59, 'page_label': '60'}, page_content='4.3. NETWORKS OF TLUS 51\nThe PWL machine groups its weighted summing units into R banks corre-\nsponding to the R categories. An input vector X is assigned to that category\ncorresponding to the bank with the largest weighted sum. We can use an error-\ncorrection training algorithm similar to that used for a linear machine. If a\npattern is classi\ufb01ed incorrectly, we subtract (a constant times) the pattern vec-\ntor from the weight vector producing the largest dot product (it was incorrectly\nthe largest) and add (a constant times) the pattern vector to that weight vector\nin the correct bank of weight vectors whose dot product is locally largest in\nthat bank. (Again, we use augmented vectors here.) Unfortunately, there are\nexample training sets that are separable by a given PWL machine structure\nbut for which this error-correction training method fails to \ufb01nd a solution. The\nmethod does appear to work well in some situations [Duda & Fossum, 1966], al-\nthough [Nilsson, 1965, page 89] observed that it is probably not a very e\ufb00ective\nmethod for training PWL machines having more than three [weight vectors] in\neach bank.\n4.3.4 Cascade Networks\nAnother interesting class of feedforward networks is that in which all of the TLUs\nare ordered and each TLU receives inputs from all of the pattern components\nand from all TLUs lower in the ordering. Such a network is called a cascade\nnetwork. An example is shown in Fig. 4.15 in which the TLUs are labeled by\nthe linearly separable functions (of their inputs) that they implement. Each\nTLU in the network implements a set of 2 k parallel hyperplanes, where k is\nthe number of TLUs from which it receives inputs. (Each of the k preceding\nTLUs can have an output of 1 or 0; thats 2 k di\ufb00erent combinationsresulting\nin 2k di\ufb00erent positions for the parallel hyperplanes.) We show a 3-dimensional\nsketch for a network of two TLUs in Fig. 4.16. The reader might consider how\nthe n-dimensional parity function might be implemented by a cascade network\nhaving log2 n TLUs.\nx\nL1\nL2\noutput\nL3\nFigure 4.15: A Cascade Network'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 60, 'page_label': '61'}, page_content='52 CHAPTER 4. NEURAL NETWORKS\nL1\nL2\nL2\nFigure 4.16: Planes Implemented by a Cascade Network with Two TLUs\nCascade networks might be trained by \ufb01rst training L1 to do as good a job\nas possible at separating all the training patterns (perhaps by using the pocket\nalgorithm, for example), then training L2 (including the weight from L1 to L2)\nalso to do as good a job as possible at separating all the training patterns,\nand so on until the resulting network classi\ufb01es the patterns in the training set\nsatisfactorily.Also mention the\ncascade-correlation method of\n[Fahlman & Lebiere, 1990].\n4.4 Training Feedforward Networks by Back-\npropagation\n4.4.1 Notation\nThe general problem of training a network of TLUs is di\ufb03cult. Consider, for\nexample, the layered, feedforward network of Fig. 4.11. If such a network makes\nan error on a pattern, there are usually several di\ufb00erent ways in which the error\ncan be corrected. It is di\ufb03cult to assign blame for the error to any particular\nTLU in the network. Intuitively, one looks for weight-adjusting procedures that\nmove the network in the correct direction (relative to the error) by making\nminimal changes. In this spirit, the Widrow-Ho\ufb00 method of gradient descent\nhas been generalized to deal with multilayer networks.\nIn explaining this generalization, we use Fig. 4.17 to introduce some nota-\ntion. This network has only one output unit, but, of course, it is possible to have\nseveral TLUs in the output layereach implementing a di\ufb00erent function. Each\nof the layers of TLUs will have outputs that we take to be the components of\nvectors, just as the input features are components of an input vector. The j-th\nlayer of TLUs (1 \u2264j <k) will have as their outputs the vector X(j). The input\nfeature vector is denoted by X(0), and the \ufb01nal output (of the k-th layer TLU)\nis f. Each TLU in each layer has a weight vector (connecting it to its inputs)\nand a threshold; the i-th TLU in the j-th layer has a weight vector denoted by\nW(j)\ni . (We will assume that the threshold weight is the last component of\nthe associated weight vector; we might have used V notation instead to include'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 61, 'page_label': '62'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION53\nthis threshold component, but we have chosen here to use the familiar X,W\nnotation, assuming that these vectors are augmented as appropriate.) We\ndenote the weighted sum input to the i-th threshold unit in the j-th layer by\ns(j)\ni . (That is, s(j)\ni = X(j\u22121)W(j)\ni .) The number of TLUs in the j-th layer is\ngiven by mj. The vector W(j)\ni has components w(j)\nl,i for l= 1,...,m (j\u22121) + 1.\nX(0)\n. . .\n. . .\n. . .\n. . .\nWi(1)\nW(k)\nX(1)\nm1 TLUs\n. . .\nWi(j)\n. . .\nX(j)\n. . .\nWi(k-1)\nX(k-1)\nmj TLUs m(k-1) TLUs\nwli(j)\nwl(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . .\nf\nsi(1) si(j) si(k-1)\ns(k)\nFigure 4.17: A k-layer Network\n4.4.2 The Backpropagation Method\nA gradient descent method, similar to that used in the Widrow Ho\ufb00 method,\nhas been proposed by various authors for training a multi-layer, feedforward\nnetwork. As before, we de\ufb01ne an error function on the \ufb01nal output of the\nnetwork and we adjust each weight in the network so as to minimize the error.\nIf we have a desired response, di, for the i-th input vector, Xi, in the training\nset, \u039e, we can compute the squared error over the entire training set to be:\n\u03b5=\n\u2211\nXi \u03f5 \u039e\n(di \u2212fi)2\nwhere fi is the actual response of the network for input Xi. To do gradient\ndescent on this squared error, we adjust each weight in the network by an\namount proportional to the negative of the partial derivative of \u03b5 with respect\nto that weight. Again, we use a single-pattern error function so that we can\nuse an incremental weight adjustment procedure. The squared error for a single\ninput vector, X, evoking an output of f when the desired output is d is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 62, 'page_label': '63'}, page_content='54 CHAPTER 4. NEURAL NETWORKS\n\u03b5= (d\u2212f)2\nIt is convenient to take the partial derivatives of\u03b5with respect to the various\nweights in groups corresponding to the weight vectors. We de\ufb01ne a partial\nderivative of a quantity \u03c6, say, with respect to a weight vector, W(j)\ni , thus:\n\u2202\u03c6\n\u2202W(j)\ni\ndef\n=\n[\n\u2202\u03c6\n\u2202w(j)\n1i\n,..., \u2202\u03c6\n\u2202w(j)\nli\n,..., \u2202\u03c6\n\u2202w(j)\nmj\u22121+1,i\n]\nwhere w(j)\nli is the l-th component of W(j)\ni . This vector partial derivative of \u03c6is\ncalled the gradient of \u03c6 with respect to W and is sometimes denoted by \u2207W\u03c6.\nSince \u03b5s dependence on W(j)\ni is entirely through s(j)\ni , we can use the chain\nrule to write:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\n\u2202s(j)\ni\n\u2202W(j)\ni\nBecause s(j)\ni = X(j\u22121)W(j)\ni ,\n\u2202s(j)\ni\n\u2202W(j)\ni\n= X(j\u22121). Substituting yields:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\nX(j\u22121)\nNote that \u2202\u03b5\n\u2202s(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\n. Thus,\n\u2202\u03b5\n\u2202W(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\nX(j\u22121)\nThe quantity (d\u2212f) \u2202f\n\u2202s(j)\ni\nplays an important role in our calculations; we shall\ndenote it by \u03b4(j)\ni . Each of the \u03b4(j)\ni s tells us how sensitive the squared error of\nthe network output is to changes in the input to each threshold function. Since\nwe will be changing weight vectors in directions along their negative gradient,\nour fundamental rule for weight changes throughout the network will be:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nwhere c(j)\ni is the learning rate constant for this weight vector. (Usually, the\nlearning rate constants for all weight vectors in the network are the same.) We\nsee that this rule is quite similar to that used in the error correction procedure'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 63, 'page_label': '64'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION55\nfor a single TLU. A weight vector is changed by the addition of a constant times\nits vector of (unweighted) inputs.\nNow, we must turn our attention to the calculation of the \u03b4(j)\ni s. Using the\nde\ufb01nition, we have:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nWe have a problem, however, in attempting to carry out the partial deriva-\ntives of f with respect to the ss. The network output, f, is not continuously\ndi\ufb00erentiable with respect to the ss because of the presence of the threshold\nfunctions. Most small changes in these sums do not change f at all, and when\nf does change, it changes abruptly from 1 to 0 or vice versa.\nA way around this di\ufb03culty was proposed by Werbos [Werbos, 1974] and\n(perhaps independently) pursued by several other researchers, for example\n[Rumelhart, Hinton, & Williams, 1986]. The trick involves replacing all the\nthreshold functions by di\ufb00erentiable functions called sigmoids.1 The output\nof a sigmoid function, superimposed on that of a threshold function, is shown\nin Fig. 4.18. Usually, the sigmoid function used is f(s) = 1\n1+e\u2212s , where s is\nthe input and f is the output.\nsigmoid\nthreshold function\nf (s)\ns\nf (s) = 1/[1 + e<s]\nFigure 4.18: A Sigmoid Function\n1[Russell & Norvig 1995, page 595] attributes the use of this idea to [Bryson & Ho 1969].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 64, 'page_label': '65'}, page_content='56 CHAPTER 4. NEURAL NETWORKS\nWe show the network containing sigmoid units in place of TLUs in Fig. 4.19.\nThe output of the i-th sigmoid unit in the j-th layer is denoted by f(j)\ni . (That\nis, f(j)\ni = 1\n1+e\u2212s(j)\ni\n.)\nX(0)\n. . .\n. . .\n. . .\n. . .\nWi(1)\nsi(1)\nW(k)\nX(1)\nfi(1)\nm1 sigmoids\n. . .\nWi(j) fi(j)\nsi(j)\n. . .\nX(j)\n. . .\nWi(k-1)\nfi(k-1)\nsi(k-1)\nf(k)\ns(k)\nX(k-1)\nmj sigmoids m(k-1) sigmoids\nwli(j)\nwl(k)\nbi(j)bi(1)\nbi(k-1)\nb(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . .\nFigure 4.19: A Network with Sigmoid Units\n4.4.3 Computing Weight Changes in the Final Layer\nWe \ufb01rst calculate\u03b4(k) in order to compute the weight change for the \ufb01nal sigmoid\nunit:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 65, 'page_label': '66'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION57\n\u03b4(k) = (d\u2212f(k))\u2202f(k)\n\u2202s(k)\nGiven the sigmoid function that we are using, namely f(s) = 1\n1+e\u2212s, we have\nthat \u2202f\n\u2202s = f(1 \u2212f). Substituting gives us:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nRewriting our general rule for weight vector changes, the weight vector in\nthe \ufb01nal layer is changed according to the rule:\nW(k) \u2190W(k) + c(k)\u03b4(k)X(k\u22121)\nwhere \u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nIt is interesting to compare backpropagation to the error-correction rule and\nto the Widrow-Ho\ufb00 rule. The backpropagation weight adjustment for the single\nelement in the \ufb01nal layer can be written as:\nW \u2190\u2212W + c(d\u2212f)f(1 \u2212f)X\nWritten in the same format, the error-correction rule is:\nW \u2190\u2212W + c(d\u2212f)X\nand the Widrow-Ho\ufb00 rule is:\nW \u2190\u2212W + c(d\u2212f)X\nThe only di\ufb00erence (except for the fact that f is not thresholded in Widrow-\nHo\ufb00) is the f(1 \u2212f) term due to the presence of the sigmoid function. With\nthe sigmoid function, f(1 \u2212f) can vary in value from 0 to 1. When f is 0,\nf(1 \u2212f) is also 0; when f is 1, f(1 \u2212f) is 0; f(1 \u2212f) obtains its maximum\nvalue of 1/4 when f is 1/2 (that is, when the input to the sigmoid is 0). The\nsigmoid function can be thought of as implementing a fuzzy hyperplane. For\na pattern far away from this fuzzy hyperplane, f(1 \u2212f) has value close to 0,\nand the backpropagation rule makes little or no change to the weight values\nregardless of the desired output. (Small changes in the weights will have little\ne\ufb00ect on the output for inputs far from the hyperplane.) Weight changes are\nonly made within the region of fuzz surrounding the hyperplane, and these\nchanges are in the direction of correcting the error, just as in the error-correction\nand Widrow-Ho\ufb00 rules.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 66, 'page_label': '67'}, page_content='58 CHAPTER 4. NEURAL NETWORKS\n4.4.4 Computing Changes to the Weights in Intermediate\nLayers\nUsing our expression for the \u03b4s, we can similarly compute how to change each\nof the weight vectors in the network. Recall:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nAgain we use a chain rule. The \ufb01nal output, f, depends on s(j)\ni through\neach of the summed inputs to the sigmoids in the ( j+ 1)-th layer. So:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\n= (d\u2212f)\n[\n\u2202f\n\u2202s(j+1)\n1\n\u2202s(j+1)\n1\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nmj+1\n\u2202s(j+1)\nmj+1\n\u2202s(j)\ni\n]\n=\nmj+1\u2211\nl=1\n(d\u2212f) \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\nIt remains to compute the\n\u2202s(j+1)\nl\n\u2202s(j)\ni\ns. To do that we \ufb01rst write:\ns(j+1)\nl = X(j)W(j+1)\nl\n=\nmj+1\u2211\n\u03bd=1\nf(j)\n\u03bd w(j+1)\n\u03bdl\nAnd then, since the weights do not depend on the ss:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\n\u2202\n[\u2211mj+1\n\u03bd=1 f(j)\n\u03bd w(j+1)\n\u03bdl\n]\n\u2202s(j)\ni\n=\nmj+1\u2211\n\u03bd=1\nw(j+1)\n\u03bdl\n\u2202f(j)\n\u03bd\n\u2202s(j)\ni\nNow, we note that \u2202f(j)\n\u03bd\n\u2202s(j)\ni\n= 0 unless \u03bd = i, in which case \u2202f(j)\n\u03bd\n\u2202s(j)\n\u03bd\n= f(j)\n\u03bd (1 \u2212f(j)\n\u03bd ).\nTherefore:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n= w(j+1)\nil f(j)\ni (1 \u2212f(j)\ni )'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 67, 'page_label': '68'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION59\nWe use this result in our expression for \u03b4(j)\ni to give:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nThe above equation is recursive in the \u03b4s. (It is interesting to note that\nthis expression is independent of the error function; the error function explicitly\na\ufb00ects only the computation of \u03b4(k).) Having computed the \u03b4(j+1)\ni s for layer\nj + 1, we can use this equation to compute the \u03b4(j)\ni s. The base case is \u03b4(k),\nwhich we have already computed:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nWe use this expression for the\u03b4s in our generic weight changing rule, namely:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nAlthough this rule appears complex, it has an intuitively reasonable explanation.\nThe quantity \u03b4(k) = (d\u2212f)f(1 \u2212f) controls the overall amount and sign of all\nweight adjustments in the network. (Adjustments diminish as the \ufb01nal output,\nf, approaches either 0 or 1, because they have vanishing e\ufb00ect on f then.) As\nthe recursion equation for the \u03b4s shows, the adjustments for the weights going\nin to a sigmoid unit in the j-th layer are proportional to the e\ufb00ect that such\nadjustments have on that sigmoid units output (its f(j)(1 \u2212f(j)) factor). They\nare also proportional to a kind of average e\ufb00ect that any change in the output\nof that sigmoid unit will have on the \ufb01nal output. This average e\ufb00ect depends\non the weights going out of the sigmoid unit in the j-th layer (small weights\nproduce little downstream e\ufb00ect) and the e\ufb00ects that changes in the outputs of\n(j+ 1)-th layer sigmoid units will have on the \ufb01nal output (as measured by the\n\u03b4(j+1)s). These calculations can be simply implemented by backpropagating\nthe \u03b4s through the weights in reverse direction (thus, the name backprop for\nthis algorithm).\n4.4.5 Variations on Backprop\n[To be written: problem of local minima, simulated annealing, momemtum\n(Plaut, et al., 1986, see [Hertz, Krogh, & Palmer, 1991]), quickprop, regulariza-\ntion methods]\nSimulated Annealing\nTo apply simulated annealing, the value of the learning rate constant is gradually\ndecreased with time. If we fall early into an error-function valley that is not\nvery deep (a local minimum), it typically will neither be very broad, and soon'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 68, 'page_label': '69'}, page_content='60 CHAPTER 4. NEURAL NETWORKS\na subsequent large correction will jostle us out of it. It is less likely that we will\nmove out of deep valleys, and at the end of the process (with very small values\nof the learning rate constant), we descend to its deepest point. The process\ngets its name by analogy with annealing in metallurgy, in which a materials\ntemperature is gradually decreased allowing its crystalline structure to reach a\nminimal energy state.\n4.4.6 An Application: Steering a Van\nA neural network system called ALVINN (Autonomous Land Vehicle in a Neural\nNetwork) has been trained to steer a Chevy van successfully on ordinary roads\nand highways at speeds of 55 mph [Pomerleau, 1991, Pomerleau, 1993]. The\ninput to the network is derived from a low-resolution (30 x 32) television image.\nThe TV camera is mounted on the van and looks at the road straight ahead.\nThis image is sampled and produces a stream of 960-dimensional input vectors\nto the neural network. The network is shown in Fig. 4.20.\n960 inputs\n30 x 32 retina\n. . .\n5 hidden\nunits connected\nto all 960 inputs\n30 output units\nconnected to all\nhidden units\n. . .\nsharp left\nsharp right\nstraight ahead\ncentroid\nof outputs\nsteers\nvehicle\nFigure 4.20: The ALVINN Network\nThe network has \ufb01ve hidden units in its \ufb01rst layer and 30 output units in the\nsecond layer; all are sigmoid units. The output units are arranged in a linear\norder and control the vans steering angle. If a unit near the top of the array\nof output units has a higher output than most of the other units, the van is\nsteered to the left; if a unit near the bottom of the array has a high output, the\nvan is steered to the right. The centroid of the responses of all of the output'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 69, 'page_label': '70'}, page_content='4.5. SYNERGIES BETWEEN NEURAL NETWORK AND KNOWLEDGE-BASED METHODS61\nunits is computed, and the vans steering angle is set at a corresponding value\nbetween hard left and hard right.\nThe system is trained by a modi\ufb01ed on-line training regime. A driver drives\nthe van, and his actual steering angles are taken as the correct labels for the\ncorresponding inputs. The network is trained incrementally by backprop to\nproduce the driver-speci\ufb01ed steering angles in response to each visual pattern\nas it occurs in real time while driving.\nThis simple procedure has been augmented to avoid two potential problems.\nFirst, since the driver is usually driving well, the network would never get any\nexperience with far-from-center vehicle positions and/or incorrect vehicle orien-\ntations. Also, on long, straight stretches of road, the network would be trained\nfor a long time only to produce straight-ahead steering angles; this training\nwould swamp out earlier training to follow a curved road. We wouldnt want\nto try to avoid these problems by instructing the driver to drive erratically\noccasionally, because the system would learn to mimic this erratic behavior.\nInstead, each original image is shifted and rotated in software to create 14\nadditional images in which the vehicle appears to be situated di\ufb00erently relative\nto the road. Using a model that tells the system what steering angle ought to\nbe used for each of these shifted images, given the driver-speci\ufb01ed steering angle\nfor the original image, the system constructs an additional 14 labeled training\npatterns to add to those encountered during ordinary driver training.\n4.5 Synergies Between Neural Network and\nKnowledge-Based Methods\nTo be written; discuss\nrule-generating procedures (such as\n[Towell & Shavlik, 1992]) and how\nexpert-provided rules can aid\nneural net training and vice-versa\n[Towell, Shavlik, & Noordweier, 1990].\n4.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 70, 'page_label': '71'}, page_content='62 CHAPTER 4. NEURAL NETWORKS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 71, 'page_label': '72'}, page_content='Chapter 5\nStatistical Learning\n5.1 Using Statistical Decision Theory\n5.1.1 Background and General Method\nSuppose the pattern vector, X, is a random variable whose probability distri-\nbution for category 1 is di\ufb00erent than it is for category 2. (The treatment given\nhere can easily be generalized to R-category problems.) Speci\ufb01cally, suppose we\nhave the two probability distributions (perhaps probability density functions),\np(X |1) and p(X |2). Given a pattern, X, we want to use statistical tech-\nniques to determine its categorythat is, to determine from which distribution\nit was drawn. These techniques are based on the idea of minimizing the ex-\npected value of a quantity similar to the error function we used in deriving the\nweight-changing rules for backprop.\nIn developing a decision method, it is necessary to know the relative serious-\nness of the two kinds of mistakes that might be made. (We might decide that a\npattern really in category 1 is in category 2, and vice versa.) We describe this\ninformation by a loss function, \u03bb(i|j), for i,j = 1,2. \u03bb(i|j) represents the loss\nincurred when we decide a pattern is in category i when really it is in category\nj. We assume here that \u03bb(1 |1) and \u03bb(2 |2) are both 0. For any given pattern,\nX, we want to decide its category in such a way that minimizes the expected\nvalue of this loss.\nGiven a pattern, X, if we decide category i, the expected value of the loss\nwill be:\nLX(i) = \u03bb(i|1)p(1 |X) + \u03bb(i|2)p(2 |X)\nwhere p(j |X) is the probability that given a pattern X, its category is j. Our\ndecision rule will be to decide that X belongs to category 1 if LX(1) \u2264LX(2),\nand to decide on category 2 otherwise.\n63'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 72, 'page_label': '73'}, page_content='64 CHAPTER 5. STATISTICAL LEARNING\nWe can use Bayes Rule to get expressions for p(j |X) in terms of p(X |j),\nwhich we assume to be known (or estimatible):\np(j |X) = p(X |j)p(j)\np(X)\nwhere p(j) is the (a priori) probability of category j (one category may be much\nmore probable than the other); and p(X) is the (a priori) probability of pattern\nX being the pattern we are asked to classify. Performing the substitutions given\nby Bayes Rule, our decision rule becomes:\nDecide category 1 i\ufb00:\n\u03bb(1 |1)p(X |1)p(1)\np(X) + \u03bb(1 |2)p(X |2)p(2)\np(X)\n\u2264\u03bb(2 |1)p(X |1)p(1)\np(X) + \u03bb(2 |2)p(X |2)p(2)\np(X)\nUsing the fact that \u03bb(i |i) = 0, and noticing that p(X) is common to both\nexpressions, we obtain,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nIf \u03bb(1 |2) = \u03bb(2 |1) and if p(1) = p(2), then the decision becomes particu-\nlarly simple:\nDecide category 1 i\ufb00:\np(X |2) \u2264p(X |1)\nSince p(X |j) is called the likelihood of j with respect to X, this simple decision\nrule implements what is called a maximum-likelihood decision. More generally,\nif we de\ufb01ne k(i|j) as \u03bb(i|j)p(j), then our decision rule is simply,\nDecide category1 i\ufb00:\nk(1 |2)p(X |2) \u2264k(2 |1)p(X |1)\nIn any case, we need to compare the (perhaps weighted) quantities p(X |i) for\ni= 1 and 2. The exact decision rule depends on the the probability distributions\nassumed. We will treat two interesting distributions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 73, 'page_label': '74'}, page_content='5.1. USING STATISTICAL DECISION THEORY 65\n5.1.2 Gaussian (or Normal) Distributions\nThe multivariate (n-dimensional) Gaussian distribution is given by the proba-\nbility density function:\np(X) = 1\n(2\u03c0)n/2|\u03a3|1/2 e\n\u2212(X\u2212M)t\u03a3\n\u22121\n(X\u2212M)\n2\nwhere nis the dimension of the column vector X, the column vector M is called\nthe mean vector, (X \u2212M)t is the transpose of the vector ( X \u2212M), \u03a3 is the\ncovariance matrix of the distribution (an n×n symmetric, positive de\ufb01nite\nmatrix), \u03a3\u22121 is the inverse of the covariance matrix, and |\u03a3|is the determinant\nof the covariance matrix.\nThe mean vector, M, with components ( m1,...,m n), is the expected value\nof X (using this distribution); that is, M = E[X]. The components of the\ncovariance matrix are given by:\n\u03c32\nij = E[(xi \u2212mi)(xj \u2212mj)]\nIn particular, \u03c32\nii is called the variance of xi.\nAlthough the formula appears complex, an intuitive idea for Gaussian dis-\ntributions can be given when n = 2. We show a two-dimensional Gaussian\ndistribution in Fig. 5.1. A three-dimensional plot of the distribution is shown\nat the top of the \ufb01gure, and contours of equal probability are shown at the bot-\ntom. In this case, the covariance matrix, \u03a3, is such that the elliptical contours\nof equal probability are skewed. If the covariance matrix were diagonal, that is\nif all o\ufb00-diagonal terms were 0, then the major axes of the elliptical contours\nwould be aligned with the coordinate axes. In general the principal axes are\ngiven by the eigenvectors of \u03a3. In any case, the equi-probability contours are\nall centered on the mean vector, M, which in our \ufb01gure happens to be at the\norigin. In general, the formula in the exponent in the Gaussian distribution\nis a positive de\ufb01nite quadratic form (that is, its value is always positive); thus\nequi-probability contours are hyper-ellipsoids in n-dimensional space.\nSuppose we now assume that the two classes of pattern vectors that we\nwant to distinguish are each distributed according to a Gaussian distribution\nbut with di\ufb00erent means and covariance matrices. That is, one class tends to\nhave patterns clustered around one point in the n-dimensional space, and the\nother class tends to have patterns clustered around another point. We show a\ntwo-dimensional instance of this problem in Fig. 5.2. (In that \ufb01gure, we have\nplotted the sum of the two distributions.) What decision rule should we use to\nseparate patterns into the two appropriate categories?\nSubstituting the Gaussian distributions into our maximum likelihood for-\nmula yields:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 74, 'page_label': '75'}, page_content='66 CHAPTER 5. STATISTICAL LEARNING\n-5\n0\n5\n-5\n0\n5\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n-5\n0\n5\n0\n25\n.5\n75\n1\n-6 -4 -2 0 2 4 6\n-6\n-4\n-2\n0\n2\n4\n6\nx1\nx2\np(x1,x2)\n2\n4\n6\n24 6\nx1\nx2\nFigure 5.1: The Two-Dimensional Gaussian Distribution\nDecide category 1 i\ufb00:\n1\n(2\u03c0)n/2|\u03a32|1/2 e\u22121/2(X\u2212M2)t\u03a3\n\u22121\n2 (X\u2212M2)\nis less than or equal to\n1\n(2\u03c0)n/2|\u03a31|1/2 e\u22121/2(X\u2212M1)t\u03a3\n\u22121\n1 (X\u2212M1)\nwhere the category 1 patterns are distributed with mean and covariance M1\nand \u03a31, respectively, and the category 2 patterns are distributed with mean\nand covariance M2 and \u03a32.\nThe result of the comparison isnt changed if we compare logarithms instead.\nAfter some manipulation, our decision rule is then:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 75, 'page_label': '76'}, page_content='5.1. USING STATISTICAL DECISION THEORY 67\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n25\n.5\n75\n1\nx1\nx2\np(x1,x2)\n-5 -2.5 0 2.5 5 7.5 10\n-5\n-2.5\n0\n2.5\n5\n7.5\n10\nFigure 5.2: The Sum of Two Gaussian Distributions\nDecide category 1 i\ufb00:\n(X \u2212M1)t\u03a3\u22121\n1 (X \u2212M1) <(X \u2212M2)t\u03a3\u22121\n2 (X \u2212M2) + B\nwhere B, a constant bias term, incorporates the logarithms of the fractions\npreceding the exponential, etc.\nWhen the quadratic forms are multiplied out and represented in terms of\nthe components xi, the decision rule involves a quadric surface (a hyperquadric)\nin n-dimensional space. The exact shape and position of this hyperquadric is\ndetermined by the means and the covariance matrices. The surface separates\nthe space into two parts, one of which contains points that will be assigned to\ncategory 1 and the other contains points that will be assigned to category 2.\nIt is interesting to look at a special case of this surface. If the covariance\nmatrices for each category are identical and diagonal, with all \u03c3ii equal to each\nother, then the contours of equal probability for each of the two distributions'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 76, 'page_label': '77'}, page_content='68 CHAPTER 5. STATISTICAL LEARNING\nare hyperspherical. The quadric forms then become (1 /|\u03a3|)(X\u2212Mi)t(X\u2212Mi),\nand the decision rule is:\nDecide category 1 i\ufb00:\n(X \u2212M1)t(X \u2212M1) <(X \u2212M2)t(X \u2212M2)\nMultiplying out yields:\nXX \u22122XM1 + M1M1 <XX \u22122XM2 + M2M2\nor \ufb01nally,\nDecide category 1 i\ufb00:\nXM1 \u2265XM2 + Constant\nor\nX(M1 \u2212M2) \u2265Constant\nwhere the constant depends on the lengths of the mean vectors.\nWe see that the optimal decision surface in this special case is a hyperplane.\nIn fact, the hyperplane is perpendicular to the line joining the two means. The\nweights in a TLU implementation are equal to the di\ufb00erence in the mean vectors.\nIf the parameters ( Mi,\u03a3i) of the probability distributions of the categories\nare not known, there are various techniques for estimating them, and then using\nthose estimates in the decision rule. For example, if there are su\ufb03cient training\npatterns, one can use sample means and sample covariance matrices. (Caution:\nthe sample covariance matrix will be singular if the training patterns happen to\nlie on a subspace of the whole n-dimensional spaceas they certainly will, for\nexample, if the number of training patterns is less than n.)\n5.1.3 Conditionally Independent Binary Components\nSuppose the vector X is a random variable having binary (0,1) components.\nWe continue to denote the two probability distributions by p(X |1) and p(X |\n2). Further suppose that the components of these vectors are conditionally\nindependent given the category. By conditional independence in this case, we\nmean that the formulas for the distribution can be expanded as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 77, 'page_label': '78'}, page_content='5.1. USING STATISTICAL DECISION THEORY 69\np(X |i) = p(x1 |i)p(x2 |i) ···p(xn |i)\nfor i= 1,2\nRecall the minimum-average-loss decision rule,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nAssuming conditional independence of the components and that \u03bb(1 |2) = \u03bb(2 |\n1), we obtain,\nDecide category 1 i\ufb00:\np(1)p(x1 |1)p(x2 |1) ···p(xn |1) \u2265p(x1 |2)p(x2 |2) ···p(xn |2)p(2)\nor i\ufb00:\np(x1 |1)p(x2 |1) ...p (xn |1)\np(x1 |2)p(x2 |2) ...p (xn |2) \u2265p(2)\np(1)\nor i\ufb00:\nlog p(x1 |1)\np(x1 |2) + log p(x2 |1)\np(x2 |2) + ··· + log p(xn |1)\np(xn |2) + log p(1)\np(2) \u22650\nLet us de\ufb01ne values of the components of the distribution for speci\ufb01c values of\ntheir arguments, xi :\np(xi = 1 |1) = pi\np(xi = 0 |1) = 1 \u2212pi\np(xi = 1 |2) = qi\np(xi = 0 |2) = 1 \u2212qi\nNow, we note that since xi can only assume the values of 1 or 0:\nlog p(xi |1)\np(xi |2) = xilog pi\nqi\n+ (1 \u2212xi) log (1 \u2212pi)\n(1 \u2212qi)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 78, 'page_label': '79'}, page_content='70 CHAPTER 5. STATISTICAL LEARNING\n= xilog pi(1 \u2212qi)\nqi(1 \u2212pi) + log (1 \u2212pi)\n(1 \u2212qi)\nSubstituting these expressions into our decision rule yields:\nDecide category 1 i\ufb00:\nn\u2211\ni=1\nxilog pi(1 \u2212qi)\nqi(1 \u2212pi) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi) + log p(1)\np(2) \u22650\nWe see that we can achieve this decision with a TLU with weight values as\nfollows:\nwi = log pi(1 \u2212qi)\nqi(1 \u2212pi)\nfor i= 1,...,n , and\nwn+1 = log p(1)\n1 \u2212p(1) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi)\nIf we do not know the pi,qi and p(1), we can use a sample of labeled training\npatterns to estimate these parameters.\n5.2 Learning Belief Networks\nTo be added.\n5.3 Nearest-Neighbor Methods\nAnother class of methods can be related to the statistical ones. These are called\nnearest-neighbor methods or, sometimes, memory-based methods. (A collection\nof papers on this subject is in [Dasarathy, 1991].) Given a training set \u039e of m\nlabeled patterns, a nearest-neighbor procedure decides that some new pattern,\nX, belongs to the same category as do its closest neighbors in \u039e. More precisely,\na k-nearest-neighbor method assigns a new pattern,X, to that category to which\nthe plurality of its k closest neighbors belong. Using relatively large values of\nk decreases the chance that the decision will be unduly in\ufb02uenced by a noisy\ntraining pattern close to X. But large values of k also reduce the acuity of the\nmethod. The k-nearest-neighbor method can be thought of as estimating the\nvalues of the probabilities of the classes given X. Of course the denser are the\npoints around X, and the larger the value of k, the better the estimate.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 79, 'page_label': '80'}, page_content='5.3. NEAREST-NEIGHBOR METHODS 71\nThe distance metric used in nearest-neighbor methods (for numerical at-\ntributes) can be simple Euclidean distance. That is, the distance between two\npatterns (x11,x12,...,x 1n) and (x21,x22,...,x 2n) is\n\u221a\u2211n\nj=1(x1j \u2212x2j)2. This\ndistance measure is often modi\ufb01ed by scaling the features so that the spread of\nattribute values along each dimension is approximately the same. In that case,\nthe distance between the two vectors would be\n\u221a\u2211n\nj=1 a2\nj(x1j \u2212x2j)2, where\naj is the scale factor for dimension j.\nAn example of a nearest-neighbor decision problem is shown in Fig. 5.3. In\nthe \ufb01gure the class of a training pattern is indicated by the number next to it.\nk = 8\nX (a pattern to be classified)\n1\n1\n1 1\n1\n11\n1\n2\n1\n2\n2\n2\n2\n2\n2 2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\ntraining patternclass of training pattern\nfour patterns of category 1\ntwo patterns of category 2\ntwo patterns of category 3\nplurality are in category 1, so\ndecide X is in category 1\nFigure 5.3: An 8-Nearest-Neighbor Decision\nSee [Baum, 1994] for theoretical\nanalysis of error rate as a function\nof the number of training patterns\nfor the case in which points are\nrandomly distributed on the surface\nof a unit sphere and underlying\nfunction is linearly separable.\nNearest-neighbor methods are memory intensive because a large number of\ntraining patterns must be stored to achieve good generalization. Since memory\ncost is now reasonably low, the method and its derivatives have seen several\npractical applications. (See, for example, [Moore, 1992, Moore, et al., 1994].\nAlso, the distance calculations required to \ufb01nd nearest neighbors can often be\ne\ufb03ciently computed by kd-tree methods [Friedman, et al., 1977].\nA theorem by Cover and Hart [Cover & Hart, 1967] relates the performance\nof the 1-nearest-neighbor method to the performance of a minimum-probability-\nof-error classi\ufb01er. As mentioned earlier, the minimum-probability-of-error clas-\nsi\ufb01er would assign a new patternX to that category that maximizedp(i)p(X |i),\nwhere p(i) is the a priori probability of categoryi, and p(X |i) is the probability\n(or probability density function) of X given that X belongs to category i, for\ncategories i= 1,...,R . Suppose the probability of error in classifying patterns\nof such a minimum-probability-of-error classi\ufb01er is \u03b5. The Cover-Hart theo-\nrem states that under very mild conditions (having to do with the smoothness'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 80, 'page_label': '81'}, page_content='72 CHAPTER 5. STATISTICAL LEARNING\nof probability density functions) the probability of error, \u03b5nn, of a 1-nearest-\nneighbor classi\ufb01er is bounded by:\n\u03b5\u2264\u03b5nn \u2264\u03b5\n(\n2 \u2212\u03b5 R\nR\u22121\n)\n\u22642\u03b5\nwhere R is the number of categories.Also see [Aha, 1991].\n5.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 81, 'page_label': '82'}, page_content='Chapter 6\nDecision Trees\n6.1 De\ufb01nitions\nA decision tree (generally de\ufb01ned) is a tree whose internal nodes are tests (on\ninput patterns) and whose leaf nodes are categories (of patterns). We show an\nexample in Fig. 6.1. A decision tree assigns a class number (or output) to an\ninput pattern by \ufb01ltering the pattern down through the tests in the tree. Each\ntest has mutually exclusive and exhaustive outcomes. For example, test T2 in\nthe tree of Fig. 6.1 has three outcomes; the left-most one assigns the input\npattern to class 3, the middle one sends the input pattern down to test T4, and\nthe right-most one assigns the pattern to class 1. We follow the usual convention\nof depicting the leaf nodes by the class number.1 Note that in discussing decision\ntrees we are not limited to implementing Boolean functionsthey are useful for\ngeneral, categorically valued functions.\nThere are several dimensions along which decision trees might di\ufb00er:\na. The tests might be multivariate (testing on several features of the input\nat once) or univariate (testing on only one of the features).\nb. The tests might have two outcomes or more than two. (If all of the tests\nhave two outcomes, we have a binary decision tree.)\nc. The features or attributes might be categorical or numeric. (Binary-valued\nones can be regarded as either.)\n1One of the researchers who has done a lot of work on learning decision trees is Ross\nQuinlan. Quinlan distinguishes between classes and categories. He calls the subsets of patterns\nthat \ufb01lter down to each tip categories and subsets of patterns having the same label classes.\nIn Quinlans terminology, our example tree has nine categories and three classes. We will not\nmake this distinction, however, but will use the words category and class interchangeably\nto refer to what Quinlan calls class.\n73'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 82, 'page_label': '83'}, page_content='74 CHAPTER 6. DECISION TREES\nT1\nT2 T3\nT4\nT4\nT4\n3\n1\n3 2\n1 2 3\n2 1\nFigure 6.1: A Decision Tree\nd. We might have two classes or more than two. If we have two classes and\nbinary inputs, the tree implements a Boolean function, and is called a\nBoolean decision tree.\nIt is straightforward to represent the function implemented by a univariate\nBoolean decision tree in DNF form. The DNF form implemented by such a tree\ncan be obtained by tracing down each path leading to a tip node corresponding\nto an output value of 1, forming the conjunction of the tests along this path,\nand then taking the disjunction of these conjunctions. We show an example in\nFig. 6.2. In drawing univariate decision trees, each non-leaf node is depicted by\na single attribute. If the attribute has value 0 in the input pattern, we branch\nleft; if it has value 1, we branch right.\nThe k-DL class of Boolean functions can be implemented by a multivariate\ndecision tree having the (highly unbalanced) form shown in Fig. 6.3. Each test,\nci, is a term of size k or less. The vi all have values of 0 or 1.\n6.2 Supervised Learning of Univariate Decision\nTrees\nSeveral systems for learning decision trees have been proposed. Prominent\namong these are ID3 and its new version, C4.5 [Quinlan, 1986, Quinlan, 1993],\nand CART [Breiman, et al., 1984] We discuss here only batch methods, al-\nthough incremental ones have also been proposed [Utgo\ufb00, 1989].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 83, 'page_label': '84'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES75\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.2: A Decision Tree Implementing a DNF Function\n6.2.1 Selecting the Type of Test\nAs usual, we have n features or attributes. If the attributes are binary, the\ntests are simply whether the attributes value is 0 or 1. If the attributes are\ncategorical, but non-binary, the tests might be formed by dividing the attribute\nvalues into mutually exclusive and exhaustive subsets. A decision tree with such\ntests is shown in Fig. 6.4. If the attributes are numeric, the tests might involve\ninterval tests, for example 7 \u2264xi \u226413.2.\n6.2.2 Using Uncertainty Reduction to Select Tests\nThe main problem in learning decision trees for the binary-attribute case is\nselecting the order of the tests. For categorical and numeric attributes, we\nmust also decide what the tests should be (besides selecting the order). Several\ntechniques have been tried; the most popular one is at each stage to select that\ntest that maximally reduces an entropy-like measure.\nWe show how this technique works for the simple case of tests with binary\noutcomes. Extension to multiple-outcome tests is straightforward computation-\nally but gives poor results because entropy is always decreased by having more\noutcomes.\nThe entropy or uncertainty still remaining about the class of a pattern\nknowing that it is in some set, \u039e, of patterns is de\ufb01ned as:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 84, 'page_label': '85'}, page_content='76 CHAPTER 6. DECISION TREES\ncq\ncq-1\nci\n1\nvn\nvn-1\nvi\nv1\nFigure 6.3: A Decision Tree Implementing a Decision List\nwhere p(i|\u039e) is the probability that a pattern drawn at random from \u039e belongs\nto class i, and the summation is over all of the classes. We want to select tests at\neach node such that as we travel down the decision tree, the uncertainty about\nthe class of a pattern becomes less and less.\nSince we do not in general have the probabilitiesp(i|\u039e), we estimate them by\nsample statistics. Although these estimates might be errorful, they are never-\ntheless useful in estimating uncertainties. Let p(i|\u039e) be the number of patterns\nin \u039e belonging to class idivided by the total number of patterns in \u039e. Then an\nestimate of the uncertainty is:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)\nFor simplicity, from now on well drop the hats and use sample statistics as\nif they were real probabilities.\nIf we perform a test, T, having k possible outcomes on the patterns in \u039e, we\nwill create ksubsets, \u039e1,\u039e2,..., \u039ek. Suppose that ni of the patterns in \u039e are in\n\u039ei for i= 1,...,k . (Some ni may be 0.) If we knew that T applied to a pattern\nin \u039e resulted in the j-th outcome (that is, we knew that the pattern was in \u039e j),\nthe uncertainty about its class would be:\nH(\u039ej) = \u2212\n\u2211\ni\np(i|\u039ej) log2 p(i|\u039ej)\nand the reduction in uncertainty (beyond knowing only that the pattern was in\n\u039e) would be:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 85, 'page_label': '86'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES77\nx3 = a, b, c, or d \n{a, c} {b}\nx1 = e, b, or d \n{e,b} {d}\nx4 = a, e, f, or g\n{a, g} {e, f}\nx2 = a, or g\n{a} {g}\n1\n2 1\n1 2\n{d}\n2\nFigure 6.4: A Decision Tree with Categorical Attributes\nH(\u039e) \u2212H(\u039ej)\nOf course we cannot say that the test T is guaranteed always to produce that\namount of reduction in uncertainty because we dont know that the result of\nthe test will be the j-th outcome. But we can estimate the average uncertainty\nover all the \u039ej, by:\nE[HT(\u039e)] =\n\u2211\nj\np(\u039ej)H(\u039ej)\nwhere by HT(\u039e) we mean the average uncertainty after performing test T on\nthe patterns in \u039e, p(\u039ej) is the probability that the test has outcome j, and the\nsum is taken from 1 to k. Again, we dont know the probabilities p(\u039ej), but we\ncan use sample values. The estimate p(\u039ej) of p(\u039ej) is just the number of those\npatterns in \u039e that have outcome j divided by the total number of patterns in\n\u039e. The average reduction in uncertainty achieved by test T (applied to patterns\nin \u039e) is then:\nRT(\u039e) = H(\u039e) \u2212E[HT(\u039e)]\nAn important family of decision tree learning algorithms selects for the root\nof the tree that test that gives maximum reduction of uncertainty, and then\napplies this criterion recursively until some termination condition is met (which\nwe shall discuss in more detail later). The uncertainty calculations are particu-\nlarly simple when the tests have binary outcomes and when the attributes have'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 86, 'page_label': '87'}, page_content='78 CHAPTER 6. DECISION TREES\nbinary values. Well give a simple example to illustrate how the test selection\nmechanism works in that case.\nSuppose we want to use the uncertainty-reduction method to build a decision\ntree to classify the following patterns:\npattern class\n(0, 0, 0) 0\n(0, 0, 1) 0\n(0, 1, 0) 0\n(0, 1, 1) 0\n(1, 0, 0) 0\n(1, 0, 1) 1\n(1, 1, 0) 0\n(1, 1, 1) 1\nWhat single test, x1, x2, or x3, should be performed \ufb01rst? The illustration in\nFig. 6.5 gives geometric intuition about the problem.\nx1\nx2\nx3\nThe test x1\nFigure 6.5: Eight Patterns to be Classi\ufb01ed by a Decision Tree\nThe initial uncertainty for the set, \u039e, containing all eight points is:\nH(\u039e) = \u2212(6/8) log2(6/8) \u2212(2/8) log2(2/8) = 0.81\nNext, we calculate the uncertainty reduction if we perform x1 \ufb01rst. The left-\nhand branch has only patterns belonging to class 0 (we call them the set \u039el), and\nthe right-hand-branch (\u039er) has two patterns in each class. So, the uncertainty\nof the left-hand branch is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 87, 'page_label': '88'}, page_content='6.3. NETWORKS EQUIVALENT TO DECISION TREES 79\nHx1 (\u039el) = \u2212(4/4) log2(4/4) \u2212(0/4) log2(0/4) = 0\nAnd the uncertainty of the right-hand branch is:\nHx1 (\u039er) = \u2212(2/4) log2(2/4) \u2212(2/4) log2(2/4) = 1\nHalf of the patterns go left and half go right on test x1. Thus, the average\nuncertainty after performing the x1 test is:\n1/2Hx1 (\u039el) + 1/2Hx1 (\u039er) = 0.5\nTherefore the uncertainty reduction on \u039e achieved by x1 is:\nRx1 (\u039e) = 0.81 \u22120.5 = 0.31\nBy similar calculations, we see that the test x3 achieves exactly the same\nuncertainty reduction, but x2 achieves no reduction whatsoever. Thus, our\ngreedy algorithm for selecting a \ufb01rst test would select eitherx1 or x3. Suppose\nx1 is selected. The uncertainty-reduction procedure would select x3 as the next\ntest. The decision tree that this procedure creates thus implements the Boolean\nfunction: f = x1x3. See [Quinlan, 1986, sect. 4] for\nanother example.\n6.2.3 Non-Binary Attributes\nIf the attributes are non-binary, we can still use the uncertainty-reduction tech-\nnique to select tests. But now, in addition to selecting an attribute, we must\nselect a test on that attribute. Suppose for example that the value of an at-\ntribute is a real number and that the test to be performed is to set a threshold\nand to test to see if the number is greater than or less than that threshold. In\nprinciple, given a set of labeled patterns, we can measure the uncertainty reduc-\ntion for each test that is achieved by every possible threshold (there are only\na \ufb01nite number of thresholds that give di\ufb00erent test results if there are only\na \ufb01nite number of training patterns). Similarly, if an attribute is categorical\n(with a \ufb01nite number of categories), there are only a \ufb01nite number of mutually\nexclusive and exhaustive subsets into which the values of the attribute can be\nsplit. We can calculate the uncertainty reduction for each split.\n6.3 Networks Equivalent to Decision Trees\nSince univariate Boolean decision trees are implementations of DNF functions,\nthey are also equivalent to two-layer, feedforward neural networks. We show\nan example in Fig. 6.6. The decision tree at the left of the \ufb01gure implements'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 88, 'page_label': '89'}, page_content='80 CHAPTER 6. DECISION TREES\nthe same function as the network at the right of the \ufb01gure. Of course, when\nimplemented as a network, all of the features are evaluated in parallel for any\ninput pattern, whereas when implemented as a decision tree only those features\non the branch traveled down by the input pattern need to be evaluated. The\ndecision-tree induction methods discussed in this chapter can thus be thought of\nas particular ways to establish the structure and the weight values for networks.\nX\nx1\nx2\nx3\nx4\nterms\n-1\n+1\ndisjunction\nx3x2\nx3x4x1\n+1\n-1\n+1\nf\n1.5\n0.5\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.6: A Univariate Decision Tree and its Equivalent Network\nMultivariate decision trees with linearly separable functions at each node can\nalso be implemented by feedforward networksin this case three-layer ones. We\nshow an example in Fig. 6.7 in which the linearly separable functions, each im-\nplemented by a TLU, are indicated by L1,L2,L3, and L4. Again, the \ufb01nal layer\nhas \ufb01xed weights, but the weights in the \ufb01rst two layers must be trained. Dif-\nferent approaches to training procedures have been discussed by [Brent, 1990],\nby [John, 1995], and (for a special case) by [Marchand & Golea, 1993].\n6.4 Over\ufb01tting and Evaluation\n6.4.1 Over\ufb01tting\nIn supervised learning, we must choose a function to \ufb01t the training set from\namong a set of hypotheses. We have already showed that generalization is\nimpossible without bias. When we know a priori that the function we are\ntrying to guess belongs to a small subset of all possible functions, then, even\nwith an incomplete set of training samples, it is possible to reduce the subset\nof functions that are consistent with the training set su\ufb03ciently to make useful\nguesses about the value of the function for inputs not in the training set. And,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 89, 'page_label': '90'}, page_content='6.4. OVERFITTING AND EVALUATION 81\nL1\nL2 L3\nL4\n10\n1\n1\n0 0\n0\n1\n1\n0\n0\n1 0\nX\nL1\nL2\nL3\nL4\nconjunctions\nL1L2\nL1 L3 L4\n<\n+\n++\ndisjunction\n<\nf\nFigure 6.7: A Multivariate Decision Tree and its Equivalent Network\nthe larger the training set, the more likely it is that even a randomly selected\nconsistent function will have appropriate outputs for patterns not yet seen.\nHowever, even with bias, if the training set is not su\ufb03ciently large compared\nwith the size of the hypothesis space, there will still be too many consistent\nfunctions for us to make useful guesses, and generalization performance will be\npoor. When there are too many hypotheses that are consistent with the training\nset, we say that we are over\ufb01tting the training data. Over\ufb01tting is a problem\nthat we must address for all learning methods.\nSince a decision tree of su\ufb03cient size can implement any Boolean function\nthere is a danger of over\ufb01ttingespecially if the training set is small. That\nis, even if the decision tree is synthesized to classify all the members of the\ntraining set correctly, it might perform poorly on new patterns that were not\nused to build the decision tree. Several techniques have been proposed to avoid\nover\ufb01tting, and we shall examine some of them here. They make use of methods\nfor estimating how well a given decision tree might generalizemethods we shall\ndescribe next.\n6.4.2 Validation Methods\nThe most straightforward way to estimate how well a hypothesized function\n(such as a decision tree) performs on a test set is to test it on the test set! But,\nif we are comparing several learning systems (for example, if we are comparing\ndi\ufb00erent decision trees) so that we can select the one that performs the best on\nthe test set, then such a comparison amounts to training on the test data.\nTrue, training on the test data enlarges the training set, with a consequent ex-\npected improvement in generalization, but there is still the danger of over\ufb01tting\nif we are comparing several di\ufb00erent learning systems. Another technique is to'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 90, 'page_label': '91'}, page_content='82 CHAPTER 6. DECISION TREES\nsplit the training setusing (say) two-thirds for training and the other third\nfor estimating generalization performance. But splitting reduces the size of the\ntraining set and thereby increases the possibility of over\ufb01tting. We next describe\nsome validation techniques that attempt to avoid these problems.\nCross-Validation\nIn cross-validation, we divide the training set \u039e into K mutually exclusive and\nexhaustive equal-sized subsets: \u039e 1,..., \u039eK. For each subset, \u039e i, train on the\nunion of all of the other subsets, and empirically determine the error rate, \u03b5i,\non \u039ei. (The error rate is the number of classi\ufb01cation errors made on \u039e i divided\nby the number of patterns in \u039e i.) An estimate of the error rate that can be\nexpected on new patterns of a classi\ufb01er trained on all the patterns in \u039e is then\nthe average of the \u03b5i.\nLeave-one-out Validation\nLeave-one-out validation is the same as cross validation for the special case in\nwhich K equals the number of patterns in \u039e, and each \u039e i consists of a single\npattern. When testing on each \u039e i, we simply note whether or not a mistake\nwas made. We count the total number of mistakes and divide by K to get\nthe estimated error rate. This type of validation is, of course, more expensive\ncomputationally, but useful when a more accurate estimate of the error rate for\na classi\ufb01er is needed.Describe bootstrapping also\n[Efron, 1982].\n6.4.3 Avoiding Over\ufb01tting in Decision Trees\nNear the tips of a decision tree there may be only a few patterns per node.\nFor these nodes, we are selecting a test based on a very small sample, and thus\nwe are likely to be over\ufb01tting. This problem can be dealt with by terminating\nthe test-generating procedure before all patterns are perfectly split into their\nseparate categories. That is, a leaf node may contain patterns of more than one\nclass, but we can decide in favor of the most numerous class. This procedure\nwill result in a few errors but often accepting a small number of errors on the\ntraining set results in fewer errors on a testing set.\nThis behavior is illustrated in Fig. 6.8.\nOne can use cross-validation techniques to determine when to stop splitting\nnodes. If the cross validation error increases as a consequence of a node split,\nthen dont split. One has to be careful about when to stop, though, because\nunder\ufb01tting usually leads to more errors on test sets than does over\ufb01tting. There\nis a general rule that the lowest error-rate attainable by a sub-tree of a fully\nexpanded tree can be no less than 1/2 of the error rate of the fully expanded\ntree [Weiss & Kulikowski, 1991, page 126].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 91, 'page_label': '92'}, page_content='6.4. OVERFITTING AND EVALUATION 83\n(From Weiss, S., and Kulikowski, C., Computer Systems that Learn,\nMorgan Kaufmann, 1991)\ntraining errors\nvalidation errors\n1 2 34 5 6 78 9\n0.2\n0.4\n0.6\n0.8\n1.0\n0\n0\nError Rate\nNumber of Terminal\nNodes\nIris Data Decision Tree\nFigure 6.8: Determining When Over\ufb01tting Begins\nRather than stopping the growth of a decision tree, one might grow it to\nits full size and then prune away leaf nodes and their ancestors until cross-\nvalidation accuracy no longer increases. This technique is called post-pruning.\nVarious techniques for pruning are discussed in [Weiss & Kulikowski, 1991].\n6.4.4 Minimum-Description Length Methods\nAn important tree-growing and pruning technique is based on the minimum-\ndescription-length (MDL) principle. (MDL is an important idea that extends\nbeyond decision-tree methods [Rissanen, 1978].) The idea is that the simplest\ndecision tree that can predict the classes of the training patterns is the best\none. Consider the problem of transmitting just the labels of a training set of\npatterns, assuming that the receiver of this information already has the ordered\nset of patterns. If there are m patterns, each labeled by one of R classes,\none could transmit a list of m R-valued numbers. Assuming equally probable\nclasses, this transmission would require mlog2 Rbits. Or, one could transmit a\ndecision tree that correctly labelled all of the patterns. The number of bits that\nthis transmission would require depends on the technique for encoding decision\ntrees and on the size of the tree. If the tree is small and accurately classi\ufb01es\nall of the patterns, it might be more economical to transmit the tree than to\ntransmit the labels directly. In between these extremes, we might transmit a\ntree plus a list of labels of all the patterns that the tree misclassi\ufb01es.\nIn general, the number of bits (or description length of the binary encoded\nmessage) is t+ d, where t is the length of the message required to transmit\nthe tree, and d is the length of the message required to transmit the labels of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 92, 'page_label': '93'}, page_content='84 CHAPTER 6. DECISION TREES\nthe patterns misclassi\ufb01ed by the tree. In a sense, that tree associated with the\nsmallest value of t+ d is the best or most economical tree. The MDL method\nis one way of adhering to the Occams razor principle.\nQuinlan and Rivest [Quinlan & Rivest, 1989] have proposed techniques for\nencoding decision trees and lists of exception labels and for calculating the\ndescription length (t+d) of these trees and labels. They then use the description\nlength as a measure of quality of a tree in two ways:\na. In growing a tree, they use the reduction in description length to select\ntests (instead of reduction in uncertainty).\nb. In pruning a tree after it has been grown to zero error, they prune away\nthose nodes (starting at the tips) that achieve a decrease in the description\nlength.\nThese techniques compare favorably with the uncertainty-reduction method,\nalthough they are quite sensitive to the coding schemes used.\n6.4.5 Noise in Data\nNoise in the data means that one must inevitably accept some number of\nerrorsdepending on the noise level. Refusal to tolerate errors on the training\nset when there is noise leads to the problem of \ufb01tting the noise. Dealing with\nnoise, then, requires accepting some errors at the leaf nodes just as does the\nfact that there are a small number of patterns at leaf nodes.\n6.5 The Problem of Replicated Subtrees\nDecision trees are not the most economical means of implementing some Boolean\nfunctions. Consider, for example, the function f = x1x2 +x3x4. A decision tree\nfor this function is shown in Fig. 6.9. Notice the replicated subtrees shown\ncircled. The DNF-form equivalent to the function implemented by this decision\ntree is f = x1x2 + x1x2x3x4 + x1x3x4. This DNF form is non-minimal (in the\nnumber of disjunctions) and is equivalent to f = x1x2 + x3x4.\nThe need for replication means that it takes longer to learn the tree and\nthat subtrees replicated further down the tree must be learned using a smaller\ntraining subset. This problem is sometimes called the fragmentation problem.\nSeveral approaches might be suggested for dealing with fragmenta-\ntion. One is to attempt to build a decision graph instead of a tree\n[Oliver, Dowe, & Wallace, 1992, Kohavi, 1994]. A decision graph that imple-\nments the same decisions as that of the decision tree of Fig. 6.9 is shown in Fig.\n6.10.\nAnother approach is to use multivariate (rather than univariate tests at each\nnode). In our example of learning f = x1x2 + x3x4, if we had a test for x1x2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 93, 'page_label': '94'}, page_content='6.6. THE PROBLEM OF MISSING ATTRIBUTES 85\nx1\nx3 x2\n10\nx4\n0 1\nx3\n0\nx4\n0 1\nFigure 6.9: A Decision Tree with Subtree Replication\nand a test for x3x4, the decision tree could be much simpli\ufb01ed, as shown in Fig.\n6.11. Several researchers have proposed techniques for learning decision trees in\nwhich the tests at each node are linearly separable functions. [John, 1995] gives\na nice overview (with several citations) of learning suchlinear discriminant trees\nand presents a method based on soft entropy.\nA third method for dealing with the replicated subtree problem involves ex-\ntracting propositional rules from the decision tree. The rules will have as an-\ntecedents the conjunctions that lead down to the leaf nodes, and as consequents\nthe name of the class at the corresponding leaf node. An example rule from the\ntree with the repeating subtree of our example would be: x1 \u2227¬x2 \u2227x3 \u2227x4 \u22831.\nQuinlan [Quinlan, 1987] discusses methods for reducing a set of rules to a sim-\npler set by 1) eliminating from the antecedent of each rule any unnecessary\nconjuncts, and then 2) eliminating unnecessary rules. A conjunct or rule is\ndetermined to be unnecessary if its elimination has little e\ufb00ect on classi\ufb01cation\naccuracyas determined by a chi-square test, for example. After a rule set is\nprocessed, it might be the case that more than one rule is active for any given\npattern, and care must be taken that the active rules do not con\ufb02ict in their\ndecision about the class of a pattern.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 94, 'page_label': '95'}, page_content='86 CHAPTER 6. DECISION TREES\nx1\nx3\nx2\n1\n0\nx4\n0 1\nFigure 6.10: A Decision Graph\n6.6 The Problem of Missing Attributes\nTo be added.\n6.7 Comparisons\nSeveral experimenters have compared decision-tree, neural-net, and nearest-\nneighbor classi\ufb01ers on a wide variety of problems. For a comparison of\nneural nets versus decision trees, for example, see [Dietterich, et al., 1990,\nShavlik, Mooney, & Towell, 1991, Quinlan, 1994]. In their StatLog project,\n[Taylor, Michie, & Spiegalhalter, 1994] give thorough comparisons of several\nmachine learning algorithms on several di\ufb00erent types of problems. There seems\nx1x2\n1\n0\nx3x4\n1\nFigure 6.11: A Multivariate Decision Tree'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 95, 'page_label': '96'}, page_content='6.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 87\nto be no single type of classi\ufb01er that is best for all problems. And, there do\nnot seem to be any general conclusions that would enable one to say which\nclassi\ufb01er method is best for which sorts of classi\ufb01cation problems, although\n[Quinlan, 1994] does provide some intuition about properties of problems that\nmight render them ill suited for decision trees, on the one hand, or backpropa-\ngation, on the other.\n6.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 96, 'page_label': '97'}, page_content='88 CHAPTER 6. DECISION TREES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 97, 'page_label': '98'}, page_content='Chapter 7\nInductive Logic\nProgramming\nThere are many di\ufb00erent representational forms for functions of input vari-\nables. So far, we have seen (Boolean) algebraic expressions, decision trees, and\nneural networks, plus other computational mechanisms such as techniques for\ncomputing nearest neighbors. Of course, the representation most important\nin computer science is a computer program. For example, a Lisp predicate of\nbinary-valued inputs computes a Boolean function of those inputs. Similarly, a\nlogic program (whose ordinary application is to compute bindings for variables)\ncan also be used simply to decide whether or not a predicate has value True\n(T) or False (F). For example, the Boolean exclusive-or (odd parity) function\nof two variables can be computed by the following logic program:\nParity(x,y) :- True(x), ¬ True(y)\n:- True(y), ¬ True(x)\nWe follow Prolog syntax (see, for example, [Mueller & Page, 1988]), except that\nour convention is to write variables as strings beginning with lower-case letters\nand predicates as strings beginning with upper-case letters. The unary function\nTrue returns T if and only if the value of its argument is T. (We now think\nof Boolean functions and arguments as having values of T and F instead of 0\nand 1.) Programs will be written in  typewriter font.\nIn this chapter, we consider the matter of learning logic programs given\na set of variable values for which the logic program should return T (the\npositive instances ) and a set of variable values for which it should return\nF (the negative instances). The subspecialty of machine learning that deals\nwith learning logic programs is called inductive logic programming (ILP)\n[Lavra\u02c7 c & D\u02c7 zeroski, 1994]. As with any learning problem, this one can be quite\ncomplex and intractably di\ufb03cult unless we constrain it with biases of some sort.\n89'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 98, 'page_label': '99'}, page_content='90 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nIn ILP, there are a variety of possible biases (calledlanguage biases). One might\nrestrict the program to Horn clauses, not allow recursion, not allow functions,\nand so on.\nAs an example of an ILP problem, suppose we are trying to induce a func-\ntion Nonstop(x,y), that is to have value T for pairs of cities connected by a\nnon-stop air \ufb02ight and F for all other pairs of cities. We are given a training set\nconsisting of positive and negative examples. As positive examples, we might\nhave (A,B), (A, A1), and some other pairs; as negative examples, we might\nhave (A1, A2), and some other pairs. In ILP, we usually have additional infor-\nmation about the examples, called background knowledge. In our air-\ufb02ight\nproblem, the background information might be such ground facts as Hub(A),\nHub(B), Satellite(A1,A), plus others. ( Hub(A) is intended to mean that the\ncity denoted by A is a hub city, and Satellite(A1,A) is intended to mean that\nthe city denoted by A1 is a satellite of the city denoted by A.) From these train-\ning facts, we want to induce a program Nonstop(x,y), written in terms of the\nbackground relations Hub and Satellite, that has value T for all the positive\ninstances and has value F for all the negative instances. Depending on the exact\nset of examples, we might induce the program:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nwhich would have value T if both of the two cities were hub cities or if one were\na satellite of the other. As with other learning problems, we want the induced\nprogram to generalize well; that is, if presented with arguments not represented\nin the training set (but for which we have the needed background knowledge),\nwe would like the function to guess well.\n7.1 Notation and De\ufb01nitions\nIn evaluating logic programs in ILP, we implicitly append the background facts\nto the program and adopt the usual convention that a program has value T for\na set of inputs if and only if the program interpreter returns T when actually\nrunning the program (with background facts appended) on those inputs; oth-\nerwise it has value F. Using the given background facts, the program above\nwould return T for input (A, A1), for example. If a logic program, \u03c0, returns\nT for a set of arguments X, we say that the program covers the arguments and\nwrite covers(\u03c0,X). Following our terminology introduced in connection with\nversion spaces, we will say that a program is su\ufb03cient if it covers all of the\npositive instances and that it is necessary if it does not cover any of the neg-\native instances. (That is, a program implements a su\ufb03cient condition that a\ntraining instance is positive if it covers all of the positive training instances; it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 99, 'page_label': '100'}, page_content='7.2. A GENERIC ILP ALGORITHM 91\nimplements a necessary condition if it covers none of the negative instances.) In\nthe noiseless case, we want to induce a program that is both su\ufb03cient and nec-\nessary, in which case we will call it consistent. With imperfect (noisy) training\nsets, we might relax this criterion and settle for a program that covers all but\nsome fraction of the positive instances while allowing it to cover some fraction\nof the negative instances. We illustrate these de\ufb01nitions schematically in Fig.\n7.1.\n<\n<\n<\n<<\n<\n<\n/1 is a necessary program\n/2 is a sufficient program\n/3 is a consistent program\n+\n+\n+\n+\n+ +\n+\n+\n+\n+\n<\n<\nA positive instance\n covered by /2 and /3\nFigure 7.1: Su\ufb03cient, Necessary, and Consistent Programs\nAs in version spaces, if a program is su\ufb03cient but not necessary it can be\nmade to cover fewer examples by specializing it. Conversely, if it is necessary\nbut not su\ufb03cient, it can be made to cover more examples by generalizing it.\nSuppose we are attempting to induce a logic program to compute the relation\n\u03c1. The most general logic program, which is certainly su\ufb03cient, is the one that\nhas value T for all inputs, namely a single clause with an empty body, [ \u03c1 :-\n], which is called a fact in Prolog. The most special logic program, which is\ncertainly necessary, is the one that has value F for all inputs, namely [ \u03c1 :-\nF ]. Two of the many di\ufb00erent ways to search for a consistent logic program\nare: 1) start with [ \u03c1 :- ] and specialize until the program is consistent, or 2)\nstart with [ \u03c1 :- F ] and generalize until the program is consistent. We will\nbe discussing a method that starts with [ \u03c1 :- ], specializes until the program\nis necessary (but might no longer be su\ufb03cient), then reachieves su\ufb03ciency in\nstages by generalizingensuring within each stage that the program remains\nnecessary (by specializing).\n7.2 A Generic ILP Algorithm\nSince the primary operators in our search for a consistent program are special-\nization and generalization, we must next discuss those operations. There are'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 100, 'page_label': '101'}, page_content='92 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nthree major ways in which a logic program might be generalized:\na. Replace some terms in a program clause by variables. (Readers familiar\nwith substitutions in the predicate calculus will note that this process is\nthe inverse of substitution.)\nb. Remove literals from the body of a clause.\nc. Add a clause to the program\nAnalogously, there are three ways in which a logic program might be specialized:\na. Replace some variables in a program clause by terms (a substitution).\nb. Add literals to the body of a clause.\nc. Remove a clause from the program\nWe will be presenting an ILP learning method that adds clauses to a program\nwhen generalizing and that adds literals to the body of a clause when special-\nizing. When we add a clause, we will always add the clause [ \u03c1 :- ] and then\nspecialize it by adding literals to the body. Thus, we need only describe the\nprocess for adding literals.\nClauses can be partially ordered by the specialization relation. In general,\nclause c1 is more special than clause c2 if c2 |= c1. A special case, which is what\nwe use here, is that a clause c1 is more special than a clause c2 if the set of\nliterals in the body of c2 is a subset of those in c1. This ordering relation can\nbe used in a structure of partially ordered clauses, called the re\ufb01nement graph,\nthat is similar to a version space. Clause c1 is an immediate successor of clause\nc2 in this graph if and only if clause c1 can be obtained from clause c2 by adding\na literal to the body of c2. A re\ufb01nement graph then tells us the ways in which\nwe can specialize a clause by adding a literal to it.\nOf course there are unlimited possible literals we might add to the body of\na clause. Practical ILP systems restrict the literals in various ways. Typical\nallowed additions are:\na. Literals used in the background knowledge.\nb. Literals whose arguments are a subset of those in the head of the clause.\nc. Literals that introduce a new distinct variable di\ufb00erent from those in the\nhead of the clause.\nd. A literal that equates a variable in the head of the clause with another\nsuch variable or with a term mentioned in the background knowledge.\n(This possibility is equivalent to forming a specialization by making a\nsubstitution.)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 101, 'page_label': '102'}, page_content='7.2. A GENERIC ILP ALGORITHM 93\ne. A literal that is the same (except for its arguments) as that in the head\nof the clause. (This possibility admits recursive programs, which are dis-\nallowed in some systems.)\nWe can illustrate these possibilities using our air-\ufb02ight example. We start\nwith the program [ Nonstop(x,y) :- ]. The literals used in the background\nknowledge are Hub and Satellite. Thus the literals that we might consider\nadding are:\nHub(x)\nHub(y)\nHub(z)\nSatellite(x,y)\nSatellite(y,x)\nSatellite(x,z)\nSatellite(z,y)\n(x = y)\n(If recursive programs are allowed, we could also add the literals Nonstop(x,z)\nand Nonstop(z,y).) These possibilities are among those illustrated in the re-\n\ufb01nement graph shown in Fig. 7.2. Whatever restrictions on additional literals\nare imposed, they are all syntactic ones from which the successors in the re\ufb01ne-\nment graph are easily computed. ILP programs that follow the approach we\nare discussing (of specializing clauses by adding a literal) thus have well de\ufb01ned\nmethods of computing the possible literals to add to a clause.\nNow we are ready to write down a simple generic algorithm for inducing a\nlogic program, \u03c0 for inducing a relation \u03c1. We are given a training set, \u039e of\nargument sets some known to be in the relation \u03c1 and some not in \u03c1; \u039e+ are\nthe positive instances, and \u039e \u2212 are the negative instances. The algorithm has\nan outer loop in which it successively adds clauses to make \u03c0 more and more\nsu\ufb03cient. It has an inner loop for constructing a clause, c, that is more and\nmore necessary and in which it refers only to a subset, \u039e cur, of the training\ninstances. (The positive instances in \u039e cur will be denoted by \u039e +\ncur, and the\nnegative ones by \u039e \u2212\ncur.) The algorithm is also given background relations and\nthe means for adding literals to a clause. It uses a logic program interpreter to\ncompute whether or not the program it is inducing covers training instances.\nThe algorithm can be written as follows:\nGeneric ILP Algorithm\n(Adapted from [Lavra\u02c7 c & D\u02c7 zeroski, 1994, p. 60].)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 102, 'page_label': '103'}, page_content='94 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nNonstop(x,y) :-\nNonstop(x,y) :-\n   Hub(x)\nNonstop(x,y) :-\n   Satellite(x,y)\nNonstop(x,y) :-\n   (x = y)\n. . .\n. . .\n. . . . . .\nNonstop(x,y) :- Hub(x), Hub(y)\n. . .\n. . .\n. . .\nFigure 7.2: Part of a Re\ufb01nement Graph\nInitialize \u039ecur := \u039e.\nInitialize \u03c0:= empty set of clauses.\nrepeat [The outer loop works to make \u03c0 su\ufb03cient.]\nInitialize c := \u03c1 : \u2212.\nrepeat [The inner loop makes c necessary.]\nSelect a literal l to add to c. [This is a nondeterministic choice point.]\nAssign c:= c,l.\nuntil c is necessary. [That is, until c covers no negative instances in \u039e cur.]\nAssign \u03c0:= \u03c0,c. [We add the clause c to the program.]\nAssign \u039ecur := \u039ecur \u2212(the positive instances in \u039e cur covered by \u03c0).\nuntil \u03c0 is su\ufb03cient.\n(The termination tests for the inner and outer loops can be relaxed as appro-\npriate for the case of noisy instances.)\n7.3 An Example\nWe illustrate how the algorithm works by returning to our example of airline\n\ufb02ights. Consider the portion of an airline route map, shown in Fig. 7.3. Cities\nA, B, and C are hub cities, and we know that there are nonstop \ufb02ights between\nall hub cities (even those not shown on this portion of the route map). The other'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 103, 'page_label': '104'}, page_content='7.3. AN EXAMPLE 95\ncities are satellites of one of the hubs, and we know that there are nonstop\n\ufb02ights between each satellite city and its hub. The learning program is given a\nset of positive instances, \u039e +, of pairs of cities between which there are nonstop\n\ufb02ights and a set of negative instances, \u039e\u2212, of pairs of cities between which there\nare not nonstop \ufb02ights. \u039e + contains just the pairs:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nFor our example, we will assume that \u039e\u2212contains all those pairs of cities shown\nin Fig. 7.3 that are not in \u039e + (a type of closed-world assumption). These are:\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<B,C 1 >,<B,C 2 >,\n<B,A 1 >,<B,A 2 >,<C,A 1 >,<C,A 2 >,<C,B 1 >,<C,B 2 >,\n<B 1,A>,<B 2,A>,<C 1,A>,<C 2,A>,<C 1,B >,<C 2,B >,\n<A1,B >,<A2,B >,<A1,C >,<A2,C >,<B 1,C >,<B 2,C >}\nThere may be other cities not shown on this map, so the training set does not\nnecessarily exhaust all the cities.\nA\nB\nC\nC1\nC2\nB1 B2\nA1\nA2\nFigure 7.3: Part of an Airline Route Map\nWe want the learning program to induce a program for computing the value\nof the relation Nonstop. The training set, \u039e, can be thought of as a partial'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 104, 'page_label': '105'}, page_content='96 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\ndescription of this relation in extensional formit explicitly names some pairs\nin the relation and some pairs not in the relation. We desire to learn the\nNonstop relation as a logic program in terms of the background relations, Hub\nand Satellite, which are also given in extensional form. Doing so will give us\na more compact, intensional, description of the relation, and this description\ncould well generalize usefully to other cities not mentioned in the map.\nWe assume the learning program has the following extensional de\ufb01nitions of\nthe relations Hub and Satellite:\nHub\n{<A>,<B >,<C > }\nAll other cities mentioned in the map are assumed not in the relation Hub. We\nwill use the notation Hub(x) to express that the city named xis in the relation\nHub.\nSatellite\n{<A1,A,>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nAll other pairs of cities mentioned in the map are not in the relation Satellite.\nWe will use the notation Satellite(x,y) to express that the pair < x,y >is\nin the relation Satellite.\nKnowing that the predicate Nonstop is a two-place predicate, the inner loop\nof our algorithm initializes the \ufb01rst clause to Nonstop(x,y) :- . This clause\nis not necessary because it covers all the negative examples (since it covers all\nexamples). So we must add a literal to its (empty) body. Suppose (selecting\na literal from the re\ufb01nement graph) the algorithm adds Hub(x). The following\npositive instances in \u039e are covered by Nonstop(x,y) :- Hub(x):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}\nTo compute this covering, we interpret the logic program Nonstop(x,y) :-\nHub(x) for all pairs of cities in \u039e, using the pairs given in the background\nrelation Hub as ground facts. The following negative instances are also covered:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 105, 'page_label': '106'}, page_content='7.3. AN EXAMPLE 97\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<C,A 1 >,<C,A 2 >,\n<C,B 1 >,<C,B 2 >,<B,A 1 >,<B,A 2 >,<B,C 1 >,<B,C 2 >}\nThus, the clause is not yet necessary and another literal must be added. Sup-\npose we next add Hub(y). The following positive instances are covered by\nNonstop(x,y) :- Hub(x), Hub(y):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B > }\nThere are no longer any negative instances in \u039e covered so the clause\nNonstop(x,y) :- Hub(x), Hub(y) is necessary, and we can terminate the \ufb01rst\npass through the inner loop.\nBut the program, \u03c0, consisting of just this clause is not su\ufb03cient. These\npositive instances are not covered by the clause:\n{<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nThe positive instances that were covered byNonstop(x,y) :- Hub(x), Hub(y)\nare removed from \u039e to form the \u039e cur to be used in the next pass through the\ninner loop. \u039e cur consists of all the negative instances in \u039e plus the positive\ninstances (listed above) that are not yet covered. In order to attempt to cover\nthem, the inner loop creates another clause c, initially set to Nonstop(x,y)\n:- . This clause covers all the negative instances, and so we must add liter-\nals to make it necessary. Suppose we add the literal Satellite(x,y). The\nclause Nonstop(x,y) :- Satellite(x,y) covers no negative instances, so it is\nnecessary. It does cover the following positive instances in \u039e cur:\n{<A1,A>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nThese instances are removed from \u039ecur for the next pass through the inner loop.\nThe program now contains two clauses:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\nThis program is not yet su\ufb03cient since it does not cover the following positive\ninstances:\n{<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 106, 'page_label': '107'}, page_content='98 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nDuring the next pass through the inner loop, we add the clauseNonstop(x,y)\n:- Satellite(y,x). This clause is necessary, and since the program containing\nall three clauses is now su\ufb03cient, the procedure terminates with:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nSince each clause is necessary, and the whole program is su\ufb03cient, the pro-\ngram is also consistent with all instances of the training set. Note that this\nprogram can be applied (perhaps with good generalization) to other cities be-\nsides those in our partial mapso long as we can evaluate the relations Hub and\nSatellite for these other cities. In the next section, we show how the technique\ncan be extended to use recursion on the relation we are inducing. With that\nextension, the method can be used to induce more general logic programs.\n7.4 Inducing Recursive Programs\nTo induce a recursive program, we allow the addition of a literal having the\nsame predicate letter as that in the head of the clause. Various mechanisms\nmust be used to ensure that such a program will terminate; one such is to make\nsure that the new literal has di\ufb00erent variables than those in the head literal.\nThe process is best illustrated with another example. Our example continues\nthe one using the airline map, but we make the map somewhat simpler in order\nto reduce the size of the extensional relations used. Consider the map shown\nin Fig. 7.4. Again, B and C are hub cities, B1 and B2 are satellites of B, C1\nand C2 are satellites of C. We have introduced two new cities, B3 and C3. No\n\ufb02ights exist between these cities and any other citiesperhaps there are only\nbus routes as shown by the grey lines in the map.\nWe now seek to learn a program for Canfly(x,y) that covers only those\npairs of cities that can be reached by one or more nonstop \ufb02ights. The relation\nCanfly is satis\ufb01ed by the following pairs of postive instances:\n{<B 1,B >,<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,\n<B,B 1 >,<B 2,B1 >,<C,B 1 >,<C 1,B1 >,<C 2,B1 >,\n<B 2,B >,<B 2,C >,<B 2,C1 >,<B 2,C2 >,<B,B 2 >,\n<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C >,<B,C 1 >,\n<B,C 2 >,<C,B >,<C 1,B >,<C 2,B >,<C,C 1 >,\n<C,C 2 >,<C 1,C >,<C 2,C >,<C 1,C2 >,<C 2,C1 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 107, 'page_label': '108'}, page_content='7.4. INDUCING RECURSIVE PROGRAMS 99\nB\nC\nC1\nC2\nB1\nB2\nB3\nC3\nFigure 7.4: Another Airline Route Map\nUsing a closed-world assumption on our map, we take the negative instances of\nCanfly to be:\n{<B 3,B2 >,<B 3,B >,<B 3,B1 >,<B 3,C >,<B 3,C1 >,\n<B 3,C2 >,<B 3,C3 >,<B 2,B3 >,<B,B 3 >,<B 1,B3 >,\n<C,B 3 >,<C 1,B3 >,<C 2,B3 >,<C 3,B3 >,<C 3,B2 >,\n<C 3,B >,<C 3,B1 >,<C 3,C >,<C 3,C1 >,<C 3,C2 >,\n<B 2,C3 >,<B,C 3 >,<B 1,C3 >,<C,C 3 >,<C 1,C3 >,\n<C 2,C3 >}\nWe will induce Canfly(x,y) using the extensionally de\ufb01ned background\nrelation Nonstop given earlier (modi\ufb01ed as required for our reduced airline map)\nand Canfly itself (recursively).\nAs before, we start with the empty program and proceed to the inner loop\nto construct a clause that is necessary. Suppose that the inner loop adds the\nbackground literal Nonstop(x,y). The clause Canfly(x,y) :- Nonstop(x,y)\nis necessary; it covers no negative instances. But it is not su\ufb03cient because it\ndoes not cover the following positive instances:\n{<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,<B 2,B1 >,\n<C,B 1 >,<C 1,B1 >,<C 2,B1 >,<B 2,C >,<B 2,C1 >,\n<B 2,C2 >,<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C 1 >,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 108, 'page_label': '109'}, page_content='100 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n<B,C 2 >,<C 1,B >,<C 2,B >,<C 1,C2 >,<C 2,C1 >}\nThus, we must add another clause to the program. In the inner loop, we \ufb01rst\ncreate the clause Canfly(x,y) :- Nonstop(x,z) which introduces the new\nvariable z. We digress brie\ufb02y to describe how a program containing a clause\nwith unbound variables in its body is interpreted. Suppose we try to inter-\npret it for the positive instance Canfly(B1,B2). The interpreter attempts to\nestablish Nonstop(B1,z) for some z. Since Nonstop(B1, B), for example, is\na background fact, the interpreter returns Twhich means that the instance\n< B1,B2 > is covered. Suppose now, we attempt to interpret the clause\nfor the negative instance Canfly(B3,B). The interpreter attempts to estab-\nlish Nonstop(B3,z) for some z. There are no background facts that match, so\nthe clause does not cover < B3,B >. Using the interpreter, we see that the\nclause Canfly(x,y) :- Nonstop(x,z) covers all of the positive instances not\nalready covered by the \ufb01rst clause, but it also covers many negative instances\nsuch as <B 2,B3 >, and <B,B 3 >. So the inner loop must add another literal.\nThis time, suppose it adds Canfly(z,y) to yield the clause Canfly(x,y) :-\nNonstop(x,z), Canfly(z,y). This clause is necessary; no negative instances\nare covered. The program is now su\ufb03cient and consistent; it is:\nCanfly(x,y) :- Nonstop(x,y)\n:- Nonstop(x,z), Canfly(z,y)\n7.5 Choosing Literals to Add\nOne of the \ufb01rst practical ILP systems was Quinlans FOIL [Quinlan, 1990]. A\nmajor problem involves deciding how to select a literal to add in the inner loop\n(from among the literals that are allowed). In FOIL, Quinlan suggested that\ncandidate literals can be compared using an information-like measuresimilar\nto the measures used in inducing decision trees. A measure that gives the same\ncomparison as does Quinlans is based on the amount by which adding a literal\nincreases the odds that an instance drawn at random from those covered by the\nnew clause is a positive instance beyond what these odds were before adding\nthe literal.\nLet p be an estimate of the probability that an instance drawn at random\nfrom those covered by a clause before adding the literal is a positive instance.\nThat is, p=(number of positive instances covered by the clause)/(total number\nof instances covered by the clause). It is convenient to express this probability\nin odds form. The odds, o, that a covered instance is positive is de\ufb01ned to\nbe o = p/(1 \u2212p). Expressing the probability in terms of the odds, we obtain\np= o/(1 + o).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 109, 'page_label': '110'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION101\nAfter selecting a literal, l, to add to a clause, some of the instances previously\ncovered are still covered; some of these are positive and some are negative. Let\npl denote the probability that an instance drawn at random from the instances\ncovered by the new clause (with l added) is positive. The odds will be denoted\nby ol. We want to select a literal, l, that gives maximal increase in these\nodds. That is, if we de\ufb01ne \u03bbl = ol/o, we want a literal that gives a high\nvalue of \u03bbl. Specializing the clause in such a way that it fails to cover many of\nthe negative instances previously covered but still covers most of the positive\ninstances previously covered will result in a high value of \u03bbl. (It turns out that\nthe value of Quinlans information theoretic measure increases monotonically\nwith \u03bbl, so we could just as well use the latter instead.)\nBesides \ufb01nding a literal with a high value of \u03bbl, Quinlans FOIL system also\nrestricts the choice to literals that:\na) contain at least one variable that has already been used,\nb) place further restrictions on the variables if the literal selected has the\nsame predicate letter as the literal being induced (in order to prevent in\ufb01nite\nrecursion), and\nc) survive a pruning test based on the values of \u03bbl for those literals selected\nso far.\nWe refer the reader to Quinlans paper for further discussion of these points.\nQuinlan also discusses post-processing pruning methods and presents experi-\nmental results of the method applied to learning recursive relations on lists, on\nlearning rules for chess endgames and for the card game Eleusis, and for some\nother standard tasks mentioned in the machine learning literature.\nThe reader should also refer to [Pazzani & Kibler, 1992,\nLavra\u02c7 c & D\u02c7 zeroski, 1994, Muggleton, 1991, Muggleton, 1992]. Discuss preprocessing,\npostprocessing, bottom-up\nmethods, and LINUS.\n7.6 Relationships Between ILP and Decision\nTree Induction\nThe generic ILP algorithm can also be understood as a type of decision tree\ninduction. Recall the problem of inducing decision trees when the values of\nattributes are categorical. When splitting on a single variable, the split at\neach node involves asking to which of several mutually exclusive and exhaustive\nsubsets the value of a variable belongs. For example, if a node tested the variable\nxi, and if xi could have values drawn from {A,B,C,D,E,F }, then one possible\nsplit (among many) might be according to whether the value of xi had as value\none of {A,B,C }or one of {D,E,F }.\nIt is also possible to make a multi-variate splittesting the values of two or\nmore variables at a time. With categorical variables, an n-variable split would\nbe based on which of several n-ary relations the values of the variables satis\ufb01ed.\nFor example, if a node tested the variables xi and xj, and if xi and xj both\ncould have values drawn from {A,B,C,D,E,F }, then one possible binary split'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 110, 'page_label': '111'}, page_content='102 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n(among many) might be according to whether or not < xi,xj > satis\ufb01ed the\nrelation {<A,C >,<C,D> }. (Note that our subset method of forming single-\nvariable splits could equivalently have been framed using 1-ary relationswhich\nare usually called properties.)\nIn this framework, the ILP problem is as follows: We are given a training set,\n\u039e, of positively and negatively labeled patterns whose components are drawn\nfrom a set of variables {x,y,z,... }. The positively labeled patterns in \u039e form an\nextensional de\ufb01nition of a relation, R. We are also given background relations,\nR1,...,R k, on various subsets of these variables. (That is, we are given sets\nof tuples that are in these relations.) We desire to construct an intensional\nde\ufb01nition of Rin terms of the R1,...,R k, such that all of the positively labeled\npatterns in \u039e are satis\ufb01ed by R and none of the negatively labeled patterns\nare. The intensional de\ufb01nition will be in terms of a logic program in which the\nrelation R is the head of a set of clauses whose bodies involve the background\nrelations.\nThe generic ILP algorithm can be understood as decision tree induction,\nwhere each node of the decision tree is itself a sub-decision tree, and each sub-\ndecision tree consists of nodes that make binary splits on several variables using\nthe background relations, Ri. Thus we will speak of a top-level decision tree\nand various sub-decision trees. (Actually, our decision trees will be decision\nlistsa special case of decision trees, but we will refer to them as trees in our\ndiscussions.)\nIn broad outline, the method for inducing an intensional version of the rela-\ntion R is illustrated by considering the decision tree shown in Fig. 7.5. In this\ndiagram, the patterns in \u039e are \ufb01rst \ufb01ltered through the decision tree in top-\nlevel node 1. The background relation R1 is satis\ufb01ed by some of these patterns;\nthese are \ufb01ltered to the right (to relation R2), and the rest are \ufb01ltered to the\nleft (more on what happens to these later). Right-going patterns are \ufb01ltered\nthrough a sequence of relational tests until only positively labeled patterns sat-\nisfy the last relationin this case R3. That is, the subset of patterns satisfying\nall the relations, R1, R2, and R3 contains only positive instances from \u039e. (We\nmight say that this combination of tests is necessary. They correspond to the\nclause created in the \ufb01rst pass through the inner loop of the generic ILP algo-\nrithm.) Let us call the subset of patterns satisfying these relations, \u039e 1; these\nsatisfy Node 1 at the top level. All other patterns, that is {\u039e \u2212\u039e1}= \u039e2 are\n\ufb01ltered to the left by Node 1.\n\u039e2 is then \ufb01ltered by top-level Node 2 in much the same manner, so that\nNode 2 is satis\ufb01ed only by the positively labeled samples in \u039e 2. We continue\n\ufb01ltering through top-level nodes until only the negatively labeled patterns fail to\nsatisfy a top node. In our example, \u039e 4 contains only negatively labeled patterns\nand the union of \u039e 1 and \u039e3 contains all the positively labeled patterns. The\nrelation, R, that distinguishes positive from negative patterns in \u039e is then given\nin terms of the following logic program:\nR :- R1, R2, R3'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 111, 'page_label': '112'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION103\nR1\nR2\nR3\nT\nT\nT\nF\nF\nF\nT\nF\nR4\nR5\nT\nT\nF\nF\nTF\nU\nU1\nU2 = U < U1\nU3U4= U2 < U3\nNode 1\nNode 2\n(only positive\ninstances\nsatisfy all three\ntests)\n(only positivel\ninstances satisfy\nthese two tests)\n(only negative\ninstances)\nFigure 7.5: A Decision Tree for ILP\n:- R4, R5\nIf we apply this sort of decision-tree induction procedure to the problem\nof generating a logic program for the relation Nonstop (refer to Fig. 7.3), we\nobtain the decision tree shown in Fig. 7.6. The logic program resulting from\nthis decision tree is the same as that produced by the generic ILP algorithm.\nIn setting up the problem, the training set, \u039e can be expressed as a set of 2-\ndimensional vectors with components xand y. The values of these components\nrange over the cities {A,B,C,A 1,A2,B1,B2,C1,C2}except (for simplicity)\nwe do not allow patterns in which x and y have the same value. As before, the\nrelation, Nonstop, contains the following pairs of cities, which are the positive\ninstances:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nAll other pairs of cities named in the map of Fig. 7.3 (using the closed world\nassumption) are not in the relation Nonstop and thus are negative instances.\nBecause the values of xand y are categorical, decision-tree induction would\nbe a very di\ufb03cult taskinvolving as it does the need to invent relations on'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 112, 'page_label': '113'}, page_content='104 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nx and y to be used as tests. But with the background relations, Ri (in this\ncase Hub and Satellite), the problem is made much easier. We select these\nrelations in the same way that we select literals; from among the available tests,\nwe make a selection based on which leads to the largest value of \u03bbRi.\n7.7 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 113, 'page_label': '114'}, page_content='7.7. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 105\nHub(x) T\nF\nU\nNode 1\n(top level)\n{<A,B>, <A,C>,\n<B,C>, <B,A>,\n<C,A>, <C,B>}\nHub(y) T\nT\nFNode 2\n(top level)\nSatellite(x,y)\nF T\nT {<A1,A>, <A2,A>, <B1,B>,\n<B2,B>, <C1,C>, <C2,C>}\nF\n{<A,A1>, <A,A2>,<B,B1>,\n<B,B2>,  <C,C1>, <C,C2>}\nSatellite(y,x)\nF\nF\nT\nNode 3\n(top level)\nT\n{Only negative instances}\n(Only positive instances)\n(Only positive instances)\n(Only positive instances)\nF\nFigure 7.6: A Decision Tree for the Airline Route Problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 114, 'page_label': '115'}, page_content='106 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 115, 'page_label': '116'}, page_content='Chapter 8\nComputational Learning\nTheory\nIn chapter one we posed the problem of guessing a function given a set of\nsample inputs and their values. We gave some intuitive arguments to support\nthe claim that after seeing only a small fraction of the possible inputs (and\ntheir values) that we could guess almost correctly the values of most subsequent\ninputsif we knew that the function we were trying to guess belonged to an\nappropriately restricted subset of functions. That is, a given training set of\nsample patterns might be adequate to allow us to select a function, consistent\nwith the labeled samples , from among a restricted set of hypotheses such that\nwith high probability the function we select will be approximately correct (small\nprobability of error) on subsequent samples drawn at random according to the\nsame distribution from which the labeled samples were drawn. This insight\nled to the theory of probably approximately correct (PAC) learninginitially\ndeveloped by Leslie Valiant [Valiant, 1984]. We present here a brief description\nof the theory for the case of Boolean functions. [Dietterich, 1990, Haussler, 1988,\nHaussler, 1990] give nice surveys of the important results. Other overviews?\n8.1 Notation and Assumptions for PAC Learn-\ning Theory\nWe assume a training set \u039e of n-dimensional vectors, Xi, i = 1 ,...,m , each\nlabeled (by 1 or 0) according to a target function, f, which is unknown to\nthe learner. The probability of any given vector X being in \u039e, or later being\npresented to the learner, is P(X). The probability distribution, P, can be\narbitrary. (In the literature of PAC learning theory, the target function is usually\ncalled the target concept and is denoted by c, but to be consistent with our\nprevious notation we will continue to denote it by f.) Our problem is to guess\n107'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 116, 'page_label': '117'}, page_content='108 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\na function, h(X), based on the labeled samples in \u039e. In PAC theory such a\nguessed function is called the hypothesis. We assume that the target function\nis some element of a set of functions, C. We also assume that the hypothesis,\nh, is an element of a set, H, of hypotheses, which includes the set, C, of target\nfunctions. His called the hypothesis space.\nIn general, h wont be identical to f, but we can strive to have the value of\nh(X) = the value of f(X) for most Xs. That is, we want hto be approximately\ncorrect. To quantify this notion, we de\ufb01ne the error of h, \u03b5h, as the probability\nthat an X drawn randomly according to P will be misclassi\ufb01ed:\n\u03b5h =\n\u2211\n[X:h(X)\u0338=f(X)]\nP(X)\nBoldface symbols need to be\nsmaller when they are subscripts in\nmath environments. We say that h is approximately (except for \u03b5 ) correct if \u03b5h \u2264\u03b5, where \u03b5 is the\naccuracy parameter.\nSuppose we are able to \ufb01nd anhthat classi\ufb01es all mrandomly drawn training\nsamples correctly; that is, h is consistent with this randomly selected training\nset, \u039e. If m is large enough, will such an h be approximately correct (and\nfor what value of \u03b5)? On some training occasions, using m randomly drawn\ntraining samples, such an h might turn out to be approximately correct (for a\ngiven value of \u03b5), and on others it might not. We say that his probably (except\nfor \u03b4) approximately correct (PAC) if the probability that it is approximately\ncorrect is greater than 1\u2212\u03b4, where \u03b4is the con\ufb01dence parameter. We shall show\nthat if m is greater than some bound whose value depends on \u03b5 and \u03b4, such an\nh is guaranteed to be probably approximately correct.\nIn general, we say that a learning algorithm PAC-learns functions from Cin\nterms of Hi\ufb00 for every function f\u03f5 C, it outputs a hypothesis h\u03f5 H, such that\nwith probability at least (1 \u2212\u03b4), \u03b5h \u2264\u03b5. Such a hypothesis is called probably\n(except for \u03b4) approximately (except for \u03b5) correct.\nWe want learning algorithms that are tractable, so we want an algorithm\nthat PAC-learns functions in polynomial time. This can only be done for certain\nclasses of functions. If there are a \ufb01nite number of hypotheses in a hypothesis\nset (as there are for many of the hypothesis sets we have considered), we could\nalways produce a consistent hypothesis from this set by testing all of them\nagainst the training data. But if there are an exponential number of hypotheses,\nthat would take exponential time. We seek training methods that produce\nconsistent hypotheses in less time. The time complexities for various hypothesis\nsets have been determined, and these are summarized in a table to be presented\nlater.\nA class, C, is polynomially PAC learnable in terms of Hprovided there exists\na polynomial-time learning algorithm (polynomial in the number of samples\nneeded, m, in the dimension, n, in 1 /\u03b5, and in 1 /\u03b4) that PAC-learns functions\nin Cin terms of H.\nInitial work on PAC assumed H= C, but it was later shown that some func-\ntions cannot be polynomially PAC-learned under such an assumption (assuming'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 117, 'page_label': '118'}, page_content='8.2. PAC LEARNING 109\nP \u0338= NP)but can be polynomially PAC-learned if His a strict superset of C!\nAlso our de\ufb01nition does not specify the distribution, P, from which patterns\nare drawn nor does it say anything about the properties of the learning algo-\nrithm. Since Cand Hdo not have to be identical, we have the further restrictive\nde\ufb01nition:\nA properly PAC-learnableclass is a classCfor which there exists an algorithm\nthat polynomially PAC-learns functions from Cin terms of C.\n8.2 PAC Learning\n8.2.1 The Fundamental Theorem\nSuppose our learning algorithm selects some hrandomly from among those that\nare consistent with the values of f on the mtraining patterns. The probability\nthat the error of this randomly selected his greater than some \u03b5, with hconsis-\ntent with the values of f(X) for minstances of X (drawn according to arbitrary\nP), is less than or equal to |H|e\u2212\u03b5m, where |H|is the number of hypotheses in\nH. We state this result as a theorem [Blumer, et al., 1987]:\nTheorem 8.1 (Blumer, et al.) Let Hbe any set of hypotheses, \u039e be a set of\nm \u22651 training examples drawn independently according to some distribution\nP, f be any classi\ufb01cation function in H, and \u03b5> 0. Then, the probability that\nthere exists a hypothesis hconsistent with f for the members of \u039e but with error\ngreater than \u03b5 is at most |H|e\u2212\u03b5m.\nProof:\nConsider the set of all hypotheses, {h1,h2,...,h i,...,h S}, in H, where S =\n|H|. The error for hi is \u03b5hi= the probability that hi will classify a pattern in\nerror (that is, di\ufb00erently than f would classify it). The probability that hi will\nclassify a pattern correctly is (1\u2212\u03b5hi). A subset, HB, of Hwill have error greater\nthan \u03b5. We will call the hypotheses in this subset bad. The probability that any\nparticular one of these bad hypotheses, sayhb, would classify a pattern correctly\nis (1\u2212\u03b5hb). Since \u03b5hb >\u03b5, the probability that hb (or any other bad hypothesis)\nwould classify a pattern correctly is less than (1 \u2212\u03b5). The probability that it\nwould classify all m independently drawn patterns correctly is then less than\n(1 \u2212\u03b5)m.\nThat is,\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB] \u2264(1 \u2212\u03b5)m.\nprob[some h \u03f5HB classi\ufb01es all m patterns correctly]\n= \u2211\nhb \u03f5 HB\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB]\n\u2264K(1 \u2212\u03b5)m, where K = |HB|.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 118, 'page_label': '119'}, page_content='110 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nThat is,\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n\u2264K(1 \u2212\u03b5)m.\nSince K \u2264|H| and (1 \u2212\u03b5)m \u2264e\u2212\u03b5m, we have:\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n= prob[there is a hypothesis with error >\u03b5 and that classi\ufb01es all mpatterns\ncorrectly] \u2264|H|e\u2212\u03b5m.\nQED\nA corollary of this theorem is:\nCorollary 8.2 Given m \u2265 (1/\u03b5)(ln |H|+ ln(1/\u03b4)) independent samples, the\nprobability that there exists a hypothesis in Hthat is consistent with f on these\nsamples and has error greater than \u03b5 is at most \u03b4.\nProof: We are to \ufb01nd a bound on m that guarantees that\nprob[there is a hypothesis with error > \u03b5and that classi\ufb01es all m patterns\ncorrectly] \u2264 \u03b4. Thus, using the result of the theorem, we must show that\n|H|e\u2212\u03b5m \u2264\u03b4. Taking the natural logarithm of both sides yields:\nln |H|\u2212\u03b5m\u2264ln \u03b4\nor\nm\u2265(1/\u03b5)(ln |H|+ ln(1/\u03b4))\nQED\nThis corollary is important for two reasons. First it clearly states that we\ncan select any hypothesis consistent with the m samples and be assured that\nwith probability (1 \u2212\u03b4) its error will be less than \u03b5. Also, it shows that in\norder for mto increase no more than polynomially with n, |H|can be no larger\nthan 2O(nk). No class larger than that can be guaranteed to be properly PAC\nlearnable.\nHere is a possible point of confusion: The bound given in the corollary is\nan upper bound on the value of mneeded to guarantee polynomial probably ap-\nproximately correct learning. Values of mgreater than that bound are su\ufb03cient\n(but might not be necessary). We will present a lower (necessary) bound later\nin the chapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 119, 'page_label': '120'}, page_content='8.2. PAC LEARNING 111\n8.2.2 Examples\nTerms\nLet Hbe the set of terms (conjunctions of literals). Then, |H|= 3n, and\nm\u2265(1/\u03b5)(ln(3n) + ln(1/\u03b4))\n\u2265(1/\u03b5)(1.1n+ ln(1/\u03b4))\nNote that the bound on m increases only polynomially with n, 1/\u03b5, and 1/\u03b4.\nFor n= 50, \u03b5= 0.01 and \u03b4= 0.01, m\u22655,961 guarantees PAC learnability.\nIn order to show that terms are properly PAC learnable , we additionally\nhave to show that one can \ufb01nd in time polynomial in m and n a hypothesis\nh consistent with a set of m patterns labeled by the value of a term. The\nfollowing procedure for \ufb01nding such a consistent hypothesis requires O(nm)\nsteps (adapted from [Dietterich, 1990, page 268]):\nWe are given a training sequence, \u039e, of m examples. Find the \ufb01rst pattern,\nsay X1, in that list that is labeled with a 1. Initialize a Boolean function,\nh, to the conjunction of the n literals corresponding to the values of the n\ncomponents of X1. (Components with value 1 will have corresponding positive\nliterals; components with value 0 will have corresponding negative literals.) If\nthere are no patterns labeled by a 1, we exit with the null concept ( h \u22610 for\nall patterns). Then, for each additional pattern, Xi, that is labeled with a 1,\nwe delete from h any Boolean variables appearing in Xi with a sign di\ufb00erent\nfrom their sign in h. After processing all the patterns labeled with a 1, we check\nall of the patterns labeled with a 0 to make sure that none of them is assigned\nvalue 1 by h. If, at any stage of the algorithm, any patterns labeled with a 0\nare assigned a 1 by h, then there exists no term that consistently classi\ufb01es the\npatterns in \u039e, and we exit with failure. Otherwise, we exit with h. Change this paragraph if this\nalgorithm was presented in Chapter\nThree.As an example, consider the following patterns, all labeled with a 1 (from\n[Dietterich, 1990]):\n(0,1,1,0)\n(1,1,1,0)\n(1,1,0,0)\nAfter processing the \ufb01rst pattern, we have h = x1x2x3x4; after processing the\nsecond pattern, we have h = x2x3x4; \ufb01nally, after the third pattern, we have\nh= x2x4.\nLinearly Separable Functions\nLet Hbe the set of all linearly separable functions. Then, |H|\u2264 2n2\n, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 120, 'page_label': '121'}, page_content='112 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nm\u2265(1/\u03b5)\n(\nn2 ln 2 + ln(1/\u03b4)\n)\nAgain, note that the bound on m increases only polynomially with n, 1/\u03b5, and\n1/\u03b4.\nFor n= 50, \u03b5= 0.01 and \u03b4 = 0.01, m\u2265173,748 guarantees PAC learnabil-\nity.\nTo show that linearly separable functions are properly PAC learnable , we\nwould have additionally to show that one can \ufb01nd in time polynomial in mand\nna hypothesis hconsistent with a set of mlabeled linearly separable patterns.Linear programming is polynomial.\n8.2.3 Some Properly PAC-Learnable Classes\nSome properly PAC-learnable classes of functions are given in the following\ntable. (Adapted from [Dietterich, 1990, pages 262 and 268] which also gives\nreferences to proofs of some of the time complexities.)\nH |H| Time Complexity P. Learnable?\nterms 3n polynomial yes\nk-term DNF 2O(kn) NP-hard no\n(k disjunctive terms)\nk-DNF 2O(nk) polynomial yes\n(a disjunction of k-sized terms)\nk-CNF 2O(nk) polynomial yes\n(a conjunction of k-sized clauses)\nk-DL 2O(nkklg n) polynomial yes\n(decision lists with k-sized terms)\nlin. sep. 2O(n2) polynomial yes\nlin. sep. with (0,1) weights ? NP-hard no\nk-2NN ? NP-hard no\nDNF 22n\npolynomial no\n(all Boolean functions)\n(Members of the class k-2NN are two-layer, feedforward neural networks with\nexactly k hidden units and one output unit.)\nSummary: In order to show that a class of functions is Properly PAC-\nLearnable :\na. Show that there is an algorithm that produces a consistent hypothesis on\nm n-dimensional samples in time polynomial in m and n.\nb. Show that the sample size, m, needed to ensure PAC learnability is polyno-\nmial (or better) in (1/\u03b5), (1/\u03b4), and nby showing that ln|H|is polynomial\nor better in the number of dimensions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 121, 'page_label': '122'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 113\nAs hinted earlier, sometimes enlarging the class of hypotheses makes learning\neasier. For example, the table above shows that k-CNF is PAC learnable, but\nk-term-DNF is not. And yet, k-term-DNF is a subclass of k-CNF! So, even if\nthe target function were in k-term-DNF, one would be able to \ufb01nd a hypothesis\nin k-CNF that is probably approximately correct for the target function. Sim-\nilarly, linearly separable functions implemented by TLUs whose weight values\nare restricted to 0 and 1 are not properly PAC learnable, whereas unrestricted\nlinearly separable functions are. It is possible that enlarging the space of hy-\npotheses makes \ufb01nding one that is consistent with the training examples easier.\nAn interesting question is whether or not the class of functions ink-2NN is poly-\nnomially PAC learnable if the hypotheses are drawn from k\u2032-2NN with k\u2032>k .\n(At the time of writing, this matter is still undecided.)\nAlthough PAC learning theory is a powerful analytic tool, it (like complexity\ntheory) deals mainly with worst-case results. The fact that the class of two-\nlayer, feedforward neural networks is not polynomially PAC learnable is more an\nattack on the theory than it is on the networks, which have had many successful\napplications. As [Baum, 1994, page 416-17] says:  ... humans are capable of\nlearning in the natural world. Therefore, a proof within some model of learning\nthat learning is not feasible is an indictment of the model. We should examine\nthe model to see what constraints can be relaxed and made more realistic.\n8.3 The Vapnik-Chervonenkis Dimension\n8.3.1 Linear Dichotomies\nConsider a set, H, of functions, and a set, \u039e, of (unlabeled) patterns. One\nmeasure of the expressive power of a set of hypotheses, relative to \u039e, is its\nability to make arbitrary classi\ufb01cations of the patterns in \u039e. 1 If there are m\npatterns in \u039e, there are 2 m di\ufb00erent ways to divide these patterns into two\ndisjoint and exhaustive subsets. We say there are 2 m di\ufb00erent dichotomies of\n\u039e. If \u039e were to include all of the 2 n Boolean patterns, for example, there are\n22n\nways to dichotomize them, and (of course) the set of all possible Boolean\nfunctions dichotomizes them in all of these ways. But a subset,H, of the Boolean\nfunctions might not be able to dichotomize an arbitrary set, \u039e, of m Boolean\npatterns in all 2 m ways. In general (that is, even in the non-Boolean case), we\nsay that if a subset, H, of functions can dichotomize a set, \u039e, of m patterns in\nall 2m ways, then Hshatters \u039e.\nAs an example, consider a set \u039e of m patterns in the n-dimensional space,\nRn. (That is, the ncomponents of these patterns are real numbers.) We de\ufb01ne\na linear dichotomy as one implemented by an (n\u22121)-dimensional hyperplane in\nthe n-dimensional space. How many linear dichotomies of m patterns in n di-\nmensions are there? For example, as shown in Fig. 8.1, there are 14 dichotomies\n1And, of course, if a hypothesis drawn from a set that could make arbitrary classi\ufb01cations\nof a set of training patterns, there is little likelihood that such a hypothesis will generalize\nwell beyond the training set.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 122, 'page_label': '123'}, page_content='114 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nof four points in two dimensions (each separating line yields two dichotomies\ndepending on whether the points on one side of the line are classi\ufb01ed as 1 or 0).\n(Note that even though there are an in\ufb01nite number of hyperplanes, there are,\nnevertheless, only a \ufb01nite number of ways in which hyperplanes can dichotomize\na \ufb01nite number of patterns. Small movements of a hyperplane typically do not\nchange the classi\ufb01cations of any patterns.)\n12\n3\n4\n14 dichotomies of 4 points in 2 dimensions\n5\n6\n7\nFigure 8.1: Dichotomizing Points in Two Dimensions\nThe number of dichotomies achievable by hyperplanes depends on how the\npatterns are disposed. For the maximum number of linear dichotomies, the\npoints must be in what is called general position. For m>n , we say that a set\nof m points is in general position in an n-dimensional space if and only if no\nsubset of (n+1) points lies on an (n\u22121)-dimensional hyperplane. When m\u2264n,\na set of m points is in general position if no ( m\u22122)-dimensional hyperplane\ncontains the set. Thus, for example, a set of m\u22654 points is in general position\nin a three-dimensional space if no four of them lie on a (two-dimensional) plane.\nWe will denote the number of linear dichotomies of mpoints in general position\nin an n-dimensional space by the expression \u03a0 L(m,n).\nIt is not too di\ufb03cult to verify that:Include the derivation.\n\u03a0L(m,n) = 2\nn\u2211\ni=0\nC(m\u22121,i) for m>n, and\n= 2m for m\u2264n'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 123, 'page_label': '124'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 115\nwhere C(m\u22121,i) is the binomial coe\ufb03cient (m\u22121)!\n(m\u22121\u2212i)!i! .\nThe table below shows some values for \u03a0 L(m,n).\nm n\n(no. of patterns) (dimension)\n1 2 3 4 5\n1 2 2 2 2 2\n2 4 4 4 4 4\n3 6 8 8 8 8\n4 8 14 16 16 16\n5 10 22 30 32 32\n6 12 32 52 62 64\n7 14 44 84 114 126\n8 16 58 128 198 240\nNote that the class of linear dichotomies shatters the m patterns if m\u2264n+ 1.\nThe bold-face entries in the table correspond to the highest values of m for\nwhich linear dichotomies shatter m patterns in n dimensions.\n8.3.2 Capacity\nLet Pm,n = \u03a0L(m,n)\n2m = the probability that a randomly selected dichotomy (out\nof the 2 m possible dichotomies of m patterns in n dimensions) will be linearly\nseparable. In Fig. 8.2 we plot P\u03bb(n+1),n versus \u03bb and n, where \u03bb= m/(n+ 1).\nNote that for large n (say n >30) how quickly Pm,n falls from 1 to 0 as\nm goes above 2( n+ 1). For m <2(n+ 1), any dichotomy of the m points is\nalmost certainly linearly separable. But for m> 2(n+ 1), a randomly selected\ndichotomy of the m points is almost certainly not linearly separable. For this\nreason m= 2(n+ 1) is called the capacity of a TLU [Cover, 1965]. Unless the\nnumber of training patterns exceeds the capacity, the fact that a TLU separates\nthose training patterns according to their labels means nothing in terms of how\nwell that TLU will generalize to new patterns. There is nothing special about\na separation found for m <2(n+ 1) patternsalmost any dichotomy of those\npatterns would have been linearly separable. To make sure that the separation\nfound is forced by the training set and thus generalizes well, it has to be the\ncase that there are very few linearly separable functions that would separate\nthe m training patterns.\nAnalogous results about the generalizing abilities of neural networks have\nbeen developed by [Baum & Haussler, 1989] and given intuitive and experimen-\ntal justi\ufb01cation in [Baum, 1994, page 438]:\nThe results seemed to indicate the following heuristic rule holds. If\nM examples [can be correctly classi\ufb01ed by] a net withW weights (for\nM >>W), the net will make a fraction \u03b5of errors on new examples\nchosen from the same [uniform] distribution where \u03b5= W/M.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 124, 'page_label': '125'}, page_content='116 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n0.25\n0.5\n0.75\n1\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n25\n.5\n75\n1\nPh(n + 1), n\nh\nn\nFigure 8.2: Probability that a Random Dichotomy is Linearly Separable\n8.3.3 A More General Capacity Result\nCorollary 7.2 gave us an expression for the number of training patterns su\ufb03cient\nto guarantee a required level of generalizationassuming that the function we\nwere guessing was a function belonging to a class of known and \ufb01nite cardinality.\nThe capacity result just presented applies to linearly separable functions for non-\nbinary patterns. We can extend these ideas to general dichotomies of non-binary\npatterns.\nIn general, let us denote the maximum number of dichotomies of any set\nof m n-dimensional patterns by hypotheses in Has \u03a0H(m,n). The number of\ndichotomies will, of course, depend on the disposition of the m points in the\nn-dimensional space; we take \u03a0 H(m,n) to be the maximum over all possible\narrangements of the m points. (In the case of the class of linearly separable\nfunctions, the maximum number is achieved when the m points are in general\nposition.) For each class, H, there will be some maximum value of mfor which\n\u03a0H(m,n) = 2m, that is, for which Hshatters the m patterns. This maximum\nnumber is called the Vapnik-Chervonenkis (VC) dimension and is denoted by\nVCdim(H) [Vapnik & Chervonenkis, 1971].\nWe saw that for the class of linear dichotomies, VCdim( Linear) = (n+ 1).\nAs another example, let us calculate the VC dimension of the hypothesis space\nof single intervals on the real lineused to classify points on the real line. We\nshow an example of how points on the line might be dichotomized by a single\ninterval in Fig. 8.3. The set \u039e could be, for example, {0.5, 2.5, - 2.3, 3.14}, and\none of the hypotheses in our set would be [1, 4.5]. This hypothesis would label\nthe points 2.5 and 3.14 with a 1 and the points - 2.3 and 0.5 with a 0. This'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 125, 'page_label': '126'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 117\nset of hypotheses (single intervals on the real line) can arbitrarily classify any\ntwo points. But no single interval can classify three points such that the outer\ntwo are classi\ufb01ed as 1 and the inner one as 0. Therefore the VC dimension of\nsingle intervals on the real line is 2. As soon as we have many more than 2\ntraining patterns on the real line and provided we know that the classi\ufb01cation\nfunction we are trying to guess is a single interval, then we begin to have good\ngeneralization.\nFigure 8.3: Dichotomizing Points by an Interval\nThe VC dimension is a useful measure of the expressive power of a hypothesis\nset. Since any dichotomy of VCdim(H) or fewer patterns in general position inn\ndimensions can be achieved by some hypothesis in H, we must have many more\nthan VCdim(H) patterns in the training set in order that a hypothesis consistent\nwith the training set is su\ufb03ciently constrained to imply good generalization.\nOur examples have shown that the concept of VC dimension is not restricted\nto Boolean functions.\n8.3.4 Some Facts and Speculations About the VC Dimen-\nsion\n If there are a \ufb01nite number, |H|, of hypotheses in H, then:\nVCdim(H) \u2264log(|H|)\n The VC dimension of terms in n dimensions is n.\n Suppose we generalize our example that used a hypothesis set of single\nintervals on the real line. Now let us consider an n-dimensional feature\nspace and tests of the form Li \u2264xi \u2264Hi. We allow only one such test per\ndimension. A hypothesis space consisting of conjunctions of these tests\n(called axis-parallel hyper-rectangles) has VC dimension bounded by:\nn\u2264 VCdim \u22642n\n As we have already seen, TLUs with n inputs have a VC dimension of\nn+ 1.\n [Baum, 1994, page 438] gives experimental evidence for the proposition\nthat  ... multilayer [neural] nets have a VC dimension roughly equal to\ntheir total number of [adjustable] weights.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 126, 'page_label': '127'}, page_content='118 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n8.4 VC Dimension and PAC Learning\nThere are two theorems that connect the idea of VC dimension with PAC learn-\ning [Blumer, et al., 1990]. We state these here without proof.\nTheorem 8.3 (Blumer, et al.) A hypothesis space His PAC learnable i\ufb00 it\nhas \ufb01nite VC dimension.\nTheorem 8.4 A set of hypotheses, H, is properly PAC learnable if:\na. m\u2265(1/\u03b5) max [4 lg(2/\u03b4), 8 VCdim lg(13 /\u03b5)], and\nb. if there is an algorithm that outputs a hypothesis h\u03f5 Hconsistent with the\ntraining set in polynomial (in m and n) time.\nThe second of these two theorems improves the bound on the number of\ntraining patterns needed for linearly separable functions to one that is linear\nin n. In our previous example of how many training patterns were needed to\nensure PAC learnability of a linearly separable function if n= 50, \u03b5= 0.01, and\n\u03b4 = 0.01, we obtained m \u2265173,748. Using the Blumer, et al. result we would\nget m\u226552,756.\nAs another example of the second theorem, let us take Hto be the set of\nclosed intervals on the real line. The VC dimension is 2 (as shown previously).\nWith n= 50, \u03b5= 0.01, and \u03b4= 0.01, m\u226516,551 ensures PAC learnability.\nThere is also a theorem that gives a lower (necessary) bound on the number\nof training patterns required for PAC learning [Ehrenfeucht, et al., 1988]:\nTheorem 8.5 Any PAC learning algorithm must examine at least\n\u2126(1/\u03b5lg(1/\u03b4) + VCdim(H)) training patterns.\nThe di\ufb00erence between the lower and upper bounds is\nO(log(1/\u03b5)VCdim(H)/\u03b5).\n8.5 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 127, 'page_label': '128'}, page_content='Chapter 9\nUnsupervised Learning\n9.1 What is Unsupervised Learning?\nConsider the various sets of points in a two-dimensional space illustrated in Fig.\n9.1. The \ufb01rst set (a) seems naturally partitionable into two classes, while the\nsecond (b) seems di\ufb03cult to partition at all, and the third (c) is problematic.\nUnsupervised learning uses procedures that attempt to \ufb01nd natural partitions\nof patterns. There are two stages:\n Form an R-way partition of a set \u039e of unlabeled training patterns (where\nthe value of R, itself, may need to be induced from the patterns). The\npartition separates \u039e into R mutually exclusive and exhaustive subsets,\n\u039e1,..., \u039eR, called clusters.\n Design a classi\ufb01er based on the labels assigned to the training patterns by\nthe partition.\nWe will explain shortly various methods for deciding how many clusters there\nshould be and for separating a set of patterns into that many clusters. We can\nbase some of these methods, and their motivation, on minimum-description-\nlength (MDL) principles. In that setting, we assume that we want to encode\na description of a set of points, \u039e, into a message of minimal length. One\nencoding involves a description of each point separately; other, perhaps shorter,\nencodings might involve a description of clusters of points together with how\neach point in a cluster can be described given the cluster it belongs to. The\nspeci\ufb01c techniques described in this chapter do not explicitly make use of MDL\nprinciples, but the MDL method has been applied with success. One of the\nMDL-based methods, Autoclass II [Cheeseman, et al., 1988] discovered a new\nclassi\ufb01cation of stars based on the properties of infrared sources.\nAnother type of unsupervised learning involves \ufb01nding hierarchies of par-\ntitionings or clusters of clusters. A hierarchical partition is one in which \u039e is\n119'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 128, 'page_label': '129'}, page_content='120 CHAPTER 9. UNSUPERVISED LEARNING\na)  two clusters\nb) one cluster\nc) ?\nFigure 9.1: Unlabeled Patterns\ndivided into mutually exclusive and exhaustive subsets, \u039e 1,..., \u039eR; each set,\n\u039ei, ( i = 1 ,...,R ) is divided into mutually exclusive and exhaustive subsets,\nand so on. We show an example of such a hierarchical partition in Fig. 9.2.\nThe hierarchical form is best displayed as a tree, as shown in Fig. 9.3. The tip\nnodes of the tree can further be expanded into their individual pattern elements.\nOne application of such hierarchical partitions is in organizing individuals into\ntaxonomic hierarchies such as those used in botany and zoology.\n9.2 Clustering Methods\n9.2.1 A Method Based on Euclidean Distance\nMost of the unsupervised learning methods use a measure of similarity between\npatterns in order to group them into clusters. The simplest of these involves\nde\ufb01ning a distance between patterns. For patterns whose features are numeric,\nthe distance measure can be ordinary Euclidean distance between two points in\nan n-dimensional space.\nThere is a simple, iterative clustering method based on distance. It can\nbe described as follows. Suppose we have R randomly chosen cluster seekers,\nC1,..., CR. These are points in an n-dimensional space that we want to adjust\nso that they each move toward the center of one of the clusters of patterns.\nWe present the (unlabeled) patterns in the training set, \u039e, to the algorithm'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 129, 'page_label': '130'}, page_content='9.2. CLUSTERING METHODS 121\nU11\nU12\nU21\nU22\nU23\nU31\nU32\nU11 F U12 = U1\nU21 F U22 F U23 = U2\nU31 F U32 = U3\nU1 F U2 F U3 = U\nFigure 9.2: A Hierarchy of Clusters\none-by-one. For each pattern, Xi, presented, we \ufb01nd that cluster seeker, Cj,\nthat is closest to Xi and move it closer to Xi:\nCj \u2190\u2212(1 \u2212\u03b1j)Cj + \u03b1jXi\nwhere \u03b1j is a learning rate parameter for the j-th cluster seeker; it determines\nhow far Cj is moved toward Xi.\nRe\ufb01nements on this procedure make the cluster seekers move less far as\ntraining proceeds. Suppose each cluster seeker, Cj, has a mass, mj, equal to\nthe number of times that it has moved. As a cluster seekers mass increases it\nmoves less far towards a pattern. For example, we might set \u03b1j = 1/(1 + mj)\nand use the above rule together with mj \u2190\u2212mj+1. With this adjustment rule,\na cluster seeker is always at the center of gravity (sample mean) of the set of\npatterns toward which it has so far moved. Intuitively, if a cluster seeker ever\ngets within some reasonably well clustered set of patterns (and if that cluster\nseeker is the only one so located), it will converge to the center of gravity of\nthat cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 130, 'page_label': '131'}, page_content='122 CHAPTER 9. UNSUPERVISED LEARNING\nU\nU2\nU11 U12 U31 U32 U21 U22 U23\nU1 U3\nFigure 9.3: Displaying a Hierarchy as a Tree\nOnce the cluster seekers have converged, the classi\ufb01er implied by the now-\nlabeled patterns in \u039e can be based on a Voronoi partitioning of the space (based\non distances to the various cluster seekers). This kind of classi\ufb01cation, an ex-\nample of which is shown in Fig. 9.4, can be implemented by a linear machine.\nGeorgy Fedoseevich Voronoi, was a\nRussian mathematician who lived\nfrom 1868 to 1909. When basing partitioning on distance, we seek clusters whose patterns are\nas close together as possible. We can measure the badness, V, of a cluster of\npatterns, {Xi}, by computing its sample variance de\ufb01ned by:\nV = (1/K)\n\u2211\ni\n(Xi \u2212M)2\nwhere M is the sample mean of the cluster, which is de\ufb01ned to be:\nM = (1/K)\n\u2211\ni\nXi\nand K is the number of points in the cluster.\nWe would like to partition a set of patterns into clusters such that the sum of\nthe sample variances (badnesses) of these clusters is small. Of course if we have\none cluster for each pattern, the sample variances will all be zero, so we must\narrange that our measure of the badness of a partition must increase with the\nnumber of clusters. In this way, we can seek a trade-o\ufb00 between the variances of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 131, 'page_label': '132'}, page_content='9.2. CLUSTERING METHODS 123\nC1\nC2\nC3\nSeparating boundaries\nFigure 9.4: Minimum-Distance Classi\ufb01cation\nthe clusters and the number of them in a way somewhat similar to the principle\nof minimal description length discussed earlier.\nElaborations of our basic cluster-seeking procedure allow the number of clus-\nter seekers to vary depending on the distances between them and depending on\nthe sample variances of the clusters. For example, if the distance, dij, between\ntwo cluster seekers, Ci and Cj, ever falls below some threshold \u03b5, then we can\nreplace them both by a single cluster seeker placed at their center of gravity\n(taking into account their respective masses). In this way we can decrease the\noverall badness of a partition by reducing the number of clusters for compara-\ntively little penalty in increased variance.\nOn the other hand, if any of the cluster seekers, say Ci, de\ufb01nes a cluster\nwhose sample variance is larger than some amount \u03b4, then we can place a new\ncluster seeker, Cj, at some random location somewhat adjacent to Ci and reset\nthe masses of both Ci and Cj to zero. In this way the badness of the par-\ntition might ultimately decrease by decreasing the total sample variance with\ncomparatively little penalty for the additional cluster seeker. The values of the\nparameters \u03b5 and \u03b4 are set depending on the relative weights given to sample\nvariances and numbers of clusters.\nIn distance-based methods, it is important to scale the components of the\npattern vectors. The variation of values along some dimensions of the pattern\nvector may be much di\ufb00erent than that of other dimensions. One commonly\nused technique is to compute the standard deviation (i.e., the square root of the\nvariance) of each of the components over the entire training set and normalize\nthe values of the components so that their adjusted standard deviations are\nequal.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 132, 'page_label': '133'}, page_content='124 CHAPTER 9. UNSUPERVISED LEARNING\n9.2.2 A Method Based on Probabilities\nSuppose we have a partition of the training set, \u039e, into R mutually exclusive\nand exhaustive clusters, C1,...,C R. We can decide to which of these clusters\nsome arbitrary pattern, X, should be assigned by selecting the Ci for which\nthe probability, p(Ci|X), is largest, providing p(Ci|X) is larger than some \ufb01xed\nthreshold, \u03b4. As we saw earlier, we can use Bayes rule and base our decision on\nmaximizing p(X|Ci)p(Ci). Assuming conditional independence of the pattern\ncomponents, xi, the quantity to be maximized is:\nS(X,Ci) = p(x1|Ci)p(x2|Ci) ···p(xn|Ci)p(Ci)\nThe p(xj|Ci) can be estimated from the sample statistics of the patterns in the\nclusters and then used in the above expression. (Recall the linear form that this\nformula took in the case of binary-valued components.)\nWe call S(X,Ci) the similarity of X to a cluster, Ci, of patterns. Thus, we\nassign X to the cluster to which it is most similar, providing the similarity is\nlarger than \u03b4.\nJust as before, we can de\ufb01ne the sample mean of a cluster, Ci, to be:\nMi = (1/Ki)\n\u2211\nXj\u03f5 Ci\nXj\nwhere Ki is the number of patterns in Ci.\nWe can base an iterative clustering algorithm on this measure of similarity\n[Mahadevan & Connell, 1992]. It can be described as follows:\na. Begin with a set of unlabeled patterns \u039e and an empty list, L, of clusters.\nb. For the next pattern, X, in \u039e, compute S(X,Ci) for each cluster, Ci.\n(Initially, these similarities are all zero.) Suppose the largest of these\nsimilarities is S(X,Cmax).\n(a) If S(X,Cmax) >\u03b4, assign X to Cmax. That is,\nCmax \u2190\u2212Cmax \u222a{X}\nUpdate the sample statisticsp(x1|Cmax),p(x2|Cmax),...,p (xn|Cmax),\nand p(Cmax) to take the new pattern into account. Go to 3.\n(b) If S(X,Cmax) \u2264\u03b4, create a new cluster, Cnew = {X}and add Cnew\nto L. Go to 3.\nc. Merge any existing clusters, Ci and Cj if ( Mi \u2212Mj)2 < \u03b5. Compute\nnew sample statistics p(x1|Cmerge),p(x2|Cmerge),...,p (xn|Cmerge), and\np(Cmerge) for the merged cluster, Cmerge = Ci \u222aCj.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 133, 'page_label': '134'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 125\nd. If the sample statistics of the clusters have not changed during an entire\niteration through \u039e, then terminate with the clusters in L; otherwise go\nto 2.\nThe value of the parameter \u03b4 controls the number of clusters. If \u03b4 is high,\nthere will be a large number of clusters with few patterns in each cluster. For\nsmall values of \u03b4, there will be a small number of clusters with many patterns in\neach cluster. Similarly, the larger the value of \u03b5, the smaller the number clusters\nthat will be found.\nDesigning a classi\ufb01er based on the patterns labeled by the partitioning is\nstraightforward. We assign any pattern, X, to that category that maximizes\nS(X,Ci). Mention k-means and EM\nmethods.\n9.3 Hierarchical Clustering Methods\n9.3.1 A Method Based on Euclidean Distance\nSuppose we have a set, \u039e, of unlabeled training patterns. We can form a hi-\nerarchical classi\ufb01cation of the patterns in \u039e by a simple agglomerative method.\n(The description of this algorithm is based on an unpublished manuscript by\nPat Langley.) Our description here gives the general idea; we leave it to the\nreader to generate a precise algorithm.\nWe \ufb01rst compute the Euclidean distance between all pairs of patterns in \u039e.\n(Again, appropriate scaling of the dimensions is assumed.) Suppose the smallest\ndistance is between patterns Xi and Xj. We collect Xi and Xj into a cluster,\nC, eliminate Xi and Xj from \u039e and replace them by a cluster vector, C, equal\nto the average of Xi and Xj. Next we compute the Euclidean distance again\nbetween all pairs of points in \u039e. If the smallest distance is between pairs of\npatterns, we form a new cluster, C, as before and replace the pair of patterns\nin \u039e by their average. If the shortest distance is between a pattern, Xi, and\na cluster vector, Cj (representing a cluster, Cj), we form a new cluster, C,\nconsisting of the union of Cj and {Xi}. In this case, we replace Cj and Xi\nin \u039e by their (appropriately weighted) average and continue. If the shortest\ndistance is between two cluster vectors, Ci and Cj, we form a new cluster, C,\nconsisting of the union of Ci and Cj. In this case, we replace Ci and Cj by their\n(appropriately weighted) average and continue. Since we reduce the number of\npoints in \u039e by one each time, we ultimately terminate with a tree of clusters\nrooted in the cluster containing all of the points in the original training set.\nAn example of how this method aggregates a set of two dimensional patterns\nis shown in Fig. 9.5. The numbers associated with each cluster indicate the order\nin which they were formed. These clusters can be organized hierarchically in a\nbinary tree with cluster 9 as root, clusters 7 and 8 as the two descendants of the\nroot, and so on. A ternary tree could be formed instead if one searches for the\nthree points in \u039e whose triangle de\ufb01ned by those patterns has minimal area.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 134, 'page_label': '135'}, page_content='126 CHAPTER 9. UNSUPERVISED LEARNING\n1\n2 3\n5\n4\n6\n7\n8\n9\nFigure 9.5: Agglommerative Clustering\n9.3.2 A Method Based on Probabilities\nA probabilistic quality measure for partitions\nWe can develop a measure of the goodness of a partitioning based on how\naccurately we can guess a pattern given only what partition it is in. Suppose\nwe are given a partitioning of \u039e into R classes, C1,...,C R. As before, we can\ncompute the sample statistics p(xi|Ck) which give probability values for each\ncomponent given the class assigned to it by the partitioning. Suppose each\ncomponent xi of X can take on the values vij, where the index j steps over the\ndomain of that component. We use the notation pi(vij|Ck) = probability(xi =\nvij|Ck).\nSuppose we use the following probabilistic guessing rule about the values\nof the components of a vector X given only that it is in class k. Guess that\nxi = vij with probability pi(vij|Ck). Then, the probability that we guess the\ni-th component correctly is:\n\u2211\nj\nprobability(guess is vij)pi(vij|Ck) =\n\u2211\nj\n[pi(vij|Ck)]2\nThe average number of (the n) components whose values are guessed correctly\nby this method is then given by the sum of these probabilities over all of the\ncomponents of X:\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 135, 'page_label': '136'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 127\nGiven our partitioning into R classes, the goodness measure, G, of this parti-\ntioning is the average of the above expression over all classes:\nG=\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nwhere p(Ck) is the probability that a pattern is in class Ck. In order to penalize\nthis measure for having a large number of classes, we divide it by R to get an\noverall quality measure of a partitioning:\nZ = (1/R)\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nWe give an example of the use of this measure for a trivially simple\nclustering of the four three-dimensional patterns shown in Fig. 9.6. There\nare several di\ufb00erent partitionings. Lets evaluate Z values for the follow-\ning ones: P1 = {a,b,c,d }, P2 = {{a,b},{c,d}}, P3 = {{a,c},{b,d}}, and\nP4 = {{a},{b},{c},{d}}. The \ufb01rst, P1, puts all of the patterns into a single\ncluster. The sample probabilities pi(vi1 = 1) and pi(vi0 = 0) are all equal to 1/2\nfor each of the three components. Summing over the values of the components\n(0 and 1) gives (1 /2)2 + (1/2)2 = 1 /2. Summing over the three components\ngives 3/2. Averaging over all of the clusters (there is just one) also gives 3 /2.\nFinally, dividing by the number of clusters produces the \ufb01nal Z value of this\npartition, Z(P1) = 3/2.\nThe second partition, P2, gives the following sample probabilities:\np1(v11 = 1|C1) = 1\np2(v21 = 1|C1) = 1/2\np3(v31 = 1|C1) = 1\nSumming over the values of the components (0 and 1) gives (1) 2 + (0)2 = 1 for\ncomponent 1, (1 /2)2 + (1/2)2 = 1/2 for component 2, and (1) 2 + (0)2 = 1 for\ncomponent 3. Summing over the three components gives 2 1 /2 for class 1. A\nsimilar calculation also gives 2 1 /2 for class 2. Averaging over the two clusters\nalso gives 2 1 /2. Finally, dividing by the number of clusters produces the \ufb01nal\nZ value of this partition, Z(P2) = 1 1/4, not quite as high as Z(P1).\nSimilar calculations yield Z(P3) = 1 and Z(P4) = 3 /4, so this method of\nevaluating partitions would favor placing all patterns in a single cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 136, 'page_label': '137'}, page_content='128 CHAPTER 9. UNSUPERVISED LEARNING\nx2\nx3\nx1\nab\ncd\nFigure 9.6: Patterns in 3-Dimensional Space\nAn iterative method for hierarchical clustering\nEvaluating all partitionings of mpatterns and then selecting the best would be\ncomputationally intractable. The following iterative method is based on a hi-\nerarchical clustering procedure called COBWEB [Fisher, 1987]. The procedure\ngrows a tree each node of which is labeled by a set of patterns. At the end\nof the process, the root node contains all of the patterns in \u039e. The successors\nof the root node will contain mutually exclusive and exhaustive subsets of \u039e.\nIn general, the successors of a node, \u03b7, are labeled by mutually exclusive and\nexhaustive subsets of the pattern set labelling node \u03b7. The tips of the tree will\ncontain singleton sets. The method uses Z values to place patterns at the vari-\nous nodes; sample statistics are used to update the Z values whenever a pattern\nis placed at a node. The algorithm is as follows:\na. We start with a tree whose root node contains all of the patterns in \u039e\nand a single empty successor node. We arrange that at all times dur-\ning the process every non-empty node in the tree has (besides any other\nsuccessors) exactly one empty successor.\nb. Select a pattern Xi in \u039e (if there are no more patterns to select, terminate).\nc. Set µ to the root node.\nd. For each of the successors of µ(including the empty successor!), calculate\nthe best host for Xi. A best host is determined by tentatively placing\nXi in one of the successors and calculating the resulting Z value for each'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 137, 'page_label': '138'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 129\none of these ways of accomodating Xi. The best host corresponds to the\nassignment with the highest Z value.\ne. If the best host is an empty node, \u03b7, we place Xi in \u03b7, generate an empty\nsuccessor node of \u03b7, generate an empty sibling node of \u03b7, and go to 2.\nf. If the best host is a non-empty, singleton (tip) node, \u03b7, we place Xi in \u03b7,\ncreate one successor node of \u03b7 containing the singleton pattern that was\nin \u03b7, create another successor node of \u03b7 containing Xi, create an empty\nsuccessor node of \u03b7, create empty successor nodes of the new non-empty\nsuccessors of \u03b7, and go to 2.\ng. If the best host is a non-empty, non-singleton node, \u03b7, we place Xi in \u03b7,\nset µ to \u03b7, and go to 4.\nThis process is rather sensitive to the order in which patterns are presented.\nTo make the \ufb01nal classi\ufb01cation tree less order dependent, the COBWEB proce-\ndure incorporates node merging and splitting.\nNode merging:\nIt may happen that two nodes having the same parent could be merged with\nan overall increase in the quality of the resulting classi\ufb01cation performed by the\nsuccessors of that parent. Rather than try all pairs to merge, a good heuristic\nis to attempt to merge the two best hosts. When such a merging improves the\nZ value, a new node containing the union of the patterns in the merged nodes\nreplaces the merged nodes, and the two nodes that were merged are installed\nas successors of the new node.\nNode splitting:\nA heuristic for node splitting is to consider replacing the best host among a\ngroup of siblings by that hosts successors. This operation is performed only if\nit increases the Z value of the classi\ufb01cation performed by a group of siblings.\nExample results from COBWEB\nWe mention two experiments with COBWEB. In the \ufb01rst, the program at-\ntempted to \ufb01nd two categories (we will call them Class 1 and Class 2) of United\nStates Senators based on their votes ( yes or no) on six issues. After the clus-\nters were established, the majority vote in each class was computed. These are\nshown in the table below.\nIssue Class 1 Class 2\nToxic Waste yes no\nBudget Cuts yes no\nSDI Reduction no yes\nContra Aid yes no\nLine-Item Veto yes no\nMX Production yes no'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 138, 'page_label': '139'}, page_content='130 CHAPTER 9. UNSUPERVISED LEARNING\nIn the second experiment, the program attempted to classify soybean dis-\neases based on various characteristics. COBWEB grouped the diseases in the\ntaxonomy shown in Fig. 9.7.\nN0\nsoybean\ndiseases\nN1\n  Diaporthe\nStem Canker\nN2\nCharcoal\n     Rot\nN3\nN31\nRhizoctonia\n       Rot\nN32\nPhytophthora\n       Rot\nFigure 9.7: Taxonomy Induced for Soybean Diseases\n9.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 139, 'page_label': '140'}, page_content='Chapter 10\nTemporal-Di\ufb00erence\nLearning\n10.1 Temporal Patterns and Prediction Prob-\nlems\nIn this chapter, we consider problems in which we wish to learn to predict the\nfuture value of some quantity, say z, from an n-dimensional input pattern, X.\nIn many of these problems, the patterns occur in temporal sequence, X1, X2,\n. . ., Xi, Xi+1, ... , Xm, and are generated by a dynamical process. The\ncomponents of Xi are features whose values are available at time, t = i. We\ndistinguish two kinds of prediction problems. In one, we desire to predict the\nvalue of z at time t = i+ 1 based on input Xi for every i. For example, we\nmight wish to predict some aspects of tomorrows weather based on a set of\nmeasurements made today. In the other kind of prediction problem, we desire\nto make a sequence of predictions about the value of z at some \ufb01xed time, say\nt= m+ 1, based on each of the Xi, i= 1,...,m . For example, we might wish\nto make a series of predictions about some aspect of the weather on next New\nYears Day, based on measurements taken every day before New Years. Sutton\n[Sutton, 1988] has called this latter problem, multi-step prediction, and that is\nthe problem we consider here. In multi-step prediction, we might expect that\nthe prediction accuracy should get better and better as i increases toward m.\n10.2 Supervised and Temporal-Di\ufb00erence Meth-\nods\nA training method that naturally suggests itself is to use the actual value of\nz at time m+ 1 (once it is known) in a supervised learning procedure using a\n131'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 140, 'page_label': '141'}, page_content='132 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nsequence of training patterns, {X1, X2, ... , Xi, Xi+1, ... , Xm}. That is, we\nseek to learn a function, f, such that f(Xi) is as close as possible to zfor each i.\nTypically, we would need a training set, \u039e, consisting of several such sequences.\nWe will show that a method that is better than supervised learning for some\nimportant problems is to base learning on the di\ufb00erence between f(Xi+1) and\nf(Xi) rather than on the di\ufb00erence between zand f(Xi). Such methods involve\nwhat is called temporal-di\ufb00erence (TD) learning.\nWe assume that our prediction, f(X), depends on a vector of modi\ufb01able\nweights, W. To make that dependence explicit, we write f(X,W). For su-\npervised learning, we consider procedures of the following type: For each Xi,\nthe prediction f(Xi,W) is computed and compared to z, and the learning rule\n(whatever it is) computes the change, (\u2206 Wi), to be made to W. Then, taking\ninto account the weight changes for each pattern in a sequence all at once after\nhaving made all of the predictions with the old weight vector, we change W as\nfollows:\nW \u2190\u2212W +\nm\u2211\ni=1\n(\u2206W)i\nWhenever we are attempting to minimize the squared error between z and\nf(Xi,W) by gradient descent, the weight-changing rule for each pattern is:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nwhere c is a learning rate parameter, fi is our prediction of z, f(Xi,W),\nat time t = i, and \u2202fi\n\u2202W is, by de\ufb01nition, the vector of partial derivatives\n( \u2202fi\n\u2202w1\n,..., \u2202fi\n\u2202wi\n,..., \u2202fi\n\u2202wn\n) in which the wi are the individual components of W.\n(The expression \u2202fi\n\u2202W is sometimes written \u2207Wfi.) The reader will recall that\nwe used an equivalent expression for (\u2206 W)i in deriving the backpropagation\nformulas used in training multi-layer neural networks.\nThe Widrow-Ho\ufb00 rule results when f(X,W) = X W. Then:\n(\u2206W)i = c(z\u2212fi)Xi\nAn interesting form for (\u2206 W)i can be developed if we note that\n(z\u2212fi) =\nm\u2211\nk=i\n(fk+1 \u2212fk)\nwhere we de\ufb01ne fm+1 = z. Substituting in our formula for (\u2206 W)i yields:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 141, 'page_label': '142'}, page_content='10.2. SUPERVISED AND TEMPORAL-DIFFERENCE METHODS 133\n= c\u2202fi\n\u2202W\nm\u2211\nk=i\n(fk+1 \u2212fk)\nIn this form, instead of using the di\ufb00erence between a prediction and the value\nof z, we use the di\ufb00erences between successive predictionsthus the phrase\ntemporal-di\ufb00erence (TD) learning.\nIn the case when f(X,W) = X W, the temporal di\ufb00erence form of the\nWidrow-Ho\ufb00 rule is:\n(\u2206W)i = cXi\nm\u2211\nk=i\n(fk+1 \u2212fk)\nOne reason for writing (\u2206 W)i in temporal-di\ufb00erence form is to permit an\ninteresting generalization as follows:\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nwhere 0 < \u03bb\u22641. Here, the \u03bb term gives exponentially decreasing weight to\ndi\ufb00erences later in time than t = i. When \u03bb = 1, we have the same rule with\nwhich we beganweighting all di\ufb00erences equally, but as\u03bb\u21920, we weight only\nthe (fi+1 \u2212fi) di\ufb00erence. With the \u03bb term, the method is called TD( \u03bb).\nIt is interesting to compare the two extreme cases:\nFor TD(0):\n(\u2206W)i = c(fi+1 \u2212fi) \u2202fi\n\u2202W\nFor TD(1):\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nBoth extremes can be handled by the same learning mechanism; only the error\nterm is di\ufb00erent. In TD(0), the error is the di\ufb00erence between successive predic-\ntions, and in TD(1), the error is the di\ufb00erence between the \ufb01nally revealed value\nof z and the prediction. Intermediate values of \u03bb take into account di\ufb00erently\nweighted di\ufb00erences between future pairs of successive predictions.\nOnly TD(1) can be considered a puresupervised learning procedure, sensitive\nto the \ufb01nal value ofzprovided by the teacher. For\u03bb< 1, we have various degrees\nof unsupervised learning, in which the prediction function strives to make each\nprediction more like successive ones (whatever they might be). We shall soon\nsee that these unsupervised procedures result in better learning than do the\nsupervised ones for an important class of problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 142, 'page_label': '143'}, page_content='134 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n10.3 Incremental Computation of the (\u2206W)i\nWe can rewrite our formula for (\u2206 W)i, namely\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nto allow a type of incremental computation. First we write the expression for\nthe weight change rule that takes into account all of the (\u2206 W)i:\nW \u2190\u2212W +\nm\u2211\ni=1\nc\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nInterchanging the order of the summations yields:\nW \u2190\u2212W +\nm\u2211\nk=1\nc\nk\u2211\ni=1\n\u03bb(k\u2212i)(fk+1 \u2212fk) \u2202fi\n\u2202W\n= W +\nm\u2211\nk=1\nc(fk+1 \u2212fk)\nk\u2211\ni=1\n\u03bb(k\u2212i) \u2202fi\n\u2202W\nInterchanging the indices k and i \ufb01nally yields:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nIf, as earlier, we want to use an expression of the formW \u2190\u2212W+\u2211m\ni=1(\u2206W)i,\nwe see that we can write:\n(\u2206W)i = c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nNow, if we let ei = \u2211i\nk=1 \u03bb(i\u2212k) \u2202fk\n\u2202W , we can develop a computationally e\ufb03cient\nrecurrence equation for ei+1 as follows:\nei+1 =\ni+1\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W\n= \u2202fi+1\n\u2202W +\ni\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 143, 'page_label': '144'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 135\n= \u2202fi+1\n\u2202W + \u03bbei\nRewriting (\u2206W)i in these terms, we obtain:\n(\u2206W)i = c(fi+1 \u2212fi)ei\nwhere:\ne1 = \u2202f1\n\u2202W\ne2 = \u2202f2\n\u2202W + \u03bbe1\netc.\nQuoting Sutton [Sutton, 1988, page 15] (about a di\ufb00erent equation, but the\nquote applies equally well to this one):\n... this equation can be computed incrementally, because each\n(\u2206W)i depends only on a pair of successive predictions and on the\n[weighted] sum of all past values for \u2202fi\n\u2202W . This saves substantially on\nmemory, because it is no longer necessary to individually remember\nall past values of \u2202fi\n\u2202W .\n10.4 An Experiment with TD Methods\nTD prediction methods [especially TD(0)] are well suited to situations in which\nthe patterns are generated by a dynamic process. In that case, sequences of\ntemporally presented patterns contain important information that is ignored\nby a conventional supervised method such as the Widrow-Ho\ufb00 rule. Sutton\n[Sutton, 1988, page 19] gives an interesting example involving a random walk,\nwhich we repeat here. In Fig. 10.1, sequences of vectors, X, are generated as\nfollows: We start with vector XD; the next vector in the sequence is equally\nlikely to be one of the adjacent vectors in the diagram. If the next vector is\nXC (or XE), the next one after that is equally likely to be one of the vectors\nadjacent to XC (or XE). When XB is in the sequence, it is equally likely that\nthe sequence terminates with z = 0 or that the next vector is XC. Similarly,\nwhen XF is in the sequence, it is equally likely that the sequence terminates\nwith z= 1 or that the next vector is XE. Thus the sequences are random, but\nthey always start with XD. Some sample sequences are shown in the \ufb01gure.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 144, 'page_label': '145'}, page_content='136 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\nz = 0 z = 1\nXB XC XD XE XF\nTypical Sequences:\nXDXCXDXEXF  1\nXDXCXBXCXDXEXDXEXF  1\nXDXEXDXCXB  0\nFigure 10.1: A Markov Process\nThis random walk is an example of a Markov process; transitions from state i\nto state j occur with probabilities that depend only on i and j.\nGiven a set of sequences generated by this process as a training set, we want\nto be able to predict the value of z for each X in a test sequence. We assume\nthat the learning system does not know the transition probabilities.\nFor his experiments with this process, Sutton used a linear predictor, that\nis f(X,W) = X W. The learning problem is to \ufb01nd a weight vector, W, that\nminimizes the mean-squared error betweenzand the predicted value of z. Given\nthe \ufb01ve di\ufb00erent values that X can take on, we have the following predictions:\nf(XB) = w1, f(XC) = w2, f(XD) = w3, f(XE) = w4, f(XF) = w5, where\nwi is the i-th component of the weight vector. (Note that the values of the\npredictions are not limited to 1 or 0even though z can only have one of\nthose valuesbecause we are minimizing mean-squared error.) After training,\nthese predictions will be compared with the optimal onesgiven the transition\nprobabilities.\nThe experimental setup was as follows: ten random sequences were generated\nusing the transition probabilities. Each of these sequences was presented in turn\nto a TD(\u03bb) method for various values of \u03bb. Weight vector increments, (\u2206 W)i,\nwere computed after each pattern presentation but no weight changes were\nmade until all ten sequences were presented. The weight vector increments were\nsummed after all ten sequences were presented, and this sum was used to change\nthe weight vector to be used for the next pass through the ten sequences. This\nprocess was repeated over and over (using the same training sequences) until\n(quoting Sutton) the procedure no longer produced any signi\ufb01cant changes in\nthe weight vector. For small c, the weight vector always converged in this way,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 145, 'page_label': '146'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 137\nand always to the same \ufb01nal value [for 100 di\ufb00erent training sets of ten random\nsequences], independent of its initial value. (Even though, for \ufb01xed, small c,\nthe weight vector always converged to the same vector, it might converge to a\nsomewhat di\ufb00erent vector for di\ufb00erent values of c.)\nAfter convergence, the predictions made by the \ufb01nal weight vector are com-\npared with the optimal predictions made using the transition probabilities.\nThese optimal predictions are simply p(z= 1|X). We can compute these proba-\nbilities to be 1/6, 1/3, 1/2, 2/3, and 5/6 forXB, XC, XD, XE, XF, respectively.\nThe root-mean-squared di\ufb00erences between the best learned predictions (over\nall c) and these optimal ones are plotted in Fig. 10.2 for seven di\ufb00erent values\nof \u03bb. (For each data point, the standard error is approximately \u03c3= 0.01.)\n0.10\n0.12\n0.14\n0.16\n0.18\n0.20\n0.0 0.1 0.3 0.5 0.7 0.9 1.0\nh\nError using\nbest c\nWidrow-Hoff\nTD(1)\nTD(0)\n(Adapted from Sutton, p. 20, 1988)\nFigure 10.2: Prediction Errors for TD( \u03bb)\nNotice that the Widrow-Ho\ufb00 procedure does not perform as well as other\nversions of TD(\u03bb) for \u03bb< 1! Quoting [Sutton, 1988, page 21]:\nThis result contradicts conventional wisdom. It is well known that,\nunder repeated presentations, the Widrow-Ho\ufb00 procedure minimizes\nthe RMS error between its predictions and the actual outcomes in\nthe training set ([Widrow & Stearns, 1985]). How can it be that this\noptimal method peformed worse than all the TD methods for \u03bb <\n1? The answer is that the Widrow-Ho\ufb00 procedure only minimizes\nerror on the training set ; it does not necessarily minimize error for\nfuture experience. [Later] we prove that in fact it is linear TD(0)\nthat converges to what can be considered the optimal estimates for'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 146, 'page_label': '147'}, page_content='138 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nmatching future experiencethose consistent with the maximum-\nlikelihood estimate of the underlying Markov process.\n10.5 Theoretical Results\nIt is possible to analyze the performance of the linear-prediction TD(\u03bb) methods\non Markov processes. We state some theorems here without proof.\nTheorem 10.1 (Sutton, page 24, 1988) For any absorbing Markov chain,\nand for any linearly independent set of observation vectors {Xi}for the non-\nterminal states, there exists an \u03b5> 0 such that for all positive c<\u03b5 and for any\ninitial weight vector, the predictions of linear TD(0) (with weight updates after\neach sequence) converge in expected value to the optimal (maximum likelihood)\npredictions of the true process.\nEven though the expected values of the predictions converge, the predictions\nthemselves do not converge but vary around their expected values depending on\ntheir most recent experience. Sutton conjectures that if c is made to approach\n0 as training progresses, the variance of the predictions will approach 0 also.\nDayan [Dayan, 1992] has extended the result of Theorem 9.1 to TD( \u03bb) for\narbitrary \u03bb between 0 and 1. (Also see [Dayan & Sejnowski, 1994].)\n10.6 Intra-Sequence Weight Updating\nOur standard weight updating rule for TD( \u03bb) methods is:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere the weight update occurs after an entire sequence is observed. To make\nthe method truly incremental (in analogy with weight updating rules for neural\nnets), it would be desirable to change the weight vector after every pattern\npresentation. The obvious extension is:\nWi+1 \u2190\u2212Wi + c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere fi+1 is computed before making the weight change; that is, fi+1 =\nf(Xi+1,Wi). But that would make fi = f(Xi,Wi\u22121), and such a rule would\nmake the prediction di\ufb00erence, namely ( fi+1 \u2212fi), sensitive both to changes in\nX and changes in W and could lead to instabilities. Instead, we modify the rule\nso that, for every pair of predictions, fi+1 = f(Xi+1,Wi) and fi = f(Xi,Wi).\nThis version of the rule has been used in practice with excellent results.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 147, 'page_label': '148'}, page_content='10.6. INTRA-SEQUENCE WEIGHT UPDATING 139\nFor TD(0) and linear predictors, the rule is:\nWi+1 = Wi + c(fi+1 \u2212fi)Xi\nThe rule is implemented as follows:\na. Initialize the weight vector, W, arbitrarily.\nb. For i= 1,...,m , do:\n(a) fi \u2190\u2212Xi W\n(We compute fi anew each time through rather than use the value\nof fi+1 the previous time through.)\n(b) fi+1 \u2190\u2212Xi+1 W\n(c) di+1 \u2190\u2212fi+1 \u2212fi\n(d) W \u2190\u2212W + c di+1Xi\n(If fi were computed again with this changed weight vector, its value\nwould be closer to fi+1 as desired.)\nThe linear TD(0) method can be regarded as a technique for training a\nvery simple network consisting of a single dot product unit (and no threshold\nor sigmoid function). TD methods can also be used in combination with back-\npropagation to train neural networks. For TD(0) we change the network weights\naccording to the expression:\nWi+1 = Wi + c(fi+1 \u2212fi) \u2202fi\n\u2202W\nThe only change that must be made to the standard backpropagation weight-\nchanging rule is that the di\ufb00erence term between the desired output and the\noutput of the unit in the \ufb01nal ( k-th) layer, namely (d\u2212f(k)), must be replaced\nby a di\ufb00erence term between successive outputs, ( fi+1 \u2212fi). This change has a\ndirect e\ufb00ect only on the expression for \u03b4(k) which becomes:\n\u03b4(k) = 2(f\u2032(k) \u2212f(k))f(k)(1 \u2212f(k))\nwhere f\u2032(k) and f(k) are two successive outputs of the network.\nThe weight changing rule for the i-th weight vector in the j-th layer of weights\nhas the same form as before, namely:\nW(j)\ni \u2190\u2212W(j)\ni + c\u03b4(j)\ni X(j\u22121)\nwhere the \u03b4(j)\ni are given recursively by:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nand w(j+1)\nil is the l-th component of the i-th weight vector in the (j+1)-th layer\nof weights. Of course, here also it is assumed that f\u2032(k) and f(k) are computed\nusing the same weights and then the weights are changed. In the next section\nwe shall see an interesting example of this application of TD learning.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 148, 'page_label': '149'}, page_content='140 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n10.7 An Example Application: TD-gammon\nA program called TD-gammon [Tesauro, 1992] learns to play backgammon by\ntraining a neural network via temporal-di\ufb00erence methods. The structure of\nthe neural net, and its coding is as shown in Fig. 10.3. The network is trained\nto minimize the error between actual payo\ufb00 and estimated payo\ufb00, where the\nactual payo\ufb00 is de\ufb01ned to be df = p1 + 2p2 \u2212p3 \u22122p4, and the pi are the actual\nprobabilities of the various outcomes as de\ufb01ned in the \ufb01gure.\n. . . p3 = pr(black wins)\np4 = pr(black gammons)\np1 = pr(white wins)\np2 = pr(white gammons)\nestimated payoff:\nd = p1 + 2p2 < p3 < 2p4\nno. of white\non cell 1\nno. on bar,\noff board,\nand who\nmoves\n198 inputs\n1\n2\n3\n# > 3\n. . .\nup to 40 hidden units\n2 x 24\ncells\n4 output units\nhidden and output units are sigmoids\nlearning rate:  c = 0.1; initial weights chosen\nrandomly between <0.5 and +0.5.\nestimated probabilities:\nFigure 10.3: The TD-gammon Network\nTD-gammon learned by using the network to select that move that results\nin the best predicted payo\ufb00. That is, at any stage of the game some \ufb01nite set of\nmoves is possible and these lead to the set, {X}, of new board positions. Each\nmember of this set is evaluated by the network, and the one with the largest'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 149, 'page_label': '150'}, page_content='10.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 141\npredicted payo\ufb00 is selected if it is whites move (and the smallest if it is blacks).\nThe move is made, and the network weights are adjusted to make the predicted\npayo\ufb00 from the original position closer to that of the resulting position.\nThe weight adjustment procedure combines temporal-di\ufb00erence (TD( \u03bb))\nlearning with backpropagation. If dt is the networks estimate of the payo\ufb00\nat time t (before a move is made), and dt+1 is the estimate at time t+ 1 (after\na move is made), the weight adjustment rule is:\n\u2206Wt = c(dt+1 \u2212dt)\nt\u2211\nk=1\n\u03bbt\u2212k \u2202dk\n\u2202W\nwhere Wt is a vector of all weights in the network at time t, and \u2202dk\n\u2202W is the\ngradient of dk in this weight space. (For a layered, feedforward network, such\nas that of TD-gammon, the weight changes for the weight vectors in each layer\ncan be expressed in the usual manner.)\nTo make the special cases clear, recall that for TD(0), the network would be\ntrained so that, for all t, its output, dt, for input Xt tended toward its expected\noutput, dt+1, for input Xt+1. For TD(1), the network would be trained so that,\nfor all t, its output, dt, for input Xt tended toward the expected \ufb01nal payo\ufb00,\ndf, given that input. The latter case is the same as the Widrow-Ho\ufb00 rule.\nAfter about 200,000 games the following results were obtained. TD-gammon\n(with 40 hidden units, \u03bb= 0.7, and c= 0.1) won 66.2% of 10,000 games against\nSUN Microsystems Gammontool and 55% of 10,000 games against a neural\nnetwork trained using expert moves. Commenting on a later version of TD-\ngammon, incorporating special features as inputs, Tesauro said: It appears to\nbe the strongest program ever seen by this author.\n10.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 150, 'page_label': '151'}, page_content='142 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 151, 'page_label': '152'}, page_content='Chapter 11\nDelayed-Reinforcement\nLearning\n11.1 The General Problem\nImagine a robot that exists in an environment in which it can sense and act.\nSuppose (as an extreme case) that it has no idea about the e\ufb00ects of its actions.\nThat is, it doesnt know how acting will change its sensory inputs. Along with\nits sensory inputs are rewards, which it occasionally receives. How should it\nchoose its actions so as to maximize its rewards over the long run? To maximize\nrewards, it will need to be able to predict how actions change inputs, and in\nparticular, how actions lead to rewards.\nWe formalize the problem in the following way: The robot exists in an\nenvironment consisting of a set,S, of states. We assume that the robots sensory\napparatus constructs an input vector, X, from the environment, which informs\nthe robot about which state the environment is in. For the moment, we will\nassume that the mapping from states to vectors is one-to-one, and, in fact, will\nuse the notation X to refer to the state of the environment as well as to the\ninput vector. When presented with an input vector, the robot decides which\naction from a set, A, of actions to perform. Performing the action produces an\ne\ufb00ect on the environmentmoving it to a new state. The new state results in\nthe robot perceiving a new input vector, and the cycle repeats. We assume a\ndiscrete time model; the input vector at time t = i is Xi, the action taken at\nthat time is ai, and the expected reward, ri, received at t = i depends on the\naction taken and on the state, that is ri = r(Xi,ai). The learners goal is to \ufb01nd\na policy, \u03c0(X), that maps input vectors to actions in such a way that maximizes\nrewards accumulated over time. This type of learning is called reinforcement\nlearning. The learner must \ufb01nd the policy by trial and error; it has no initial\nknowledge of the e\ufb00ects of its actions. The situation is as shown in Fig. 11.1.\n143'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 152, 'page_label': '153'}, page_content='144 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nXi\nri\nLearner\nEnvironment\n(reward)\n(state)\n(action)\nai\nFigure 11.1: Reinforcement Learning\n11.2 An Example\nA grid world, such as the one shown in Fig. 11.2 is often used to illustrate\nreinforcement learning. Imagine a robot initially in cell (2,3). The robot receives\ninput vector ( x1,x2) telling it what cell it is in; it is capable of four actions,\nn,e,s,w moving the robot one cell up, right, down, or left, respectively. It is\nrewarded one negative unit whenever it bumps into the wall or into the blocked\ncells. For example, if the input to the robot is (1,3), and the robot chooses\naction w, the next input to the robot is still (1,3) and it receives a reward of\n\u22121. If the robot lands in the cell marked G (for goal), it receives a reward of\n+10. Lets suppose that whenever the robot lands in the goal cell and gets its\nreward, it is immediately transported out to some random cell, and the quest\nfor reward continues.\nA policy for our robot is a speci\ufb01cation of what action to take for every one\nof its inputs, that is, for every one of the cells in the grid. For example, a com-\nponent of such a policy would be when in cell (3,1), move right. An optimal\npolicy is a policy that maximizes long-term reward. One way of displaying a\npolicy for our grid-world robot is by an arrow in each cell indicating the direc-\ntion the robot should move when in that cell. In Fig. 11.3, we show an optimal\npolicy displayed in this manner. In this chapter we will describe methods for\nlearning optimal policies based on reward values received by the learner.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 153, 'page_label': '154'}, page_content='11.3. TEMPORAL DISCOUNTING AND OPTIMAL POLICIES 145\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.2: A Grid World\n11.3 Temporal Discounting and Optimal Poli-\ncies\nIn delayed reinforcement learning, one often assumes that rewards in the distant\nfuture are not as valuable as are more immediate rewards. This preference can\nbe accomodated by a temporal discount factor, 0 \u2264\u03b3 <1. The present value of\na reward, ri, occuring i time units in the future, is taken to be \u03b3iri. Suppose\nwe have a policy \u03c0(X) that maps input vectors into actions, and let r\u03c0(X)\ni be\nthe reward that will be received on the i-th time step after one begins executing\npolicy \u03c0 starting in state X. Then the total reward accumulated over all time\nsteps by policy \u03c0 beginning in state X is:\nV\u03c0(X) =\n\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\nOne reason for using a temporal discount factor is so that the above sum will\nbe \ufb01nite. An optimal policy is one that maximizes V\u03c0(X) for all inputs, X.\nIn general, we want to consider the case in which the rewards,ri, are random\nvariables and in which the e\ufb00ects of actions on environmental states are random.\nIn Markovian environments, for example, the probability that action a in state\nXi will lead to state Xj is given by a transition probability p[Xj|Xi,a]. Then,\nwe will want to maximize expected future reward and would de\ufb01ne V\u03c0(X) as:\nV\u03c0(X) = E\n[\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\n]\nIn either case, we call V\u03c0(X) the value of policy \u03c0 for input X.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 154, 'page_label': '155'}, page_content='146 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.3: An Optimal Policy in the Grid World\nIf the action prescribed by \u03c0 taken in state X leads to state X\u2032 (randomly\naccording to the transition probabilities), then we can write V\u03c0(X) in terms of\nV\u03c0(X\u2032) as follows:\nV\u03c0(X) = r[X,\u03c0(X)] + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,\u03c0(X)]V\u03c0(X\u2032)\nwhere (in summary):\n\u03b3 = the discount factor,\nV\u03c0(X) = the value of state X under policy \u03c0,\nr[X,\u03c0(X)] = the expected immediate reward received when we execute the\naction prescribed by \u03c0 in state X, and\np[X\u2032|X,\u03c0(X)] = the probability that the environment transitions to state\nX\u2032when we execute the action prescribed by \u03c0 in state X.\nIn other words, the value of state X under policy \u03c0 is the expected value of\nthe immediate reward received when executing the action recommended by \u03c0\nplus the average value (under \u03c0) of all of the states accessible from X.\nFor an optimal policy, \u03c0\u2217(and no others!), we have the famous optimality\nequation:\nV\u03c0\u2217\n(X) = max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nThe theory of dynamic programming (DP) [Bellman, 1957, Ross, 1983] assures\nus that there is at least one optimal policy, \u03c0\u2217, that satis\ufb01es this equation. DP'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 155, 'page_label': '156'}, page_content='11.4. Q-LEARNING 147\nalso provides methods for calculating V\u03c0\u2217\n(X) and at least one \u03c0\u2217, assuming\nthat we know the average rewards and the transition probabilities. If we knew\nthe transition probabilities, the average rewards, and V\u03c0\u2217\n(X) for all X and a,\nthen it would be easy to implement an optimal policy. We would simply select\nthat a that maximizes r(X,a) + \u03b3\u2211\nX\u2032p[X\u2032|X,a]V\u03c0\u2217\n(X\u2032). That is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nBut, of course, we are assuming that we do not know these average rewards nor\nthe transition probabilities, so we have to \ufb01nd a method that e\ufb00ectively learns\nthem.\nIf we had a model of actions, that is, if we knew for every state, X, and\naction a, which state, X\u2032 resulted, then we could use a method called value\niteration to \ufb01nd an optimal policy. Value iteration works as follows: We begin\nby assigning, randomly, an estimated value V(X) to every state, X. On the i-th\nstep of the process, suppose we are at state Xi (that is, our input on the i-th\nstep is Xi), and that the estimated value of state Xi on the i-th step is Vi(Xi).\nWe then select that actionathat maximizes the estimated value of the predicted\nsubsequent state. Suppose this subsequent state having the highest estimated\nvalue is X\u2032\ni. Then we update the estimated value, Vi(Xi), of state Xi as follows:\nVi(X) = (1 \u2212ci) Vi\u22121(X) + ci\n[\nri + \u03b3Vi\u22121(X\u2032\ni)\n]\nif X = Xi,\n= Vi\u22121(X)\notherwise.\nWe see that this adjustment moves the value ofVi(Xi) an increment (depend-\ning on ci) closer to\n[\nri + \u03b3Vi(X\u2032\ni)\n]\n. Assuming that Vi(X\u2032\ni) is a good estimate for\nVi(X\u2032\ni), then this adjustment helps to make the two estimates more consistent.\nProviding that 0 < ci < 1 and that we visit each state in\ufb01nitely often, this\nprocess of value iteration will converge to the optimal values. Discuss synchronous dynamic\nprogramming, asynchronous\ndynamic programming, and policy\niteration.\n11.4 Q-Learning\nWatkins [Watkins, 1989] has proposed a technique that he calls incremental\ndynamic programming. Let a; \u03c0 stand for the policy that chooses action aonce,\nand thereafter chooses actions according to policy \u03c0. We de\ufb01ne:\nQ\u03c0(X,a) = Va;\u03c0(X)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 156, 'page_label': '157'}, page_content='148 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nThen the optimal value from state X is given by:\nV\u03c0\u2217\n(X) = max\na\nQ\u03c0\u2217\n(X,a)\nThis equation holds only for an optimal policy, \u03c0\u2217. The optimal policy is given\nby:\n\u03c0\u2217(X) = arg max\na\nQ\u03c0\u2217\n(X,a)\nNote that if an actionamakes Q\u03c0(X,a) larger than V\u03c0(X), then we can improve\n\u03c0 by changing it so that \u03c0(X) = a. Making such a change is the basis for a\npowerful learning rule that we shall describe shortly.\nSuppose action ain state X leads to state X\u2032. Then using the de\ufb01nitions of\nQ and V, it is easy to show that:\nQ\u03c0(X,a) = r(X,a) + \u03b3E[V\u03c0(X\u2032)]\nwhere r(X,a) is the average value of the immediate reward received when we\nexecute action a in state X. For an optimal policy (and no others), we have\nanother version of the optimality equation in terms of Q values:\nQ\u03c0\u2217\n(X,a) = max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nfor all actions, a, and states, X. Now, if we had the optimal Q values (for all\na and X), then we could implement an optimal policy simply by selecting that\naction that maximized r(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]\n.\nThat is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nWatkins proposal amounts to a TD(0) method of learning the Q values.\nWe quote (with minor notational changes) from [Watkins & Dayan, 1992, page\n281]:\nIn Q-Learning, the agents experience consists of a sequence of dis-\ntinct stages or episodes. In the i-th episode, the agent:\n observes its current state Xi,\n selects [using the method described below] and performs an\naction ai,\n observes the subsequent state X\u2032\ni,\n receives an immediate reward ri, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 157, 'page_label': '158'}, page_content='11.4. Q-LEARNING 149\n adjusts its Qi\u22121 values using a learning factor ci, according to:\nQi(X,a) = (1 \u2212ci)Qi\u22121(X,a) + ci[ri + \u03b3Vi\u22121(X\u2032\ni)]\nif X = Xi and a= ai,\n= Qi\u22121(X,a)\notherwise,\nwhere\nVi\u22121(X\u2032) = max\nb\n[Qi\u22121(X\u2032,b)]\nis the best the agent thinks it can do from state X\u2032. ... The\ninitial Qvalues, Q0(X,a), for all states and actions are assumed\ngiven.\nUsing the current Q values, Qi(X,a), the agent always selects that action\nthat maximizes Qi(X,a). Note that only the Q value corresponding to the\nstate just exited and the action just taken is adjusted. And that Q value is\nadjusted so that it is closer (by an amount determined by ci) to the sum of\nthe immediate reward plus the discounted maximum (over all actions) of the Q\nvalues of the state just entered. If we imagine the Qvalues to be predictions of\nultimate (in\ufb01nite horizon) total reward, then the learning procedure described\nabove is exactly a TD(0) method of learning how to predict these Q values.\nQ learning strengthens the usual TD methods, however, because TD (applied\nto reinforcement problems using value iteration) requires a one-step lookahead,\nusing a model of the e\ufb00ects of actions, whereas Q learning does not.\nA convenient notation (proposed by [Schwartz, 1993]) for representing the\nchange in Q value is:\nQ(X,a)\n\u03b2\n\u2190\u2212r+ \u03b3V(X\u2032)\nwhere Q(X,a) is the new Qvalue for input X and action a, r is the immediate\nreward when action a is taken in response to input X, V(X\u2032) is the maximum\n(over all actions) of the Qvalue of the state next reached when action ais taken\nfrom state X, and \u03b2 is the fraction of the way toward which the new Q value,\nQ(X,a), is adjusted to equal r+ \u03b3V(X\u2032).\nWatkins and Dayan [Watkins & Dayan, 1992] prove that, under certain con-\nditions, the Q values computed by this learning procedure converge to optimal\nones (that is, to ones on which an optimal policy can be based).\nWe de\ufb01ne ni(X,a) as the index (episode number) of thei-th time that action\na is tried in state X. Then, we have:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 158, 'page_label': '159'}, page_content='150 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nTheorem 11.1 (Watkins and Dayan) For Markov problems with states{X}\nand actions {a}, and given bounded rewards |rn|\u2264 R, learning rates 0 \u2264cn <1,\nand\n\u221e\u2211\ni=0\ncni(X,a) = \u221e,\n\u221e\u2211\ni=0\n[\ncni(X,a)\n]2\n<\u221e\nfor all X and a, then\nQn(X,a) \u2192Q\u2217\nn(X,a) as n \u2192\u221e, for all X and a, with probability 1, where\nQ\u2217\nn(X,a) corresponds to the Q values of an optimal policy.\nAgain, we quote from [Watkins & Dayan, 1992, page 281]:\nThe most important condition implicit in the convergence theorem\n... is that the sequence of episodes that forms the basis of learning\nmust include an in\ufb01nite number of episodes for each starting state\nand action. This may be considered a strong condition on the way\nstates and actions are selectedhowever, under the stochastic con-\nditions of the theorem, no method could be guaranteed to \ufb01nd an\noptimal policy under weaker conditions. Note, however, that the\nepisodes need not form a continuous sequencethat is the X\u2032of one\nepisode need not be the X of the next episode.\nThe relationships among Q learning, dynamic programming, and control\nare very well described in [Barto, Bradtke, & Singh, 1994]. Q learning is best\nthought of as a stochastic approximation method for calculating the Q values.\nAlthough the de\ufb01nition of the optimalQvalues for any state depends recursively\non expected values of the Q values for subsequent states (and on the expected\nvalues of rewards), no expected values are explicitly computed by the procedure.\nInstead, these values are approximated by iterative sampling using the actual\nstochastic mechanism that produces successor states.\n11.5 Discussion, Limitations, and Extensions of\nQ-Learning\n11.5.1 An Illustrative Example\nThe Q-learning procedure requires that we maintain a table of Q(X,a) values\nfor all state-action pairs. In the grid world that we described earlier, such a\ntable would not be excessively large. We might start with random entries in the\ntable; a portion of such an intial table might be as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 159, 'page_label': '160'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING151\nX a Q(X,a) r(X,a)\n(2,3) w 7 0\n(2,3) n 4 0\n(2,3) e 3 0\n(2,3) s 6 0\n(1,3) w 4 -1\n(1,3) n 5 0\n(1,3) e 2 0\n(1,3) s 4 0\nSuppose the robot is in cell (2,3). The maximumQvalue occurs fora= w, so the\nrobot moves west to cell (1,3)receiving no immediate reward. The maximum\nQ value in cell (1,3) is 5, and the learning mechanism attempts to make the\nvalue of Q((2,3),w) closer to the discounted value of 5 plus the immediate\nreward (which was 0 in this case). With a learning rate parameter c = 0 .5\nand \u03b3 = 0.9, the Q value of Q((2,3),w) is adjusted from 7 to 5.75. No other\nchanges are made to the table at this episode. The reader might try this learning\nprocedure on the grid world with a simple computer program. Notice that an\noptimal policy might not be discovered if some cells are not visited nor some\nactions not tried frequently enough.\nThe learning problem faced by the agent is to associate speci\ufb01c actions with\nspeci\ufb01c input patterns. Q learning gradually reinforces those actions that con-\ntribute to positive rewards by increasing the associated Q values. Typically, as\nin this example, rewards occur somewhat after the actions that lead to them\nhence the phrase delayed-reinforcement learning. One can imagine that better\nand better approximations to the optimal Q values gradually propagate back\nfrom states producing rewards toward all of the other states that the agent fre-\nquently visits. With random Qvalues to begin, the agents actions amount to a\nrandom walk through its space of states. Only when this random walk happens\nto stumble into rewarding states does Q learning begin to produce Q values\nthat are useful, and, even then, the Q values have to work their way outward\nfrom these rewarding states. The general problem of associating rewards with\nstate-action pairs is called the temporal credit assignment problemhow should\ncredit for a reward be apportioned to the actions leading up to it? Qlearning is,\nto date, the most successful technique for temporal credit assignment, although\na related method, called the bucket brigade algorithm , has been proposed by\n[Holland, 1986].\nLearning problems similar to that faced by the agent in our grid world have\nbeen thoroughly studied by Sutton who has proposed an architecture, called\nDYNA, for solving them [Sutton, 1990]. DYNA combines reinforcement learning\nwith planning. Sutton characterizes planning as learning in a simulated world\nthat models the world that the agent inhabits. The agents model of the world\nis obtained by Q learning in its actual world, and planning is accomplished by\nQ learning in its model of the world.\nWe should note that the learning problem faced by our grid-world robot'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 160, 'page_label': '161'}, page_content='152 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\ncould be modi\ufb01ed to have several places in the grid that give positive rewards.\nThis possibility presents an interesting way to generalize the classical notion of\na goal in AI planning systemseven in those that do no learning. Instead of\nrepresenting a goal as a condition to be achieved, we represent a goal struc-\nture as a set of rewards to be given for achieving various conditions. Then,\nthe generalized goal becomes maximizing discounted future reward instead of\nsimply achieving some particular condition. This generalization can be made to\nencompass so-called goals of maintenance and goals of avoidance. The exam-\nple presented above included avoiding bumping into the grid-world boundary.\nA goal of maintenance, of a particular state, could be expressed in terms of a\nreward that was earned whenever the agent was in that state and performed an\naction that transitioned back to that state in one step.\n11.5.2 Using Random Actions\nWhen the next pattern presentation in a sequence of patterns is the one caused\nby the agents own action in response to the last pattern, we have what is called\nan on-line learning method. In Watkins and Dayans terminology, in on-line\nlearning the episodes form a continous sequence. As already mentioned, the\nconvergence theorem for Q learning does not require on-line learning; indeed,\nspecial precautions must be taken to ensure that on-line learning meets the\nconditions of the theorem. If on-line learning discovers some good paths to\nrewards, the agent may \ufb01xate on these and never discover a policy that leads\nto a possibly greater long-term reward. In reinforcement learning phraseology,\nthis problem is referred to as the problem of exploitation (of already learned\nbehavior) versus exploration (of possibly better behavior).\nOne way to force exploration is to perform occasional random actions (in-\nstead of that single action prescribed by the current Q values). For example,\nin the grid-world problem, one could imagine selecting an action randomly ac-\ncording to a probability distribution over the actions ( n,e,s, and w). This\ndistribution, in turn, could depend on the Q values. For example, we might\n\ufb01rst \ufb01nd that action prescribed by the Q values and then choose that action\nwith probability 1/2, choose the two orthogonal actions with probability 3/16\neach, and choose the opposite action with probability 1/8. This policy might be\nmodi\ufb01ed by simulated annealing which would gradually increase the probabil-\nity of the action prescribed by theQvalues more and more as time goes on. This\nstrategy would favor exploration at the beginning of learning and exploitation\nlater.\nOther methods, also, have been proposed for dealing with exploration, in-\ncluding making unvisited states intrinsically rewarding and using an interval\nestimate, which is related to the uncertainty in the estimate of a states value\n[Kaelbling, 1993].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 161, 'page_label': '162'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING153\n11.5.3 Generalizing Over Inputs\nFor large problems it would be impractical to maintain a table like that used\nin our grid-world example. Various researchers have suggested mechanisms for\ncomputing Q values, given pattern inputs and actions. One method that sug-\ngests itself is to use a neural network. For example, consider the simple linear\nmachine shown in Fig. 11.4.\nX\n. . .\n. . .\nY\nY\nY\ntrainable weights\nY\nWi\nR dot product units\nQ(ai, X) = X . Wi\nQ(a1, X)\nQ(a2, X)\nQ(aR, X)\nFigure 11.4: A Net that Computes Q Values\nSuch a neural net could be used by an agent that has R actions to select\nfrom. The Qvalues (as a function of the input pattern X and the action ai) are\ncomputed as dot products of weight vectors (one for each action) and the input\nvector. Weight adjustments are made according to a TD(0) procedure to bring\nthe Qvalue for the action last selected closer to the sum of the immediate reward\n(if any) and the (discounted) maximum Q value for the next input pattern.\nIf the optimum Qvalues for the problem (whatever they might be) are more\ncomplex than those that can be computed by a linear machine, a layered neural\nnetwork might be used. Sigmoid units in the \ufb01nal layer would compute Qvalues\nin the range 0 to 1. The TD(0) method for updatingQvalues would then have to\nbe combined with a multi-layer weight-changing rule, such as backpropagation.\nNetworks of this sort are able to aggregate di\ufb00erent input vectors into regions\nfor which the same action should be performed. This kind of aggregation is an\nexample of what has been calledstructural credit assignment. Combining TD(\u03bb)\nand backpropagation is a method for dealing with both the temporal and the\nstructural credit assignment problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 162, 'page_label': '163'}, page_content='154 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nInteresting examples of delayed-reinforcement training of simulated and\nactual robots requiring structural credit assignment have been reported by\n[Lin, 1992, Mahadevan & Connell, 1992].\n11.5.4 Partially Observable States\nSo far, we have identi\ufb01ed the input vector, X, with the actual state of the envi-\nronment. When the input vector results from an agents perceptual apparatus\n(as we assume it does), there is no reason to suppose that it uniquely identi\ufb01es\nthe environmental state. Because of inevitable perceptual limitations, several\ndi\ufb00erent environmental states might give rise to the same input vector. This\nphenomenon has been referred to as perceptual aliasing. With perceptual alias-\ning, we can no longer guarantee that Qlearning will result in even useful action\npolicies, let alone optimal ones. Several researchers have attempted to deal with\nthis problem using a variety of methods including attempting to model hid-\nden states by using internal memory [Lin, 1993]. That is, if some aspect of\nthe environment cannot be sensed currently, perhaps it was sensed once and\ncan be remembered by the agent. When such is the case, we no longer have a\nMarkov problem; that is, the next X vector, given any action, may depend on\na sequence of previous ones rather than just the immediately preceding one. It\nmight be possible to reinstate a Markov framework (over the Xs) if X includes\nnot only current sensory precepts but information from the agents memory.\n11.5.5 Scaling Problems\nSeveral di\ufb03culties have so far prohibited wide application of reinforcement learn-\ning to large problems. (The TD-gammon program, mentioned in the last chap-\nter, is probably unique in terms of success on a high-dimensional problem.)\nWe have already touched on some di\ufb03culties; these and others are summarized\nbelow with references to attempts to overcome them.\na. Exploration versus exploitation.\n use random actions\n favor states not visited recently\n separate the learning phase from the use phase\n employ a teacher to guide exploration\nb. Slow time to convergence\n combine learning with prior knowledge; use estimates of Q values\n(rather than random values) initially\n use a hierarchy of actions; learn primitive actions \ufb01rst and freeze the\nuseful sequences into macros and then learn how to use the macros'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 163, 'page_label': '164'}, page_content='11.6. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 155\n employ a teacher; use graded lessonsstarting near the rewards\nand then backing away, and use examples of good behavior [Lin, 1992]\n use more e\ufb03cient computations; e.g. do several updates per episode\n[Moore & Atkeson, 1993]\nc. Large state spaces\n use hand-coded features\n use neural networks\n use nearest-neighbor methods [Moore, 1990]\nd. Temporal discounting problems. Using small \u03b3 can make the learner too\ngreedy for present rewards and indi\ufb00erent to the future; but using large \u03b3\nslows down learning.\n use a learning method based on average rewards [Schwartz, 1993]\ne. No transfer of learning . What is learned depends on the reward struc-\nture; if the rewards change, learning has to start over.\n Separate the learning into two parts: learn an action model which\npredicts how actions change states (and is constant over all prob-\nlems), and then learn the values of states by reinforcement learn-\ning for each di\ufb00erent set of rewards. Sometimes the reinforcement\nlearning part can be replaced by a planner that uses the action\nmodel to produce plans to achieve goals.\nAlso see other articles in the special issue on reinforcement learning:Machine\nLearning, 8, May, 1992.\n11.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 164, 'page_label': '165'}, page_content='156 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 165, 'page_label': '166'}, page_content='Chapter 12\nExplanation-Based\nLearning\n12.1 Deductive Learning\nIn the learning methods studied so far, typically the training set does not ex-\nhaust the version space. Using logical terminology, we could say that the classi-\n\ufb01ers output does not logically follow from the training set. In this sense, these\nmethods are inductive. In logic, a deductive system is one whose conclusions\nlogically follow from a set of input facts, if the system is sound. 1\nTo contrast inductive with deductive systems in a logical setting, suppose\nwe have a set of facts (the training set) that includes the following formulas:\n{Round(Obj1),Round(Obj2),Round(Obj3),Round(Obj4),\nBall(Obj1),Ball(Obj2),Ball(Obj3),Ball(Obj4)}\nA learning system that forms the conclusion ( \u2200x)[Ball(x) \u2283Round(x)] is in-\nductive. This conclusion may be useful (if there are no facts of the form\nBall(\u03c3) \u2227¬Round(\u03c3)), but it does not logically follow from the facts. On the\nother hand, if we had the facts Green(Obj5) and Green(Obj5) \u2283Round(Obj5),\nthen we could logically conclude Round(Obj5). Making this conclusion and sav-\ning it is an instance of deductive learninga topic we study in this chapter.\nSuppose that some logical proposition, \u03c6, logically follows from some set of\nfacts, \u2206. Under what circumstances might we say that the process of deducing\n\u03c6 from \u2206 results in our learning \u03c6? In a sense, we implicitly knew \u03c6 all along,\nsince it was inherent in knowing \u2206. Yet, \u03c6 might not be obvious given \u2206, and\n1Logical reasoning systems that are not sound, for example those using non-monotonic\nreasoning, themselves might produce inductive conclusions that do not logically follow from\nthe input facts.\n157'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 166, 'page_label': '167'}, page_content='158 CHAPTER 12. EXPLANATION-BASED LEARNING\nthe deduction process to establish \u03c6might have been arduous. Rather than have\nto deduce \u03c6 again, we might want to save it, perhaps along with its deduction,\nin case it is needed later. Shouldnt that process count as learning? Dietterich\n[Dietterich, 1990] has called this type of learning speed-up learning.\nStrictly speaking, speed-up learning does not result in a system being able to\nmake decisions that, in principle, could not have been made before the learning\ntook place. Speed-up learning simply makes it possible to make those decisions\nmore e\ufb03ciently. But, in practice, this type of learning might make possible\ncertain decisions that might otherwise have been infeasible.\nTo take an extreme case, a chess player can be said to learn chess even though\noptimal play is inherent in the rules of chess. On the surface, there seems to be\nno real di\ufb00erence between the experience-based hypotheses that a chess player\nmakes about what constitutes good play and the kind of learning we have been\nstudying so far.\nAs another example, suppose we are given some theorems about geometry\nand are asked to prove that the sum of the angles of a right triangle is 180\ndegrees. Let us further suppose that the proof we constructed did not depend\non the given triangle being a right triangle; in that case we can learn a more\ngeneral fact. The learning technique that we are going to study next is related\nto this example. It is called explanation-based learning (EBL) . EBL can be\nthought of as a process in which implicit knowledge is converted into explicit\nknowledge.\nIn EBL, we specialize parts of a domain theory to explain a particular ex-\nample, then we generalize the explanation to produce another element of the\ndomain theory that will be useful on similar examples. This process is illustrated\nin Fig. 12.1.\n12.2 Domain Theories\nTwo types of information were present in the inductive methods we have studied:\nthe information inherent in the training samples and the information about the\ndomain that is implied by the bias (for example, the hypothesis set from which\nwe choose functions). The learning methods are successful only if the hypothesis\nset is appropriate for the problem. Typically, the smaller the hypothesis set (that\nis, the more a priori information we have about the function being sought), the\nless dependent we are on information being supplied by a training set (that\nis, fewer samples). A priori information about a problem can be expressed in\nseveral ways. The methods we have studied so far restrict the hypotheses in a\nrather direct way. A less direct method involves making assertions in a logical\nlanguage about the property we are trying to learn. A set of such assertions is\nusually called a domain theory.\nSuppose, for example, that we wanted to classify people according to whether\nor not they were good credit risks. We might represent a person by a set of\nproperties (income, marital status, type of employment, etc.), assemble such'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 167, 'page_label': '168'}, page_content='12.3. AN EXAMPLE 159\nDomain\nTheory\nExample\n(X is P) Prove: X is P\nspecialize\nExplanation\n(Proof)\ngeneralize\nA New Domain Rule:\nThings "like" X are P\nY is like X\nComplex Proof\nProcess\nTrivial  Proof\nY is P\nFigure 12.1: The EBL Process\ndata about people who are known to be good and bad credit risks and train a\nclassi\ufb01er to make decisions. Or, we might go to a loan o\ufb03cer of a bank, ask him\nor her what sorts of things s/he looks for in making a decision about a loan,\nencode this knowledge into a set of rules for an expert system, and then use\nthe expert system to make decisions. The knowledge used by the loan o\ufb03cer\nmight have originated as a set of policies (the domain theory), but perhaps the\napplication of these policies were specialized and made more e\ufb03cient through\nexperience with the special cases of loans made in his or her district.\n12.3 An Example\nTo make our discussion more concrete, lets consider the following fanciful exam-\nple. We want to \ufb01nd a way to classify robots as robust or not. The attributes\nthat we use to represent a robot might include some that are relevant to this\ndecision and some that are not.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 168, 'page_label': '169'}, page_content='160 CHAPTER 12. EXPLANATION-BASED LEARNING\nSuppose we have a domain theory of logical sentences that taken together,\nhelp to de\ufb01ne whether or not a robot can be classi\ufb01ed as robust. (The same\ndomain theory may be useful for several other purposes also, but among other\nthings, it describes the concept robust.)\nIn this example, lets suppose that our domain theory includes the sentences:\nFixes(u,u) \u2283Robust(u)\n(An individual that can \ufb01x itself is robust.)\nSees(x,y) \u2227Habile(x) \u2283Fixes(x,y)\n(A habile individual that can see another entity can \ufb01x that entity.)\nRobot(w) \u2283Sees(w,w)\n(All robots can see themselves.)\nR2D2(x) \u2283Habile(x)\n(R2D2-class individuals are habile.)\nC3PO(x) \u2283Habile(x)\n(C3PO-class individuals are habile.)\n...\n(By convention, variables are assumed to be universally quanti\ufb01ed.) We could\nuse theorem-proving methods operating on this domain theory to conclude\nwhether certain robots are robust. These methods might be computationally\nquite expensive because extensive search may have to be performed to derive a\nconclusion. But after having found a proof for some particular robot, we might\nbe able to derive some new sentence whose use allows a much faster conclusion.\nWe next show how such a new rule might be derived in this example. Suppose\nwe are given a number of facts about Num5, such as:\nRobot(Num5)\nR2D2(Num5)\nAge(Num5,5)\nManufacturer(Num5,GR)\n...'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 169, 'page_label': '170'}, page_content='12.3. AN EXAMPLE 161\nFixes(u, u) => Robust(u)\nRobust(Num5)\nFixes(Num5, Num5)\nSees(Num5,Num5) Habile(Num5)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nRobot(w)\n     => Sees(w,w)\nRobot(Num5)\nR2D2(x)\n         => Habile(x)\nR2D2(Num5)\nFigure 12.2: A Proof Tree\nWe are also told that Robust(Num5) is true, but we nevertheless attempt to\n\ufb01nd a proof of that assertion using these facts about Num5 and the domain\ntheory. The facts about Num5 correspond to the features that we might use\nto represent Num5. In this example, not all of them are relevant to a decision\nabout Robust(Num5). The relevant ones are those used or needed in proving\nRobust(Num5) using the domain theory. The proof tree in Fig. 12.2 is one that\na typical theorem-proving system might produce.\nIn the language of EBL, this proof is an explanation for the fact\nRobust(Num5). We see from this explanation that the only facts about Num5\nthat were used were Robot(Num5) and R2D2(Num5). In fact, we could con-\nstruct the following rule from this explanation:\nRobot(Num5) \u2227R2D2(Num5) \u2283Robust(Num5)\nThe explanation has allowed us to prune some attributes about Num5 that are\nirrelevant (at least for decidingRobust(Num5)). This type of pruning is the \ufb01rst\nsense in which an explanation is used to generalize the classi\ufb01cation problem.\n([DeJong & Mooney, 1986] call this aspect of explanation-based learning feature\nelimination.) But the rule we extracted from the explanation applies only to\nNum5. There might be little value in learning that rule since it is so speci\ufb01c.\nCan it be generalized so that it can be applied to other individuals as well?'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 170, 'page_label': '171'}, page_content='162 CHAPTER 12. EXPLANATION-BASED LEARNING\nExamination of the proof shows that the same proof structure, using the\nsame sentences from the domain theory, could be used independently of whether\nwe are talking about Num5 or some other individual. We can generalize the\nproof by a process that replaces constants in the tip nodes of the proof tree\nwith variables and works upwardusing uni\ufb01cation to constrain the values of\nvariables as needed to obtain a proof.\nIn this example, we replace Robot(Num5) by Robot(r) and R2D2(Num5)\nby R2D2(s) and redo the proofusing the explanation proof as a template.\nNote that we use di\ufb00erent values for the two di\ufb00erent occurrences of Num5 at\nthe tip nodes. Doing so sometimes results in more general, but nevertheless\nvalid rules. We now apply the rules used in the proof in the forward direction,\nkeeping track of the substitutions imposed by the most general uni\ufb01ers used in\nthe proof. (Note that we always substitute terms that are already in the tree for\nvariables in rules.) This process results in the generalized proof tree shown in\nFig. 12.3. Note that the occurrence of Sees(r,r) as a node in the tree forces the\nuni\ufb01cation of xwith yin the domain rule, Sees(x,y)\u2227Habile(y) \u2283Fixes(x,y).\nThe substitutions are then applied to the variables in the tip nodes and the root\nnode to yield the general rule: Robot(r) \u2227R2D2(r) \u2283Robust(r).\nThis rule is the end result of EBL for this example. The process\nby which Num5 in this example was generalized to a variable is what\n[DeJong & Mooney, 1986] call identity elimination (the precise identity of Num5\nturned out to be irrelevant). (The generalization process described in this ex-\nample is based on that of [DeJong & Mooney, 1986] and di\ufb00ers from that of\n[Mitchell, et al., 1986]. It is also similar to that used in [Fikes, et al., 1972].)\nClearly, under certain assumptions, this general rule is more easily used to con-\nclude Robust about an individual than the original proof process was.\nIt is important to note that we could have derived the general rule from the\ndomain theory without using the example. (In the literature, doing so is called\nstatic analysis [Etzioni, 1991].) In fact, the example told us nothing new other\nthan what it told us about Num5. The sole role of the example in this instance\nof EBL was to provide a template for a proof to help guide the generalization\nprocess. Basing the generalization process on examples helps to insure that we\nlearn rules matched to the distribution of problems that occur.\nThere are a number of quali\ufb01cations and elaborations about EBL that need\nto be mentioned.\n12.4 Evaluable Predicates\nThe domain theory includes a number of predicates other than the one occuring\nin the formula we are trying to prove and other than those that might custom-\narily be used to describe an individual. One might note, for example, that if we\nused Habile(Num5) to describe Num5, the proof would have been shorter. Why\ndidnt we? The situation is analogous to that of using a data base augmented\nby logical rules. In the latter application, the formulas in the actual data base'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 171, 'page_label': '172'}, page_content='12.4. EVALUABLE PREDICATES 163\nRobust(r)\nFixes(r, r)\nSees(r,r) Habile(s)\nRobot(r) R2D2(s)\n{r/w}\n{s/x}\n{r/x, r/y, r/s}\n{r/u}\nRobot(w)\n     => Sees(w,w)\nR2D2(x)\n         => Habile(x)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nFixes(u, u) => Robust(u)\nbecomes R2D2(r) after\napplying {r/s}\nFigure 12.3: A Generalized Proof Tree\nare extensional, and those in the logical rules are intensional. This usage\nre\ufb02ects the fact that the predicates in the data base part are de\ufb01ned by their\nextensionwe explicitly list all the tuples sastisfying a relation. The logical\nrules serve to connect the data base predicates with higher level abstractions\nthat are described (if not de\ufb01ned) by the rules. We typically cannot look up\nthe truth values of formulas containing these intensional predicates; they have\nto be derived using the rules and the database.\nThe EBL process assumes something similar. The domain theory is useful\nfor connecting formulas that we might want to prove with those whose truth\nvalues can be looked up or otherwise evaluated. In the EBL literature, such\nformulas satisfy what is called the operationality criterion. Perhaps another\nanalogy might be to neural networks. The evaluable predicates correspond to\nthe components of the input pattern vector; the predicates in the domain theory\ncorrespond to the hidden units. Finding the new rule corresponds to \ufb01nding a\nsimpler expression for the formula to be proved in terms only of the evaluable\npredicates.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 172, 'page_label': '173'}, page_content='164 CHAPTER 12. EXPLANATION-BASED LEARNING\n12.5 More General Proofs\nExamining the domain theory for our example reveals that an alternative rule\nmight have been: Robot(u) \u2227C3PO(u) \u2283 Robust(u). Such a rule might\nhave resulted if we were given {C3PO(Num6),Robot(Num6),... }and proved\nRobust(Num6). After considering these two examples (Num5 and Num6),\nthe question arises, do we want to generalize the two rules to something like:\nRobot(u)\u2227[C3PO(u)\u2228R2D2(u)] \u2283Robust(u)? Doing so is an example of what\n[DeJong & Mooney, 1986] call structural generalization (via disjunctive augmen-\ntation ).\nAdding disjunctions for every alternative proof can soon become cumbersome\nand destroy any e\ufb03ciency advantage of EBL. In our example, the e\ufb03ciency\nmight be retrieved if there were another evaluable predicate, say,Bionic(u) such\nthat the domain theory also contained R2D2(x) \u2283Bionic(x) and C3PO(x) \u2283\nBionic(x). After seeing a number of similar examples, we might be willing to\ninduce the formula Bionic(u) \u2283[C3PO(u) \u2228R2D2(u)] in which case the rule\nwith the disjunction could be replaced with Robot(u) \u2227Bionic(u) \u2283Robust(u).\n12.6 Utility of EBL\nIt is well known in theorem proving that the complexity of \ufb01nding a proof\ndepends both on the number of formulas in the domain theory and on the depth\nof the shortest proof. Adding a new rule decreases the depth of the shortest\nproof but it also increases the number of formulas in the domain theory. In\nrealistic applications, the added rules will be relevant for some tasks and not for\nothers. Thus, it is unclear whether the overall utility of the new rules will turn\nout to be positive. EBL methods have been applied in several settings, usually\nwith positive utility. (See [Minton, 1990] for an analysis).\n12.7 Applications\nThere have been several applications of EBL methods. We mention two here,\nnamely the formation of macro-operators in automatic plan generation and\nlearning how to control search.\n12.7.1 Macro-Operators in Planning\nIn automatic planning systems, e\ufb03ciency can sometimes be enhanced by chain-\ning together a sequence of operators into macro-operators. We show an exam-\nple of a process for creating macro-operators based on techniques explored by\n[Fikes, et al., 1972].\nReferring to Fig. 12.4, consider the problem of \ufb01nding a plan for a robot in\nroom R1 to fetch a box, B1, by going to an adjacent room, R2, and pushing it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 173, 'page_label': '174'}, page_content='12.7. APPLICATIONS 165\nback to R1. The goal for the robot is INROOM (B1,R1), and the facts that\nare true in the initial state are listed in the \ufb01gure.\nR1 R2\nR3\nD1\nD2\nB1\nInitial State:\nINROOM(ROBOT, R1)\nINROOM(B1,R2)\nCONNECTS(D1,R1,R2)\nCONNECTS(D1,R2,R1)\n. . .\nFigure 12.4: Initial State of a Robot Problem\nWe will construct the plan from a set of STRIPS operators that include:\nGOTHRU(d,r1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2)\nDelete list: INROOM (ROBOT,r 1)\nAdd list: INROOM (ROBOT,r 2)\nPUSHTHRU(b,d,r 1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2),INROOM (b,r1)\nDelete list: INROOM (ROBOT,r 1),INROOM (b,r1)\nAdd list: INROOM (ROBOT,r 2),INROOM (b,r2)\nA backward-reasoning STRIPS system might produce the plan shown in\nFig. 12.5. We show there the main goal and the subgoals along a solution path.\n(The conditions in each subgoal that are true in the initial state are shown\nunderlined.) The preconditions for this plan, true in the initial state, are:\nINROOM (ROBOT,R 1)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 174, 'page_label': '175'}, page_content='166 CHAPTER 12. EXPLANATION-BASED LEARNING\nCONNECTS (D1,R1,R2)\nCONNECTS (D1,R2,R1)\nINROOM (B1,R2)\nSaving this speci\ufb01c plan, valid only for the speci\ufb01c constants it mentions, would\nnot be as useful as would be saving a more general one. We \ufb01rst generalize\nthese preconditions by substituting variables for constants. We then follow the\nstructure of the speci\ufb01c plan to produce the generalized plan shown in Fig. 12.6\nthat achievesINROOM (b1,r4). Note that the generalized plan does not require\npushing the box back to the place where the robot started. The preconditions\nfor the generalized plan are:\nINROOM (ROBOT,r 1)\nCONNECTS (d1,r1,r2)\nCONNECTS (d2,r2,r4)\nINROOM (b,r4)\nINROOM(B1,R1)\nPUSHTHRU(B1,d,r1,R1)\nINROOM(ROBOT, r1),\nCONNECTS(d, r1, R1),\nINROOM(B1, r1)\nINROOM(ROBOT, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2){R2/r1,\nD1/d}\nGOTHRU(d2, r3, R2)\nINROOM(ROBOT, r3),\nCONNECTS(d2, r3, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\n{R1/r3, D1/d2}\nINROOM(ROBOT, R1),\nCONNECTS(D1, R1, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\nR1 R2\nR3\nD1\nD2\nGOTHRU(D1,R1,R2)\nPUSHTHRU(B1,D1,R2,R1)\nB1\nPLAN:\nFigure 12.5: A Plan for the Robot Problem\nAnother related technique that chains together sequences of operators to\nform more general ones is the chunking mechanism in Soar [Laird, et al., 1986].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 175, 'page_label': '176'}, page_content='12.7. APPLICATIONS 167\nINROOM(b1,r4)\nPUSHTHRU(b1,d2,r2,r4)\nINROOM(ROBOT, r2),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nGOTHRU(d1, r1, r2)\nINROOM(ROBOT, r1),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nFigure 12.6: A Generalized Plan\n12.7.2 Learning Search Control Knowledge\nBesides their use in creating macro-operators, EBL methods can be used to\nimprove the e\ufb03ciency of planning in another way also. In his system called\nPRODIGY, Minton proposed using EBL to learn e\ufb00ective ways to control\nsearch [Minton, 1988]. PRODIGY is a STRIPS-like system that solves planning\nproblems in the blocks-world, in a simple mobile robot world, and in job-shop\nscheduling. PRODIGY has a domain theory involving both the domain of the\nproblem and a simple (meta) theory about planning. Its meta theory includes\nstatements about whether a control choice about a subgoal to work on, an oper-\nator to apply, etc. either succeedsor fails. After producing a plan, it analyzes its\nsuccessful and its unsuccessful choices and attempts to explain them in terms\nof its domain theory. Using an EBL-like process, it is able to produce useful\ncontrol rules such as:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 176, 'page_label': '177'}, page_content='168 CHAPTER 12. EXPLANATION-BASED LEARNING\nIF (AND (CURRENT \u2212NODE node)\n(CANDIDATE \u2212GOAL node (ON x y))\n(CANDIDATE \u2212GOAL node (ON y z)))\nTHEN (PREFER GOAL (ON y z) TO (ON x y))\nPRODIGY keeps statistics on how often these learned rules are used, their\nsavings (in time to \ufb01nd plans), and their cost of application. It saves only the\nrules whose utility, thus measured, is judged to be high. Minton [Minton, 1990]\nhas shown that there is an overall advantage of using these rules (as against not\nhaving any rules and as against hand-coded search control rules).\n12.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 177, 'page_label': '178'}, page_content='Bibliography\n[Acorn & Walden, 1992] Acorn, T., and Walden, S., SMART: Support Man-\nagement Automated Reasoning Technology for COMPAQ Customer Ser-\nvice, Proc. Fourth Annual Conf. on Innovative Applications of Arti\ufb01cial\nIntelligence, Menlo Park, CA: AAAI Press, 1992.\n[Aha, 1991] Aha, D., Kibler, D., and Albert, M., Instance-Based Learning\nAlgorithms, Machine Learning, 6, 37-66, 1991.\n[Anderson & Bower, 1973] Anderson, J. R., and Bower, G. H., Human Asso-\nciative Memory, Hillsdale, NJ: Erlbaum, 1973.\n[Anderson, 1958] Anderson, T. W., An Introduction to Multivariate Statistical\nAnalysis, New York: John Wiley, 1958.\n[Barto, Bradtke, & Singh, 1994] Barto, A., Bradtke, S., and Singh, S., Learn-\ning to Act Using Real-Time Dynamic Programming, to appear in Ar-\nti\ufb01cial Intelligence, 1994.\n[Baum & Haussler, 1989] Baum, E, and Haussler, D., What Size Net Gives\nValid Generalization? Neural Computation, 1, pp. 151-160, 1989.\n[Baum, 1994] Baum, E., When Are k-Nearest Neighbor and Backpropagation\nAccurate for Feasible-Sized Sets of Examples? in Hanson, S., Drastal,\nG., and Rivest, R., (eds.), Computational Learning Theory and Natural\nLearning Systems, Volume 1: Constraints and Prospects , pp. 415-442,\nCambridge, MA: MIT Press, 1994.\n[Bellman, 1957] Bellman, R. E., Dynamic Programming, Princeton: Princeton\nUniversity Press, 1957.\n[Blumer, et al., 1987] Blumer, A., et al., Occams Razor, Info. Process. Lett.,\nvol 24, pp. 377-80, 1987.\n[Blumer, et al., 1990] Blumer, A., et al ., Learnability and the Vapnik-\nChervonenkis Dimension, JACM, 1990.\n[Bollinger & Du\ufb03e, 1988] Bollinger, J., and Du\ufb03e, N., Computer Control of\nMachines and Processes, Reading, MA: Addison-Wesley, 1988.\n169'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 178, 'page_label': '179'}, page_content='170 BIBLIOGRAPHY\n[Brain, et al., 1962] Brain, A. E., et al. , Graphical Data Processing Research\nStudy and Experimental Investigation, Report No. 8 (pp. 9-13) and No.\n9 (pp. 3-10), Contract DA 36-039 SC-78343, SRI International, Menlo\nPark, CA, June 1962 and September 1962.\n[Breiman, et al., 1984] Breiman, L., Friedman, J., Olshen, R., and Stone, C.,\nClassi\ufb01cation and Regression Trees, Monterey, CA: Wadsworth, 1984.\n[Brent, 1990] Brent, R. P., Fast Training Algorithms for Multi-Layer Neural\nNets, Numerical Analysis Project Manuscript NA-90-03, Computer Sci-\nence Department, Stanford University, Stanford, CA 94305, March 1990.\n[Bryson & Ho 1969] Bryson, A., and Ho, Y.-C., Applied Optimal Control, New\nYork: Blaisdell.\n[Buchanan & Wilkins, 1993] Buchanan, B. and Wilkins, D., (eds.), Readings in\nKnowledge Acquisition and Learning, San Francisco: Morgan Kaufmann,\n1993.\n[Carbonell, 1983] Carbonell, J., Learning by Analogy, in Machine Learning:\nAn Arti\ufb01cial Intelligence Approach , Michalski, R., Carbonell, J., and\nMitchell, T., (eds.), San Francisco: Morgan Kaufmann, 1983.\n[Cheeseman, et al., 1988] Cheeseman, P., et al., AutoClass: A Bayesian Clas-\nsi\ufb01cation System, Proc. Fifth Intl. Workshop on Machine Learning ,\nMorgan Kaufmann, San Mateo, CA, 1988. Reprinted in Shavlik, J. and\nDietterich, T., Readings in Machine Learning , Morgan Kaufmann, San\nFrancisco, pp. 296-306, 1990.\n[Cover & Hart, 1967] Cover, T., and Hart, P., Nearest Neighbor Pattern Clas-\nsi\ufb01cation, IEEE Trans. on Information Theory , 13, 21-27, 1967.\n[Cover, 1965] Cover, T., Geometrical and Statistical Properties of Systems\nof Linear Inequalities with Applications in Pattern Recognition, IEEE\nTrans. Elec. Comp., EC-14, 326-334, June, 1965.\n[Dasarathy, 1991] Dasarathy, B. V., Nearest Neighbor Pattern Classi\ufb01cation\nTechniques, IEEE Computer Society Press, 1991.\n[Dayan & Sejnowski, 1994] Dayan, P., and Sejnowski, T.,  TD(\u03bb) Converges\nwith Probability 1, Machine Learning, 14, pp. 295-301, 1994.\n[Dayan, 1992] Dayan, P., The Convergence of TD( \u03bb) for General \u03bb, Machine\nLearning, 8, 341-362, 1992.\n[DeJong & Mooney, 1986] DeJong, G., and Mooney, R., Explanation-Based\nLearning: An Alternative View, Machine Learning, 1:145-176, 1986.\nReprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 452-467.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 179, 'page_label': '180'}, page_content='BIBLIOGRAPHY 171\n[Dietterich & Bakiri, 1991] Dietterich, T. G., and Bakiri, G., Error-Correcting\nOutput Codes: A General Method for Improving Multiclass Induc-\ntive Learning Programs, Proc. Ninth Nat. Conf. on A.I. , pp. 572-577,\nAAAI-91, MIT Press, 1991.\n[Dietterich, et al., 1990] Dietterich, T., Hild, H., and Bakiri, G., A Compara-\ntive Study of ID3 and Backpropagation for English Text-to-Speech Map-\nping, Proc. Seventh Intl. Conf. Mach. Learning, Porter, B. and Mooney,\nR. (eds.), pp. 24-31, San Francisco: Morgan Kaufmann, 1990.\n[Dietterich, 1990] Dietterich, T., Machine Learning, Annu. Rev. Comput.\nSci., 4:255-306, Palo Alto: Annual Reviews Inc., 1990.\n[Duda & Fossum, 1966] Duda, R. O., and Fossum, H., Pattern Classi\ufb01cation\nby Iteratively Determined Linear and Piecewise Linear Discriminant\nFunctions, IEEE Trans. on Elect. Computers , vol. EC-15, pp. 220-232,\nApril, 1966.\n[Duda & Hart, 1973] Duda, R. O., and Hart, P.E., Pattern Classi\ufb01cation and\nScene Analysis, New York: Wiley, 1973.\n[Duda, 1966] Duda, R. O., Training a Linear Machine on Mislabeled Patterns,\nSRI Tech. Report prepared for ONR under Contract 3438(00), SRI In-\nternational, Menlo Park, CA, April 1966.\n[Efron, 1982] Efron, B., The Jackknife, the Bootstrap and Other Resampling\nPlans, Philadelphia: SIAM, 1982.\n[Ehrenfeucht, et al., 1988] Ehrenfeucht, A., et al., A General Lower Bound on\nthe Number of Examples Needed for Learning, in Proc. 1988 Workshop\non Computational Learning Theory, pp. 110-120, San Francisco: Morgan\nKaufmann, 1988.\n[Etzioni, 1991] Etzioni, O., STATIC: A Problem-Space Compiler for\nPRODIGY, Proc. of Ninth National Conf. on Arti\ufb01cial Intelligence ,\npp. 533-540, Menlo Park: AAAI Press, 1991.\n[Etzioni, 1993] Etzioni, O., A Structural Theory of Explanation-Based Learn-\ning, Arti\ufb01cial Intelligence, 60:1, pp. 93-139, March, 1993.\n[Evans & Fisher, 1992] Evans, B., and Fisher, D., Process Delay Analyses Using\nDecision-Tree Induction, Tech. Report CS92-06, Department of Com-\nputer Science, Vanderbilt University, TN, 1992.\n[Fahlman & Lebiere, 1990] Fahlman, S., and Lebiere, C., The Cascade-\nCorrelation Learning Architecture, in Touretzky, D., (ed.), Advances in\nNeural Information Processing Systems, 2 , pp. 524-532, San Francisco:\nMorgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 180, 'page_label': '181'}, page_content='172 BIBLIOGRAPHY\n[Fayyad, et al., 1993] Fayyad, U. M., Weir, N., and Djorgovski, S., SKICAT:\nA Machine Learning System for Automated Cataloging of Large Scale\nSky Surveys, in Proc. Tenth Intl. Conf. on Machine Learning , pp. 112-\n119, San Francisco: Morgan Kaufmann, 1993. (For a longer version of\nthis paper see: Fayyad, U. Djorgovski, G., and Weir, N., Automating\nthe Analysis and Cataloging of Sky Surveys, in Fayyad, U., et al.(eds.),\nAdvances in Knowledge Discovery and Data Mining , Chapter 19, pp.\n471\ufb00., Cambridge: The MIT Press, March, 1996.)\n[Feigenbaum, 1961] Feigenbaum, E. A., The Simulation of Verbal Learning Be-\nhavior, Proceedings of the Western Joint Computer Conference, 19:121-\n132, 1961.\n[Fikes, et al., 1972] Fikes, R., Hart, P., and Nilsson, N., Learning and Execut-\ning Generalized Robot Plans, Arti\ufb01cial Intelligence, pp 251-288, 1972.\nReprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 468-486.\n[Fisher, 1987] Fisher, D., Knowledge Acquisition via Incremental Conceptual\nClustering, Machine Learning, 2:139-172, 1987. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 267283.\n[Friedman, et al., 1977] Friedman, J. H., Bentley, J. L., and Finkel, R. A., An\nAlgorithm for Finding Best Matches in Logarithmic Expected Time,\nACM Trans. on Math. Software , 3(3):209-226, September 1977.\n[Fu, 1994] Fu, L., Neural Networks in Arti\ufb01cial Intelligence , New York:\nMcGraw-Hill, 1994.\n[Gallant, 1986] Gallant, S. I., Optimal Linear Discriminants, in Eighth Inter-\nnational Conf. on Pattern Recognition , pp. 849-852, New York: IEEE,\n1986.\n[Genesereth & Nilsson, 1987] Genesereth, M., and Nilsson, N., Logical Founda-\ntions of Arti\ufb01cial Intelligence , San Francisco: Morgan Kaufmann, 1987.\n[Gluck & Rumelhart, 1989] Gluck, M. and Rumelhart, D., Neuroscience and\nConnectionist Theory, The Developments in Connectionist Theory, Hills-\ndale, NJ: Erlbaum Associates, 1989.\n[Hammerstrom, 1993] Hammerstrom, D., Neural Networks at Work, IEEE\nSpectrum, pp. 26-32, June 1993.\n[Haussler, 1988] Haussler, D., Quantifying Inductive Bias: AI Learning Al-\ngorithms and Valiants Learning Framework, Arti\ufb01cial Intelligence ,\n36:177-221, 1988. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96-107.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 181, 'page_label': '182'}, page_content='BIBLIOGRAPHY 173\n[Haussler, 1990] Haussler, D., Probably Approximately Correct Learning,\nProc. Eighth Nat. Conf. on AI , pp. 1101-1108. Cambridge, MA: MIT\nPress, 1990.\n[Hebb, 1949] Hebb, D. O., The Organization of Behaviour , New York: John\nWiley, 1949.\n[Hertz, Krogh, & Palmer, 1991] Hertz, J., Krogh, A, and Palmer, R., Introduc-\ntion to the Theory of Neural Computation , Lecture Notes, vol. 1, Santa\nFe Inst. Studies in the Sciences of Complexity, New York: Addison-\nWesley, 1991.\n[Hirsh, 1994] Hirsh, H., Generalizing Version Spaces, Machine Learning, 17,\n5-45, 1994.\n[Holland, 1975] Holland, J., Adaptation in Natural and Arti\ufb01cial Systems , Ann\nArbor: The University of Michigan Press, 1975. (Second edition printed\nin 1992 by MIT Press, Cambridge, MA.)\n[Holland, 1986] Holland, J. H., Escaping Brittleness; The Possibilities of\nGeneral-Purpose Learning Algorithms Applied to Parallel Rule-Based\nSystems. In Michalski, R., Carbonell, J., and Mitchell, T. (eds.) , Ma-\nchine Learning: An Arti\ufb01cial Intelligence Approach, Volume 2 , chapter\n20, San Francisco: Morgan Kaufmann, 1986.\n[Hunt, Marin, & Stone, 1966] Hunt, E., Marin, J., and Stone, P., Experiments\nin Induction, New York: Academic Press, 1966.\n[Jabbour, K., et al., 1987] Jabbour, K., et al. , ALFA: Automated Load Fore-\ncasting Assistant, Proc. of the IEEE Pwer Engineering Society Summer\nMeeting, San Francisco, CA, 1987.\n[John, 1995] John, G., Robust Linear Discriminant Trees, Proc. of the Conf.\non Arti\ufb01cial Intelligence and Statistics , Ft. Lauderdale, FL, January,\n1995.\n[Kaelbling, 1993] Kaelbling, L. P., Learning in Embedded Systems, Cambridge,\nMA: MIT Press, 1993.\n[Kohavi, 1994] Kohavi, R., Bottom-Up Induction of Oblivious Read-Once De-\ncision Graphs, Proc. of European Conference on Machine Learning\n(ECML-94), 1994.\n[Kolodner, 1993] Kolodner, J., Case-Based Reasoning, San Francisco: Morgan\nKaufmann, 1993.\n[Koza, 1992] Koza, J., Genetic Programming: On the Programming of Comput-\ners by Means of Natural Selection , Cambridge, MA: MIT Press, 1992.\n[Koza, 1994] Koza, J., Genetic Programming II: Automatic Discovery of\nReusable Programs, Cambridge, MA: MIT Press, 1994.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 182, 'page_label': '183'}, page_content='174 BIBLIOGRAPHY\n[Laird, et al., 1986] Laird, J., Rosenbloom, P., and Newell, A., Chunking in\nSoar: The Anatomy of a General Learning Mechanism, Machine Learn-\ning, 1, pp. 11-46, 1986. Reprinted in Buchanan, B. and Wilkins, D.,\n(eds.), Readings in Knowledge Acquisition and Learning , pp. 518-535,\nMorgan Kaufmann, San Francisco, CA, 1993.\n[Langley, 1992] Langley, P., Areas of Application for Machine Learning,Proc.\nof Fifth Intl. Symp. on Knowledge Engineering , Sevilla, 1992.\n[Langley, 1996] Langley, P., Elements of Machine Learning , San Francisco:\nMorgan Kaufmann, 1996.\n[Lavra\u02c7 c & D\u02c7 zeroski, 1994] Lavra\u02c7 c, N., and D\u02c7 zeroski, S.,Inductive Logic Pro-\ngramming, Chichester, England: Ellis Horwood, 1994.\n[Lin, 1992] Lin, L., Self-Improving Reactive Agents Based on Reinforcement\nLearning, Planning, and Teaching, Machine Learning, 8, 293-321, 1992.\n[Lin, 1993] Lin, L., Scaling Up Reinforcement Learning for Robot Control,\nProc. Tenth Intl. Conf. on Machine Learning, pp. 182-189, San Francisco:\nMorgan Kaufmann, 1993.\n[Littlestone, 1988] Littlestone, N., Learning Quickly When Irrelevant At-\ntributes Abound: A New Linear-Threshold Algorithm, Machine Learn-\ning 2: 285-318, 1988.\n[Maass & Tur´ an, 1994] Maass, W., and Tur´ an, G., How Fast Can a Thresh-\nold Gate Learn?, in Hanson, S., Drastal, G., and Rivest, R., (eds.),\nComputational Learning Theory and Natural Learning Systems, Volume\n1: Constraints and Prospects , pp. 381-414, Cambridge, MA: MIT Press,\n1994.\n[Mahadevan & Connell, 1992] Mahadevan, S., and Connell, J., Automatic\nProgramming of Behavior-Based Robots Using Reinforcement Learn-\ning, Arti\ufb01cial Intelligence, 55, pp. 311-365, 1992.\n[Marchand & Golea, 1993] Marchand, M., and Golea, M., On Learning Sim-\nple Neural Concepts: From Halfspace Intersections to Neural Decision\nLists, Network, 4:67-85, 1993.\n[McCulloch & Pitts, 1943] McCulloch, W. S., and Pitts, W. H., A Logical Cal-\nculus of the Ideas Immanent in Nervous Activity, Bulletin of Mathe-\nmatical Biophysics, Vol. 5, pp. 115-133, Chicago: University of Chicago\nPress, 1943.\n[Michie, 1992] Michie, D., Some Directions in Machine Intelligence, unpub-\nlished manuscript, The Turing Institute, Glasgow, Scotland, 1992.\n[Minton, 1988] Minton, S., Learning Search Control Knowledge: An\nExplanation-Based Approach , Kluwer Academic Publishers, Boston,\nMA, 1988.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 183, 'page_label': '184'}, page_content='BIBLIOGRAPHY 175\n[Minton, 1990] Minton, S., Quantitative Results Concerning the Utility of\nExplanation-Based Learning, Arti\ufb01cial Intelligence , 42, pp. 363-392,\n1990. Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine\nLearning, San Francisco: Morgan Kaufmann, 1990, pp. 573-587.\n[Mitchell, et al., 1986] Mitchell, T., et al., Explanation-Based Generalization:\nA Unifying View, Machine Learning, 1:1, 1986. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 435-451.\n[Mitchell, 1982] Mitchell, T., Generalization as Search, Arti\ufb01cial Intelligence,\n18:203-226, 1982. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96107.\n[Moore & Atkeson, 1993] Moore, A., and Atkeson, C., Prioritized Sweeping:\nReinforcement Learning with Less Data and Less Time,Machine Learn-\ning, 13, pp. 103-130, 1993.\n[Moore, et al., 1994] Moore, A. W., Hill, D. J., and Johnson, M. P., An Em-\npirical Investigation of Brute Force to Choose Features, Smoothers, and\nFunction Approximators, in Hanson, S., Judd, S., and Petsche, T.,\n(eds.), Computational Learning Theory and Natural Learning Systems ,\nVol. 3, Cambridge: MIT Press, 1994.\n[Moore, 1990] Moore, A., E\ufb03cient Memory-based Learning for Robot Control ,\nPhD. Thesis; Technical Report No. 209, Computer Laboratory, Univer-\nsity of Cambridge, October, 1990.\n[Moore, 1992] Moore, A., Fast, Robust Adaptive Control by Learning Only\nForward Models, in Moody, J., Hanson, S., and Lippman, R., (eds.),\nAdvances in Neural Information Processing Systems 4 , San Francisco:\nMorgan Kaufmann, 1992.\n[Mueller & Page, 1988] Mueller, R. and Page, R., Symbolic Computing with\nLisp and Prolog, New York: John Wiley & Sons, 1988.\n[Muggleton, 1991] Muggleton, S., Inductive Logic Programming, New Gen-\neration Computing, 8, pp. 295-318, 1991.\n[Muggleton, 1992] Muggleton, S., Inductive Logic Programming, London: Aca-\ndemic Press, 1992.\n[Muroga, 1971] Muroga, S., Threshold Logic and its Applications , New York:\nWiley, 1971.\n[Natarjan, 1991] Natarajan, B., Machine Learning: A Theoretical Approach ,\nSan Francisco: Morgan Kaufmann, 1991.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 184, 'page_label': '185'}, page_content='176 BIBLIOGRAPHY\n[Nilsson, 1965] Nilsson, N. J., Theoretical and Experimental Investigations in\nTrainable Pattern-Classifying Systems, Tech. Report No. RADC-TR-\n65-257, Final Report on Contract AF30(602)-3448, Rome Air Develop-\nment Center (Now Rome Laboratories), Gri\ufb03ss Air Force Base, New\nYork, September, 1965.\n[Nilsson, 1990] Nilsson, N. J., The Mathematical Foundations of Learning Ma-\nchines, San Francisco: Morgan Kaufmann, 1990. (This book is a reprint\nof Learning Machines: Foundations of Trainable Pattern-Classifying\nSystems, New York: McGraw-Hill, 1965.)\n[Oliver, Dowe, & Wallace, 1992] Oliver, J., Dowe, D., and Wallace, C., Infer-\nring Decision Graphs using the Minimum Message Length Principle,\nProc. 1992 Australian Arti\ufb01cial Intelligence Conference , 1992.\n[Pagallo & Haussler, 1990] Pagallo, G. and Haussler, D., Boolean Feature Dis-\ncovery in Empirical Learning, Machine Learning, vol.5, no.1, pp. 71-99,\nMarch 1990.\n[Pazzani & Kibler, 1992] Pazzani, M., and Kibler, D., The Utility of Knowl-\nedge in Inductive Learning, Machine Learning, 9, 57-94, 1992.\n[Peterson, 1961] Peterson, W., Error Correcting Codes, New York: John Wiley,\n1961.\n[Pomerleau, 1991] Pomerleau, D., Rapidly Adapting Arti\ufb01cial Neural Net-\nworks for Autonomous Navigation, in Lippmann, P., et al. (eds.), Ad-\nvances in Neural Information Processing Systems, 3 , pp. 429-435, San\nFrancisco: Morgan Kaufmann, 1991.\n[Pomerleau, 1993] Pomerleau, D, Neural Network Perception for Mobile Robot\nGuidance, Boston: Kluwer Academic Publishers, 1993.\n[Quinlan & Rivest, 1989] Quinlan, J. Ross, and Rivest, Ron, Inferring Deci-\nsion Trees Using the Minimum Description Length Principle, Informa-\ntion and Computation , 80:227248, March, 1989.\n[Quinlan, 1986] Quinlan, J. Ross, Induction of Decision Trees, Machine\nLearning, 1:81106, 1986. Reprinted in Shavlik, J. and Dietterich, T.,\nReadings in Machine Learning, San Francisco: Morgan Kaufmann, 1990,\npp. 5769.\n[Quinlan, 1987] Quinlan, J. R., Generating Production Rules from Decision\nTrees, In IJCAI-87: Proceedings of the Tenth Intl. Joint Conf. on Ar-\nti\ufb01cial Intelligence, pp. 304-7, San Francisco: Morgan-Kaufmann, 1987.\n[Quinlan, 1990] Quinlan, J. R., Learning Logical De\ufb01nitions from Relations,\nMachine Learning, 5, 239-266, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 185, 'page_label': '186'}, page_content='BIBLIOGRAPHY 177\n[Quinlan, 1993] Quinlan, J. Ross, C4.5: Programs for Machine Learning , San\nFrancisco: Morgan Kaufmann, 1993.\n[Quinlan, 1994] Quinlan, J. R., Comparing Connectionist and Symbolic Learn-\ning Methods, in Hanson, S., Drastal, G., and Rivest, R., (eds.), Com-\nputational Learning Theory and Natural Learning Systems, Volume 1:\nConstraints and Prospects , pp. 445-456,, Cambridge, MA: MIT Press,\n1994.\n[Ridgway, 1962] Ridgway, W. C., An Adaptive Logic System with Generalizing\nProperties, PhD thesis, Tech. Rep. 1556-1, Stanford Electronics Labs.,\nStanford, CA, April 1962.\n[Rissanen, 1978] Rissanen, J., Modeling by Shortest Data Description, Auto-\nmatica, 14:465-471, 1978.\n[Rivest, 1987] Rivest, R. L., Learning Decision Lists, Machine Learning, 2,\n229-246, 1987.\n[Rosenblatt, 1958] Rosenblatt, F., Principles of Neurodynamics , Washington:\nSpartan Books, 1961.\n[Ross, 1983] Ross, S., Introduction to Stochastic Dynamic Programming , New\nYork: Academic Press, 1983.\n[Rumelhart, Hinton, & Williams, 1986] Rumelhart, D. E., Hinton, G. E., and\nWilliams, R. J., Learning Internal Representations by Error Propa-\ngation, In Rumelhart, D. E., and McClelland, J. L., (eds.) Parallel\nDistributed Processing, Vol 1, 318362, 1986.\n[Russell & Norvig 1995] Russell, S., and Norvig, P., Arti\ufb01cial Intelligence: A\nModern Approach, Englewood Cli\ufb00s, NJ: Prentice Hall, 1995.\n[Samuel, 1959] Samuel, A., Some Studies in Machine Learning Using the Game\nof Checkers,IBM Journal of Research and Development, 3:211-229, July\n1959.\n[Schwartz, 1993] Schwartz, A., A Reinforcement Learning Method for Max-\nimizing Undiscounted Rewards, Proc. Tenth Intl. Conf. on Machine\nLearning, pp. 298-305, San Francisco: Morgan Kaufmann, 1993.\n[Sejnowski, Koch, & Churchland, 1988] Sejnowski, T., Koch, C., and Church-\nland, P., Computational Neuroscience, Science, 241: 1299-1306, 1988.\n[Shavlik, Mooney, & Towell, 1991] Shavlik, J., Mooney, R., and Towell, G.,\nSymbolic and Neural Learning Algorithms: An Experimental Compar-\nison, Machine Learning, 6, pp. 111-143, 1991.\n[Shavlik & Dietterich, 1990] Shavlik, J. and Dietterich, T., Readings in Ma-\nchine Learning, San Francisco: Morgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 186, 'page_label': '187'}, page_content='178 BIBLIOGRAPHY\n[Sutton & Barto, 1987] Sutton, R. S., and Barto, A. G., A Temporal-\nDi\ufb00erence Model of Classical Conditioning, in Proceedings of the Ninth\nAnnual Conference of the Cognitive Science Society , Hillsdale, NJ: Erl-\nbaum, 1987.\n[Sutton, 1988] Sutton, R. S., Learning to Predict by the Methods of Temporal\nDi\ufb00erences, Machine Learning 3: 9-44, 1988.\n[Sutton, 1990] Sutton, R., Integrated Architectures for Learning, Planning,\nand Reacting Based on Approximating Dynamic Programming,Proc. of\nthe Seventh Intl. Conf. on Machine Learning, pp. 216-224, San Francisco:\nMorgan Kaufmann, 1990.\n[Taylor, Michie, & Spiegalhalter, 1994] Taylor, C., Michie, D., and Spiegal-\nhalter, D., Machine Learning, Neural and Statistical Classi\ufb01cation ,\nParamount Publishing International.\n[Tesauro, 1992] Tesauro, G., Practical Issues in Temporal Di\ufb00erence Learn-\ning, Machine Learning, 8, nos. 3/4, pp. 257-277, 1992.\n[Towell & Shavlik, 1992] Towell G., and Shavlik, J., Interpretation of Arti\ufb01-\ncial Neural Networks: Mapping Knowledge-Based Neural Networks into\nRules, in Moody, J., Hanson, S., and Lippmann, R., (eds.), Advances in\nNeural Information Processing Systems, 4 , pp. 977-984, San Francisco:\nMorgan Kaufmann, 1992.\n[Towell, Shavlik, & Noordweier, 1990] Towell, G., Shavlik, J., and Noordweier,\nM., Re\ufb01nement of Approximate Domain Theories by Knowledge-Based\nArti\ufb01cial Neural Networks, Proc. Eighth Natl., Conf. on Arti\ufb01cial In-\ntelligence, pp. 861-866, 1990.\n[Unger, 1989] Unger, S., The Essence of Logic Circuits , Englewood Cli\ufb00s, NJ:\nPrentice-Hall, 1989.\n[Utgo\ufb00, 1989] Utgo\ufb00, P., Incremental Induction of Decision Trees, Machine\nLearning, 4:161186, Nov., 1989.\n[Valiant, 1984] Valiant, L., A Theory of the Learnable, Communications of\nthe ACM, Vol. 27 , pp. 1134-1142, 1984.\n[Vapnik & Chervonenkis, 1971] Vapnik, V., and Chervonenkis, A., On the\nUniform Convergence of Relative Frequencies, Theory of Probability and\nits Applications, Vol. 16 , No. 2, pp. 264-280, 1971.\n[Various Editors, 1989-1994] Advances in Neural Information Processing Sys-\ntems, vols 1 through 6, San Francisco: Morgan Kaufmann, 1989 -1994.\n[Watkins & Dayan, 1992] Watkins, C. J. C. H., and Dayan, P., Technical Note:\nQ-Learning, Machine Learning, 8, 279-292, 1992.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 187, 'page_label': '188'}, page_content='BIBLIOGRAPHY 179\n[Watkins, 1989] Watkins, C. J. C. H., Learning From Delayed Rewards , PhD\nThesis, University of Cambridge, England, 1989.\n[Weiss & Kulikowski, 1991] Weiss, S., and Kulikowski, C., Computer Systems\nthat Learn, San Francisco: Morgan Kaufmann, 1991.\n[Werbos, 1974] Werbos, P., Beyond Regression: New Tools for Prediction and\nAnalysis in the Behavioral Sciences , Ph.D. Thesis, Harvard University,\n1974.\n[Widrow & Lehr, 1990] Widrow, B., and Lehr, M. A., 30 Years of Adaptive\nNeural Networks: Perceptron, Madaline and Backpropagation, Proc.\nIEEE, vol. 78, no. 9, pp. 1415-1442, September, 1990.\n[Widrow & Stearns, 1985] Widrow, B., and Stearns, S., Adaptive Signal Pro-\ncessing, Englewood Cli\ufb00s, NJ: Prentice-Hall.\n[Widrow, 1962] Widrow, B., Generalization and Storage in Networks of Ada-\nline Neurons, in Yovits, Jacobi, and Goldstein (eds.), Self-organizing\nSystems1962, pp. 435-461, Washington, DC: Spartan Books, 1962.\n[Winder, 1961] Winder, R., Single Stage Threshold Logic, Proc. of the AIEE\nSymp. on Switching Circuits and Logical Design , Conf. paper CP-60-\n1261, pp. 321-332, 1961.\n[Winder, 1962] Winder, R., Threshold Logic, PhD Dissertation, Princeton Uni-\nversity, Princeton, NJ, 1962.\n[Wnek, et al., 1990] Wnek, J., et al., Comparing Learning Paradigms via Di-\nagrammatic Visualization, in Proc. Fifth Intl. Symp. on Methodologies\nfor Intelligent Systems , pp. 428-437, 1990. (Also Tech. Report MLI90-2,\nUniversity of Illinois at Urbana-Champaign.)')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 401 Unauthorized"
ERROR:root:Error indexing document: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************zh0A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
INFO:root:File ID: 4, Temp file path: temp_MLpdf.pdf
INFO:root:File ID: 4, file path: temp_MLpdf.pdf
INFO:root:PDF file loaded: temp_MLpdf.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 0, 'page_label': '1'}, page_content='INTRODUCTION\nTO\nMACHINE LEARNING\nAN EARLY DRAFT OF A PROPOSED\nTEXTBOOK\nNils J. Nilsson\nRobotics Laboratory\nDepartment of Computer Science\nStanford University\nStanford, CA 94305\ne-mail: nilsson@cs.stanford.edu\nNovember 3, 1998\nCopyright c\u20dd2005 Nils J. Nilsson\nThis material may not be copied, reproduced, or distributed without the\nwritten permission of the copyright holder.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 1, 'page_label': '2'}, page_content='ii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='Contents\n1 Preliminaries 1\n1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1.1 What is Machine Learning? . . . . . . . . . . . . . . . . . 1\n1.1.2 Wellsprings of Machine Learning . . . . . . . . . . . . . . 3\n1.1.3 Varieties of Machine Learning . . . . . . . . . . . . . . . . 4\n1.2 Learning Input-Output Functions . . . . . . . . . . . . . . . . . . 5\n1.2.1 Types of Learning . . . . . . . . . . . . . . . . . . . . . . 5\n1.2.2 Input Vectors . . . . . . . . . . . . . . . . . . . . . . . . . 7\n1.2.3 Outputs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.4 Training Regimes . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.5 Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.2.6 Performance Evaluation . . . . . . . . . . . . . . . . . . . 9\n1.3 Learning Requires Bias . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.4 Sample Applications . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.5 Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 13\n2 Boolean Functions 15\n2.1 Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1.1 Boolean Algebra . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1.2 Diagrammatic Representations . . . . . . . . . . . . . . . 16\n2.2 Classes of Boolean Functions . . . . . . . . . . . . . . . . . . . . 17\n2.2.1 Terms and Clauses . . . . . . . . . . . . . . . . . . . . . . 17\n2.2.2 DNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.2.3 CNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.2.4 Decision Lists . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.2.5 Symmetric and Voting Functions . . . . . . . . . . . . . . 23\n2.2.6 Linearly Separable Functions . . . . . . . . . . . . . . . . 23\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 25\niii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='3 Using Version Spaces for Learning 27\n3.1 Version Spaces and Mistake Bounds . . . . . . . . . . . . . . . . 27\n3.2 Version Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n3.3 Learning as Search of a Version Space . . . . . . . . . . . . . . . 32\n3.4 The Candidate Elimination Method . . . . . . . . . . . . . . . . 32\n3.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 34\n4 Neural Networks 35\n4.1 Threshold Logic Units . . . . . . . . . . . . . . . . . . . . . . . . 35\n4.1.1 De\ufb01nitions and Geometry . . . . . . . . . . . . . . . . . . 35\n4.1.2 Special Cases of Linearly Separable Functions . . . . . . . 37\n4.1.3 Error-Correction Training of a TLU . . . . . . . . . . . . 38\n4.1.4 Weight Space . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4.1.5 The Widrow-Ho\ufb00 Procedure . . . . . . . . . . . . . . . . . 42\n4.1.6 Training a TLU on Non-Linearly-Separable Training Sets 44\n4.2 Linear Machines . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.3 Networks of TLUs . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n4.3.1 Motivation and Examples . . . . . . . . . . . . . . . . . . 46\n4.3.2 Madalines . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.3.3 Piecewise Linear Machines . . . . . . . . . . . . . . . . . . 50\n4.3.4 Cascade Networks . . . . . . . . . . . . . . . . . . . . . . 51\n4.4 Training Feedforward Networks by Backpropagation . . . . . . . 52\n4.4.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.4.2 The Backpropagation Method . . . . . . . . . . . . . . . . 53\n4.4.3 Computing Weight Changes in the Final Layer . . . . . . 56\n4.4.4 Computing Changes to the Weights in Intermediate Layers 58\n4.4.5 Variations on Backprop . . . . . . . . . . . . . . . . . . . 59\n4.4.6 An Application: Steering a Van . . . . . . . . . . . . . . . 60\n4.5 Synergies Between Neural Network and Knowledge-Based Methods 61\n4.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 61\n5 Statistical Learning 63\n5.1 Using Statistical Decision Theory . . . . . . . . . . . . . . . . . . 63\n5.1.1 Background and General Method . . . . . . . . . . . . . . 63\n5.1.2 Gaussian (or Normal) Distributions . . . . . . . . . . . . 65\n5.1.3 Conditionally Independent Binary Components . . . . . . 68\n5.2 Learning Belief Networks . . . . . . . . . . . . . . . . . . . . . . 70\n5.3 Nearest-Neighbor Methods . . . . . . . . . . . . . . . . . . . . . . 70\n5.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 72\niv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='6 Decision Trees 73\n6.1 De\ufb01nitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n6.2 Supervised Learning of Univariate Decision Trees . . . . . . . . . 74\n6.2.1 Selecting the Type of Test . . . . . . . . . . . . . . . . . . 75\n6.2.2 Using Uncertainty Reduction to Select Tests . . . . . . . 75\n6.2.3 Non-Binary Attributes . . . . . . . . . . . . . . . . . . . . 79\n6.3 Networks Equivalent to Decision Trees . . . . . . . . . . . . . . . 79\n6.4 Over\ufb01tting and Evaluation . . . . . . . . . . . . . . . . . . . . . 80\n6.4.1 Over\ufb01tting . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n6.4.2 Validation Methods . . . . . . . . . . . . . . . . . . . . . 81\n6.4.3 Avoiding Over\ufb01tting in Decision Trees . . . . . . . . . . . 82\n6.4.4 Minimum-Description Length Methods . . . . . . . . . . . 83\n6.4.5 Noise in Data . . . . . . . . . . . . . . . . . . . . . . . . . 84\n6.5 The Problem of Replicated Subtrees . . . . . . . . . . . . . . . . 84\n6.6 The Problem of Missing Attributes . . . . . . . . . . . . . . . . . 86\n6.7 Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n6.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 87\n7 Inductive Logic Programming 89\n7.1 Notation and De\ufb01nitions . . . . . . . . . . . . . . . . . . . . . . . 90\n7.2 A Generic ILP Algorithm . . . . . . . . . . . . . . . . . . . . . . 91\n7.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n7.4 Inducing Recursive Programs . . . . . . . . . . . . . . . . . . . . 98\n7.5 Choosing Literals to Add . . . . . . . . . . . . . . . . . . . . . . 100\n7.6 Relationships Between ILP and Decision Tree Induction . . . . . 101\n7.7 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 104\n8 Computational Learning Theory 107\n8.1 Notation and Assumptions for PAC Learning Theory . . . . . . . 107\n8.2 PAC Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n8.2.1 The Fundamental Theorem . . . . . . . . . . . . . . . . . 109\n8.2.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n8.2.3 Some Properly PAC-Learnable Classes . . . . . . . . . . . 112\n8.3 The Vapnik-Chervonenkis Dimension . . . . . . . . . . . . . . . . 113\n8.3.1 Linear Dichotomies . . . . . . . . . . . . . . . . . . . . . . 113\n8.3.2 Capacity . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n8.3.3 A More General Capacity Result . . . . . . . . . . . . . . 116\n8.3.4 Some Facts and Speculations About the VC Dimension . 117\n8.4 VC Dimension and PAC Learning . . . . . . . . . . . . . . . . . 118\n8.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 118\nv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='9 Unsupervised Learning 119\n9.1 What is Unsupervised Learning? . . . . . . . . . . . . . . . . . . 119\n9.2 Clustering Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n9.2.1 A Method Based on Euclidean Distance . . . . . . . . . . 120\n9.2.2 A Method Based on Probabilities . . . . . . . . . . . . . . 124\n9.3 Hierarchical Clustering Methods . . . . . . . . . . . . . . . . . . 125\n9.3.1 A Method Based on Euclidean Distance . . . . . . . . . . 125\n9.3.2 A Method Based on Probabilities . . . . . . . . . . . . . . 126\n9.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 130\n10 Temporal-Di\ufb00erence Learning 131\n10.1 Temporal Patterns and Prediction Problems . . . . . . . . . . . . 131\n10.2 Supervised and Temporal-Di\ufb00erence Methods . . . . . . . . . . . 131\n10.3 Incremental Computation of the (\u2206 W)i . . . . . . . . . . . . . . 134\n10.4 An Experiment with TD Methods . . . . . . . . . . . . . . . . . 135\n10.5 Theoretical Results . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n10.6 Intra-Sequence Weight Updating . . . . . . . . . . . . . . . . . . 138\n10.7 An Example Application: TD-gammon . . . . . . . . . . . . . . . 140\n10.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 141\n11 Delayed-Reinforcement Learning 143\n11.1 The General Problem . . . . . . . . . . . . . . . . . . . . . . . . 143\n11.2 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n11.3 Temporal Discounting and Optimal Policies . . . . . . . . . . . . 145\n11.4 Q-Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n11.5 Discussion, Limitations, and Extensions of Q-Learning . . . . . . 150\n11.5.1 An Illustrative Example . . . . . . . . . . . . . . . . . . . 150\n11.5.2 Using Random Actions . . . . . . . . . . . . . . . . . . . 152\n11.5.3 Generalizing Over Inputs . . . . . . . . . . . . . . . . . . 153\n11.5.4 Partially Observable States . . . . . . . . . . . . . . . . . 154\n11.5.5 Scaling Problems . . . . . . . . . . . . . . . . . . . . . . . 154\n11.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 155\nvi'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='12 Explanation-Based Learning 157\n12.1 Deductive Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 157\n12.2 Domain Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n12.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n12.4 Evaluable Predicates . . . . . . . . . . . . . . . . . . . . . . . . . 162\n12.5 More General Proofs . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.6 Utility of EBL . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.7 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.7.1 Macro-Operators in Planning . . . . . . . . . . . . . . . . 164\n12.7.2 Learning Search Control Knowledge . . . . . . . . . . . . 167\n12.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 168\nvii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 7, 'page_label': '8'}, page_content='viii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 8, 'page_label': '9'}, page_content='Preface\nThese notes are in the process of becoming a textbook. The process is quite\nun\ufb01nished, and the author solicits corrections, criticisms, and suggestions from\nstudents and other readers. Although I have tried to eliminate errors, some un-\ndoubtedly remaincaveat lector. Many typographical infelicities will no doubt\npersist until the \ufb01nal version. More material has yet to be added. Please let Some of my plans for additions and\nother reminders are mentioned in\nmarginal notes.me have your suggestions about topics that are too important to be left out.\nI hope that future versions will cover Hop\ufb01eld nets, Elman nets and other re-\ncurrent nets, radial basis functions, grammar and automata learning, genetic\nalgorithms, and Bayes networks ... . I am also collecting exercises and project\nsuggestions which will appear in future versions.\nMy intention is to pursue a middle ground between a theoretical textbook\nand one that focusses on applications. The book concentrates on the important\nideas in machine learning. I do not give proofs of many of the theorems that I\nstate, but I do give plausibility arguments and citations to formal proofs. And, I\ndo not treat many matters that would be of practical importance in applications;\nthe book is not a handbook of machine learning practice. Instead, my goal is\nto give the reader su\ufb03cient preparation to make the extensive literature on\nmachine learning accessible.\nStudents in my Stanford courses on machine learning have already made\nseveral useful suggestions, as have my colleague, Pat Langley, and my teaching\nassistants, Ron Kohavi, Karl P\ufb02eger, Robert Allen, and Lise Getoor.\nix'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 9, 'page_label': '10'}, page_content='Chapter 1\nPreliminaries\n1.1 Introduction\n1.1.1 What is Machine Learning?\nLearning, like intelligence, covers such a broad range of processes that it is dif-\n\ufb01cult to de\ufb01ne precisely. A dictionary de\ufb01nition includes phrases such as to\ngain knowledge, or understanding of, or skill in, by study, instruction, or expe-\nrience, and modi\ufb01cation of a behavioral tendency by experience. Zoologists\nand psychologists study learning in animals and humans. In this book we fo-\ncus on learning in machines. There are several parallels between animal and\nmachine learning. Certainly, many techniques in machine learning derive from\nthe e\ufb00orts of psychologists to make more precise their theories of animal and\nhuman learning through computational models. It seems likely also that the\nconcepts and techniques being explored by researchers in machine learning may\nilluminate certain aspects of biological learning.\nAs regards machines, we might say, very broadly, that a machine learns\nwhenever it changes its structure, program, or data (based on its inputs or in\nresponse to external information) in such a manner that its expected future\nperformance improves. Some of these changes, such as the addition of a record\nto a data base, fall comfortably within the province of other disciplines and are\nnot necessarily better understood for being called learning. But, for example,\nwhen the performance of a speech-recognition machine improves after hearing\nseveral samples of a persons speech, we feel quite justi\ufb01ed in that case to say\nthat the machine has learned.\nMachine learning usually refers to the changes in systems that perform tasks\nassociated with arti\ufb01cial intelligence (AI) . Such tasks involve recognition, diag-\nnosis, planning, robot control, prediction, etc. The changes might be either\nenhancements to already performing systems or ab initio synthesis of new sys-\ntems. To be slightly more speci\ufb01c, we show the architecture of a typical AI\n1'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 10, 'page_label': '11'}, page_content='2 CHAPTER 1. PRELIMINARIES\nagent in Fig. 1.1. This agent perceives and models its environment and com-\nputes appropriate actions, perhaps by anticipating their e\ufb00ects. Changes made\nto any of the components shown in the \ufb01gure might count as learning. Di\ufb00erent\nlearning mechanisms might be employed depending on which subsystem is being\nchanged. We will study several di\ufb00erent learning methods in this book.\nSensory signals\nPerception\nActions\nAction\nComputation\nModel\nPlanning and\nReasoning\nGoals\nFigure 1.1: An AI System\nOne might ask Why should machines have to learn? Why not design ma-\nchines to perform as desired in the \ufb01rst place? There are several reasons why\nmachine learning is important. Of course, we have already mentioned that the\nachievement of learning in machines might help us understand how animals and\nhumans learn. But there are important engineering reasons as well. Some of\nthese are:\n Some tasks cannot be de\ufb01ned well except by example; that is, we might be\nable to specify input/output pairs but not a concise relationship between\ninputs and desired outputs. We would like machines to be able to adjust\ntheir internal structure to produce correct outputs for a large number of\nsample inputs and thus suitably constrain their input/output function to\napproximate the relationship implicit in the examples.\n It is possible that hidden among large piles of data are important rela-\ntionships and correlations. Machine learning methods can often be used\nto extract these relationships ( data mining).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 11, 'page_label': '12'}, page_content='1.1. INTRODUCTION 3\n Human designers often produce machines that do not work as well as\ndesired in the environments in which they are used. In fact, certain char-\nacteristics of the working environment might not be completely known\nat design time. Machine learning methods can be used for on-the-job\nimprovement of existing machine designs.\n The amount of knowledge available about certain tasks might be too large\nfor explicit encoding by humans. Machines that learn this knowledge\ngradually might be able to capture more of it than humans would want to\nwrite down.\n Environments change over time. Machines that can adapt to a changing\nenvironment would reduce the need for constant redesign.\n New knowledge about tasks is constantly being discovered by humans.\nVocabulary changes. There is a constant stream of new events in the\nworld. Continuing redesign of AI systems to conform to new knowledge is\nimpractical, but machine learning methods might be able to track much\nof it.\n1.1.2 Wellsprings of Machine Learning\nWork in machine learning is now converging from several sources. These dif-\nferent traditions each bring di\ufb00erent methods and di\ufb00erent vocabulary which\nare now being assimilated into a more uni\ufb01ed discipline. Here is a brief listing\nof some of the separate disciplines that have contributed to machine learning;\nmore details will follow in the the appropriate chapters:\n Statistics: A long-standing problem in statistics is how best to use sam-\nples drawn from unknown probability distributions to help decide from\nwhich distribution some new sample is drawn. A related problem is how\nto estimate the value of an unknown function at a new point given the\nvalues of this function at a set of sample points. Statistical methods\nfor dealing with these problems can be considered instances of machine\nlearning because the decision and estimation rules depend on a corpus of\nsamples drawn from the problem environment. We will explore some of\nthe statistical methods later in the book. Details about the statistical the-\nory underlying these methods can be found in statistical textbooks such\nas [Anderson, 1958].\n Brain Models: Non-linear elements with weighted inputs\nhave been suggested as simple models of biological neu-\nrons. Networks of these elements have been studied by sev-\neral researchers including [McCulloch & Pitts, 1943, Hebb, 1949,\nRosenblatt, 1958] and, more recently by [Gluck & Rumelhart, 1989,\nSejnowski, Koch, & Churchland, 1988]. Brain modelers are interested\nin how closely these networks approximate the learning phenomena of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 12, 'page_label': '13'}, page_content='4 CHAPTER 1. PRELIMINARIES\nliving brains. We shall see that several important machine learning\ntechniques are based on networks of nonlinear elementsoften called\nneural networks . Work inspired by this school is sometimes called\nconnectionism, brain-style computation, or sub-symbolic processing.\n Adaptive Control Theory: Control theorists study the problem of con-\ntrolling a process having unknown parameters which must be estimated\nduring operation. Often, the parameters change during operation, and the\ncontrol process must track these changes. Some aspects of controlling a\nrobot based on sensory inputs represent instances of this sort of problem.\nFor an introduction see [Bollinger & Du\ufb03e, 1988].\n Psychological Models: Psychologists have studied the performance of\nhumans in various learning tasks. An early example is the EPAM net-\nwork for storing and retrieving one member of a pair of words when\ngiven another [Feigenbaum, 1961]. Related work led to a number of\nearly decision tree [Hunt, Marin, & Stone, 1966] and semantic network\n[Anderson & Bower, 1973] methods. More recent work of this sort has\nbeen in\ufb02uenced by activities in arti\ufb01cial intelligence which we will be pre-\nsenting.\nSome of the work in reinforcement learning can be traced to e\ufb00orts to\nmodel how reward stimuli in\ufb02uence the learning of goal-seeking behavior in\nanimals [Sutton & Barto, 1987]. Reinforcement learning is an important\ntheme in machine learning research.\n Arti\ufb01cial Intelligence: From the beginning, AI research has been con-\ncerned with machine learning. Samuel developed a prominent early pro-\ngram that learned parameters of a function for evaluating board posi-\ntions in the game of checkers [Samuel, 1959]. AI researchers have also\nexplored the role of analogies in learning [Carbonell, 1983] and how fu-\nture actions and decisions can be based on previous exemplary cases\n[Kolodner, 1993]. Recent work has been directed at discovering rules\nfor expert systems using decision-tree methods [Quinlan, 1990] and in-\nductive logic programming [Muggleton, 1991, Lavra\u02c7 c & D\u02c7 zeroski, 1994].\nAnother theme has been saving and generalizing the results of prob-\nlem solving using explanation-based learning [DeJong & Mooney, 1986,\nLaird, et al., 1986, Minton, 1988, Etzioni, 1993].\n Evolutionary Models:\nIn nature, not only do individual animals learn to perform better, but\nspecies evolve to be better \ufb01t in their individual niches. Since the distinc-\ntion between evolving and learning can be blurred in computer systems,\ntechniques that model certain aspects of biological evolution have been\nproposed as learning methods to improve the performance of computer\nprograms. Genetic algorithms [Holland, 1975] and genetic programming\n[Koza, 1992, Koza, 1994] are the most prominent computational tech-\nniques for evolution.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 13, 'page_label': '14'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 5\n1.1.3 Varieties of Machine Learning\nOrthogonal to the question of the historical source of any learning technique is\nthe more important question of what is to be learned. In this book, we take it\nthat the thing to be learned is a computational structure of some sort. We will\nconsider a variety of di\ufb00erent computational structures:\n Functions\n Logic programs and rule sets\n Finite-state machines\n Grammars\n Problem solving systems\nWe will present methods both for the synthesis of these structures from examples\nand for changing existing structures. In the latter case, the change to the\nexisting structure might be simply to make it more computationally e\ufb03cient\nrather than to increase the coverage of the situations it can handle. Much of\nthe terminology that we shall be using throughout the book is best introduced\nby discussing the problem of learning functions, and we turn to that matter\n\ufb01rst.\n1.2 Learning Input-Output Functions\nWe use Fig. 1.2 to help de\ufb01ne some of the terminology used in describing the\nproblem of learning a function. Imagine that there is a function, f, and the task\nof the learner is to guess what it is. Our hypothesis about the function to be\nlearned is denoted by h. Both f and h are functions of a vector-valued input\nX = (x1,x2,...,x i,...,x n) which has n components. We think of h as being\nimplemented by a device that has X as input and h(X) as output. Both f and\nh themselves may be vector-valued. We assume a priori that the hypothesized\nfunction, h, is selected from a class of functions H. Sometimes we know that\nf also belongs to this class or to a subset of this class. We select h based on a\ntraining set, \u039e, of minput vector examples. Many important details depend on\nthe nature of the assumptions made about all of these entities.\n1.2.1 Types of Learning\nThere are two major settings in which we wish to learn a function. In one,\ncalled supervised learning, we know (sometimes only approximately) the values\nof f for the m samples in the training set, \u039e. We assume that if we can \ufb01nd\na hypothesis, h, that closely agrees with f for the members of \u039e, then this\nhypothesis will be a good guess for fespecially if \u039e is large.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 14, 'page_label': '15'}, page_content='6 CHAPTER 1. PRELIMINARIES\nh(X)\nh\nU = {X1, X2, . . . Xi, . . ., Xm}\nTraining Set:\nX =\nx1\n.\n.\n.\nxi\n.\n.\n.\nxn h D H\nFigure 1.2: An Input-Output Function\nCurve-\ufb01tting is a simple example of supervised learning of a function. Sup-\npose we are given the values of a two-dimensional function,f, at the four sample\npoints shown by the solid circles in Fig. 1.3. We want to \ufb01t these four points\nwith a function, h, drawn from the set, H, of second-degree functions. We show\nthere a two-dimensional parabolic surface above the x1, x2 plane that \ufb01ts the\npoints. This parabolic function, h, is our hypothesis about the function, f, that\nproduced the four samples. In this case, h= f at the four samples, but we need\nnot have required exact matches.\nIn the other setting, termed unsupervised learning, we simply have a train-\ning set of vectors without function values for them. The problem in this case,\ntypically, is to partition the training set into subsets, \u039e 1, . . . , \u039eR, in some ap-\npropriate way. (We can still regard the problem as one of learning a function;\nthe value of the function is the name of the subset to which an input vector be-\nlongs.) Unsupervised learning methods have application in taxonomic problems\nin which it is desired to invent ways to classify data into meaningful categories.\nWe shall also describe methods that are intermediate between supervised\nand unsupervised learning.\nWe might either be trying to \ufb01nd a new function, h, or to modify an existing\none. An interesting special case is that of changing an existing function into an\nequivalent one that is computationally more e\ufb03cient. This type of learning is\nsometimes called speed-uplearning. A very simple example of speed-up learning\ninvolves deduction processes. From the formulas A \u2283B and B \u2283C, we can\ndeduce C if we are given A. From this deductive process, we can create the\nformula A\u2283Ca new formula but one that does not sanction any more con-'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 15, 'page_label': '16'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 7\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n500\n1000\n1500\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n00\n00\n0\nx1\nx2\nh sample f-value\nFigure 1.3: A Surface that Fits Four Points\nclusions than those that could be derived from the formulas that we previously\nhad. But with this new formula we can derive C more quickly, given A, than\nwe could have done before. We can contrast speed-up learning with methods\nthat create genuinely new functionsones that might give di\ufb00erent results after\nlearning than they did before. We say that the latter methods involve inductive\nlearning. As opposed to deduction, there are no correct inductionsonly useful\nones.\n1.2.2 Input Vectors\nBecause machine learning methods derive from so many di\ufb00erent traditions, its\nterminology is rife with synonyms, and we will be using most of them in this\nbook. For example, the input vector is called by a variety of names. Some\nof these are: input vector, pattern vector, feature vector, sample, example, and\ninstance. The components, xi, of the input vector are variously called features,\nattributes, input variables, and components.\nThe values of the components can be of three main types. They might\nbe real-valued numbers, discrete-valued numbers, or categorical values. As an\nexample illustrating categorical values, information about a student might be\nrepresented by the values of the attributes class, major, sex, adviser . A par-\nticular student would then be represented by a vector such as: (sophomore,\nhistory, male, higgins). Additionally, categorical values may be ordered (as in\n{small, medium, large}) or unordered (as in the example just given). Of course,\nmixtures of all these types of values are possible.\nIn all cases, it is possible to represent the input in unordered form by listing\nthe names of the attributes together with their values. The vector form assumes\nthat the attributes are ordered and given implicitly by a form. As an example\nof an attribute-value representation, we might have: (major: history, sex: male,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 16, 'page_label': '17'}, page_content='8 CHAPTER 1. PRELIMINARIES\nclass: sophomore, adviser: higgins, age: 19). We will be using the vector form\nexclusively.\nAn important specialization uses Boolean values, which can be regarded as\na special case of either discrete numbers (1,0) or of categorical variables ( True,\nFalse).\n1.2.3 Outputs\nThe output may be a real number, in which case the process embodying the\nfunction, h, is called a function estimator , and the output is called an output\nvalue or estimate.\nAlternatively, the output may be a categorical value, in which case the pro-\ncess embodying h is variously called a classi\ufb01er, a recognizer, or a categorizer,\nand the output itself is called a label, a class, a category, or a decision. Classi-\n\ufb01ers have application in a number of recognition problems, for example in the\nrecognition of hand-printed characters. The input in that case is some suitable\nrepresentation of the printed character, and the classi\ufb01er maps this input into\none of, say, 64 categories.\nVector-valued outputs are also possible with components being real numbers\nor categorical values.\nAn important special case is that of Boolean output values. In that case,\na training pattern having value 1 is called a positive instance, and a training\nsample having value 0 is called a negative instance. When the input is also\nBoolean, the classi\ufb01er implements a Boolean function. We study the Boolean\ncase in some detail because it allows us to make important general points in\na simpli\ufb01ed setting. Learning a Boolean function is sometimes called concept\nlearning, and the function is called a concept.\n1.2.4 Training Regimes\nThere are several ways in which the training set, \u039e, can be used to produce a\nhypothesized function. In the batch method, the entire training set is available\nand used all at once to compute the function, h. A variation of this method\nuses the entire training set to modify a current hypothesis iteratively until an\nacceptable hypothesis is obtained. By contrast, in the incremental method, we\nselect one member at a time from the training set and use this instance alone\nto modify a current hypothesis. Then another member of the training set is\nselected, and so on. The selection method can be random (with replacement)\nor it can cycle through the training set iteratively. If the entire training set\nbecomes available one member at a time, then we might also use an incremental\nmethodselecting and using training set members as they arrive. (Alterna-\ntively, at any stage all training set members so far available could be used in a\nbatch process.) Using the training set members as they become available is\ncalled an online method. Online methods might be used, for example, when the'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 17, 'page_label': '18'}, page_content='1.3. LEARNING REQUIRES BIAS 9\nnext training instance is some function of the current hypothesis and the previ-\nous instanceas it would be when a classi\ufb01er is used to decide on a robots next\naction given its current set of sensory inputs. The next set of sensory inputs\nwill depend on which action was selected.\n1.2.5 Noise\nSometimes the vectors in the training set are corrupted by noise. There are two\nkinds of noise. Class noise randomly alters the value of the function; attribute\nnoise randomly alters the values of the components of the input vector. In either\ncase, it would be inappropriate to insist that the hypothesized function agree\nprecisely with the values of the samples in the training set.\n1.2.6 Performance Evaluation\nEven though there is no correct answer in inductive learning, it is important\nto have methods to evaluate the result of learning. We will discuss this matter\nin more detail later, but, brie\ufb02y, in supervised learning the induced function is\nusually evaluated on a separate set of inputs and function values for them called\nthe testing set . A hypothesized function is said to generalize when it guesses\nwell on the testing set. Both mean-squared-error and the total number of errors\nare common measures.\n1.3 Learning Requires Bias\nLong before now the reader has undoubtedly asked why is learning a function\npossible at all? Certainly, for example, there are an uncountable number of\ndi\ufb00erent functions having values that agree with the four samples shown in Fig.\n1.3. Why would a learning procedure happen to select the quadratic one shown\nin that \ufb01gure? In order to make that selection we had at least to limit a priori\nthe set of hypotheses to quadratic functions and then to insist that the one we\nchose passed through all four sample points. This kind of a priori information\nis called bias, and useful learning without bias is impossible.\nWe can gain more insight into the role of bias by considering the special case\nof learning a Boolean function of n dimensions. There are 2 n di\ufb00erent Boolean\ninputs possible. Suppose we had no bias; that is His the set of all 22n\nBoolean\nfunctions, and we have no preference among those that \ufb01t the samples in the\ntraining set. In this case, after being presented with one member of the training\nset and its value we can rule out precisely one-half of the members of Hthose\nBoolean functions that would misclassify this labeled sample. The remaining\nfunctions constitute what is called a version space; well explore that concept\nin more detail later. As we present more members of the training set, the graph\nof the number of hypotheses not yet ruled out as a function of the number of\ndi\ufb00erent patterns presented is as shown in Fig. 1.4. At any stage of the process,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 18, 'page_label': '19'}, page_content='10 CHAPTER 1. PRELIMINARIES\nhalf of the remaining Boolean functions have value 1 and half have value 0 for\nany training pattern not yet seen. No generalization is possible in this case\nbecause the training patterns give no clue about the value of a pattern not yet\nseen. Only memorization is possible here, which is a trivial sort of learning.\nlog2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n2n < j\n(generalization is not possible)\n|Hv| = no. of functions not ruled out\nFigure 1.4: Hypotheses Remaining as a Function of Labeled Patterns Presented\nBut suppose we limited Hto some subset, Hc, of all Boolean functions.\nDepending on the subset and on the order of presentation of training patterns,\na curve of hypotheses not yet ruled out might look something like the one\nshown in Fig. 1.5. In this case it is even possible that after seeing fewer than\nall 2 n labeled samples, there might be only one hypothesis that agrees with\nthe training set. Certainly, even if there is more than one hypothesis remaining,\nmost of them may have the same value formost of the patterns not yet seen! The\ntheory of Probably Approximately Correct (PAC) learning makes this intuitive\nidea precise. Well examine that theory later.\nLets look at a speci\ufb01c example of how bias aids learning. A Boolean function\ncan be represented by a hypercube each of whose vertices represents a di\ufb00erent\ninput pattern. We show a 3-dimensional version in Fig. 1.6. There, we show a\ntraining set of six sample patterns and have marked those having a value of 1 by\na small square and those having a value of 0 by a small circle. If the hypothesis\nset consists of just the linearly separable functionsthose for which the positive\nand negative instances can be separated by a linear surface, then there is only\none function remaining in this hypothsis set that is consistent with the training\nset. So, in this case, even though the training set does not contain all possible\npatterns, we can already pin down what the function must begiven the bias.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 19, 'page_label': '20'}, page_content='1.4. SAMPLE APPLICATIONS 11\nlog2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n|Hv| = no. of functions not ruled out\ndepends on order\nof presentation\nlog2|Hc|\nFigure 1.5: Hypotheses Remaining From a Restricted Subset\nMachine learning researchers have identi\ufb01ed two main varieties of bias, ab-\nsolute and preference. In absolute bias (also called restricted hypothesis-space\nbias), one restricts Hto a de\ufb01nite subset of functions. In our example of Fig. 1.6,\nthe restriction was to linearly separable Boolean functions. In preference bias,\none selects that hypothesis that is minimal according to some ordering scheme\nover all hypotheses. For example, if we had some way of measuring thecomplex-\nity of a hypothesis, we might select the one that was simplest among those that\nperformed satisfactorily on the training set. The principle of Occams razor,\nused in science to prefer simple explanations to more complex ones, is a type\nof preference bias. (William of Occam, 1285-?1349, was an English philosopher\nwho said:  non sunt multiplicanda entia praeter necessitatem , which means\nentities should not be multiplied unnecessarily.)\n1.4 Sample Applications\nOur main emphasis in this book is on the concepts of machine learningnot\non its applications. Nevertheless, if these concepts were irrelevant to real-world\nproblems they would probably not be of much interest. As motivation, we give\na short summary of some areas in which machine learning techniques have been\nsuccessfully applied. [Langley, 1992] cites some of the following applications and\nothers:\na. Rule discovery using a variant of ID3 for a printing industry problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 20, 'page_label': '21'}, page_content='12 CHAPTER 1. PRELIMINARIES\nx1\nx2\nx3\nFigure 1.6: A Training Set That Completely Determines a Linearly Separable\nFunction\n[Evans & Fisher, 1992].\nb. Electric power load forecasting using a k-nearest-neighbor rule system\n[Jabbour, K., et al., 1987].\nc. Automatic help desk assistant using a nearest-neighbor system\n[Acorn & Walden, 1992].\nd. Planning and scheduling for a steel mill using ExpertEase, a marketed\n(ID3-like) system [Michie, 1992].\ne. Classi\ufb01cation of stars and galaxies [Fayyad, et al., 1993].\nMany application-oriented papers are presented at the annual conferences\non Neural Information Processing Systems. Among these are papers on: speech\nrecognition, dolphin echo recognition, image processing, bio-engineering, diag-\nnosis, commodity trading, face recognition, music composition, optical character\nrecognition, and various control applications [Various Editors, 1989-1994].\nAs additional examples, [Hammerstrom, 1993] mentions:\na. Sharps Japanese kanji character recognition system processes 200 char-\nacters per second with 99+% accuracy. It recognizes 3000+ characters.\nb. NeuroForecasting Centres (London Business School and University Col-\nlege London) trading strategy selection network earned an average annual\npro\ufb01t of 18% against a conventional systems 12.3%.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 21, 'page_label': '22'}, page_content='1.5. SOURCES 13\nc. Fujitsus (plus a partners) neural network for monitoring a continuous\nsteel casting operation has been in successful operation since early 1990.\nIn summary, it is rather easy nowadays to \ufb01nd applications of machine learn-\ning techniques. This fact should come as no surprise inasmuch as many machine\nlearning techniques can be viewed as extensions of well known statistical meth-\nods which have been successfully applied for many years.\n1.5 Sources\nBesides the rich literature in machine learning (a small part of\nwhich is referenced in the Bibliography), there are several text-\nbooks that are worth mentioning [Hertz, Krogh, & Palmer, 1991,\nWeiss & Kulikowski, 1991, Natarjan, 1991, Fu, 1994, Langley, 1996].\n[Shavlik & Dietterich, 1990, Buchanan & Wilkins, 1993] are edited vol-\numes containing some of the most important papers. A survey paper by\n[Dietterich, 1990] gives a good overview of many important topics. There are\nalso well established conferences and publications where papers are given and\nappear including:\n The Annual Conferences on Advances in Neural Information Processing\nSystems\n The Annual Workshops on Computational Learning Theory\n The Annual International Workshops on Machine Learning\n The Annual International Conferences on Genetic Algorithms\n(The Proceedings of the above-listed four conferences are published by\nMorgan Kaufmann.)\n The journal Machine Learning (published by Kluwer Academic Publish-\ners).\nThere is also much information, as well as programs and datasets, available over\nthe Internet through the World Wide Web.\n1.6 Bibliographical and Historical Remarks\nTo be added. Every chapter will\ncontain a brief survey of the history\nof the material covered in that\nchapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 22, 'page_label': '23'}, page_content='14 CHAPTER 1. PRELIMINARIES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 23, 'page_label': '24'}, page_content='Chapter 2\nBoolean Functions\n2.1 Representation\n2.1.1 Boolean Algebra\nMany important ideas about learning of functions are most easily presented\nusing the special case of Boolean functions. There are several important sub-\nclasses of Boolean functions that are used as hypothesis classes for function\nlearning. Therefore, we digress in this chapter to present a review of Boolean\nfunctions and their properties. (For a more thorough treatment see, for example,\n[Unger, 1989].)\nA Boolean function, f(x1,x2,...,x n) maps an n-tuple of (0,1) values to\n{0,1}. Boolean algebra is a convenient notation for representing Boolean func-\ntions. Boolean algebra uses the connectives ·, +, and . For example, the and\nfunction of two variables is written x1 ·x2. By convention, the connective,  ·\nis usually suppressed, and the and function is written x1x2. x1x2 has value 1 if\nand only if both x1 and x2 have value 1; if either x1 or x2 has value 0, x1x2 has\nvalue 0. The (inclusive) or function of two variables is written x1 + x2. x1 + x2\nhas value 1 if and only if either or both of x1 or x2 has value 1; if both x1 and\nx2 have value 0, x1 + x2 has value 0. The complement or negation of a variable,\nx, is written x. xhas value 1 if and only if xhas value 0; if xhas value 1, xhas\nvalue 0.\nThese de\ufb01nitions are compactly given by the following rules for Boolean\nalgebra:\n1 + 1 = 1, 1 + 0 = 1, 0 + 0 = 0,\n1 ·1 = 1, 1 ·0 = 0, 0 ·0 = 0, and\n1 = 0, 0 = 1.\nSometimes the arguments and values of Boolean functions are expressed in\nterms of the constants T (True) and F (False) instead of 1 and 0, respectively.\n15'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 24, 'page_label': '25'}, page_content='16 CHAPTER 2. BOOLEAN FUNCTIONS\nThe connectives ·and + are each commutative and associative. Thus, for\nexample, x1(x2x3) = ( x1x2)x3, and both can be written simply as x1x2x3.\nSimilarly for +.\nA Boolean formula consisting of a single variable, such as x1 is called an\natom. One consisting of either a single variable or its complement, such as x1,\nis called a literal.\nThe operators ·and + do not commute between themselves. Instead, we\nhave DeMorgans laws (which can be veri\ufb01ed by using the above de\ufb01nitions):\nx1x2 = x1 + x2, and\nx1 + x2 = x1 x2.\n2.1.2 Diagrammatic Representations\nWe saw in the last chapter that a Boolean function could be represented by\nlabeling the vertices of a cube. For a function of n variables, we would need\nan n-dimensional hypercube. In Fig. 2.1 we show some 2- and 3-dimensional\nexamples. Vertices having value 1 are labeled with a small square, and vertices\nhaving value 0 are labeled with a small circle.\nx1\nx2\nx1\nx2\nx1\nx2\nand or\nxor (exclusive or)\nx1x2 x1 + x2\nx1x2  +  x1x2\neven parity functionx1\nx2\nx3\nx1x2x3  +  x1x2x3\n+ x1x2x3 + x1x2x3\nFigure 2.1: Representing Boolean Functions on Cubes\nUsing the hypercube representations, it is easy to see how many Boolean\nfunctions of n dimensions there are. A 3-dimensional cube has 2 3 = 8 vertices,\nand each may be labeled in two di\ufb00erent ways; thus there are 2 (23) = 256'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 25, 'page_label': '26'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 17\ndi\ufb00erent Boolean functions of 3 variables. In general, there are 2 2n\nBoolean\nfunctions of n variables.\nWe will be using 2- and 3-dimensional cubes later to provide some intuition\nabout the properties of certain Boolean functions. Of course, we cannot visualize\nhypercubes (for n > 3), and there are many surprising properties of higher\ndimensional spaces, so we must be careful in using intuitions gained in low\ndimensions. One diagrammatic technique for dimensions slightly higher than\n3 is the Karnaugh map . A Karnaugh map is an array of values of a Boolean\nfunction in which the horizontal rows are indexed by the values of some of\nthe variables and the vertical columns are indexed by the rest. The rows and\ncolumns are arranged in such a way that entries that are adjacent in the map\ncorrespond to vertices that are adjacent in the hypercube representation. We\nshow an example of the 4-dimensional even parity function in Fig. 2.2. (An\neven parity function is a Boolean function that has value 1 if there are an even\nnumber of its arguments that have value 1; otherwise it has value 0.) Note\nthat all adjacent cells in the table correspond to inputs di\ufb00ering in only one\ncomponent. Also describe general logic\ndiagrams, [Wnek, et al., 1990].\n00 01 1011\n00\n01\n10\n11\n11\n1\n1\n11\n1\n10\n00\n0\n0\n0\n0\n0\nx1,x2\nx3,x4\nFigure 2.2: A Karnaugh Map\n2.2 Classes of Boolean Functions\n2.2.1 Terms and Clauses\nTo use absolute bias in machine learning, we limit the class of hypotheses. In\nlearning Boolean functions, we frequently use some of the common sub-classes of\nthose functions. Therefore, it will be important to know about these subclasses.\nOne basic subclass is called terms. A term is any function written in the\nform l1l2 ···lk, where the li are literals. Such a form is called a conjunction of\nliterals. Some example terms are x1x7 and x1x2x4. The size of a term is the\nnumber of literals it contains. The examples are of sizes 2 and 3, respectively.\n(Strictly speaking, the class of conjunctions of literals is called the monomials,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 26, 'page_label': '27'}, page_content='18 CHAPTER 2. BOOLEAN FUNCTIONS\nand a conjunction of literals itself is called a term. This distinction is a \ufb01ne one\nwhich we elect to blur here.)\nIt is easy to show that there are exactly 3 n possible terms of n variables.\nThe number of terms of size kor less is bounded from above by \u2211k\ni=0 C(2n,i) =\nO(nk), where C(i,j) = i!\n(i\u2212j)!j! is the binomial coe\ufb03cient.Probably Ill put in a simple\nterm-learning algorithm hereso\nwe can get started on learning!\nAlso for DNF functions and\ndecision listsas they are de\ufb01ned\nin the next few pages.\nA clause is any function written in the form l1 +l2 +···+lk, where the li are\nliterals. Such a form is called a disjunction of literals. Some example clauses\nare x3 + x5 + x6 and x1 + x4. The size of a clause is the number of literals it\ncontains. There are 3 n possible clauses and fewer than \u2211k\ni=0 C(2n,i) clauses of\nsize k or less. If f is a term, then (by De Morgans laws) f is a clause, and vice\nversa. Thus, terms and clauses are duals of each other.\nIn psychological experiments, conjunctions of literals seem easier for humans\nto learn than disjunctions of literals.\n2.2.2 DNF Functions\nA Boolean function is said to be in disjunctive normal form (DNF) if it can be\nwritten as adisjunction of terms. Some examples in DNF are: f = x1x2+x2x3x4\nand f = x1x3 + x2 x3 + x1x2x3. A DNF expression is called a k-term DNF\nexpression if it is a disjunction of k terms; it is in the class k-DNF if the size of\nits largest term is k. The examples above are 2-term and 3-term expressions,\nrespectively. Both expressions are in the class 3-DNF.\nEach term in a DNF expression for a function is called an implicant because\nit implies the function (if the term has value 1, so does the function). In\ngeneral, a term, t, is an implicant of a function, f, if f has value 1 whenever\nt does. A term, t, is a prime implicant of f if the term, t\u2032, formed by taking\nany literal out of an implicant t is no longer an implicant of f. (The implicant\ncannot be divided by any term and remain an implicant.)\nThus, both x2x3 and x1 x3 are prime implicants off = x2x3+x1 x3+x2x1x3,\nbut x2x1x3 is not.\nThe relationship between implicants and prime implicants can be geometri-\ncally illustrated using the cube representation for Boolean functions. Consider,\nfor example, the function f = x2x3 + x1 x3 + x2x1x3. We illustrate it in Fig.\n2.3. Note that each of the three planes in the \ufb01gure cuts o\ufb00 a group of\nvertices having value 1, but none cuts o\ufb00 any vertices having value 0. These\nplanes are pictorial devices used to isolate certain lower dimensional subfaces\nof the cube. Two of them isolate one-dimensional edges, and the third isolates\na zero-dimensional vertex. Each group of vertices on a subface corresponds to\none of the implicants of the function, f, and thus each implicant corresponds\nto a subface of some dimension. A k-dimensional subface corresponds to an\n(n\u2212k)-size implicant term. The function is written as the disjunction of the\nimplicantscorresponding to the union of all the vertices cut o\ufb00 by all of the\nplanes. Geometrically, an implicant is prime if and only if its corresponding\nsubface is the largest dimensional subface that includes all of its vertices and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 27, 'page_label': '28'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 19\nno other vertices having value 0. Note that the term x2x1x3 is not a prime\nimplicant of f. (In this case, we dont even have to include this term in the\nfunction because the vertex cut o\ufb00 by the plane corresponding to x2x1x3 is\nalready cut o\ufb00 by the plane corresponding to x2x3.) The other two implicants\nare prime because their corresponding subfaces cannot be expanded without\nincluding vertices having value 0.\nx2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x2x1x3\n   = x2x3 + x1x3\nx2x3 and  x1x3 are prime implicants\nFigure 2.3: A Function and its Implicants\nNote that all Boolean functions can be represented in DNFtrivially by\ndisjunctions of terms of size nwhere each term corresponds to one of the vertices\nwhose value is 1. Whereas there are 22n\nfunctions of ndimensions in DNF (since\nany Boolean function can be written in DNF), there are just 2 O(nk) functions\nin k-DNF.\nAll Boolean functions can also be represented in DNF in which each term is\na prime implicant, but that representation is not unique, as shown in Fig. 2.4.\nIf we can express a function in DNF form, we can use the consensus method\nto \ufb01nd an expression for the function in which each term is a prime implicant.\nThe consensus method relies on two results: We may replace this section with\none describing the\nQuine-McCluskey method instead. Consensus:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 28, 'page_label': '29'}, page_content='20 CHAPTER 2. BOOLEAN FUNCTIONS\nx2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x1x2\n   = x1x2 + x1x3\nAll of the terms are prime implicants, but there\nis not a unique representation\nFigure 2.4: Non-Uniqueness of Representation by Prime Implicants\nxi ·f1 + xi ·f2 = xi ·f1 + xi ·f2 + f1 ·f2\nwhere f1 and f2 are terms such that no literal appearing in f1 appears\ncomplemented in f2. f1 ·f2 is called the consensus of xi ·f1 and xi ·\nf2. Readers familiar with the resolution rule of inference will note that\nconsensus is the dual of resolution.\nExamples: x1 is the consensus of x1x2 and x1x2. The terms x1x2 and x1x2\nhave no consensus since each term has more than one literal appearing\ncomplemented in the other.\n Subsumption:\nxi ·f1 + f1 = f1\nwhere f1 is a term. We say that f1 subsumes xi ·f1.\nExample: x1 x4x5 subsumes x1 x4 x2x5'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 29, 'page_label': '30'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 21\nThe consensus method for \ufb01nding a set of prime implicants for a function,\nf, iterates the following operations on the terms of a DNF expression for f until\nno more such operations can be applied:\na. initialize the process with the set, T, of terms in the DNF expression of\nf,\nb. compute the consensus of a pair of terms in T and add the result to T,\nc. eliminate any terms in T that are subsumed by other terms in T.\nWhen this process halts, the terms remaining in T are all prime implicants of\nf.\nExample: Let f = x1x2 + x1 x2x3 + x1 x2 x3 x4x5. We show a derivation of\na set of prime implicants in the consensus tree of Fig. 2.5. The circled numbers\nadjoining the terms indicate the order in which the consensus and subsumption\noperations were performed. Shaded boxes surrounding a term indicate that it\nwas subsumed. The \ufb01nal form of the function in which all terms are prime\nimplicants is: f = x1x2 + x1x3 + x1 x4x5. Its terms are all of the non-subsumed\nterms in the consensus tree.\n x1x2 x1x2x3 x1x2x3x4x5\n x1x3\nx1x2x4x5\nx1x4x5\nf =  x1x2 + + x1x3 x1x4x5\n1\n2\n6\n4\n5\n3\nFigure 2.5: A Consensus Tree\n2.2.3 CNF Functions\nDisjunctive normal form has a dual: conjunctive normal form (CNF). A Boolean\nfunction is said to be in CNF if it can be written as a conjunction of clauses.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 30, 'page_label': '31'}, page_content='22 CHAPTER 2. BOOLEAN FUNCTIONS\nAn example in CNF is: f = (x1 +x2)(x2 +x3 +x4). A CNF expression is called\na k-clause CNF expression if it is a conjunction of k clauses; it is in the class\nk-CNF if the size of its largest clause is k. The example is a 2-clause expression\nin 3-CNF. If f is written in DNF, an application of De Morgans law renders f\nin CNF, and vice versa. Because CNF and DNF are duals, there are also 2 O(nk)\nfunctions in k-CNF.\n2.2.4 Decision Lists\nRivest has proposed a class of Boolean functions calleddecision lists [Rivest, 1987].\nA decision list is written as an ordered list of pairs:\n(tq,vq)\n(tq\u22121,vq\u22121)\n···\n(ti,vi)\n···\n(t2,v2)\n(T,v1)\nwhere the vi are either 0 or 1, the ti are terms in ( x1,...,x n), and T is a term\nwhose value is 1 (regardless of the values of the xi). The value of a decision list\nis the value of vi for the \ufb01rst ti in the list that has value 1. (At least one ti will\nhave value 1, because the last one does; v1 can be regarded as a default value of\nthe decision list.) The decision list is of size k, if the size of the largest term in\nit is k. The class of decision lists of size k or less is called k-DL.\nAn example decision list is:\nf =\n(x1x2,1)\n(x1 x2x3,0)\nx2x3,1)\n(1,0)\nf has value 0 for x1 = 0, x2 = 0, and x3 = 1. It has value 1 for x1 = 1, x2 = 0,\nand x3 = 1. This function is in 3-DL.\nIt has been shown that the class k-DL is a strict superset of the union of\nk-DNF and k-CNF. There are 2 O[nkklog(n)] functions in k-DL [Rivest, 1987].\nInteresting generalizations of decision lists use other Boolean functions in\nplace of the terms, ti. For example we might use linearly separable functions in\nplace of the ti (see below and [Marchand & Golea, 1993]).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 31, 'page_label': '32'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 23\n2.2.5 Symmetric and Voting Functions\nA Boolean function is called symmetric if it is invariant under permutations\nof the input variables. For example, any function that is dependent only on\nthe number of input variables whose values are 1 is a symmetric function. The\nparity functions, which have value 1 depending on whether or not the number\nof input variables with value 1 is even or odd is a symmetric function. (The\nexclusive or function, illustrated in Fig. 2.1, is an odd-parity function of two\ndimensions. The or and and functions of two dimensions are also symmetric.)\nAn important subclass of the symmetric functions is the class of voting func-\ntions (also called m-of-nfunctions). A k-voting function has value 1 if and only\nif k or more of its n inputs has value 1. If k= 1, a voting function is the same\nas an n-sized clause; if k= n, a voting function is the same as an n-sized term;\nif k = (n+ 1)/2 for n odd or k = 1 + n/2 for n even, we have the majority\nfunction.\n2.2.6 Linearly Separable Functions\nThe linearly separable functions are those that can be expressed as follows:\nf = thresh(\nn\u2211\ni=1\nwixi,\u03b8)\nwhere wi, i= 1,...,n , are real-valued numbers called weights, \u03b8is a real-valued\nnumber called the threshold, and thresh( \u03c3,\u03b8) is 1 if \u03c3 \u2265\u03b8 and 0 otherwise.\n(Note that the concept of linearly separable functions can be extended to non-\nBoolean inputs.) The k-voting functions are all members of the class of linearly\nseparable functions in which the weights all have unit value and the threshold\ndepends on k. Thus, terms and clauses are special cases of linearly separable\nfunctions.\nA convenient way to write linearly separable functions uses vector notation:\nf = thresh(X ·W,\u03b8)\nwhere X = ( x1,...,x n) is an n-dimensional vector of input variables, W =\n(w1,...,w n) is an n-dimensional vector of weight values, and X ·W is the dot\n(or inner) product of the two vectors. Input vectors for which f has value 1 lie\nin a half-space on one side of (and on) a hyperplane whose orientation is normal\nto W and whose position (with respect to the origin) is determined by \u03b8. We\nsaw an example of such a separating plane in Fig. 1.6. With this idea in mind,\nit is easy to see that two of the functions in Fig. 2.1 are linearly separable, while\ntwo are not. Also note that the terms in Figs. 2.3 and 2.4 are linearly separable\nfunctions as evidenced by the separating planes shown.\nThere is no closed-form expression for the number of linearly separable func-\ntions of n dimensions, but the following table gives the numbers for n up to 6.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 32, 'page_label': '33'}, page_content='24 CHAPTER 2. BOOLEAN FUNCTIONS\nn Boolean Linearly Separable\nFunctions Functions\n1 4 4\n2 16 14\n3 256 104\n4 65,536 1,882\n5 \u22484.3 ×109 94,572\n6 \u22481.8 ×1019 15,028,134\n[Muroga, 1971] has shown that (for n> 1) there are no more than 2 n2\nlinearly\nseparable functions of n dimensions. (See also [Winder, 1961, Winder, 1962].)\n2.3 Summary\nThe diagram in Fig. 2.6 shows some of the set inclusions of the classes of Boolean\nfunctions that we have considered. We will be confronting these classes again\nin later chapters.\nDNF\n(All)\nk-DLk-DNFk-size-\nterms\nterms\nlin sep\nFigure 2.6: Classes of Boolean Functions\nThe sizes of the various classes are given in the following table (adapted from\n[Dietterich, 1990, page 262]):'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 33, 'page_label': '34'}, page_content='2.4. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 25\nClass Size of Class\nterms 3n\nclauses 3n\nk-term DNF 2O(kn)\nk-clause CNF 2O(kn)\nk-DNF 2O(nk)\nk-CNF 2O(nk)\nk-DL 2O[nkklog(n)]\nlin sep 2O(n2)\nDNF 22n\n2.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 34, 'page_label': '35'}, page_content='26 CHAPTER 2. BOOLEAN FUNCTIONS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 35, 'page_label': '36'}, page_content='Chapter 3\nUsing Version Spaces for\nLearning\n3.1 Version Spaces and Mistake Bounds\nThe \ufb01rst learning methods we present are based on the concepts of version\nspaces and version graphs. These ideas are most clearly explained for the case\nof Boolean function learning. Given an initial hypothesis set H(a subset of\nall Boolean functions) and the values of f(X) for each X in a training set, \u039e,\nthe version space is that subset of hypotheses, Hv, that is consistent with these\nvalues. A hypothesis, h, is consistent with the values of X in \u039e if and only if\nh(X) = f(X) for all X in \u039e. We say that the hypotheses in Hthat are not\nconsistent with the values in the training set are ruled out by the training set.\nWe could imagine (conceptually only!) that we have devices for implement-\ning every function in H. An incremental training procedure could then be\nde\ufb01ned which presented each pattern in \u039e to each of these functions and then\neliminated those functions whose values for that pattern did not agree with its\ngiven value. At any stage of the process we would then have left some subset\nof functions that are consistent with the patterns presented so far; this subset\nis the version space for the patterns already presented. This idea is illustrated\nin Fig. 3.1.\nConsider the following procedure for classifying an arbitrary input pattern,\nX: the pattern is put in the same class (0 or 1) as are the majority of the\noutputs of the functions in the version space. During the learning procedure,\nif this majority is not equal to the value of the pattern presented, we say a\nmistake is made, and we revise the version space accordinglyeliminating all\nthose (majority of the) functions voting incorrectly. Thus, whenever a mistake\nis made, we rule out at least half of the functions remaining in the version space.\nHow many mistakes can such a procedure make? Obviously, we can make\nno more than log 2(|H|) mistakes, where |H|is the number of hypotheses in the\n27'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 36, 'page_label': '37'}, page_content='28 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nh1\nh2\nhi\nhK\nX\nA Subset, H,  of all\nBoolean Functions\nRule out hypotheses not\nconsistent with training patterns\nhj\nHypotheses not ruled out\nconstitute the version space\nK = |H|\n1 or 0\nFigure 3.1: Implementing the Version Space\noriginal hypothesis set, H. (Note, though, that the number of training patterns\nseen before this maximum number of mistakes is made might be much greater.)\nThis theoretical (and very impractical!) result (due to [Littlestone, 1988]) is an\nexample of a mistake boundan important concept in machine learning theory.\nIt shows that there must exist a learning procedure that makes no more mistakes\nthan this upper bound. Later, well derive other mistake bounds.\nAs a special case, if our bias was to limit Hto terms, we would make no\nmore than log2(3n) = nlog2(3) = 1.585nmistakes before exhausting the version\nspace. This result means that if f were a term, we would make no more than\n1.585nmistakes before learning f, and otherwise we would make no more than\nthat number of mistakes before being able to decide that f is not a term.\nEven if we do not have su\ufb03cient training patterns to reduce the version\nspace to a single function, it may be that there are enough training patterns\nto reduce the version space to a set of functions such that most of them assign\nthe same values to most of the patterns we will see henceforth. We could select\none of the remaining functions at random and be reasonably assured that it\nwill generalize satisfactorily. We next discuss a computationally more feasible\nmethod for representing the version space.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 37, 'page_label': '38'}, page_content='3.2. VERSION GRAPHS 29\n3.2 Version Graphs\nBoolean functions can be ordered by generality. A Boolean function, f1, is more\ngeneral than a function, f2, (and f2 is more speci\ufb01c than f1), if f1 has value 1\nfor all of the arguments for which f2 has value 1, and f1 \u0338= f2. For example, x3\nis more general than x2x3 but is not more general than x3 + x2.\nWe can form a graph with the hypotheses, {hi}, in the version space as\nnodes. A node in the graph, hi, has an arc directed to node, hj, if and only if\nhj is more general than hi. We call such a graph a version graph. In Fig. 3.2,\nwe show an example of a version graph over a 3-dimensional input space for\nhypotheses restricted to terms (with none of them yet ruled out).\n0\nx1 x2x 3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nVersion Graph for Terms\nx1\nx2\nx3\n(for simplicity, only some arcs in the graph are shown)\n(none yet ruled out)\n(k = 1)\n(k = 2)\n(k = 3)\nx1 x3\nFigure 3.2: A Version Graph for Terms\nThat function, denoted here by 1, which has value 1 for all inputs, corre-\nsponds to the node at the top of the graph. (It is more general than any other\nterm.) Similarly, the function 0 is at the bottom of the graph. Just below\n1 is a row of nodes corresponding to all terms having just one literal, and just\nbelow them is a row of nodes corresponding to terms having two literals, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 38, 'page_label': '39'}, page_content='30 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nso on. There are 3 3 = 27 functions altogether (the function 0, included in\nthe graph, is technically not a term). To make our portrayal of the graph less\ncluttered only some of the arcs are shown; each node in the actual graph has an\narc directed to all of the nodes above it that are more general.\nWe use this same example to show how the version graph changes as we\nconsider a set of labeled samples in a training set, \u039e. Suppose we \ufb01rst consider\nthe training pattern (1, 0, 1) with value 0. Some of the functions in the version\ngraph of Fig. 3.2 are inconsistent with this training pattern. These ruled out\nnodes are no longer in the version graph and are shown shaded in Fig. 3.3. We\nalso show there the three-dimensional cube representation in which the vertex\n(1, 0, 1) has value 0.\n0\nx1 x2 x3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nNew Version Graph\n1, 0, 1 has\nvalue 0\nx1x3\nx1x2 x2x3\nx1x2x3\nx1\nx2\nx3\nx1x3\n(only some arcs in the graph are shown)\nruled out nodes\nFigure 3.3: The Version Graph Upon Seeing (1, 0, 1)\nIn a version graph, there are always a set of hypotheses that are maximally\ngeneral and a set of hypotheses that are maximally speci\ufb01c. These are called\nthe general boundary set (gbs) and the speci\ufb01c boundary set (sbs) , respectively.\nIn Fig. 3.4, we have the version graph as it exists after learning that (1,0,1) has\nvalue 0 and (1, 0, 0) has value 1. The gbs and sbs are shown.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 39, 'page_label': '40'}, page_content='3.2. VERSION GRAPHS 31\n0\nx1 x2\nx3\nx2 x3\n1\nx1x2 x3\nx1\nx2x3x1x3\ngeneral boundary set\n(gbs)\nspecific boundary set (sbs)\nx1x2\nmore specific than gbs,\nmore general than sbs\n1, 0, 1 has\nvalue 0\nx1\nx2\nx3\n1, 0, 0 has\nvalue 1\nFigure 3.4: The Version Graph Upon Seeing (1, 0, 1) and (1, 0, 0)\nBoundary sets are important because they provide an alternative to repre-\nsenting the entire version space explicitly, which would be impractical. Given\nonly the boundary sets, it is possible to determine whether or not any hypoth-\nesis (in the prescribed class of Boolean functions we are using) is a member or\nnot of the version space. This determination is possible because of the fact that\nany member of the version space (that is not a member of one of the boundary\nsets) is more speci\ufb01c than some member of the general boundary set and is more\ngeneral than some member of the speci\ufb01c boundary set.\nIf we limit our Boolean functions that can be in the version space to terms,\nit is a simple matter to determine maximally general and maximally speci\ufb01c\nfunctions (assuming that there is some term that is in the version space). A\nmaximally speci\ufb01c one corresponds to a subface of minimal dimension that\ncontains all the members of the training set labelled by a 1 and no members\nlabelled by a 0. A maximally general one corresponds to a subface of maximal\ndimension that contains all the members of the training set labelled by a 1 and\nno members labelled by a 0. Looking at Fig. 3.4, we see that the subface of\nminimal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is just\nthe vertex (1, 0, 0) itselfcorresponding to the function x1x2 x3. The subface'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 40, 'page_label': '41'}, page_content='32 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nof maximal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is\nthe bottom face of the cubecorresponding to the function x3. In Figs. 3.2\nthrough 3.4 the sbs is always singular. Version spaces for terms always have\nsingular speci\ufb01c boundary sets. As seen in Fig. 3.3, however, the gbs of a\nversion space for terms need not be singular.\n3.3 Learning as Search of a Version Space\n[To be written. Relate to term learning algorithm presented in Chapter\nTwo. Also discuss best-\ufb01rst search methods. See Pat Langleys example us-\ning pseudo-cells of how to generate and eliminate hypotheses.]\nSelecting a hypothesis from the version space can be thought of as a search\nproblem. One can start with a very general function and specialize it through\nvarious specialization operators until one \ufb01nds a function that is consistent (or\nadequately so) with a set of training patterns. Such procedures are usually\ncalled top-down methods. Or, one can start with a very special function and\ngeneralize itresulting in bottom-up methods. We shall see instances of both\nstyles of learning in this book.Compare this view of top-down\nversus bottom-up with the\ndivide-and-conquer and the\ncovering (or AQ) methods of\ndecision-tree induction. 3.4 The Candidate Elimination Method\nThe candidate elimination method, is an incremental method for computing the\nboundary sets. Quoting from [Hirsh, 1994, page 6]:\nThe candidate-elimination algorithm manipulates the boundary-set\nrepresentation of a version space to create boundary sets that rep-\nresent a new version space consistent with all the previous instances\nplus the new one. For a positive exmple the algorithm generalizes\nthe elements of the [sbs] as little as possible so that they cover the\nnew instance yet remain consistent with past data, and removes\nthose elements of the [gbs] that do not cover the new instance. For\na negative instance the algorithm specializes elements of the [gbs]\nso that they no longer cover the new instance yet remain consis-\ntent with past data, and removes from the [sbs] those elements that\nmistakenly cover the new, negative instance.\nThe method uses the following de\ufb01nitions (adapted from\n[Genesereth & Nilsson, 1987]):\n a hypothesis is called su\ufb03cient if and only if it has value 1 for all training\nsamples labeled by a 1,\n a hypothesis is called necessary if and only if it has value 0 for all training\nsamples labeled by a 0.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 41, 'page_label': '42'}, page_content='3.4. THE CANDIDATE ELIMINATION METHOD 33\nHere is how to think about these de\ufb01nitions: A hypothesis implements a su\ufb03-\ncient condition that a training sample has value 1 if the hypothesis has value 1\nfor all of the positive instances; a hypothesis implements a necessary condition\nthat a training sample has value 1 if the hypothesis has value 0 for all of the\nnegative instances. A hypothesis is consistent with the training set (and thus is\nin the version space) if and only if it is both su\ufb03cient and necessary.\nWe start (before receiving any members of the training set) with the function\n0 as the singleton element of the speci\ufb01c boundary set and with the function\n1 as the singleton element of the general boundary set. Upon receiving a new\nlabeled input vector, the boundary sets are changed as follows:\na. If the new vector is labelled with a 1:\nThe new general boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not su\ufb03cient. (That is, we exclude any\nelements that have value 0 for the new vector.)\nThe new speci\ufb01c boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least generalizations.\nThe hypothesis hg is a least generalization of h if and only if: a) h is\nmore speci\ufb01c than hg, b) hg is su\ufb03cient, c) no function (including h) that\nis more speci\ufb01c than hg is su\ufb03cient, and d) hg is more speci\ufb01c than some\nmember of the new general boundary set. It might be that hg = h. Also,\nleast generalizations of two di\ufb00erent functions in the speci\ufb01c boundary set\nmay be identical.\nb. If the new vector is labelled with a 0:\nThe new speci\ufb01c boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not necessary. (That is, we exclude\nany elements that have value 1 for the new vector.)\nThe new general boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least specializations.\nThe hypothesis hs is a least specialization of hif and only if: a) his more\ngeneral than hs, b) hs is necessary, c) no function (including h) that is\nmore general than hs is necessary, and d) hs is more general than some\nmember of the new speci\ufb01c boundary set. Again, it might be that hs = h,\nand least specializations of two di\ufb00erent functions in the general boundary\nset may be identical.\nAs an example, suppose we present the vectors in the following order:\nvector label\n(1, 0, 1) 0\n(1, 0, 0) 1\n(1, 1, 1) 0\n(0, 0, 1) 0'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 42, 'page_label': '43'}, page_content='34 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nWe start with general boundary set, 1, and speci\ufb01c boundary set, 0.\nAfter seeing the \ufb01rst sample, (1, 0, 1), labeled with a 0, the speci\ufb01c boundary\nset stays at 0 (it is necessary), and we change the general boundary set to\n{x1,x2,x3}. Each of the functions, x1, x2, and x3, are least specializations of\n1 (they are necessary, 1 is not, they are more general than 0, and there\nare no functions that are more general than they and also necessary).\nThen, after seeing (1, 0, 0), labeled with a 1, the general boundary set\nchanges to {x3}(because x1 and x2 are not su\ufb03cient), and the speci\ufb01c boundary\nset is changed to {x1x2 x3}. This single function is a least generalization of 0\n(it is su\ufb03cient, 0 is more speci\ufb01c than it, no function (including 0) that is\nmore speci\ufb01c than it is su\ufb03cient, and it is more speci\ufb01c than some member of\nthe general boundary set.\nWhen we see (1, 1, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the\ngeneral boundary set either because x3 is still necessary.\nFinally, when we see (0, 0, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the general\nboundary set either because x3 is still necessary.Maybe Ill put in an example of a\nversion graph for non-Boolean\nfunctions.\n3.5 Bibliographical and Historical Remarks\nThe concept of version spaces and their role in learning was \ufb01rst investigated\nby Tom Mitchell [Mitchell, 1982]. Although these ideas are not used in prac-\ntical machine learning procedures, they do provide insight into the nature of\nhypothesis selection. In order to accomodate noisy data, version spaces have\nbeen generalized by [Hirsh, 1994] to allow hypotheses that are not necessarily\nconsistent with the training set.More to be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 43, 'page_label': '44'}, page_content='Chapter 4\nNeural Networks\nIn chapter two we de\ufb01ned several important subsets of Boolean functions. Sup-\npose we decide to use one of these subsets as a hypothesis set for supervised\nfunction learning. We next have the question of how best to implement the\nfunction as a device that gives the outputs prescribed by the function for arbi-\ntrary inputs. In this chapter we describe how networks of non-linear elements\ncan be used to implement various input-output functions and how they can be\ntrained using supervised learning methods.\nNetworks of non-linear elements, interconnected through adjustable weights,\nplay a prominent role in machine learning. They are called neural networks be-\ncause the non-linear elements have as their inputs a weighted sum of the outputs\nof other elementsmuch like networks of biological neurons do. These networks\ncommonly use the threshold element which we encountered in chapter two in\nour study of linearly separable Boolean functions. We begin our treatment of\nneural nets by studying this threshold element and how it can be used in the\nsimplest of all networks, namely ones composed of a single threshold element.\n4.1 Threshold Logic Units\n4.1.1 De\ufb01nitions and Geometry\nLinearly separable (threshold) functions are implemented in a straightforward\nway by summing the weighted inputs and comparing this sum to a threshold\nvalue as shown in Fig. 4.1. This structure we call a threshold logic unit (TLU) .\nIts output is 1 or 0 depending on whether or not the weighted sum of its inputs is\ngreater than or equal to a threshold value, \u03b8. It has also been called an Adaline\n(for ada ptive lin ear e lement) [Widrow, 1962, Widrow & Lehr, 1990], an LTU\n(linear threshold unit), a perceptron, and a neuron. (Although the word per-\nceptron is often used nowadays to refer to a single TLU, Rosenblatt originally\nde\ufb01ned it as a class of networks of threshold elements [Rosenblatt, 1958].)\n35'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 44, 'page_label': '45'}, page_content='36 CHAPTER 4. NEURAL NETWORKS\n!\nx1\nx2\nxn+1 = 1\nxi\nw1\nw2\nwn+1\nwi\nwn\nX\nthreshold weight\nxn\nW threshold  "  = 0\nf\nf = thresh( ! wi xi,  0)\ni = 1\nn+1\nFigure 4.1: A Threshold Logic Unit (TLU)\nThe n-dimensional feature or input vector is denoted by X = (x1,...,x n).\nWhen we want to distinguish among di\ufb00erent feature vectors, we will attach\nsubscripts, such as Xi. The components of X can be any real-valued numbers,\nbut we often specialize to the binary numbers 0 and 1. The weights of a TLU\nare represented by an n-dimensional weight vector , W = ( w1,...,w n). Its\ncomponents are real-valued numbers (but we sometimes specialize to integers).\nThe TLU has output 1 if \u2211n\ni=1 xiwi \u2265 \u03b8; otherwise it has output 0. The\nweighted sum that is calculated by the TLU can be simply represented as a\nvector dot product, XW. (If the pattern and weight vectors are thought of as\ncolumn vectors, this dot product is then sometimes written as XtW, where\nthe row vector Xt is the transpose of X.) Often, the threshold, \u03b8, of the TLU\nis \ufb01xed at 0; in that case, arbitrary thresholds are achieved by using ( n+ 1)-\ndimensional augmented vectors, Y, and V, whose \ufb01rst ncomponents are the\nsame as those of X and W, respectively. The ( n+ 1)-st component, xn+1, of\nthe augmented feature vector, Y, always has value 1; the (n+ 1)-st component,\nwn+1, of the augmented weight vector, V, is set equal to the negative of the\ndesired threshold value. (When we want to emphasize the use of augmented\nvectors, well use the Y,V notation; however when the context of the discussion\nmakes it clear about what sort of vectors we are talking about, well lapse back\ninto the more familiar X,W notation.) In the Y,V notation, the TLU has an\noutput of 1 if YV \u22650. Otherwise, the output is 0.\nWe can give an intuitively useful geometric description of a TLU. A TLU\ndivides the input space by a hyperplane as sketched in Fig. 4.2. The hyperplane\nis the boundary between patterns for which XW + wn+1 > 0 and patterns\nfor which XW + wn+1 < 0. Thus, the equation of the hyperplane itself is\nXW+wn+1 = 0. The unit vector that is normal to the hyperplane is n = W\n|W|,\nwhere |W|=\n\u221a\n(w2\n1 + ... + w2n) is the length of the vector W. (The normal'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 45, 'page_label': '46'}, page_content='4.1. THRESHOLD LOGIC UNITS 37\nform of the hyperplane equation is Xn + W\n|W| = 0.) The distance from the\nhyperplane to the origin is wn+1\n|W|, and the distance from an arbitrary point, X,\nto the hyperplane is XW+wn+1\n|W| . When the distance from the hyperplane to the\norigin is negative (that is, when wn+1 < 0), then the origin is on the negative\nside of the hyperplane (that is, the side for which XW + wn+1 <0).\nX.W + wn+1 > 0\non this side\nW\nX\nW\nn = W\n|W|\nOrigin\nUnit vector normal\nto hyperplane\nW + wn+1 = 0X\nn +           = 0X\nEquations of hyperplane:\nwn+1\n|W|\nwn+1 W + wn+1X\nX.W + wn+1 < 0\non this side\nFigure 4.2: TLU Geometry\nAdjusting the weight vector, W, changes the orientation of the hyperplane;\nadjusting wn+1 changes the position of the hyperplane (relative to the origin).\nThus, training of a TLU can be achieved by adjusting the values of the weights.\nIn this way the hyperplane can be moved so that the TLU implements di\ufb00erent\n(linearly separable) functions of the input.\n4.1.2 Special Cases of Linearly Separable Functions\nTerms\nAny term of size k can be implemented by a TLU with a weight from each of\nthose inputs corresponding to variables occurring in the term. A weight of +1 is\nused from an input corresponding to a positive literal, and a weight of\u22121 is used\nfrom an input corresponding to a negative literal. (Literals not mentioned in\nthe term have weights of zerothat is, no connection at allfrom their inputs.)\nThe threshold, \u03b8, is set equal to kp \u22121/2, where kp is the number of positive\nliterals in the term. Such a TLU implements a hyperplane boundary that is'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 46, 'page_label': '47'}, page_content='38 CHAPTER 4. NEURAL NETWORKS\nparallel to a subface of dimension ( n\u2212k) of the unit hypercube. We show a\nthree-dimensional example in Fig. 4.3. Thus, linearly separable functions are a\nsuperset of terms.\n(1,1,1)\n(1,1,0)\nx2\nx1\nx3 f = x1x2\nx1 + x2 - 3/2 = 0\nEquation of plane is:\nFigure 4.3: Implementing a Term\nClauses\nThe negation of a clause is a term. For example, the negation of the clause\nf = x1 + x2 + x3 is the term f = x1 x2 x3. A hyperplane can be used to\nimplement this term. If we invert the hyperplane, it will implement the\nclause instead. Inverting a hyperplane is done by multiplying all of the TLU\nweightseven wn+1by \u22121. This process simply changes the orientation of the\nhyperplane\ufb02ipping it around by 180 degrees and thus changing its positive\nside. Therefore, linearly separable functions are also a superset of clauses. We\nshow an example in Fig. 4.4.\n4.1.3 Error-Correction Training of a TLU\nThere are several procedures that have been proposed for adjusting the weights\nof a TLU. We present next a family of incremental training procedures with\nparameter c. These methods make adjustments to the weight vector only when\nthe TLU being trained makes an error on a training pattern; they are called\nerror-correction procedures. We use augmented feature and weight vectors in\ndescribing them.\na. We start with a \ufb01nite training set, \u039e, of vectors, Yi , and their binary\nlabels.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 47, 'page_label': '48'}, page_content='4.1. THRESHOLD LOGIC UNITS 39\nf = x1 + x2 + x3\nx1\nx1 + x2 + x3 < 1/2 = 0\nf = x1x2x3\nEquation of plane is:\nx2\nx3\nFigure 4.4: Implementing a Clause\nb. Compose an in\ufb01nite training sequence, \u03a3, of vectors from \u039e and their\nlabels such that each member of \u039e occurs in\ufb01nitely often in \u03a3. Set the\ninitial weight values of an TLU to arbitrary values.\nc. Repeat forever:\nPresent the next vector, Yi, in \u03a3 to the TLU and note its response.\n(a) If the TLU responds correctly, make no change in the weight vector.\n(b) If Yi is supposed to produce an output of 0 and produces an output\nof 1 instead, modify the weight vector as follows:\nV \u2190\u2212V \u2212ciYi\nwhere ci is a positive real number called the learning rate parame-\nter (whose value is di\ufb00ererent in di\ufb00erent instances of this family of\nprocedures and may depend on i).\nNote that after this adjustment the new dot product will be ( V \u2212\nciYi)Yi = VYi\u2212ciYiYi, which is smaller than it was before the\nweight adjustment.\n(c) If Yi is supposed to produce an output of 1 and produces an output\nof 0 instead, modify the weight vector as follows:\nV \u2190\u2212V + ciYi\nIn this case, the new dot product will be ( V + ciYi)Yi = VYi +\nciYiYi, which is larger than it was before the weight adjustment.\nNote that all three of these cases can be combined in the following rule:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 48, 'page_label': '49'}, page_content='40 CHAPTER 4. NEURAL NETWORKS\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere di is the desired response (1 or 0) for Yi , and fi is the actual\nresponse (1 or 0) for Yi.]\nNote also that because the weight vector V now includes the wn+1 thresh-\nold component, the threshold of the TLU is also changed by these adjust-\nments.\nWe identify two versions of this procedure:\n1) In the \ufb01xed-increment procedure, the learning rate parameter, ci, is the\nsame \ufb01xed, positive constant for all i. Depending on the value of this constant,\nthe weight adjustment may or may not correct the response to an erroneously\nclassi\ufb01ed feature vector.\n2) In the fractional-correction procedure, the parameter ci is set to \u03bbYiV\nYiYi\n,\nwhere V is the weight vector before it is changed. Note that if \u03bb = 0, no\ncorrection takes place at all. If \u03bb = 1, the correction is just su\ufb03cient to make\nYiV = 0. If \u03bb> 1, the error will be corrected.\nIt can be proved that if there is some weight vector, V, that produces a\ncorrect output for all of the feature vectors in \u039e, then after a \ufb01nite number\nof feature vector presentations, the \ufb01xed-increment procedure will \ufb01nd such a\nweight vector and thus make no more weight changes. The same result holds\nfor the fractional-correction procedure if 1 <\u03bb \u22642.\nFor additional background, proofs, and examples of error-correction proce-\ndures, see [Nilsson, 1990].See [Maass & Tur´ an, 1994] for a\nhyperplane-\ufb01nding procedure that\nmakes no more than O(n2 log n)\nmistakes.\n4.1.4 Weight Space\nWe can give an intuitive idea about how these procedures work by considering\nwhat happens to the augmented weight vector in weight space as corrections\nare made. We use augmented vectors in our discussion here so that the threshold\nfunction compares the dot product, YiV, against a threshold of 0. A particular\nweight vector, V, then corresponds to a point in ( n+ 1)-dimensional weight\nspace. Now, for any pattern vector, Yi, consider the locus of all points in\nweight space corresponding to weight vectors yielding YiV = 0. This locus is\na hyperplane passing through the origin of the ( n+ 1)-dimensional space. Each\npattern vector will have such a hyperplane corresponding to it. Weight points\nin one of the half-spaces de\ufb01ned by this hyperplane will cause the corresponding\npattern to yield a dot product less than 0, and weight points in the other half-\nspace will cause the corresponding pattern to yield a dot product greater than\n0.\nWe show a schematic representation of such a weight space in Fig. 4.5.\nThere are four pattern hyperplanes, 1, 2, 3, 4 , corresponding to patterns Y1,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 49, 'page_label': '50'}, page_content='4.1. THRESHOLD LOGIC UNITS 41\nY2, Y3, Y4, respectively, and we indicate by an arrow the half-space for each\nin which weight vectors give dot products greater than 0. Suppose we wanted\nweight values that would give positive responses for patterns Y1, Y3, and Y4,\nand a negative response for pattern Y2. The weight point, V, indicated in the\n\ufb01gure is one such set of weight values.\n23\n4\n1\nV\nFigure 4.5: Weight Space\nThe question of whether or not there exists a weight vector that gives desired\nresponses for a given set of patterns can be given a geometric interpretation. To\ndo so involves reversing the polarity of those hyperplanes corresponding to\npatterns for which a negative response is desired. If we do that for our example\nabove, we get the weight space diagram shown in Fig. 4.6.\n23\n4\n1\nV\n0\n1\n1\n23\n2\n3\n4\nFigure 4.6: Solution Region in Weight Space'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 50, 'page_label': '51'}, page_content='42 CHAPTER 4. NEURAL NETWORKS\nIf a weight vector exists that correctly classi\ufb01es a set of patterns, then the\nhalf-spaces de\ufb01ned by the correct responses for these patterns will have a non-\nempty intersection, called the solution region. The solution region will be a\nhyper-wedge region whose vertex is at the origin of weight space and whose\ncross-section increases with increasing distance from the origin. This region\nis shown shaded in Fig. 4.6. (The boxed numbers show, for later purposes,\nthe number of errors made by weight vectors in each of the regions.) The\n\ufb01xed-increment error-correction procedure changes a weight vector by moving it\nnormal to any pattern hyperplane for which that weight vector gives an incorrect\nresponse. Suppose in our example that we present the patterns in the sequence\nY1, Y2, Y3, Y4, and start the process with a weight point V1, as shown in Fig.\n4.7. Starting at V1, we see that it gives an incorrect response for pattern Y1, so\nwe move V1 to V2 in a direction normal to plane 1. (That is what adding Y1 to\nV1 does.) Y2 gives an incorrect response for pattern Y2, and so on. Ultimately,\nthe responses are only incorrect for planes bounding the solution region. Some\nof the subsequent corrections may overshoot the solution region, but eventually\nwe work our way out far enough in the solution region that corrections (for\na \ufb01xed increment size) take us within it. The proofs for convergence of the\n\ufb01xed-increment rule make this intuitive argument precise.\n23\n4\n1\nV\nV1\nV2\nV3\nV4\nV5\nV6\nFigure 4.7: Moving Into the Solution Region\n4.1.5 The Widrow-Ho\ufb00 Procedure\nThe Widrow-Ho\ufb00 procedure (also called the LMS or the delta procedure) at-\ntempts to \ufb01nd weights that minimize a squared-error function between the pat-\ntern labels and the dot product computed by a TLU. For this purpose, the\npattern labels are assumed to be either +1 or \u22121 (instead of 1 or 0). The'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 51, 'page_label': '52'}, page_content='4.1. THRESHOLD LOGIC UNITS 43\nsquared error for a pattern, Xi, with label di (for desired output) is:\n\u03b5i = (di \u2212\nn+1\u2211\nj=1\nxijwj)2\nwhere xij is the j-th component of Xi. The total squared error (over all patterns\nin a training set, \u039e, containing m patterns) is then:\n\u03b5=\nm\u2211\ni=1\n(di \u2212\nn+1\u2211\nj=1\nxijwj)2\nWe want to choose the weightswj to minimize this squared error. One way to\n\ufb01nd such a set of weights is to start with an arbitrary weight vector and move it\nalong the negative gradient of\u03b5as a function of the weights. Since \u03b5is quadratic\nin the wj, we know that it has a global minimum, and thus this steepest descent\nprocedure is guaranteed to \ufb01nd the minimum. Each component of the gradient\nis the partial derivative of \u03b5 with respect to one of the weights. One problem\nwith taking the partial derivative of \u03b5is that \u03b5depends on all the input vectors\nin \u039e. Often, it is preferable to use an incremental procedure in which we try the\nTLU on just one element, Xi, of \u039e at a time, compute the gradient of the single-\npattern squared error, \u03b5i, make the appropriate adjustment to the weights, and\nthen try another member of \u039e. Of course, the results of the incremental version\ncan only approximate those of the batch one, but the approximation is usually\nquite e\ufb00ective. We will be describing the incremental version here.\nThe j-th component of the gradient of the single-pattern error is:\n\u2202\u03b5i\n\u2202wj\n= \u22122(di \u2212\nn+1\u2211\nj=1\nxijwj)xij\nAn adjustment in the direction of the negative gradient would then change each\nweight as follows:\nwj \u2190\u2212wj + ci(di \u2212fi)xij\nwhere fi = \u2211n+1\nj=1 xijwj, and ci governs the size of the adjustment. The entire\nweight vector (in augmented, or V, notation) is thus adjusted according to the\nfollowing rule:\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere, as before, Yi is the i-th augmented pattern vector.\nThe Widrow-Ho\ufb00 procedure makes adjustments to the weight vector when-\never the dot product itself, YiV, does not equal the speci\ufb01ed desired target'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 52, 'page_label': '53'}, page_content='44 CHAPTER 4. NEURAL NETWORKS\nvalue, di (which is either 1 or \u22121). The learning-rate factor, ci, might de-\ncrease with time toward 0 to achieve asymptotic convergence. The Widrow-\nHo\ufb00 formula for changing the weight vector has the same form as the standard\n\ufb01xed-increment error-correction formula. The only di\ufb00erence is that fi is the\nthresholded response of the TLU in the error-correction case while it is the dot\nproduct itself for the Widrow-Ho\ufb00 procedure.\nFinding weight values that give the desired dot products corresponds to solv-\ning a set of linear equalities, and the Widrow-Ho\ufb00 procedure can be interpreted\nas a descent procedure that attempts to minimize the mean-squared-error be-\ntween the actual and desired values of the dot product. (For more on Widrow-\nHo\ufb00 and other related procedures, see [Duda & Hart, 1973, pp. 151\ufb00].)Examples of training curves for\nTLUs; performance on training\nset; performance on test set;\ncumulative number of corrections. 4.1.6 Training a TLU on Non-Linearly-Separable Training\nSets\nWhen the training set is not linearly separable (perhaps because of noise or\nperhaps inherently), it may still be desired to \ufb01nd a best separating hy-\nperplane. Typically, the error-correction procedures will not do well on non-\nlinearly-separable training sets because they will continue to attempt to correct\ninevitable errors, and the hyperplane will never settle into an acceptable place.\nSeveral methods have been proposed to deal with this case. First, we might\nuse the Widrow-Ho\ufb00 procedure, which (although it will not converge to zero\nerror on non-linearly separable problems) will give us a weight vector that min-\nimizes the mean-squared-error. A mean-squared-error criterion often gives un-\nsatisfactory results, however, because it prefers many small errors to a few large\nones. As an alternative, error correction with a continuous decrease toward zero\nof the value of the learning rate constant,c, will result in ever decreasing changes\nto the hyperplane. Duda [Duda, 1966] has suggested keeping track of the average\nvalue of the weight vector during error correction and using this average to give a\nseparating hyperplane that performs reasonably well on non-linearly-separable\nproblems. Gallant [Gallant, 1986] proposed what he called the pocket algo-\nrithm. As described in [Hertz, Krogh, & Palmer, 1991, p. 160]:\n. . . the pocket algorithm . . . consists simply in storing (or putting\nin your pocket) the set of weights which has had the longest un-\nmodi\ufb01ed run of successes so far. The algorithm is stopped after some\nchosen time t . . .\nAfter stopping, the weights in the pocket are used as a set that should give a\nsmall number of errors on the training set. Error-correction proceeds as usual\nwith the ordinary set of weights.Also see methods proposed by\n[John, 1995] and by\n[Marchand & Golea, 1993]. The\nlatter is claimed to outperform the\npocket algorithm. 4.2 Linear Machines\nThe natural generalization of a (two-category) TLU to an R-category classi\ufb01er\nis the structure, shown in Fig. 4.8, called a linear machine. Here, to use more'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 53, 'page_label': '54'}, page_content='4.2. LINEAR MACHINES 45\nfamiliar notation, the Ws and X are meant to be augmented vectors (with an\n(n+1)-st component). Such a structure is also sometimes called a competitive\nnet or a winner-take-all net. The output of the linear machine is one of\nthe numbers, {1,...,R }, corresponding to which dot product is largest. Note\nthat when R = 2, the linear machine reduces to a TLU with weight vector\nW = (W1 \u2212W2).\nX\nW1\nWR\n. . .\nY\nY\nARGMAX\nW1.X\nWR.X\nFigure 4.8: A Linear Machine\nThe diagram in Fig. 4.9 shows the character of the regions in a 2-dimensional\nspace created by a linear machine for R = 5. In n dimensions, every pair of\nregions is either separated by a section of a hyperplane or is non-adjacent.\nR 1\nR 3\nR 4\nR 5\nX.W4  * X.Wi for i & 4\nR 2\nIn this region:\nFigure 4.9: Regions For a Linear Machine\nTo train a linear machine, there is a straightforward generalization of the\n2-category error-correction rule. Assemble the patterns in the training set into\na sequence as before.\na. If the machine classi\ufb01es a pattern correctly, no change is made to any of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 54, 'page_label': '55'}, page_content='46 CHAPTER 4. NEURAL NETWORKS\nthe weight vectors.\nb. If the machine mistakenly classi\ufb01es a category u pattern, Xi, in category\nv (u\u0338= v), then:\nWu \u2190\u2212Wu + ciXi\nand\nWv \u2190\u2212Wv \u2212ciXi\nand all other weight vectors are not changed.\nThis correction increases the value of the u-th dot product and decreases the\nvalue of the v-th dot product. Just as in the 2-category \ufb01xed increment proce-\ndure, this procedure is guaranteed to terminate, for constant ci, if there exists\nweight vectors that make correct separations of the training set. Note that when\nR= 2, this procedure reduces to the ordinary TLU error-correction procedure.\nA proof that this procedure terminates is given in [Nilsson, 1990, pp. 88-90]\nand in [Duda & Hart, 1973, pp. 174-177].\n4.3 Networks of TLUs\n4.3.1 Motivation and Examples\nLayered Networks\nTo classify correctly all of the patterns in non-linearly-separable training sets re-\nquires separating surfaces more complex than hyperplanes. One way to achieve\nmore complex surfaces is with networks of TLUs. Consider, for example, the 2-\ndimensional, even parity function, f = x1x2 + x1 x2. No single line through the\n2-dimensional square can separate the vertices (1,1) and (0,0) from the vertices\n(1,0) and (0,1)the function is not linearly separable and thus cannot be im-\nplemented by a single TLU. But, the network of three TLUs shown in Fig. 4.10\ndoes implement this function. In the \ufb01gure, we show the weight values along\ninput lines to each TLU and the threshold value inside the circle representing\nthe TLU.\nThe function implemented by a network of TLUs depends on its topology\nas well as on the weights of the individual TLUs. Feedforward networks have\nno cycles; in a feedforward network no TLUs input depends (through zero\nor more intermediate TLUs) on that TLUs output. (Networks that are not\nfeedforward are calledrecurrentnetworks). If the TLUs of a feedforward network\nare arranged in layers, with the elements of layer j receiving inputs only from\nTLUs in layer j \u22121, then we say that the network is a layered, feedforward'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 55, 'page_label': '56'}, page_content='4.3. NETWORKS OF TLUS 47\nf\nx1\nx2\n1.5\n-0.5\n0.5\n1\n1-1\n-1 1\n1\nFigure 4.10: A Network for the Even Parity Function\nnetwork. The network shown in Fig. 4.10 is a layered, feedforward network\nhaving two layers (of weights). (Some people count the layers of TLUs and\ninclude the inputs as a layer also; they would call this network a three-layer\nnetwork.) In general, a feedforward, layered network has the structure shown\nin Fig. 4.11. All of the TLUs except the output units are called hidden units\n(they are hidden from the output).\nX\nhidden units\noutput units\nFigure 4.11: A Layered, Feedforward Network\nImplementing DNF Functions by Two-Layer Networks\nWe have already de\ufb01nedk-term DNF functionsthey are DNF functions having\nk terms. A k-term DNF function can be implemented by a two-layer network\nwith k units in the hidden layerto implement the k termsand one output\nunit to implement the disjunction of these terms. Since any Boolean function\nhas a DNF form, any Boolean function can be implemented by some two-layer\nnetwork of TLUs. As an example, consider the function f = x1x2 + x2x3 +\nx1x3. The form of the network that implements this function is shown in Fig.\n4.12. (We leave it to the reader to calculate appropriate values of weights and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 56, 'page_label': '57'}, page_content='48 CHAPTER 4. NEURAL NETWORKS\nthresholds.) The 3-cube representation of the function is shown in Fig. 4.13.\nThe network of Fig. 4.12 can be designed so that each hidden unit implements\none of the planar boundaries shown in Fig. 4.13.\nx\nconjuncts\ndisjunct\nA Feedforward, 2-layer Network\nTLUs\ndisjunction\nof terms\nconjunctions\nof literals\n(terms)\nFigure 4.12: A Two-Layer Network\nx2\nx1\nx3\nf = x1x2 + x2x3 + x1x3\nFigure 4.13: Three Planes Implemented by the Hidden Units\nTo train a two-layer network that implements a k-term DNF function, we\n\ufb01rst note that the output unit implements a disjunction, so the weights in the\n\ufb01nal layer are \ufb01xed. The weights in the \ufb01rst layer (except for the threshold\nweights) can all have values of 1, \u22121, or 0. Later, we will present a training\nprocedure for this \ufb01rst layer of weights.Discuss half-space intersections,\nhalf-space unions, NP-hardness of\noptimal versions,\nsingle-side-error-hypeplane\nmethods, relation to AQ\nmethods.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 57, 'page_label': '58'}, page_content='4.3. NETWORKS OF TLUS 49\nImportant Comment About Layered Networks\nAdding additional layers cannot compensate for an inadequate \ufb01rst layer of\nTLUs. The \ufb01rst layer of TLUs partitions the feature space so that no two dif-\nferently labeled vectors are in the same region (that is, so that no two such\nvectors yield the same set of outputs of the \ufb01rst-layer units). If the \ufb01rst layer\ndoes not partition the feature space in this way, then regardless of what subse-\nquent layers do, the \ufb01nal outputs will not be consistent with the labeled training\nset. Add diagrams showing the\nnon-linear transformation\nperformed by a layered network.\n4.3.2 Madalines\nTwo-Category Networks\nAn interesting example of a layered, feedforward network is the two-layer one\nwhich has an odd number of hidden units, and a vote-taking TLU as the\noutput unit. Such a network was called a Madaline (for m any adalines by\nWidrow. Typically, the response of the vote taking unit is de\ufb01ned to be the\nresponse of the majority of the hidden units, although other output logics are\npossible. Ridgway [Ridgway, 1962] proposed the following error-correction rule\nfor adjusting the weights of the hidden units of a Madaline:\n If the Madaline correctly classi\ufb01es a pattern, Xi, no corrections are made\nto any of the hidden units weight vectors,\n If the Madaline incorrectly classi\ufb01es a pattern, Xi, then determine the\nminimum number of hidden units whose responses need to be changed\n(from 0 to 1 or from 1 to 0depending on the type of error) in order that\nthe Madaline would correctly classify Xi. Suppose that minimum number\nis ki. Of those hidden units voting incorrectly, change the weight vectors\nof those ki of them whose dot products are closest to 0 by using the error\ncorrection rule:\nW \u2190\u2212W + ci(di \u2212fi)Xi\nwhere di is the desired response of the hidden unit (0 or 1) and fi is the\nactual response (0 or 1). (We assume augmented vectors here even though\nwe are using X, W notation.)\nThat is, we perform error-correction on just enough hidden units to correct\nthe vote to a majority voting correctly, and we change those that are easiest to\nchange. There are example problems in which even though a set of weight values\nexists for a given Madaline structure such that it could classify all members of\na training set correctly, this procedure will fail to \ufb01nd them. Nevertheless, the\nprocedure works e\ufb00ectively in most experiments with it.\nWe leave it to the reader to think about how this training procedure could\nbe modi\ufb01ed if the output TLU implemented an or function (or an and function).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 58, 'page_label': '59'}, page_content='50 CHAPTER 4. NEURAL NETWORKS\nR-Category Madalines and Error-Correcting Output Codes\nIf there are k hidden units ( k > 1) in a two-layer network, their responses\ncorrespond to vertices of ak-dimensional hypercube. The ordinary two-category\nMadaline identi\ufb01es two special points in this space, namely the vertex consisting\nof k 1s and the vertex consisting of k 0s. The Madalines response is 1 if the\npoint in hidden-unit-space is closer to the all 1s vertex than it is to the all\n0s vertex. We could design an R-category Madaline by identifying R vertices\nin hidden-unit space and then classifying a pattern according to which of these\nvertices the hidden-unit response is closest to. A machine using that idea was\nimplemented in the early 1960s at SRI [Brain, et al., 1962]. It used the fact\nthat the 2p so-called maximal-length shift-register sequences[Peterson, 1961, pp.\n147\ufb00] in a (2p\u22121)-dimensional Boolean space are mutually equidistant (for any\ninteger p). For similar, more recent work see [Dietterich & Bakiri, 1991].\n4.3.3 Piecewise Linear Machines\nA two-category training set is linearly separable if there exists a threshold func-\ntion that correctly classi\ufb01es all members of the training set. Similarly, we can\nsay that an R-category training set is linearly separable if there exists a linear\nmachine that correctly classi\ufb01es all members of the training set. When an R-\ncategory problem is not linearly separable, we need a more powerful classi\ufb01er.\nA candidate is a structure called a piecewise linear (PWL) machine illustrated\nin Fig. 4.14.\nX\nW1\nW1\n. . .\nY\nY\nMAX\n. . .\nY\nY\nMAX\n. . .\nWR\nWR\nARG\nMAX\n1\nR\n1\nN1\n1\nNR\nFigure 4.14: A Piecewise Linear Machine'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 59, 'page_label': '60'}, page_content='4.3. NETWORKS OF TLUS 51\nThe PWL machine groups its weighted summing units into R banks corre-\nsponding to the R categories. An input vector X is assigned to that category\ncorresponding to the bank with the largest weighted sum. We can use an error-\ncorrection training algorithm similar to that used for a linear machine. If a\npattern is classi\ufb01ed incorrectly, we subtract (a constant times) the pattern vec-\ntor from the weight vector producing the largest dot product (it was incorrectly\nthe largest) and add (a constant times) the pattern vector to that weight vector\nin the correct bank of weight vectors whose dot product is locally largest in\nthat bank. (Again, we use augmented vectors here.) Unfortunately, there are\nexample training sets that are separable by a given PWL machine structure\nbut for which this error-correction training method fails to \ufb01nd a solution. The\nmethod does appear to work well in some situations [Duda & Fossum, 1966], al-\nthough [Nilsson, 1965, page 89] observed that it is probably not a very e\ufb00ective\nmethod for training PWL machines having more than three [weight vectors] in\neach bank.\n4.3.4 Cascade Networks\nAnother interesting class of feedforward networks is that in which all of the TLUs\nare ordered and each TLU receives inputs from all of the pattern components\nand from all TLUs lower in the ordering. Such a network is called a cascade\nnetwork. An example is shown in Fig. 4.15 in which the TLUs are labeled by\nthe linearly separable functions (of their inputs) that they implement. Each\nTLU in the network implements a set of 2 k parallel hyperplanes, where k is\nthe number of TLUs from which it receives inputs. (Each of the k preceding\nTLUs can have an output of 1 or 0; thats 2 k di\ufb00erent combinationsresulting\nin 2k di\ufb00erent positions for the parallel hyperplanes.) We show a 3-dimensional\nsketch for a network of two TLUs in Fig. 4.16. The reader might consider how\nthe n-dimensional parity function might be implemented by a cascade network\nhaving log2 n TLUs.\nx\nL1\nL2\noutput\nL3\nFigure 4.15: A Cascade Network'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 60, 'page_label': '61'}, page_content='52 CHAPTER 4. NEURAL NETWORKS\nL1\nL2\nL2\nFigure 4.16: Planes Implemented by a Cascade Network with Two TLUs\nCascade networks might be trained by \ufb01rst training L1 to do as good a job\nas possible at separating all the training patterns (perhaps by using the pocket\nalgorithm, for example), then training L2 (including the weight from L1 to L2)\nalso to do as good a job as possible at separating all the training patterns,\nand so on until the resulting network classi\ufb01es the patterns in the training set\nsatisfactorily.Also mention the\ncascade-correlation method of\n[Fahlman & Lebiere, 1990].\n4.4 Training Feedforward Networks by Back-\npropagation\n4.4.1 Notation\nThe general problem of training a network of TLUs is di\ufb03cult. Consider, for\nexample, the layered, feedforward network of Fig. 4.11. If such a network makes\nan error on a pattern, there are usually several di\ufb00erent ways in which the error\ncan be corrected. It is di\ufb03cult to assign blame for the error to any particular\nTLU in the network. Intuitively, one looks for weight-adjusting procedures that\nmove the network in the correct direction (relative to the error) by making\nminimal changes. In this spirit, the Widrow-Ho\ufb00 method of gradient descent\nhas been generalized to deal with multilayer networks.\nIn explaining this generalization, we use Fig. 4.17 to introduce some nota-\ntion. This network has only one output unit, but, of course, it is possible to have\nseveral TLUs in the output layereach implementing a di\ufb00erent function. Each\nof the layers of TLUs will have outputs that we take to be the components of\nvectors, just as the input features are components of an input vector. The j-th\nlayer of TLUs (1 \u2264j <k) will have as their outputs the vector X(j). The input\nfeature vector is denoted by X(0), and the \ufb01nal output (of the k-th layer TLU)\nis f. Each TLU in each layer has a weight vector (connecting it to its inputs)\nand a threshold; the i-th TLU in the j-th layer has a weight vector denoted by\nW(j)\ni . (We will assume that the threshold weight is the last component of\nthe associated weight vector; we might have used V notation instead to include'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 61, 'page_label': '62'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION53\nthis threshold component, but we have chosen here to use the familiar X,W\nnotation, assuming that these vectors are augmented as appropriate.) We\ndenote the weighted sum input to the i-th threshold unit in the j-th layer by\ns(j)\ni . (That is, s(j)\ni = X(j\u22121)W(j)\ni .) The number of TLUs in the j-th layer is\ngiven by mj. The vector W(j)\ni has components w(j)\nl,i for l= 1,...,m (j\u22121) + 1.\nX(0)\n. . .\n. . .\n. . .\n. . .\nWi(1)\nW(k)\nX(1)\nm1 TLUs\n. . .\nWi(j)\n. . .\nX(j)\n. . .\nWi(k-1)\nX(k-1)\nmj TLUs m(k-1) TLUs\nwli(j)\nwl(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . .\nf\nsi(1) si(j) si(k-1)\ns(k)\nFigure 4.17: A k-layer Network\n4.4.2 The Backpropagation Method\nA gradient descent method, similar to that used in the Widrow Ho\ufb00 method,\nhas been proposed by various authors for training a multi-layer, feedforward\nnetwork. As before, we de\ufb01ne an error function on the \ufb01nal output of the\nnetwork and we adjust each weight in the network so as to minimize the error.\nIf we have a desired response, di, for the i-th input vector, Xi, in the training\nset, \u039e, we can compute the squared error over the entire training set to be:\n\u03b5=\n\u2211\nXi \u03f5 \u039e\n(di \u2212fi)2\nwhere fi is the actual response of the network for input Xi. To do gradient\ndescent on this squared error, we adjust each weight in the network by an\namount proportional to the negative of the partial derivative of \u03b5 with respect\nto that weight. Again, we use a single-pattern error function so that we can\nuse an incremental weight adjustment procedure. The squared error for a single\ninput vector, X, evoking an output of f when the desired output is d is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 62, 'page_label': '63'}, page_content='54 CHAPTER 4. NEURAL NETWORKS\n\u03b5= (d\u2212f)2\nIt is convenient to take the partial derivatives of\u03b5with respect to the various\nweights in groups corresponding to the weight vectors. We de\ufb01ne a partial\nderivative of a quantity \u03c6, say, with respect to a weight vector, W(j)\ni , thus:\n\u2202\u03c6\n\u2202W(j)\ni\ndef\n=\n[\n\u2202\u03c6\n\u2202w(j)\n1i\n,..., \u2202\u03c6\n\u2202w(j)\nli\n,..., \u2202\u03c6\n\u2202w(j)\nmj\u22121+1,i\n]\nwhere w(j)\nli is the l-th component of W(j)\ni . This vector partial derivative of \u03c6is\ncalled the gradient of \u03c6 with respect to W and is sometimes denoted by \u2207W\u03c6.\nSince \u03b5s dependence on W(j)\ni is entirely through s(j)\ni , we can use the chain\nrule to write:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\n\u2202s(j)\ni\n\u2202W(j)\ni\nBecause s(j)\ni = X(j\u22121)W(j)\ni ,\n\u2202s(j)\ni\n\u2202W(j)\ni\n= X(j\u22121). Substituting yields:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\nX(j\u22121)\nNote that \u2202\u03b5\n\u2202s(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\n. Thus,\n\u2202\u03b5\n\u2202W(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\nX(j\u22121)\nThe quantity (d\u2212f) \u2202f\n\u2202s(j)\ni\nplays an important role in our calculations; we shall\ndenote it by \u03b4(j)\ni . Each of the \u03b4(j)\ni s tells us how sensitive the squared error of\nthe network output is to changes in the input to each threshold function. Since\nwe will be changing weight vectors in directions along their negative gradient,\nour fundamental rule for weight changes throughout the network will be:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nwhere c(j)\ni is the learning rate constant for this weight vector. (Usually, the\nlearning rate constants for all weight vectors in the network are the same.) We\nsee that this rule is quite similar to that used in the error correction procedure'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 63, 'page_label': '64'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION55\nfor a single TLU. A weight vector is changed by the addition of a constant times\nits vector of (unweighted) inputs.\nNow, we must turn our attention to the calculation of the \u03b4(j)\ni s. Using the\nde\ufb01nition, we have:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nWe have a problem, however, in attempting to carry out the partial deriva-\ntives of f with respect to the ss. The network output, f, is not continuously\ndi\ufb00erentiable with respect to the ss because of the presence of the threshold\nfunctions. Most small changes in these sums do not change f at all, and when\nf does change, it changes abruptly from 1 to 0 or vice versa.\nA way around this di\ufb03culty was proposed by Werbos [Werbos, 1974] and\n(perhaps independently) pursued by several other researchers, for example\n[Rumelhart, Hinton, & Williams, 1986]. The trick involves replacing all the\nthreshold functions by di\ufb00erentiable functions called sigmoids.1 The output\nof a sigmoid function, superimposed on that of a threshold function, is shown\nin Fig. 4.18. Usually, the sigmoid function used is f(s) = 1\n1+e\u2212s , where s is\nthe input and f is the output.\nsigmoid\nthreshold function\nf (s)\ns\nf (s) = 1/[1 + e<s]\nFigure 4.18: A Sigmoid Function\n1[Russell & Norvig 1995, page 595] attributes the use of this idea to [Bryson & Ho 1969].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 64, 'page_label': '65'}, page_content='56 CHAPTER 4. NEURAL NETWORKS\nWe show the network containing sigmoid units in place of TLUs in Fig. 4.19.\nThe output of the i-th sigmoid unit in the j-th layer is denoted by f(j)\ni . (That\nis, f(j)\ni = 1\n1+e\u2212s(j)\ni\n.)\nX(0)\n. . .\n. . .\n. . .\n. . .\nWi(1)\nsi(1)\nW(k)\nX(1)\nfi(1)\nm1 sigmoids\n. . .\nWi(j) fi(j)\nsi(j)\n. . .\nX(j)\n. . .\nWi(k-1)\nfi(k-1)\nsi(k-1)\nf(k)\ns(k)\nX(k-1)\nmj sigmoids m(k-1) sigmoids\nwli(j)\nwl(k)\nbi(j)bi(1)\nbi(k-1)\nb(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . .\nFigure 4.19: A Network with Sigmoid Units\n4.4.3 Computing Weight Changes in the Final Layer\nWe \ufb01rst calculate\u03b4(k) in order to compute the weight change for the \ufb01nal sigmoid\nunit:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 65, 'page_label': '66'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION57\n\u03b4(k) = (d\u2212f(k))\u2202f(k)\n\u2202s(k)\nGiven the sigmoid function that we are using, namely f(s) = 1\n1+e\u2212s, we have\nthat \u2202f\n\u2202s = f(1 \u2212f). Substituting gives us:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nRewriting our general rule for weight vector changes, the weight vector in\nthe \ufb01nal layer is changed according to the rule:\nW(k) \u2190W(k) + c(k)\u03b4(k)X(k\u22121)\nwhere \u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nIt is interesting to compare backpropagation to the error-correction rule and\nto the Widrow-Ho\ufb00 rule. The backpropagation weight adjustment for the single\nelement in the \ufb01nal layer can be written as:\nW \u2190\u2212W + c(d\u2212f)f(1 \u2212f)X\nWritten in the same format, the error-correction rule is:\nW \u2190\u2212W + c(d\u2212f)X\nand the Widrow-Ho\ufb00 rule is:\nW \u2190\u2212W + c(d\u2212f)X\nThe only di\ufb00erence (except for the fact that f is not thresholded in Widrow-\nHo\ufb00) is the f(1 \u2212f) term due to the presence of the sigmoid function. With\nthe sigmoid function, f(1 \u2212f) can vary in value from 0 to 1. When f is 0,\nf(1 \u2212f) is also 0; when f is 1, f(1 \u2212f) is 0; f(1 \u2212f) obtains its maximum\nvalue of 1/4 when f is 1/2 (that is, when the input to the sigmoid is 0). The\nsigmoid function can be thought of as implementing a fuzzy hyperplane. For\na pattern far away from this fuzzy hyperplane, f(1 \u2212f) has value close to 0,\nand the backpropagation rule makes little or no change to the weight values\nregardless of the desired output. (Small changes in the weights will have little\ne\ufb00ect on the output for inputs far from the hyperplane.) Weight changes are\nonly made within the region of fuzz surrounding the hyperplane, and these\nchanges are in the direction of correcting the error, just as in the error-correction\nand Widrow-Ho\ufb00 rules.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 66, 'page_label': '67'}, page_content='58 CHAPTER 4. NEURAL NETWORKS\n4.4.4 Computing Changes to the Weights in Intermediate\nLayers\nUsing our expression for the \u03b4s, we can similarly compute how to change each\nof the weight vectors in the network. Recall:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nAgain we use a chain rule. The \ufb01nal output, f, depends on s(j)\ni through\neach of the summed inputs to the sigmoids in the ( j+ 1)-th layer. So:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\n= (d\u2212f)\n[\n\u2202f\n\u2202s(j+1)\n1\n\u2202s(j+1)\n1\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nmj+1\n\u2202s(j+1)\nmj+1\n\u2202s(j)\ni\n]\n=\nmj+1\u2211\nl=1\n(d\u2212f) \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\nIt remains to compute the\n\u2202s(j+1)\nl\n\u2202s(j)\ni\ns. To do that we \ufb01rst write:\ns(j+1)\nl = X(j)W(j+1)\nl\n=\nmj+1\u2211\n\u03bd=1\nf(j)\n\u03bd w(j+1)\n\u03bdl\nAnd then, since the weights do not depend on the ss:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\n\u2202\n[\u2211mj+1\n\u03bd=1 f(j)\n\u03bd w(j+1)\n\u03bdl\n]\n\u2202s(j)\ni\n=\nmj+1\u2211\n\u03bd=1\nw(j+1)\n\u03bdl\n\u2202f(j)\n\u03bd\n\u2202s(j)\ni\nNow, we note that \u2202f(j)\n\u03bd\n\u2202s(j)\ni\n= 0 unless \u03bd = i, in which case \u2202f(j)\n\u03bd\n\u2202s(j)\n\u03bd\n= f(j)\n\u03bd (1 \u2212f(j)\n\u03bd ).\nTherefore:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n= w(j+1)\nil f(j)\ni (1 \u2212f(j)\ni )'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 67, 'page_label': '68'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION59\nWe use this result in our expression for \u03b4(j)\ni to give:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nThe above equation is recursive in the \u03b4s. (It is interesting to note that\nthis expression is independent of the error function; the error function explicitly\na\ufb00ects only the computation of \u03b4(k).) Having computed the \u03b4(j+1)\ni s for layer\nj + 1, we can use this equation to compute the \u03b4(j)\ni s. The base case is \u03b4(k),\nwhich we have already computed:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nWe use this expression for the\u03b4s in our generic weight changing rule, namely:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nAlthough this rule appears complex, it has an intuitively reasonable explanation.\nThe quantity \u03b4(k) = (d\u2212f)f(1 \u2212f) controls the overall amount and sign of all\nweight adjustments in the network. (Adjustments diminish as the \ufb01nal output,\nf, approaches either 0 or 1, because they have vanishing e\ufb00ect on f then.) As\nthe recursion equation for the \u03b4s shows, the adjustments for the weights going\nin to a sigmoid unit in the j-th layer are proportional to the e\ufb00ect that such\nadjustments have on that sigmoid units output (its f(j)(1 \u2212f(j)) factor). They\nare also proportional to a kind of average e\ufb00ect that any change in the output\nof that sigmoid unit will have on the \ufb01nal output. This average e\ufb00ect depends\non the weights going out of the sigmoid unit in the j-th layer (small weights\nproduce little downstream e\ufb00ect) and the e\ufb00ects that changes in the outputs of\n(j+ 1)-th layer sigmoid units will have on the \ufb01nal output (as measured by the\n\u03b4(j+1)s). These calculations can be simply implemented by backpropagating\nthe \u03b4s through the weights in reverse direction (thus, the name backprop for\nthis algorithm).\n4.4.5 Variations on Backprop\n[To be written: problem of local minima, simulated annealing, momemtum\n(Plaut, et al., 1986, see [Hertz, Krogh, & Palmer, 1991]), quickprop, regulariza-\ntion methods]\nSimulated Annealing\nTo apply simulated annealing, the value of the learning rate constant is gradually\ndecreased with time. If we fall early into an error-function valley that is not\nvery deep (a local minimum), it typically will neither be very broad, and soon'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 68, 'page_label': '69'}, page_content='60 CHAPTER 4. NEURAL NETWORKS\na subsequent large correction will jostle us out of it. It is less likely that we will\nmove out of deep valleys, and at the end of the process (with very small values\nof the learning rate constant), we descend to its deepest point. The process\ngets its name by analogy with annealing in metallurgy, in which a materials\ntemperature is gradually decreased allowing its crystalline structure to reach a\nminimal energy state.\n4.4.6 An Application: Steering a Van\nA neural network system called ALVINN (Autonomous Land Vehicle in a Neural\nNetwork) has been trained to steer a Chevy van successfully on ordinary roads\nand highways at speeds of 55 mph [Pomerleau, 1991, Pomerleau, 1993]. The\ninput to the network is derived from a low-resolution (30 x 32) television image.\nThe TV camera is mounted on the van and looks at the road straight ahead.\nThis image is sampled and produces a stream of 960-dimensional input vectors\nto the neural network. The network is shown in Fig. 4.20.\n960 inputs\n30 x 32 retina\n. . .\n5 hidden\nunits connected\nto all 960 inputs\n30 output units\nconnected to all\nhidden units\n. . .\nsharp left\nsharp right\nstraight ahead\ncentroid\nof outputs\nsteers\nvehicle\nFigure 4.20: The ALVINN Network\nThe network has \ufb01ve hidden units in its \ufb01rst layer and 30 output units in the\nsecond layer; all are sigmoid units. The output units are arranged in a linear\norder and control the vans steering angle. If a unit near the top of the array\nof output units has a higher output than most of the other units, the van is\nsteered to the left; if a unit near the bottom of the array has a high output, the\nvan is steered to the right. The centroid of the responses of all of the output'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 69, 'page_label': '70'}, page_content='4.5. SYNERGIES BETWEEN NEURAL NETWORK AND KNOWLEDGE-BASED METHODS61\nunits is computed, and the vans steering angle is set at a corresponding value\nbetween hard left and hard right.\nThe system is trained by a modi\ufb01ed on-line training regime. A driver drives\nthe van, and his actual steering angles are taken as the correct labels for the\ncorresponding inputs. The network is trained incrementally by backprop to\nproduce the driver-speci\ufb01ed steering angles in response to each visual pattern\nas it occurs in real time while driving.\nThis simple procedure has been augmented to avoid two potential problems.\nFirst, since the driver is usually driving well, the network would never get any\nexperience with far-from-center vehicle positions and/or incorrect vehicle orien-\ntations. Also, on long, straight stretches of road, the network would be trained\nfor a long time only to produce straight-ahead steering angles; this training\nwould swamp out earlier training to follow a curved road. We wouldnt want\nto try to avoid these problems by instructing the driver to drive erratically\noccasionally, because the system would learn to mimic this erratic behavior.\nInstead, each original image is shifted and rotated in software to create 14\nadditional images in which the vehicle appears to be situated di\ufb00erently relative\nto the road. Using a model that tells the system what steering angle ought to\nbe used for each of these shifted images, given the driver-speci\ufb01ed steering angle\nfor the original image, the system constructs an additional 14 labeled training\npatterns to add to those encountered during ordinary driver training.\n4.5 Synergies Between Neural Network and\nKnowledge-Based Methods\nTo be written; discuss\nrule-generating procedures (such as\n[Towell & Shavlik, 1992]) and how\nexpert-provided rules can aid\nneural net training and vice-versa\n[Towell, Shavlik, & Noordweier, 1990].\n4.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 70, 'page_label': '71'}, page_content='62 CHAPTER 4. NEURAL NETWORKS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 71, 'page_label': '72'}, page_content='Chapter 5\nStatistical Learning\n5.1 Using Statistical Decision Theory\n5.1.1 Background and General Method\nSuppose the pattern vector, X, is a random variable whose probability distri-\nbution for category 1 is di\ufb00erent than it is for category 2. (The treatment given\nhere can easily be generalized to R-category problems.) Speci\ufb01cally, suppose we\nhave the two probability distributions (perhaps probability density functions),\np(X |1) and p(X |2). Given a pattern, X, we want to use statistical tech-\nniques to determine its categorythat is, to determine from which distribution\nit was drawn. These techniques are based on the idea of minimizing the ex-\npected value of a quantity similar to the error function we used in deriving the\nweight-changing rules for backprop.\nIn developing a decision method, it is necessary to know the relative serious-\nness of the two kinds of mistakes that might be made. (We might decide that a\npattern really in category 1 is in category 2, and vice versa.) We describe this\ninformation by a loss function, \u03bb(i|j), for i,j = 1,2. \u03bb(i|j) represents the loss\nincurred when we decide a pattern is in category i when really it is in category\nj. We assume here that \u03bb(1 |1) and \u03bb(2 |2) are both 0. For any given pattern,\nX, we want to decide its category in such a way that minimizes the expected\nvalue of this loss.\nGiven a pattern, X, if we decide category i, the expected value of the loss\nwill be:\nLX(i) = \u03bb(i|1)p(1 |X) + \u03bb(i|2)p(2 |X)\nwhere p(j |X) is the probability that given a pattern X, its category is j. Our\ndecision rule will be to decide that X belongs to category 1 if LX(1) \u2264LX(2),\nand to decide on category 2 otherwise.\n63'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 72, 'page_label': '73'}, page_content='64 CHAPTER 5. STATISTICAL LEARNING\nWe can use Bayes Rule to get expressions for p(j |X) in terms of p(X |j),\nwhich we assume to be known (or estimatible):\np(j |X) = p(X |j)p(j)\np(X)\nwhere p(j) is the (a priori) probability of category j (one category may be much\nmore probable than the other); and p(X) is the (a priori) probability of pattern\nX being the pattern we are asked to classify. Performing the substitutions given\nby Bayes Rule, our decision rule becomes:\nDecide category 1 i\ufb00:\n\u03bb(1 |1)p(X |1)p(1)\np(X) + \u03bb(1 |2)p(X |2)p(2)\np(X)\n\u2264\u03bb(2 |1)p(X |1)p(1)\np(X) + \u03bb(2 |2)p(X |2)p(2)\np(X)\nUsing the fact that \u03bb(i |i) = 0, and noticing that p(X) is common to both\nexpressions, we obtain,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nIf \u03bb(1 |2) = \u03bb(2 |1) and if p(1) = p(2), then the decision becomes particu-\nlarly simple:\nDecide category 1 i\ufb00:\np(X |2) \u2264p(X |1)\nSince p(X |j) is called the likelihood of j with respect to X, this simple decision\nrule implements what is called a maximum-likelihood decision. More generally,\nif we de\ufb01ne k(i|j) as \u03bb(i|j)p(j), then our decision rule is simply,\nDecide category1 i\ufb00:\nk(1 |2)p(X |2) \u2264k(2 |1)p(X |1)\nIn any case, we need to compare the (perhaps weighted) quantities p(X |i) for\ni= 1 and 2. The exact decision rule depends on the the probability distributions\nassumed. We will treat two interesting distributions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 73, 'page_label': '74'}, page_content='5.1. USING STATISTICAL DECISION THEORY 65\n5.1.2 Gaussian (or Normal) Distributions\nThe multivariate (n-dimensional) Gaussian distribution is given by the proba-\nbility density function:\np(X) = 1\n(2\u03c0)n/2|\u03a3|1/2 e\n\u2212(X\u2212M)t\u03a3\n\u22121\n(X\u2212M)\n2\nwhere nis the dimension of the column vector X, the column vector M is called\nthe mean vector, (X \u2212M)t is the transpose of the vector ( X \u2212M), \u03a3 is the\ncovariance matrix of the distribution (an n×n symmetric, positive de\ufb01nite\nmatrix), \u03a3\u22121 is the inverse of the covariance matrix, and |\u03a3|is the determinant\nof the covariance matrix.\nThe mean vector, M, with components ( m1,...,m n), is the expected value\nof X (using this distribution); that is, M = E[X]. The components of the\ncovariance matrix are given by:\n\u03c32\nij = E[(xi \u2212mi)(xj \u2212mj)]\nIn particular, \u03c32\nii is called the variance of xi.\nAlthough the formula appears complex, an intuitive idea for Gaussian dis-\ntributions can be given when n = 2. We show a two-dimensional Gaussian\ndistribution in Fig. 5.1. A three-dimensional plot of the distribution is shown\nat the top of the \ufb01gure, and contours of equal probability are shown at the bot-\ntom. In this case, the covariance matrix, \u03a3, is such that the elliptical contours\nof equal probability are skewed. If the covariance matrix were diagonal, that is\nif all o\ufb00-diagonal terms were 0, then the major axes of the elliptical contours\nwould be aligned with the coordinate axes. In general the principal axes are\ngiven by the eigenvectors of \u03a3. In any case, the equi-probability contours are\nall centered on the mean vector, M, which in our \ufb01gure happens to be at the\norigin. In general, the formula in the exponent in the Gaussian distribution\nis a positive de\ufb01nite quadratic form (that is, its value is always positive); thus\nequi-probability contours are hyper-ellipsoids in n-dimensional space.\nSuppose we now assume that the two classes of pattern vectors that we\nwant to distinguish are each distributed according to a Gaussian distribution\nbut with di\ufb00erent means and covariance matrices. That is, one class tends to\nhave patterns clustered around one point in the n-dimensional space, and the\nother class tends to have patterns clustered around another point. We show a\ntwo-dimensional instance of this problem in Fig. 5.2. (In that \ufb01gure, we have\nplotted the sum of the two distributions.) What decision rule should we use to\nseparate patterns into the two appropriate categories?\nSubstituting the Gaussian distributions into our maximum likelihood for-\nmula yields:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 74, 'page_label': '75'}, page_content='66 CHAPTER 5. STATISTICAL LEARNING\n-5\n0\n5\n-5\n0\n5\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n-5\n0\n5\n0\n25\n.5\n75\n1\n-6 -4 -2 0 2 4 6\n-6\n-4\n-2\n0\n2\n4\n6\nx1\nx2\np(x1,x2)\n2\n4\n6\n24 6\nx1\nx2\nFigure 5.1: The Two-Dimensional Gaussian Distribution\nDecide category 1 i\ufb00:\n1\n(2\u03c0)n/2|\u03a32|1/2 e\u22121/2(X\u2212M2)t\u03a3\n\u22121\n2 (X\u2212M2)\nis less than or equal to\n1\n(2\u03c0)n/2|\u03a31|1/2 e\u22121/2(X\u2212M1)t\u03a3\n\u22121\n1 (X\u2212M1)\nwhere the category 1 patterns are distributed with mean and covariance M1\nand \u03a31, respectively, and the category 2 patterns are distributed with mean\nand covariance M2 and \u03a32.\nThe result of the comparison isnt changed if we compare logarithms instead.\nAfter some manipulation, our decision rule is then:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 75, 'page_label': '76'}, page_content='5.1. USING STATISTICAL DECISION THEORY 67\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n25\n.5\n75\n1\nx1\nx2\np(x1,x2)\n-5 -2.5 0 2.5 5 7.5 10\n-5\n-2.5\n0\n2.5\n5\n7.5\n10\nFigure 5.2: The Sum of Two Gaussian Distributions\nDecide category 1 i\ufb00:\n(X \u2212M1)t\u03a3\u22121\n1 (X \u2212M1) <(X \u2212M2)t\u03a3\u22121\n2 (X \u2212M2) + B\nwhere B, a constant bias term, incorporates the logarithms of the fractions\npreceding the exponential, etc.\nWhen the quadratic forms are multiplied out and represented in terms of\nthe components xi, the decision rule involves a quadric surface (a hyperquadric)\nin n-dimensional space. The exact shape and position of this hyperquadric is\ndetermined by the means and the covariance matrices. The surface separates\nthe space into two parts, one of which contains points that will be assigned to\ncategory 1 and the other contains points that will be assigned to category 2.\nIt is interesting to look at a special case of this surface. If the covariance\nmatrices for each category are identical and diagonal, with all \u03c3ii equal to each\nother, then the contours of equal probability for each of the two distributions'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 76, 'page_label': '77'}, page_content='68 CHAPTER 5. STATISTICAL LEARNING\nare hyperspherical. The quadric forms then become (1 /|\u03a3|)(X\u2212Mi)t(X\u2212Mi),\nand the decision rule is:\nDecide category 1 i\ufb00:\n(X \u2212M1)t(X \u2212M1) <(X \u2212M2)t(X \u2212M2)\nMultiplying out yields:\nXX \u22122XM1 + M1M1 <XX \u22122XM2 + M2M2\nor \ufb01nally,\nDecide category 1 i\ufb00:\nXM1 \u2265XM2 + Constant\nor\nX(M1 \u2212M2) \u2265Constant\nwhere the constant depends on the lengths of the mean vectors.\nWe see that the optimal decision surface in this special case is a hyperplane.\nIn fact, the hyperplane is perpendicular to the line joining the two means. The\nweights in a TLU implementation are equal to the di\ufb00erence in the mean vectors.\nIf the parameters ( Mi,\u03a3i) of the probability distributions of the categories\nare not known, there are various techniques for estimating them, and then using\nthose estimates in the decision rule. For example, if there are su\ufb03cient training\npatterns, one can use sample means and sample covariance matrices. (Caution:\nthe sample covariance matrix will be singular if the training patterns happen to\nlie on a subspace of the whole n-dimensional spaceas they certainly will, for\nexample, if the number of training patterns is less than n.)\n5.1.3 Conditionally Independent Binary Components\nSuppose the vector X is a random variable having binary (0,1) components.\nWe continue to denote the two probability distributions by p(X |1) and p(X |\n2). Further suppose that the components of these vectors are conditionally\nindependent given the category. By conditional independence in this case, we\nmean that the formulas for the distribution can be expanded as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 77, 'page_label': '78'}, page_content='5.1. USING STATISTICAL DECISION THEORY 69\np(X |i) = p(x1 |i)p(x2 |i) ···p(xn |i)\nfor i= 1,2\nRecall the minimum-average-loss decision rule,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nAssuming conditional independence of the components and that \u03bb(1 |2) = \u03bb(2 |\n1), we obtain,\nDecide category 1 i\ufb00:\np(1)p(x1 |1)p(x2 |1) ···p(xn |1) \u2265p(x1 |2)p(x2 |2) ···p(xn |2)p(2)\nor i\ufb00:\np(x1 |1)p(x2 |1) ...p (xn |1)\np(x1 |2)p(x2 |2) ...p (xn |2) \u2265p(2)\np(1)\nor i\ufb00:\nlog p(x1 |1)\np(x1 |2) + log p(x2 |1)\np(x2 |2) + ··· + log p(xn |1)\np(xn |2) + log p(1)\np(2) \u22650\nLet us de\ufb01ne values of the components of the distribution for speci\ufb01c values of\ntheir arguments, xi :\np(xi = 1 |1) = pi\np(xi = 0 |1) = 1 \u2212pi\np(xi = 1 |2) = qi\np(xi = 0 |2) = 1 \u2212qi\nNow, we note that since xi can only assume the values of 1 or 0:\nlog p(xi |1)\np(xi |2) = xilog pi\nqi\n+ (1 \u2212xi) log (1 \u2212pi)\n(1 \u2212qi)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 78, 'page_label': '79'}, page_content='70 CHAPTER 5. STATISTICAL LEARNING\n= xilog pi(1 \u2212qi)\nqi(1 \u2212pi) + log (1 \u2212pi)\n(1 \u2212qi)\nSubstituting these expressions into our decision rule yields:\nDecide category 1 i\ufb00:\nn\u2211\ni=1\nxilog pi(1 \u2212qi)\nqi(1 \u2212pi) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi) + log p(1)\np(2) \u22650\nWe see that we can achieve this decision with a TLU with weight values as\nfollows:\nwi = log pi(1 \u2212qi)\nqi(1 \u2212pi)\nfor i= 1,...,n , and\nwn+1 = log p(1)\n1 \u2212p(1) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi)\nIf we do not know the pi,qi and p(1), we can use a sample of labeled training\npatterns to estimate these parameters.\n5.2 Learning Belief Networks\nTo be added.\n5.3 Nearest-Neighbor Methods\nAnother class of methods can be related to the statistical ones. These are called\nnearest-neighbor methods or, sometimes, memory-based methods. (A collection\nof papers on this subject is in [Dasarathy, 1991].) Given a training set \u039e of m\nlabeled patterns, a nearest-neighbor procedure decides that some new pattern,\nX, belongs to the same category as do its closest neighbors in \u039e. More precisely,\na k-nearest-neighbor method assigns a new pattern,X, to that category to which\nthe plurality of its k closest neighbors belong. Using relatively large values of\nk decreases the chance that the decision will be unduly in\ufb02uenced by a noisy\ntraining pattern close to X. But large values of k also reduce the acuity of the\nmethod. The k-nearest-neighbor method can be thought of as estimating the\nvalues of the probabilities of the classes given X. Of course the denser are the\npoints around X, and the larger the value of k, the better the estimate.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 79, 'page_label': '80'}, page_content='5.3. NEAREST-NEIGHBOR METHODS 71\nThe distance metric used in nearest-neighbor methods (for numerical at-\ntributes) can be simple Euclidean distance. That is, the distance between two\npatterns (x11,x12,...,x 1n) and (x21,x22,...,x 2n) is\n\u221a\u2211n\nj=1(x1j \u2212x2j)2. This\ndistance measure is often modi\ufb01ed by scaling the features so that the spread of\nattribute values along each dimension is approximately the same. In that case,\nthe distance between the two vectors would be\n\u221a\u2211n\nj=1 a2\nj(x1j \u2212x2j)2, where\naj is the scale factor for dimension j.\nAn example of a nearest-neighbor decision problem is shown in Fig. 5.3. In\nthe \ufb01gure the class of a training pattern is indicated by the number next to it.\nk = 8\nX (a pattern to be classified)\n1\n1\n1 1\n1\n11\n1\n2\n1\n2\n2\n2\n2\n2\n2 2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\ntraining patternclass of training pattern\nfour patterns of category 1\ntwo patterns of category 2\ntwo patterns of category 3\nplurality are in category 1, so\ndecide X is in category 1\nFigure 5.3: An 8-Nearest-Neighbor Decision\nSee [Baum, 1994] for theoretical\nanalysis of error rate as a function\nof the number of training patterns\nfor the case in which points are\nrandomly distributed on the surface\nof a unit sphere and underlying\nfunction is linearly separable.\nNearest-neighbor methods are memory intensive because a large number of\ntraining patterns must be stored to achieve good generalization. Since memory\ncost is now reasonably low, the method and its derivatives have seen several\npractical applications. (See, for example, [Moore, 1992, Moore, et al., 1994].\nAlso, the distance calculations required to \ufb01nd nearest neighbors can often be\ne\ufb03ciently computed by kd-tree methods [Friedman, et al., 1977].\nA theorem by Cover and Hart [Cover & Hart, 1967] relates the performance\nof the 1-nearest-neighbor method to the performance of a minimum-probability-\nof-error classi\ufb01er. As mentioned earlier, the minimum-probability-of-error clas-\nsi\ufb01er would assign a new patternX to that category that maximizedp(i)p(X |i),\nwhere p(i) is the a priori probability of categoryi, and p(X |i) is the probability\n(or probability density function) of X given that X belongs to category i, for\ncategories i= 1,...,R . Suppose the probability of error in classifying patterns\nof such a minimum-probability-of-error classi\ufb01er is \u03b5. The Cover-Hart theo-\nrem states that under very mild conditions (having to do with the smoothness'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 80, 'page_label': '81'}, page_content='72 CHAPTER 5. STATISTICAL LEARNING\nof probability density functions) the probability of error, \u03b5nn, of a 1-nearest-\nneighbor classi\ufb01er is bounded by:\n\u03b5\u2264\u03b5nn \u2264\u03b5\n(\n2 \u2212\u03b5 R\nR\u22121\n)\n\u22642\u03b5\nwhere R is the number of categories.Also see [Aha, 1991].\n5.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 81, 'page_label': '82'}, page_content='Chapter 6\nDecision Trees\n6.1 De\ufb01nitions\nA decision tree (generally de\ufb01ned) is a tree whose internal nodes are tests (on\ninput patterns) and whose leaf nodes are categories (of patterns). We show an\nexample in Fig. 6.1. A decision tree assigns a class number (or output) to an\ninput pattern by \ufb01ltering the pattern down through the tests in the tree. Each\ntest has mutually exclusive and exhaustive outcomes. For example, test T2 in\nthe tree of Fig. 6.1 has three outcomes; the left-most one assigns the input\npattern to class 3, the middle one sends the input pattern down to test T4, and\nthe right-most one assigns the pattern to class 1. We follow the usual convention\nof depicting the leaf nodes by the class number.1 Note that in discussing decision\ntrees we are not limited to implementing Boolean functionsthey are useful for\ngeneral, categorically valued functions.\nThere are several dimensions along which decision trees might di\ufb00er:\na. The tests might be multivariate (testing on several features of the input\nat once) or univariate (testing on only one of the features).\nb. The tests might have two outcomes or more than two. (If all of the tests\nhave two outcomes, we have a binary decision tree.)\nc. The features or attributes might be categorical or numeric. (Binary-valued\nones can be regarded as either.)\n1One of the researchers who has done a lot of work on learning decision trees is Ross\nQuinlan. Quinlan distinguishes between classes and categories. He calls the subsets of patterns\nthat \ufb01lter down to each tip categories and subsets of patterns having the same label classes.\nIn Quinlans terminology, our example tree has nine categories and three classes. We will not\nmake this distinction, however, but will use the words category and class interchangeably\nto refer to what Quinlan calls class.\n73'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 82, 'page_label': '83'}, page_content='74 CHAPTER 6. DECISION TREES\nT1\nT2 T3\nT4\nT4\nT4\n3\n1\n3 2\n1 2 3\n2 1\nFigure 6.1: A Decision Tree\nd. We might have two classes or more than two. If we have two classes and\nbinary inputs, the tree implements a Boolean function, and is called a\nBoolean decision tree.\nIt is straightforward to represent the function implemented by a univariate\nBoolean decision tree in DNF form. The DNF form implemented by such a tree\ncan be obtained by tracing down each path leading to a tip node corresponding\nto an output value of 1, forming the conjunction of the tests along this path,\nand then taking the disjunction of these conjunctions. We show an example in\nFig. 6.2. In drawing univariate decision trees, each non-leaf node is depicted by\na single attribute. If the attribute has value 0 in the input pattern, we branch\nleft; if it has value 1, we branch right.\nThe k-DL class of Boolean functions can be implemented by a multivariate\ndecision tree having the (highly unbalanced) form shown in Fig. 6.3. Each test,\nci, is a term of size k or less. The vi all have values of 0 or 1.\n6.2 Supervised Learning of Univariate Decision\nTrees\nSeveral systems for learning decision trees have been proposed. Prominent\namong these are ID3 and its new version, C4.5 [Quinlan, 1986, Quinlan, 1993],\nand CART [Breiman, et al., 1984] We discuss here only batch methods, al-\nthough incremental ones have also been proposed [Utgo\ufb00, 1989].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 83, 'page_label': '84'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES75\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.2: A Decision Tree Implementing a DNF Function\n6.2.1 Selecting the Type of Test\nAs usual, we have n features or attributes. If the attributes are binary, the\ntests are simply whether the attributes value is 0 or 1. If the attributes are\ncategorical, but non-binary, the tests might be formed by dividing the attribute\nvalues into mutually exclusive and exhaustive subsets. A decision tree with such\ntests is shown in Fig. 6.4. If the attributes are numeric, the tests might involve\ninterval tests, for example 7 \u2264xi \u226413.2.\n6.2.2 Using Uncertainty Reduction to Select Tests\nThe main problem in learning decision trees for the binary-attribute case is\nselecting the order of the tests. For categorical and numeric attributes, we\nmust also decide what the tests should be (besides selecting the order). Several\ntechniques have been tried; the most popular one is at each stage to select that\ntest that maximally reduces an entropy-like measure.\nWe show how this technique works for the simple case of tests with binary\noutcomes. Extension to multiple-outcome tests is straightforward computation-\nally but gives poor results because entropy is always decreased by having more\noutcomes.\nThe entropy or uncertainty still remaining about the class of a pattern\nknowing that it is in some set, \u039e, of patterns is de\ufb01ned as:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 84, 'page_label': '85'}, page_content='76 CHAPTER 6. DECISION TREES\ncq\ncq-1\nci\n1\nvn\nvn-1\nvi\nv1\nFigure 6.3: A Decision Tree Implementing a Decision List\nwhere p(i|\u039e) is the probability that a pattern drawn at random from \u039e belongs\nto class i, and the summation is over all of the classes. We want to select tests at\neach node such that as we travel down the decision tree, the uncertainty about\nthe class of a pattern becomes less and less.\nSince we do not in general have the probabilitiesp(i|\u039e), we estimate them by\nsample statistics. Although these estimates might be errorful, they are never-\ntheless useful in estimating uncertainties. Let p(i|\u039e) be the number of patterns\nin \u039e belonging to class idivided by the total number of patterns in \u039e. Then an\nestimate of the uncertainty is:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)\nFor simplicity, from now on well drop the hats and use sample statistics as\nif they were real probabilities.\nIf we perform a test, T, having k possible outcomes on the patterns in \u039e, we\nwill create ksubsets, \u039e1,\u039e2,..., \u039ek. Suppose that ni of the patterns in \u039e are in\n\u039ei for i= 1,...,k . (Some ni may be 0.) If we knew that T applied to a pattern\nin \u039e resulted in the j-th outcome (that is, we knew that the pattern was in \u039e j),\nthe uncertainty about its class would be:\nH(\u039ej) = \u2212\n\u2211\ni\np(i|\u039ej) log2 p(i|\u039ej)\nand the reduction in uncertainty (beyond knowing only that the pattern was in\n\u039e) would be:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 85, 'page_label': '86'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES77\nx3 = a, b, c, or d \n{a, c} {b}\nx1 = e, b, or d \n{e,b} {d}\nx4 = a, e, f, or g\n{a, g} {e, f}\nx2 = a, or g\n{a} {g}\n1\n2 1\n1 2\n{d}\n2\nFigure 6.4: A Decision Tree with Categorical Attributes\nH(\u039e) \u2212H(\u039ej)\nOf course we cannot say that the test T is guaranteed always to produce that\namount of reduction in uncertainty because we dont know that the result of\nthe test will be the j-th outcome. But we can estimate the average uncertainty\nover all the \u039ej, by:\nE[HT(\u039e)] =\n\u2211\nj\np(\u039ej)H(\u039ej)\nwhere by HT(\u039e) we mean the average uncertainty after performing test T on\nthe patterns in \u039e, p(\u039ej) is the probability that the test has outcome j, and the\nsum is taken from 1 to k. Again, we dont know the probabilities p(\u039ej), but we\ncan use sample values. The estimate p(\u039ej) of p(\u039ej) is just the number of those\npatterns in \u039e that have outcome j divided by the total number of patterns in\n\u039e. The average reduction in uncertainty achieved by test T (applied to patterns\nin \u039e) is then:\nRT(\u039e) = H(\u039e) \u2212E[HT(\u039e)]\nAn important family of decision tree learning algorithms selects for the root\nof the tree that test that gives maximum reduction of uncertainty, and then\napplies this criterion recursively until some termination condition is met (which\nwe shall discuss in more detail later). The uncertainty calculations are particu-\nlarly simple when the tests have binary outcomes and when the attributes have'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 86, 'page_label': '87'}, page_content='78 CHAPTER 6. DECISION TREES\nbinary values. Well give a simple example to illustrate how the test selection\nmechanism works in that case.\nSuppose we want to use the uncertainty-reduction method to build a decision\ntree to classify the following patterns:\npattern class\n(0, 0, 0) 0\n(0, 0, 1) 0\n(0, 1, 0) 0\n(0, 1, 1) 0\n(1, 0, 0) 0\n(1, 0, 1) 1\n(1, 1, 0) 0\n(1, 1, 1) 1\nWhat single test, x1, x2, or x3, should be performed \ufb01rst? The illustration in\nFig. 6.5 gives geometric intuition about the problem.\nx1\nx2\nx3\nThe test x1\nFigure 6.5: Eight Patterns to be Classi\ufb01ed by a Decision Tree\nThe initial uncertainty for the set, \u039e, containing all eight points is:\nH(\u039e) = \u2212(6/8) log2(6/8) \u2212(2/8) log2(2/8) = 0.81\nNext, we calculate the uncertainty reduction if we perform x1 \ufb01rst. The left-\nhand branch has only patterns belonging to class 0 (we call them the set \u039el), and\nthe right-hand-branch (\u039er) has two patterns in each class. So, the uncertainty\nof the left-hand branch is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 87, 'page_label': '88'}, page_content='6.3. NETWORKS EQUIVALENT TO DECISION TREES 79\nHx1 (\u039el) = \u2212(4/4) log2(4/4) \u2212(0/4) log2(0/4) = 0\nAnd the uncertainty of the right-hand branch is:\nHx1 (\u039er) = \u2212(2/4) log2(2/4) \u2212(2/4) log2(2/4) = 1\nHalf of the patterns go left and half go right on test x1. Thus, the average\nuncertainty after performing the x1 test is:\n1/2Hx1 (\u039el) + 1/2Hx1 (\u039er) = 0.5\nTherefore the uncertainty reduction on \u039e achieved by x1 is:\nRx1 (\u039e) = 0.81 \u22120.5 = 0.31\nBy similar calculations, we see that the test x3 achieves exactly the same\nuncertainty reduction, but x2 achieves no reduction whatsoever. Thus, our\ngreedy algorithm for selecting a \ufb01rst test would select eitherx1 or x3. Suppose\nx1 is selected. The uncertainty-reduction procedure would select x3 as the next\ntest. The decision tree that this procedure creates thus implements the Boolean\nfunction: f = x1x3. See [Quinlan, 1986, sect. 4] for\nanother example.\n6.2.3 Non-Binary Attributes\nIf the attributes are non-binary, we can still use the uncertainty-reduction tech-\nnique to select tests. But now, in addition to selecting an attribute, we must\nselect a test on that attribute. Suppose for example that the value of an at-\ntribute is a real number and that the test to be performed is to set a threshold\nand to test to see if the number is greater than or less than that threshold. In\nprinciple, given a set of labeled patterns, we can measure the uncertainty reduc-\ntion for each test that is achieved by every possible threshold (there are only\na \ufb01nite number of thresholds that give di\ufb00erent test results if there are only\na \ufb01nite number of training patterns). Similarly, if an attribute is categorical\n(with a \ufb01nite number of categories), there are only a \ufb01nite number of mutually\nexclusive and exhaustive subsets into which the values of the attribute can be\nsplit. We can calculate the uncertainty reduction for each split.\n6.3 Networks Equivalent to Decision Trees\nSince univariate Boolean decision trees are implementations of DNF functions,\nthey are also equivalent to two-layer, feedforward neural networks. We show\nan example in Fig. 6.6. The decision tree at the left of the \ufb01gure implements'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 88, 'page_label': '89'}, page_content='80 CHAPTER 6. DECISION TREES\nthe same function as the network at the right of the \ufb01gure. Of course, when\nimplemented as a network, all of the features are evaluated in parallel for any\ninput pattern, whereas when implemented as a decision tree only those features\non the branch traveled down by the input pattern need to be evaluated. The\ndecision-tree induction methods discussed in this chapter can thus be thought of\nas particular ways to establish the structure and the weight values for networks.\nX\nx1\nx2\nx3\nx4\nterms\n-1\n+1\ndisjunction\nx3x2\nx3x4x1\n+1\n-1\n+1\nf\n1.5\n0.5\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.6: A Univariate Decision Tree and its Equivalent Network\nMultivariate decision trees with linearly separable functions at each node can\nalso be implemented by feedforward networksin this case three-layer ones. We\nshow an example in Fig. 6.7 in which the linearly separable functions, each im-\nplemented by a TLU, are indicated by L1,L2,L3, and L4. Again, the \ufb01nal layer\nhas \ufb01xed weights, but the weights in the \ufb01rst two layers must be trained. Dif-\nferent approaches to training procedures have been discussed by [Brent, 1990],\nby [John, 1995], and (for a special case) by [Marchand & Golea, 1993].\n6.4 Over\ufb01tting and Evaluation\n6.4.1 Over\ufb01tting\nIn supervised learning, we must choose a function to \ufb01t the training set from\namong a set of hypotheses. We have already showed that generalization is\nimpossible without bias. When we know a priori that the function we are\ntrying to guess belongs to a small subset of all possible functions, then, even\nwith an incomplete set of training samples, it is possible to reduce the subset\nof functions that are consistent with the training set su\ufb03ciently to make useful\nguesses about the value of the function for inputs not in the training set. And,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 89, 'page_label': '90'}, page_content='6.4. OVERFITTING AND EVALUATION 81\nL1\nL2 L3\nL4\n10\n1\n1\n0 0\n0\n1\n1\n0\n0\n1 0\nX\nL1\nL2\nL3\nL4\nconjunctions\nL1L2\nL1 L3 L4\n<\n+\n++\ndisjunction\n<\nf\nFigure 6.7: A Multivariate Decision Tree and its Equivalent Network\nthe larger the training set, the more likely it is that even a randomly selected\nconsistent function will have appropriate outputs for patterns not yet seen.\nHowever, even with bias, if the training set is not su\ufb03ciently large compared\nwith the size of the hypothesis space, there will still be too many consistent\nfunctions for us to make useful guesses, and generalization performance will be\npoor. When there are too many hypotheses that are consistent with the training\nset, we say that we are over\ufb01tting the training data. Over\ufb01tting is a problem\nthat we must address for all learning methods.\nSince a decision tree of su\ufb03cient size can implement any Boolean function\nthere is a danger of over\ufb01ttingespecially if the training set is small. That\nis, even if the decision tree is synthesized to classify all the members of the\ntraining set correctly, it might perform poorly on new patterns that were not\nused to build the decision tree. Several techniques have been proposed to avoid\nover\ufb01tting, and we shall examine some of them here. They make use of methods\nfor estimating how well a given decision tree might generalizemethods we shall\ndescribe next.\n6.4.2 Validation Methods\nThe most straightforward way to estimate how well a hypothesized function\n(such as a decision tree) performs on a test set is to test it on the test set! But,\nif we are comparing several learning systems (for example, if we are comparing\ndi\ufb00erent decision trees) so that we can select the one that performs the best on\nthe test set, then such a comparison amounts to training on the test data.\nTrue, training on the test data enlarges the training set, with a consequent ex-\npected improvement in generalization, but there is still the danger of over\ufb01tting\nif we are comparing several di\ufb00erent learning systems. Another technique is to'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 90, 'page_label': '91'}, page_content='82 CHAPTER 6. DECISION TREES\nsplit the training setusing (say) two-thirds for training and the other third\nfor estimating generalization performance. But splitting reduces the size of the\ntraining set and thereby increases the possibility of over\ufb01tting. We next describe\nsome validation techniques that attempt to avoid these problems.\nCross-Validation\nIn cross-validation, we divide the training set \u039e into K mutually exclusive and\nexhaustive equal-sized subsets: \u039e 1,..., \u039eK. For each subset, \u039e i, train on the\nunion of all of the other subsets, and empirically determine the error rate, \u03b5i,\non \u039ei. (The error rate is the number of classi\ufb01cation errors made on \u039e i divided\nby the number of patterns in \u039e i.) An estimate of the error rate that can be\nexpected on new patterns of a classi\ufb01er trained on all the patterns in \u039e is then\nthe average of the \u03b5i.\nLeave-one-out Validation\nLeave-one-out validation is the same as cross validation for the special case in\nwhich K equals the number of patterns in \u039e, and each \u039e i consists of a single\npattern. When testing on each \u039e i, we simply note whether or not a mistake\nwas made. We count the total number of mistakes and divide by K to get\nthe estimated error rate. This type of validation is, of course, more expensive\ncomputationally, but useful when a more accurate estimate of the error rate for\na classi\ufb01er is needed.Describe bootstrapping also\n[Efron, 1982].\n6.4.3 Avoiding Over\ufb01tting in Decision Trees\nNear the tips of a decision tree there may be only a few patterns per node.\nFor these nodes, we are selecting a test based on a very small sample, and thus\nwe are likely to be over\ufb01tting. This problem can be dealt with by terminating\nthe test-generating procedure before all patterns are perfectly split into their\nseparate categories. That is, a leaf node may contain patterns of more than one\nclass, but we can decide in favor of the most numerous class. This procedure\nwill result in a few errors but often accepting a small number of errors on the\ntraining set results in fewer errors on a testing set.\nThis behavior is illustrated in Fig. 6.8.\nOne can use cross-validation techniques to determine when to stop splitting\nnodes. If the cross validation error increases as a consequence of a node split,\nthen dont split. One has to be careful about when to stop, though, because\nunder\ufb01tting usually leads to more errors on test sets than does over\ufb01tting. There\nis a general rule that the lowest error-rate attainable by a sub-tree of a fully\nexpanded tree can be no less than 1/2 of the error rate of the fully expanded\ntree [Weiss & Kulikowski, 1991, page 126].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 91, 'page_label': '92'}, page_content='6.4. OVERFITTING AND EVALUATION 83\n(From Weiss, S., and Kulikowski, C., Computer Systems that Learn,\nMorgan Kaufmann, 1991)\ntraining errors\nvalidation errors\n1 2 34 5 6 78 9\n0.2\n0.4\n0.6\n0.8\n1.0\n0\n0\nError Rate\nNumber of Terminal\nNodes\nIris Data Decision Tree\nFigure 6.8: Determining When Over\ufb01tting Begins\nRather than stopping the growth of a decision tree, one might grow it to\nits full size and then prune away leaf nodes and their ancestors until cross-\nvalidation accuracy no longer increases. This technique is called post-pruning.\nVarious techniques for pruning are discussed in [Weiss & Kulikowski, 1991].\n6.4.4 Minimum-Description Length Methods\nAn important tree-growing and pruning technique is based on the minimum-\ndescription-length (MDL) principle. (MDL is an important idea that extends\nbeyond decision-tree methods [Rissanen, 1978].) The idea is that the simplest\ndecision tree that can predict the classes of the training patterns is the best\none. Consider the problem of transmitting just the labels of a training set of\npatterns, assuming that the receiver of this information already has the ordered\nset of patterns. If there are m patterns, each labeled by one of R classes,\none could transmit a list of m R-valued numbers. Assuming equally probable\nclasses, this transmission would require mlog2 Rbits. Or, one could transmit a\ndecision tree that correctly labelled all of the patterns. The number of bits that\nthis transmission would require depends on the technique for encoding decision\ntrees and on the size of the tree. If the tree is small and accurately classi\ufb01es\nall of the patterns, it might be more economical to transmit the tree than to\ntransmit the labels directly. In between these extremes, we might transmit a\ntree plus a list of labels of all the patterns that the tree misclassi\ufb01es.\nIn general, the number of bits (or description length of the binary encoded\nmessage) is t+ d, where t is the length of the message required to transmit\nthe tree, and d is the length of the message required to transmit the labels of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 92, 'page_label': '93'}, page_content='84 CHAPTER 6. DECISION TREES\nthe patterns misclassi\ufb01ed by the tree. In a sense, that tree associated with the\nsmallest value of t+ d is the best or most economical tree. The MDL method\nis one way of adhering to the Occams razor principle.\nQuinlan and Rivest [Quinlan & Rivest, 1989] have proposed techniques for\nencoding decision trees and lists of exception labels and for calculating the\ndescription length (t+d) of these trees and labels. They then use the description\nlength as a measure of quality of a tree in two ways:\na. In growing a tree, they use the reduction in description length to select\ntests (instead of reduction in uncertainty).\nb. In pruning a tree after it has been grown to zero error, they prune away\nthose nodes (starting at the tips) that achieve a decrease in the description\nlength.\nThese techniques compare favorably with the uncertainty-reduction method,\nalthough they are quite sensitive to the coding schemes used.\n6.4.5 Noise in Data\nNoise in the data means that one must inevitably accept some number of\nerrorsdepending on the noise level. Refusal to tolerate errors on the training\nset when there is noise leads to the problem of \ufb01tting the noise. Dealing with\nnoise, then, requires accepting some errors at the leaf nodes just as does the\nfact that there are a small number of patterns at leaf nodes.\n6.5 The Problem of Replicated Subtrees\nDecision trees are not the most economical means of implementing some Boolean\nfunctions. Consider, for example, the function f = x1x2 +x3x4. A decision tree\nfor this function is shown in Fig. 6.9. Notice the replicated subtrees shown\ncircled. The DNF-form equivalent to the function implemented by this decision\ntree is f = x1x2 + x1x2x3x4 + x1x3x4. This DNF form is non-minimal (in the\nnumber of disjunctions) and is equivalent to f = x1x2 + x3x4.\nThe need for replication means that it takes longer to learn the tree and\nthat subtrees replicated further down the tree must be learned using a smaller\ntraining subset. This problem is sometimes called the fragmentation problem.\nSeveral approaches might be suggested for dealing with fragmenta-\ntion. One is to attempt to build a decision graph instead of a tree\n[Oliver, Dowe, & Wallace, 1992, Kohavi, 1994]. A decision graph that imple-\nments the same decisions as that of the decision tree of Fig. 6.9 is shown in Fig.\n6.10.\nAnother approach is to use multivariate (rather than univariate tests at each\nnode). In our example of learning f = x1x2 + x3x4, if we had a test for x1x2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 93, 'page_label': '94'}, page_content='6.6. THE PROBLEM OF MISSING ATTRIBUTES 85\nx1\nx3 x2\n10\nx4\n0 1\nx3\n0\nx4\n0 1\nFigure 6.9: A Decision Tree with Subtree Replication\nand a test for x3x4, the decision tree could be much simpli\ufb01ed, as shown in Fig.\n6.11. Several researchers have proposed techniques for learning decision trees in\nwhich the tests at each node are linearly separable functions. [John, 1995] gives\na nice overview (with several citations) of learning suchlinear discriminant trees\nand presents a method based on soft entropy.\nA third method for dealing with the replicated subtree problem involves ex-\ntracting propositional rules from the decision tree. The rules will have as an-\ntecedents the conjunctions that lead down to the leaf nodes, and as consequents\nthe name of the class at the corresponding leaf node. An example rule from the\ntree with the repeating subtree of our example would be: x1 \u2227¬x2 \u2227x3 \u2227x4 \u22831.\nQuinlan [Quinlan, 1987] discusses methods for reducing a set of rules to a sim-\npler set by 1) eliminating from the antecedent of each rule any unnecessary\nconjuncts, and then 2) eliminating unnecessary rules. A conjunct or rule is\ndetermined to be unnecessary if its elimination has little e\ufb00ect on classi\ufb01cation\naccuracyas determined by a chi-square test, for example. After a rule set is\nprocessed, it might be the case that more than one rule is active for any given\npattern, and care must be taken that the active rules do not con\ufb02ict in their\ndecision about the class of a pattern.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 94, 'page_label': '95'}, page_content='86 CHAPTER 6. DECISION TREES\nx1\nx3\nx2\n1\n0\nx4\n0 1\nFigure 6.10: A Decision Graph\n6.6 The Problem of Missing Attributes\nTo be added.\n6.7 Comparisons\nSeveral experimenters have compared decision-tree, neural-net, and nearest-\nneighbor classi\ufb01ers on a wide variety of problems. For a comparison of\nneural nets versus decision trees, for example, see [Dietterich, et al., 1990,\nShavlik, Mooney, & Towell, 1991, Quinlan, 1994]. In their StatLog project,\n[Taylor, Michie, & Spiegalhalter, 1994] give thorough comparisons of several\nmachine learning algorithms on several di\ufb00erent types of problems. There seems\nx1x2\n1\n0\nx3x4\n1\nFigure 6.11: A Multivariate Decision Tree'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 95, 'page_label': '96'}, page_content='6.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 87\nto be no single type of classi\ufb01er that is best for all problems. And, there do\nnot seem to be any general conclusions that would enable one to say which\nclassi\ufb01er method is best for which sorts of classi\ufb01cation problems, although\n[Quinlan, 1994] does provide some intuition about properties of problems that\nmight render them ill suited for decision trees, on the one hand, or backpropa-\ngation, on the other.\n6.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 96, 'page_label': '97'}, page_content='88 CHAPTER 6. DECISION TREES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 97, 'page_label': '98'}, page_content='Chapter 7\nInductive Logic\nProgramming\nThere are many di\ufb00erent representational forms for functions of input vari-\nables. So far, we have seen (Boolean) algebraic expressions, decision trees, and\nneural networks, plus other computational mechanisms such as techniques for\ncomputing nearest neighbors. Of course, the representation most important\nin computer science is a computer program. For example, a Lisp predicate of\nbinary-valued inputs computes a Boolean function of those inputs. Similarly, a\nlogic program (whose ordinary application is to compute bindings for variables)\ncan also be used simply to decide whether or not a predicate has value True\n(T) or False (F). For example, the Boolean exclusive-or (odd parity) function\nof two variables can be computed by the following logic program:\nParity(x,y) :- True(x), ¬ True(y)\n:- True(y), ¬ True(x)\nWe follow Prolog syntax (see, for example, [Mueller & Page, 1988]), except that\nour convention is to write variables as strings beginning with lower-case letters\nand predicates as strings beginning with upper-case letters. The unary function\nTrue returns T if and only if the value of its argument is T. (We now think\nof Boolean functions and arguments as having values of T and F instead of 0\nand 1.) Programs will be written in  typewriter font.\nIn this chapter, we consider the matter of learning logic programs given\na set of variable values for which the logic program should return T (the\npositive instances ) and a set of variable values for which it should return\nF (the negative instances). The subspecialty of machine learning that deals\nwith learning logic programs is called inductive logic programming (ILP)\n[Lavra\u02c7 c & D\u02c7 zeroski, 1994]. As with any learning problem, this one can be quite\ncomplex and intractably di\ufb03cult unless we constrain it with biases of some sort.\n89'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 98, 'page_label': '99'}, page_content='90 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nIn ILP, there are a variety of possible biases (calledlanguage biases). One might\nrestrict the program to Horn clauses, not allow recursion, not allow functions,\nand so on.\nAs an example of an ILP problem, suppose we are trying to induce a func-\ntion Nonstop(x,y), that is to have value T for pairs of cities connected by a\nnon-stop air \ufb02ight and F for all other pairs of cities. We are given a training set\nconsisting of positive and negative examples. As positive examples, we might\nhave (A,B), (A, A1), and some other pairs; as negative examples, we might\nhave (A1, A2), and some other pairs. In ILP, we usually have additional infor-\nmation about the examples, called background knowledge. In our air-\ufb02ight\nproblem, the background information might be such ground facts as Hub(A),\nHub(B), Satellite(A1,A), plus others. ( Hub(A) is intended to mean that the\ncity denoted by A is a hub city, and Satellite(A1,A) is intended to mean that\nthe city denoted by A1 is a satellite of the city denoted by A.) From these train-\ning facts, we want to induce a program Nonstop(x,y), written in terms of the\nbackground relations Hub and Satellite, that has value T for all the positive\ninstances and has value F for all the negative instances. Depending on the exact\nset of examples, we might induce the program:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nwhich would have value T if both of the two cities were hub cities or if one were\na satellite of the other. As with other learning problems, we want the induced\nprogram to generalize well; that is, if presented with arguments not represented\nin the training set (but for which we have the needed background knowledge),\nwe would like the function to guess well.\n7.1 Notation and De\ufb01nitions\nIn evaluating logic programs in ILP, we implicitly append the background facts\nto the program and adopt the usual convention that a program has value T for\na set of inputs if and only if the program interpreter returns T when actually\nrunning the program (with background facts appended) on those inputs; oth-\nerwise it has value F. Using the given background facts, the program above\nwould return T for input (A, A1), for example. If a logic program, \u03c0, returns\nT for a set of arguments X, we say that the program covers the arguments and\nwrite covers(\u03c0,X). Following our terminology introduced in connection with\nversion spaces, we will say that a program is su\ufb03cient if it covers all of the\npositive instances and that it is necessary if it does not cover any of the neg-\native instances. (That is, a program implements a su\ufb03cient condition that a\ntraining instance is positive if it covers all of the positive training instances; it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 99, 'page_label': '100'}, page_content='7.2. A GENERIC ILP ALGORITHM 91\nimplements a necessary condition if it covers none of the negative instances.) In\nthe noiseless case, we want to induce a program that is both su\ufb03cient and nec-\nessary, in which case we will call it consistent. With imperfect (noisy) training\nsets, we might relax this criterion and settle for a program that covers all but\nsome fraction of the positive instances while allowing it to cover some fraction\nof the negative instances. We illustrate these de\ufb01nitions schematically in Fig.\n7.1.\n<\n<\n<\n<<\n<\n<\n/1 is a necessary program\n/2 is a sufficient program\n/3 is a consistent program\n+\n+\n+\n+\n+ +\n+\n+\n+\n+\n<\n<\nA positive instance\n covered by /2 and /3\nFigure 7.1: Su\ufb03cient, Necessary, and Consistent Programs\nAs in version spaces, if a program is su\ufb03cient but not necessary it can be\nmade to cover fewer examples by specializing it. Conversely, if it is necessary\nbut not su\ufb03cient, it can be made to cover more examples by generalizing it.\nSuppose we are attempting to induce a logic program to compute the relation\n\u03c1. The most general logic program, which is certainly su\ufb03cient, is the one that\nhas value T for all inputs, namely a single clause with an empty body, [ \u03c1 :-\n], which is called a fact in Prolog. The most special logic program, which is\ncertainly necessary, is the one that has value F for all inputs, namely [ \u03c1 :-\nF ]. Two of the many di\ufb00erent ways to search for a consistent logic program\nare: 1) start with [ \u03c1 :- ] and specialize until the program is consistent, or 2)\nstart with [ \u03c1 :- F ] and generalize until the program is consistent. We will\nbe discussing a method that starts with [ \u03c1 :- ], specializes until the program\nis necessary (but might no longer be su\ufb03cient), then reachieves su\ufb03ciency in\nstages by generalizingensuring within each stage that the program remains\nnecessary (by specializing).\n7.2 A Generic ILP Algorithm\nSince the primary operators in our search for a consistent program are special-\nization and generalization, we must next discuss those operations. There are'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 100, 'page_label': '101'}, page_content='92 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nthree major ways in which a logic program might be generalized:\na. Replace some terms in a program clause by variables. (Readers familiar\nwith substitutions in the predicate calculus will note that this process is\nthe inverse of substitution.)\nb. Remove literals from the body of a clause.\nc. Add a clause to the program\nAnalogously, there are three ways in which a logic program might be specialized:\na. Replace some variables in a program clause by terms (a substitution).\nb. Add literals to the body of a clause.\nc. Remove a clause from the program\nWe will be presenting an ILP learning method that adds clauses to a program\nwhen generalizing and that adds literals to the body of a clause when special-\nizing. When we add a clause, we will always add the clause [ \u03c1 :- ] and then\nspecialize it by adding literals to the body. Thus, we need only describe the\nprocess for adding literals.\nClauses can be partially ordered by the specialization relation. In general,\nclause c1 is more special than clause c2 if c2 |= c1. A special case, which is what\nwe use here, is that a clause c1 is more special than a clause c2 if the set of\nliterals in the body of c2 is a subset of those in c1. This ordering relation can\nbe used in a structure of partially ordered clauses, called the re\ufb01nement graph,\nthat is similar to a version space. Clause c1 is an immediate successor of clause\nc2 in this graph if and only if clause c1 can be obtained from clause c2 by adding\na literal to the body of c2. A re\ufb01nement graph then tells us the ways in which\nwe can specialize a clause by adding a literal to it.\nOf course there are unlimited possible literals we might add to the body of\na clause. Practical ILP systems restrict the literals in various ways. Typical\nallowed additions are:\na. Literals used in the background knowledge.\nb. Literals whose arguments are a subset of those in the head of the clause.\nc. Literals that introduce a new distinct variable di\ufb00erent from those in the\nhead of the clause.\nd. A literal that equates a variable in the head of the clause with another\nsuch variable or with a term mentioned in the background knowledge.\n(This possibility is equivalent to forming a specialization by making a\nsubstitution.)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 101, 'page_label': '102'}, page_content='7.2. A GENERIC ILP ALGORITHM 93\ne. A literal that is the same (except for its arguments) as that in the head\nof the clause. (This possibility admits recursive programs, which are dis-\nallowed in some systems.)\nWe can illustrate these possibilities using our air-\ufb02ight example. We start\nwith the program [ Nonstop(x,y) :- ]. The literals used in the background\nknowledge are Hub and Satellite. Thus the literals that we might consider\nadding are:\nHub(x)\nHub(y)\nHub(z)\nSatellite(x,y)\nSatellite(y,x)\nSatellite(x,z)\nSatellite(z,y)\n(x = y)\n(If recursive programs are allowed, we could also add the literals Nonstop(x,z)\nand Nonstop(z,y).) These possibilities are among those illustrated in the re-\n\ufb01nement graph shown in Fig. 7.2. Whatever restrictions on additional literals\nare imposed, they are all syntactic ones from which the successors in the re\ufb01ne-\nment graph are easily computed. ILP programs that follow the approach we\nare discussing (of specializing clauses by adding a literal) thus have well de\ufb01ned\nmethods of computing the possible literals to add to a clause.\nNow we are ready to write down a simple generic algorithm for inducing a\nlogic program, \u03c0 for inducing a relation \u03c1. We are given a training set, \u039e of\nargument sets some known to be in the relation \u03c1 and some not in \u03c1; \u039e+ are\nthe positive instances, and \u039e \u2212 are the negative instances. The algorithm has\nan outer loop in which it successively adds clauses to make \u03c0 more and more\nsu\ufb03cient. It has an inner loop for constructing a clause, c, that is more and\nmore necessary and in which it refers only to a subset, \u039e cur, of the training\ninstances. (The positive instances in \u039e cur will be denoted by \u039e +\ncur, and the\nnegative ones by \u039e \u2212\ncur.) The algorithm is also given background relations and\nthe means for adding literals to a clause. It uses a logic program interpreter to\ncompute whether or not the program it is inducing covers training instances.\nThe algorithm can be written as follows:\nGeneric ILP Algorithm\n(Adapted from [Lavra\u02c7 c & D\u02c7 zeroski, 1994, p. 60].)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 102, 'page_label': '103'}, page_content='94 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nNonstop(x,y) :-\nNonstop(x,y) :-\n   Hub(x)\nNonstop(x,y) :-\n   Satellite(x,y)\nNonstop(x,y) :-\n   (x = y)\n. . .\n. . .\n. . . . . .\nNonstop(x,y) :- Hub(x), Hub(y)\n. . .\n. . .\n. . .\nFigure 7.2: Part of a Re\ufb01nement Graph\nInitialize \u039ecur := \u039e.\nInitialize \u03c0:= empty set of clauses.\nrepeat [The outer loop works to make \u03c0 su\ufb03cient.]\nInitialize c := \u03c1 : \u2212.\nrepeat [The inner loop makes c necessary.]\nSelect a literal l to add to c. [This is a nondeterministic choice point.]\nAssign c:= c,l.\nuntil c is necessary. [That is, until c covers no negative instances in \u039e cur.]\nAssign \u03c0:= \u03c0,c. [We add the clause c to the program.]\nAssign \u039ecur := \u039ecur \u2212(the positive instances in \u039e cur covered by \u03c0).\nuntil \u03c0 is su\ufb03cient.\n(The termination tests for the inner and outer loops can be relaxed as appro-\npriate for the case of noisy instances.)\n7.3 An Example\nWe illustrate how the algorithm works by returning to our example of airline\n\ufb02ights. Consider the portion of an airline route map, shown in Fig. 7.3. Cities\nA, B, and C are hub cities, and we know that there are nonstop \ufb02ights between\nall hub cities (even those not shown on this portion of the route map). The other'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 103, 'page_label': '104'}, page_content='7.3. AN EXAMPLE 95\ncities are satellites of one of the hubs, and we know that there are nonstop\n\ufb02ights between each satellite city and its hub. The learning program is given a\nset of positive instances, \u039e +, of pairs of cities between which there are nonstop\n\ufb02ights and a set of negative instances, \u039e\u2212, of pairs of cities between which there\nare not nonstop \ufb02ights. \u039e + contains just the pairs:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nFor our example, we will assume that \u039e\u2212contains all those pairs of cities shown\nin Fig. 7.3 that are not in \u039e + (a type of closed-world assumption). These are:\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<B,C 1 >,<B,C 2 >,\n<B,A 1 >,<B,A 2 >,<C,A 1 >,<C,A 2 >,<C,B 1 >,<C,B 2 >,\n<B 1,A>,<B 2,A>,<C 1,A>,<C 2,A>,<C 1,B >,<C 2,B >,\n<A1,B >,<A2,B >,<A1,C >,<A2,C >,<B 1,C >,<B 2,C >}\nThere may be other cities not shown on this map, so the training set does not\nnecessarily exhaust all the cities.\nA\nB\nC\nC1\nC2\nB1 B2\nA1\nA2\nFigure 7.3: Part of an Airline Route Map\nWe want the learning program to induce a program for computing the value\nof the relation Nonstop. The training set, \u039e, can be thought of as a partial'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 104, 'page_label': '105'}, page_content='96 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\ndescription of this relation in extensional formit explicitly names some pairs\nin the relation and some pairs not in the relation. We desire to learn the\nNonstop relation as a logic program in terms of the background relations, Hub\nand Satellite, which are also given in extensional form. Doing so will give us\na more compact, intensional, description of the relation, and this description\ncould well generalize usefully to other cities not mentioned in the map.\nWe assume the learning program has the following extensional de\ufb01nitions of\nthe relations Hub and Satellite:\nHub\n{<A>,<B >,<C > }\nAll other cities mentioned in the map are assumed not in the relation Hub. We\nwill use the notation Hub(x) to express that the city named xis in the relation\nHub.\nSatellite\n{<A1,A,>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nAll other pairs of cities mentioned in the map are not in the relation Satellite.\nWe will use the notation Satellite(x,y) to express that the pair < x,y >is\nin the relation Satellite.\nKnowing that the predicate Nonstop is a two-place predicate, the inner loop\nof our algorithm initializes the \ufb01rst clause to Nonstop(x,y) :- . This clause\nis not necessary because it covers all the negative examples (since it covers all\nexamples). So we must add a literal to its (empty) body. Suppose (selecting\na literal from the re\ufb01nement graph) the algorithm adds Hub(x). The following\npositive instances in \u039e are covered by Nonstop(x,y) :- Hub(x):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}\nTo compute this covering, we interpret the logic program Nonstop(x,y) :-\nHub(x) for all pairs of cities in \u039e, using the pairs given in the background\nrelation Hub as ground facts. The following negative instances are also covered:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 105, 'page_label': '106'}, page_content='7.3. AN EXAMPLE 97\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<C,A 1 >,<C,A 2 >,\n<C,B 1 >,<C,B 2 >,<B,A 1 >,<B,A 2 >,<B,C 1 >,<B,C 2 >}\nThus, the clause is not yet necessary and another literal must be added. Sup-\npose we next add Hub(y). The following positive instances are covered by\nNonstop(x,y) :- Hub(x), Hub(y):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B > }\nThere are no longer any negative instances in \u039e covered so the clause\nNonstop(x,y) :- Hub(x), Hub(y) is necessary, and we can terminate the \ufb01rst\npass through the inner loop.\nBut the program, \u03c0, consisting of just this clause is not su\ufb03cient. These\npositive instances are not covered by the clause:\n{<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nThe positive instances that were covered byNonstop(x,y) :- Hub(x), Hub(y)\nare removed from \u039e to form the \u039e cur to be used in the next pass through the\ninner loop. \u039e cur consists of all the negative instances in \u039e plus the positive\ninstances (listed above) that are not yet covered. In order to attempt to cover\nthem, the inner loop creates another clause c, initially set to Nonstop(x,y)\n:- . This clause covers all the negative instances, and so we must add liter-\nals to make it necessary. Suppose we add the literal Satellite(x,y). The\nclause Nonstop(x,y) :- Satellite(x,y) covers no negative instances, so it is\nnecessary. It does cover the following positive instances in \u039e cur:\n{<A1,A>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nThese instances are removed from \u039ecur for the next pass through the inner loop.\nThe program now contains two clauses:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\nThis program is not yet su\ufb03cient since it does not cover the following positive\ninstances:\n{<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 106, 'page_label': '107'}, page_content='98 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nDuring the next pass through the inner loop, we add the clauseNonstop(x,y)\n:- Satellite(y,x). This clause is necessary, and since the program containing\nall three clauses is now su\ufb03cient, the procedure terminates with:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nSince each clause is necessary, and the whole program is su\ufb03cient, the pro-\ngram is also consistent with all instances of the training set. Note that this\nprogram can be applied (perhaps with good generalization) to other cities be-\nsides those in our partial mapso long as we can evaluate the relations Hub and\nSatellite for these other cities. In the next section, we show how the technique\ncan be extended to use recursion on the relation we are inducing. With that\nextension, the method can be used to induce more general logic programs.\n7.4 Inducing Recursive Programs\nTo induce a recursive program, we allow the addition of a literal having the\nsame predicate letter as that in the head of the clause. Various mechanisms\nmust be used to ensure that such a program will terminate; one such is to make\nsure that the new literal has di\ufb00erent variables than those in the head literal.\nThe process is best illustrated with another example. Our example continues\nthe one using the airline map, but we make the map somewhat simpler in order\nto reduce the size of the extensional relations used. Consider the map shown\nin Fig. 7.4. Again, B and C are hub cities, B1 and B2 are satellites of B, C1\nand C2 are satellites of C. We have introduced two new cities, B3 and C3. No\n\ufb02ights exist between these cities and any other citiesperhaps there are only\nbus routes as shown by the grey lines in the map.\nWe now seek to learn a program for Canfly(x,y) that covers only those\npairs of cities that can be reached by one or more nonstop \ufb02ights. The relation\nCanfly is satis\ufb01ed by the following pairs of postive instances:\n{<B 1,B >,<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,\n<B,B 1 >,<B 2,B1 >,<C,B 1 >,<C 1,B1 >,<C 2,B1 >,\n<B 2,B >,<B 2,C >,<B 2,C1 >,<B 2,C2 >,<B,B 2 >,\n<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C >,<B,C 1 >,\n<B,C 2 >,<C,B >,<C 1,B >,<C 2,B >,<C,C 1 >,\n<C,C 2 >,<C 1,C >,<C 2,C >,<C 1,C2 >,<C 2,C1 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 107, 'page_label': '108'}, page_content='7.4. INDUCING RECURSIVE PROGRAMS 99\nB\nC\nC1\nC2\nB1\nB2\nB3\nC3\nFigure 7.4: Another Airline Route Map\nUsing a closed-world assumption on our map, we take the negative instances of\nCanfly to be:\n{<B 3,B2 >,<B 3,B >,<B 3,B1 >,<B 3,C >,<B 3,C1 >,\n<B 3,C2 >,<B 3,C3 >,<B 2,B3 >,<B,B 3 >,<B 1,B3 >,\n<C,B 3 >,<C 1,B3 >,<C 2,B3 >,<C 3,B3 >,<C 3,B2 >,\n<C 3,B >,<C 3,B1 >,<C 3,C >,<C 3,C1 >,<C 3,C2 >,\n<B 2,C3 >,<B,C 3 >,<B 1,C3 >,<C,C 3 >,<C 1,C3 >,\n<C 2,C3 >}\nWe will induce Canfly(x,y) using the extensionally de\ufb01ned background\nrelation Nonstop given earlier (modi\ufb01ed as required for our reduced airline map)\nand Canfly itself (recursively).\nAs before, we start with the empty program and proceed to the inner loop\nto construct a clause that is necessary. Suppose that the inner loop adds the\nbackground literal Nonstop(x,y). The clause Canfly(x,y) :- Nonstop(x,y)\nis necessary; it covers no negative instances. But it is not su\ufb03cient because it\ndoes not cover the following positive instances:\n{<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,<B 2,B1 >,\n<C,B 1 >,<C 1,B1 >,<C 2,B1 >,<B 2,C >,<B 2,C1 >,\n<B 2,C2 >,<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C 1 >,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 108, 'page_label': '109'}, page_content='100 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n<B,C 2 >,<C 1,B >,<C 2,B >,<C 1,C2 >,<C 2,C1 >}\nThus, we must add another clause to the program. In the inner loop, we \ufb01rst\ncreate the clause Canfly(x,y) :- Nonstop(x,z) which introduces the new\nvariable z. We digress brie\ufb02y to describe how a program containing a clause\nwith unbound variables in its body is interpreted. Suppose we try to inter-\npret it for the positive instance Canfly(B1,B2). The interpreter attempts to\nestablish Nonstop(B1,z) for some z. Since Nonstop(B1, B), for example, is\na background fact, the interpreter returns Twhich means that the instance\n< B1,B2 > is covered. Suppose now, we attempt to interpret the clause\nfor the negative instance Canfly(B3,B). The interpreter attempts to estab-\nlish Nonstop(B3,z) for some z. There are no background facts that match, so\nthe clause does not cover < B3,B >. Using the interpreter, we see that the\nclause Canfly(x,y) :- Nonstop(x,z) covers all of the positive instances not\nalready covered by the \ufb01rst clause, but it also covers many negative instances\nsuch as <B 2,B3 >, and <B,B 3 >. So the inner loop must add another literal.\nThis time, suppose it adds Canfly(z,y) to yield the clause Canfly(x,y) :-\nNonstop(x,z), Canfly(z,y). This clause is necessary; no negative instances\nare covered. The program is now su\ufb03cient and consistent; it is:\nCanfly(x,y) :- Nonstop(x,y)\n:- Nonstop(x,z), Canfly(z,y)\n7.5 Choosing Literals to Add\nOne of the \ufb01rst practical ILP systems was Quinlans FOIL [Quinlan, 1990]. A\nmajor problem involves deciding how to select a literal to add in the inner loop\n(from among the literals that are allowed). In FOIL, Quinlan suggested that\ncandidate literals can be compared using an information-like measuresimilar\nto the measures used in inducing decision trees. A measure that gives the same\ncomparison as does Quinlans is based on the amount by which adding a literal\nincreases the odds that an instance drawn at random from those covered by the\nnew clause is a positive instance beyond what these odds were before adding\nthe literal.\nLet p be an estimate of the probability that an instance drawn at random\nfrom those covered by a clause before adding the literal is a positive instance.\nThat is, p=(number of positive instances covered by the clause)/(total number\nof instances covered by the clause). It is convenient to express this probability\nin odds form. The odds, o, that a covered instance is positive is de\ufb01ned to\nbe o = p/(1 \u2212p). Expressing the probability in terms of the odds, we obtain\np= o/(1 + o).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 109, 'page_label': '110'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION101\nAfter selecting a literal, l, to add to a clause, some of the instances previously\ncovered are still covered; some of these are positive and some are negative. Let\npl denote the probability that an instance drawn at random from the instances\ncovered by the new clause (with l added) is positive. The odds will be denoted\nby ol. We want to select a literal, l, that gives maximal increase in these\nodds. That is, if we de\ufb01ne \u03bbl = ol/o, we want a literal that gives a high\nvalue of \u03bbl. Specializing the clause in such a way that it fails to cover many of\nthe negative instances previously covered but still covers most of the positive\ninstances previously covered will result in a high value of \u03bbl. (It turns out that\nthe value of Quinlans information theoretic measure increases monotonically\nwith \u03bbl, so we could just as well use the latter instead.)\nBesides \ufb01nding a literal with a high value of \u03bbl, Quinlans FOIL system also\nrestricts the choice to literals that:\na) contain at least one variable that has already been used,\nb) place further restrictions on the variables if the literal selected has the\nsame predicate letter as the literal being induced (in order to prevent in\ufb01nite\nrecursion), and\nc) survive a pruning test based on the values of \u03bbl for those literals selected\nso far.\nWe refer the reader to Quinlans paper for further discussion of these points.\nQuinlan also discusses post-processing pruning methods and presents experi-\nmental results of the method applied to learning recursive relations on lists, on\nlearning rules for chess endgames and for the card game Eleusis, and for some\nother standard tasks mentioned in the machine learning literature.\nThe reader should also refer to [Pazzani & Kibler, 1992,\nLavra\u02c7 c & D\u02c7 zeroski, 1994, Muggleton, 1991, Muggleton, 1992]. Discuss preprocessing,\npostprocessing, bottom-up\nmethods, and LINUS.\n7.6 Relationships Between ILP and Decision\nTree Induction\nThe generic ILP algorithm can also be understood as a type of decision tree\ninduction. Recall the problem of inducing decision trees when the values of\nattributes are categorical. When splitting on a single variable, the split at\neach node involves asking to which of several mutually exclusive and exhaustive\nsubsets the value of a variable belongs. For example, if a node tested the variable\nxi, and if xi could have values drawn from {A,B,C,D,E,F }, then one possible\nsplit (among many) might be according to whether the value of xi had as value\none of {A,B,C }or one of {D,E,F }.\nIt is also possible to make a multi-variate splittesting the values of two or\nmore variables at a time. With categorical variables, an n-variable split would\nbe based on which of several n-ary relations the values of the variables satis\ufb01ed.\nFor example, if a node tested the variables xi and xj, and if xi and xj both\ncould have values drawn from {A,B,C,D,E,F }, then one possible binary split'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 110, 'page_label': '111'}, page_content='102 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n(among many) might be according to whether or not < xi,xj > satis\ufb01ed the\nrelation {<A,C >,<C,D> }. (Note that our subset method of forming single-\nvariable splits could equivalently have been framed using 1-ary relationswhich\nare usually called properties.)\nIn this framework, the ILP problem is as follows: We are given a training set,\n\u039e, of positively and negatively labeled patterns whose components are drawn\nfrom a set of variables {x,y,z,... }. The positively labeled patterns in \u039e form an\nextensional de\ufb01nition of a relation, R. We are also given background relations,\nR1,...,R k, on various subsets of these variables. (That is, we are given sets\nof tuples that are in these relations.) We desire to construct an intensional\nde\ufb01nition of Rin terms of the R1,...,R k, such that all of the positively labeled\npatterns in \u039e are satis\ufb01ed by R and none of the negatively labeled patterns\nare. The intensional de\ufb01nition will be in terms of a logic program in which the\nrelation R is the head of a set of clauses whose bodies involve the background\nrelations.\nThe generic ILP algorithm can be understood as decision tree induction,\nwhere each node of the decision tree is itself a sub-decision tree, and each sub-\ndecision tree consists of nodes that make binary splits on several variables using\nthe background relations, Ri. Thus we will speak of a top-level decision tree\nand various sub-decision trees. (Actually, our decision trees will be decision\nlistsa special case of decision trees, but we will refer to them as trees in our\ndiscussions.)\nIn broad outline, the method for inducing an intensional version of the rela-\ntion R is illustrated by considering the decision tree shown in Fig. 7.5. In this\ndiagram, the patterns in \u039e are \ufb01rst \ufb01ltered through the decision tree in top-\nlevel node 1. The background relation R1 is satis\ufb01ed by some of these patterns;\nthese are \ufb01ltered to the right (to relation R2), and the rest are \ufb01ltered to the\nleft (more on what happens to these later). Right-going patterns are \ufb01ltered\nthrough a sequence of relational tests until only positively labeled patterns sat-\nisfy the last relationin this case R3. That is, the subset of patterns satisfying\nall the relations, R1, R2, and R3 contains only positive instances from \u039e. (We\nmight say that this combination of tests is necessary. They correspond to the\nclause created in the \ufb01rst pass through the inner loop of the generic ILP algo-\nrithm.) Let us call the subset of patterns satisfying these relations, \u039e 1; these\nsatisfy Node 1 at the top level. All other patterns, that is {\u039e \u2212\u039e1}= \u039e2 are\n\ufb01ltered to the left by Node 1.\n\u039e2 is then \ufb01ltered by top-level Node 2 in much the same manner, so that\nNode 2 is satis\ufb01ed only by the positively labeled samples in \u039e 2. We continue\n\ufb01ltering through top-level nodes until only the negatively labeled patterns fail to\nsatisfy a top node. In our example, \u039e 4 contains only negatively labeled patterns\nand the union of \u039e 1 and \u039e3 contains all the positively labeled patterns. The\nrelation, R, that distinguishes positive from negative patterns in \u039e is then given\nin terms of the following logic program:\nR :- R1, R2, R3'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 111, 'page_label': '112'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION103\nR1\nR2\nR3\nT\nT\nT\nF\nF\nF\nT\nF\nR4\nR5\nT\nT\nF\nF\nTF\nU\nU1\nU2 = U < U1\nU3U4= U2 < U3\nNode 1\nNode 2\n(only positive\ninstances\nsatisfy all three\ntests)\n(only positivel\ninstances satisfy\nthese two tests)\n(only negative\ninstances)\nFigure 7.5: A Decision Tree for ILP\n:- R4, R5\nIf we apply this sort of decision-tree induction procedure to the problem\nof generating a logic program for the relation Nonstop (refer to Fig. 7.3), we\nobtain the decision tree shown in Fig. 7.6. The logic program resulting from\nthis decision tree is the same as that produced by the generic ILP algorithm.\nIn setting up the problem, the training set, \u039e can be expressed as a set of 2-\ndimensional vectors with components xand y. The values of these components\nrange over the cities {A,B,C,A 1,A2,B1,B2,C1,C2}except (for simplicity)\nwe do not allow patterns in which x and y have the same value. As before, the\nrelation, Nonstop, contains the following pairs of cities, which are the positive\ninstances:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nAll other pairs of cities named in the map of Fig. 7.3 (using the closed world\nassumption) are not in the relation Nonstop and thus are negative instances.\nBecause the values of xand y are categorical, decision-tree induction would\nbe a very di\ufb03cult taskinvolving as it does the need to invent relations on'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 112, 'page_label': '113'}, page_content='104 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nx and y to be used as tests. But with the background relations, Ri (in this\ncase Hub and Satellite), the problem is made much easier. We select these\nrelations in the same way that we select literals; from among the available tests,\nwe make a selection based on which leads to the largest value of \u03bbRi.\n7.7 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 113, 'page_label': '114'}, page_content='7.7. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 105\nHub(x) T\nF\nU\nNode 1\n(top level)\n{<A,B>, <A,C>,\n<B,C>, <B,A>,\n<C,A>, <C,B>}\nHub(y) T\nT\nFNode 2\n(top level)\nSatellite(x,y)\nF T\nT {<A1,A>, <A2,A>, <B1,B>,\n<B2,B>, <C1,C>, <C2,C>}\nF\n{<A,A1>, <A,A2>,<B,B1>,\n<B,B2>,  <C,C1>, <C,C2>}\nSatellite(y,x)\nF\nF\nT\nNode 3\n(top level)\nT\n{Only negative instances}\n(Only positive instances)\n(Only positive instances)\n(Only positive instances)\nF\nFigure 7.6: A Decision Tree for the Airline Route Problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 114, 'page_label': '115'}, page_content='106 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 115, 'page_label': '116'}, page_content='Chapter 8\nComputational Learning\nTheory\nIn chapter one we posed the problem of guessing a function given a set of\nsample inputs and their values. We gave some intuitive arguments to support\nthe claim that after seeing only a small fraction of the possible inputs (and\ntheir values) that we could guess almost correctly the values of most subsequent\ninputsif we knew that the function we were trying to guess belonged to an\nappropriately restricted subset of functions. That is, a given training set of\nsample patterns might be adequate to allow us to select a function, consistent\nwith the labeled samples , from among a restricted set of hypotheses such that\nwith high probability the function we select will be approximately correct (small\nprobability of error) on subsequent samples drawn at random according to the\nsame distribution from which the labeled samples were drawn. This insight\nled to the theory of probably approximately correct (PAC) learninginitially\ndeveloped by Leslie Valiant [Valiant, 1984]. We present here a brief description\nof the theory for the case of Boolean functions. [Dietterich, 1990, Haussler, 1988,\nHaussler, 1990] give nice surveys of the important results. Other overviews?\n8.1 Notation and Assumptions for PAC Learn-\ning Theory\nWe assume a training set \u039e of n-dimensional vectors, Xi, i = 1 ,...,m , each\nlabeled (by 1 or 0) according to a target function, f, which is unknown to\nthe learner. The probability of any given vector X being in \u039e, or later being\npresented to the learner, is P(X). The probability distribution, P, can be\narbitrary. (In the literature of PAC learning theory, the target function is usually\ncalled the target concept and is denoted by c, but to be consistent with our\nprevious notation we will continue to denote it by f.) Our problem is to guess\n107'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 116, 'page_label': '117'}, page_content='108 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\na function, h(X), based on the labeled samples in \u039e. In PAC theory such a\nguessed function is called the hypothesis. We assume that the target function\nis some element of a set of functions, C. We also assume that the hypothesis,\nh, is an element of a set, H, of hypotheses, which includes the set, C, of target\nfunctions. His called the hypothesis space.\nIn general, h wont be identical to f, but we can strive to have the value of\nh(X) = the value of f(X) for most Xs. That is, we want hto be approximately\ncorrect. To quantify this notion, we de\ufb01ne the error of h, \u03b5h, as the probability\nthat an X drawn randomly according to P will be misclassi\ufb01ed:\n\u03b5h =\n\u2211\n[X:h(X)\u0338=f(X)]\nP(X)\nBoldface symbols need to be\nsmaller when they are subscripts in\nmath environments. We say that h is approximately (except for \u03b5 ) correct if \u03b5h \u2264\u03b5, where \u03b5 is the\naccuracy parameter.\nSuppose we are able to \ufb01nd anhthat classi\ufb01es all mrandomly drawn training\nsamples correctly; that is, h is consistent with this randomly selected training\nset, \u039e. If m is large enough, will such an h be approximately correct (and\nfor what value of \u03b5)? On some training occasions, using m randomly drawn\ntraining samples, such an h might turn out to be approximately correct (for a\ngiven value of \u03b5), and on others it might not. We say that his probably (except\nfor \u03b4) approximately correct (PAC) if the probability that it is approximately\ncorrect is greater than 1\u2212\u03b4, where \u03b4is the con\ufb01dence parameter. We shall show\nthat if m is greater than some bound whose value depends on \u03b5 and \u03b4, such an\nh is guaranteed to be probably approximately correct.\nIn general, we say that a learning algorithm PAC-learns functions from Cin\nterms of Hi\ufb00 for every function f\u03f5 C, it outputs a hypothesis h\u03f5 H, such that\nwith probability at least (1 \u2212\u03b4), \u03b5h \u2264\u03b5. Such a hypothesis is called probably\n(except for \u03b4) approximately (except for \u03b5) correct.\nWe want learning algorithms that are tractable, so we want an algorithm\nthat PAC-learns functions in polynomial time. This can only be done for certain\nclasses of functions. If there are a \ufb01nite number of hypotheses in a hypothesis\nset (as there are for many of the hypothesis sets we have considered), we could\nalways produce a consistent hypothesis from this set by testing all of them\nagainst the training data. But if there are an exponential number of hypotheses,\nthat would take exponential time. We seek training methods that produce\nconsistent hypotheses in less time. The time complexities for various hypothesis\nsets have been determined, and these are summarized in a table to be presented\nlater.\nA class, C, is polynomially PAC learnable in terms of Hprovided there exists\na polynomial-time learning algorithm (polynomial in the number of samples\nneeded, m, in the dimension, n, in 1 /\u03b5, and in 1 /\u03b4) that PAC-learns functions\nin Cin terms of H.\nInitial work on PAC assumed H= C, but it was later shown that some func-\ntions cannot be polynomially PAC-learned under such an assumption (assuming'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 117, 'page_label': '118'}, page_content='8.2. PAC LEARNING 109\nP \u0338= NP)but can be polynomially PAC-learned if His a strict superset of C!\nAlso our de\ufb01nition does not specify the distribution, P, from which patterns\nare drawn nor does it say anything about the properties of the learning algo-\nrithm. Since Cand Hdo not have to be identical, we have the further restrictive\nde\ufb01nition:\nA properly PAC-learnableclass is a classCfor which there exists an algorithm\nthat polynomially PAC-learns functions from Cin terms of C.\n8.2 PAC Learning\n8.2.1 The Fundamental Theorem\nSuppose our learning algorithm selects some hrandomly from among those that\nare consistent with the values of f on the mtraining patterns. The probability\nthat the error of this randomly selected his greater than some \u03b5, with hconsis-\ntent with the values of f(X) for minstances of X (drawn according to arbitrary\nP), is less than or equal to |H|e\u2212\u03b5m, where |H|is the number of hypotheses in\nH. We state this result as a theorem [Blumer, et al., 1987]:\nTheorem 8.1 (Blumer, et al.) Let Hbe any set of hypotheses, \u039e be a set of\nm \u22651 training examples drawn independently according to some distribution\nP, f be any classi\ufb01cation function in H, and \u03b5> 0. Then, the probability that\nthere exists a hypothesis hconsistent with f for the members of \u039e but with error\ngreater than \u03b5 is at most |H|e\u2212\u03b5m.\nProof:\nConsider the set of all hypotheses, {h1,h2,...,h i,...,h S}, in H, where S =\n|H|. The error for hi is \u03b5hi= the probability that hi will classify a pattern in\nerror (that is, di\ufb00erently than f would classify it). The probability that hi will\nclassify a pattern correctly is (1\u2212\u03b5hi). A subset, HB, of Hwill have error greater\nthan \u03b5. We will call the hypotheses in this subset bad. The probability that any\nparticular one of these bad hypotheses, sayhb, would classify a pattern correctly\nis (1\u2212\u03b5hb). Since \u03b5hb >\u03b5, the probability that hb (or any other bad hypothesis)\nwould classify a pattern correctly is less than (1 \u2212\u03b5). The probability that it\nwould classify all m independently drawn patterns correctly is then less than\n(1 \u2212\u03b5)m.\nThat is,\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB] \u2264(1 \u2212\u03b5)m.\nprob[some h \u03f5HB classi\ufb01es all m patterns correctly]\n= \u2211\nhb \u03f5 HB\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB]\n\u2264K(1 \u2212\u03b5)m, where K = |HB|.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 118, 'page_label': '119'}, page_content='110 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nThat is,\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n\u2264K(1 \u2212\u03b5)m.\nSince K \u2264|H| and (1 \u2212\u03b5)m \u2264e\u2212\u03b5m, we have:\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n= prob[there is a hypothesis with error >\u03b5 and that classi\ufb01es all mpatterns\ncorrectly] \u2264|H|e\u2212\u03b5m.\nQED\nA corollary of this theorem is:\nCorollary 8.2 Given m \u2265 (1/\u03b5)(ln |H|+ ln(1/\u03b4)) independent samples, the\nprobability that there exists a hypothesis in Hthat is consistent with f on these\nsamples and has error greater than \u03b5 is at most \u03b4.\nProof: We are to \ufb01nd a bound on m that guarantees that\nprob[there is a hypothesis with error > \u03b5and that classi\ufb01es all m patterns\ncorrectly] \u2264 \u03b4. Thus, using the result of the theorem, we must show that\n|H|e\u2212\u03b5m \u2264\u03b4. Taking the natural logarithm of both sides yields:\nln |H|\u2212\u03b5m\u2264ln \u03b4\nor\nm\u2265(1/\u03b5)(ln |H|+ ln(1/\u03b4))\nQED\nThis corollary is important for two reasons. First it clearly states that we\ncan select any hypothesis consistent with the m samples and be assured that\nwith probability (1 \u2212\u03b4) its error will be less than \u03b5. Also, it shows that in\norder for mto increase no more than polynomially with n, |H|can be no larger\nthan 2O(nk). No class larger than that can be guaranteed to be properly PAC\nlearnable.\nHere is a possible point of confusion: The bound given in the corollary is\nan upper bound on the value of mneeded to guarantee polynomial probably ap-\nproximately correct learning. Values of mgreater than that bound are su\ufb03cient\n(but might not be necessary). We will present a lower (necessary) bound later\nin the chapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 119, 'page_label': '120'}, page_content='8.2. PAC LEARNING 111\n8.2.2 Examples\nTerms\nLet Hbe the set of terms (conjunctions of literals). Then, |H|= 3n, and\nm\u2265(1/\u03b5)(ln(3n) + ln(1/\u03b4))\n\u2265(1/\u03b5)(1.1n+ ln(1/\u03b4))\nNote that the bound on m increases only polynomially with n, 1/\u03b5, and 1/\u03b4.\nFor n= 50, \u03b5= 0.01 and \u03b4= 0.01, m\u22655,961 guarantees PAC learnability.\nIn order to show that terms are properly PAC learnable , we additionally\nhave to show that one can \ufb01nd in time polynomial in m and n a hypothesis\nh consistent with a set of m patterns labeled by the value of a term. The\nfollowing procedure for \ufb01nding such a consistent hypothesis requires O(nm)\nsteps (adapted from [Dietterich, 1990, page 268]):\nWe are given a training sequence, \u039e, of m examples. Find the \ufb01rst pattern,\nsay X1, in that list that is labeled with a 1. Initialize a Boolean function,\nh, to the conjunction of the n literals corresponding to the values of the n\ncomponents of X1. (Components with value 1 will have corresponding positive\nliterals; components with value 0 will have corresponding negative literals.) If\nthere are no patterns labeled by a 1, we exit with the null concept ( h \u22610 for\nall patterns). Then, for each additional pattern, Xi, that is labeled with a 1,\nwe delete from h any Boolean variables appearing in Xi with a sign di\ufb00erent\nfrom their sign in h. After processing all the patterns labeled with a 1, we check\nall of the patterns labeled with a 0 to make sure that none of them is assigned\nvalue 1 by h. If, at any stage of the algorithm, any patterns labeled with a 0\nare assigned a 1 by h, then there exists no term that consistently classi\ufb01es the\npatterns in \u039e, and we exit with failure. Otherwise, we exit with h. Change this paragraph if this\nalgorithm was presented in Chapter\nThree.As an example, consider the following patterns, all labeled with a 1 (from\n[Dietterich, 1990]):\n(0,1,1,0)\n(1,1,1,0)\n(1,1,0,0)\nAfter processing the \ufb01rst pattern, we have h = x1x2x3x4; after processing the\nsecond pattern, we have h = x2x3x4; \ufb01nally, after the third pattern, we have\nh= x2x4.\nLinearly Separable Functions\nLet Hbe the set of all linearly separable functions. Then, |H|\u2264 2n2\n, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 120, 'page_label': '121'}, page_content='112 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nm\u2265(1/\u03b5)\n(\nn2 ln 2 + ln(1/\u03b4)\n)\nAgain, note that the bound on m increases only polynomially with n, 1/\u03b5, and\n1/\u03b4.\nFor n= 50, \u03b5= 0.01 and \u03b4 = 0.01, m\u2265173,748 guarantees PAC learnabil-\nity.\nTo show that linearly separable functions are properly PAC learnable , we\nwould have additionally to show that one can \ufb01nd in time polynomial in mand\nna hypothesis hconsistent with a set of mlabeled linearly separable patterns.Linear programming is polynomial.\n8.2.3 Some Properly PAC-Learnable Classes\nSome properly PAC-learnable classes of functions are given in the following\ntable. (Adapted from [Dietterich, 1990, pages 262 and 268] which also gives\nreferences to proofs of some of the time complexities.)\nH |H| Time Complexity P. Learnable?\nterms 3n polynomial yes\nk-term DNF 2O(kn) NP-hard no\n(k disjunctive terms)\nk-DNF 2O(nk) polynomial yes\n(a disjunction of k-sized terms)\nk-CNF 2O(nk) polynomial yes\n(a conjunction of k-sized clauses)\nk-DL 2O(nkklg n) polynomial yes\n(decision lists with k-sized terms)\nlin. sep. 2O(n2) polynomial yes\nlin. sep. with (0,1) weights ? NP-hard no\nk-2NN ? NP-hard no\nDNF 22n\npolynomial no\n(all Boolean functions)\n(Members of the class k-2NN are two-layer, feedforward neural networks with\nexactly k hidden units and one output unit.)\nSummary: In order to show that a class of functions is Properly PAC-\nLearnable :\na. Show that there is an algorithm that produces a consistent hypothesis on\nm n-dimensional samples in time polynomial in m and n.\nb. Show that the sample size, m, needed to ensure PAC learnability is polyno-\nmial (or better) in (1/\u03b5), (1/\u03b4), and nby showing that ln|H|is polynomial\nor better in the number of dimensions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 121, 'page_label': '122'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 113\nAs hinted earlier, sometimes enlarging the class of hypotheses makes learning\neasier. For example, the table above shows that k-CNF is PAC learnable, but\nk-term-DNF is not. And yet, k-term-DNF is a subclass of k-CNF! So, even if\nthe target function were in k-term-DNF, one would be able to \ufb01nd a hypothesis\nin k-CNF that is probably approximately correct for the target function. Sim-\nilarly, linearly separable functions implemented by TLUs whose weight values\nare restricted to 0 and 1 are not properly PAC learnable, whereas unrestricted\nlinearly separable functions are. It is possible that enlarging the space of hy-\npotheses makes \ufb01nding one that is consistent with the training examples easier.\nAn interesting question is whether or not the class of functions ink-2NN is poly-\nnomially PAC learnable if the hypotheses are drawn from k\u2032-2NN with k\u2032>k .\n(At the time of writing, this matter is still undecided.)\nAlthough PAC learning theory is a powerful analytic tool, it (like complexity\ntheory) deals mainly with worst-case results. The fact that the class of two-\nlayer, feedforward neural networks is not polynomially PAC learnable is more an\nattack on the theory than it is on the networks, which have had many successful\napplications. As [Baum, 1994, page 416-17] says:  ... humans are capable of\nlearning in the natural world. Therefore, a proof within some model of learning\nthat learning is not feasible is an indictment of the model. We should examine\nthe model to see what constraints can be relaxed and made more realistic.\n8.3 The Vapnik-Chervonenkis Dimension\n8.3.1 Linear Dichotomies\nConsider a set, H, of functions, and a set, \u039e, of (unlabeled) patterns. One\nmeasure of the expressive power of a set of hypotheses, relative to \u039e, is its\nability to make arbitrary classi\ufb01cations of the patterns in \u039e. 1 If there are m\npatterns in \u039e, there are 2 m di\ufb00erent ways to divide these patterns into two\ndisjoint and exhaustive subsets. We say there are 2 m di\ufb00erent dichotomies of\n\u039e. If \u039e were to include all of the 2 n Boolean patterns, for example, there are\n22n\nways to dichotomize them, and (of course) the set of all possible Boolean\nfunctions dichotomizes them in all of these ways. But a subset,H, of the Boolean\nfunctions might not be able to dichotomize an arbitrary set, \u039e, of m Boolean\npatterns in all 2 m ways. In general (that is, even in the non-Boolean case), we\nsay that if a subset, H, of functions can dichotomize a set, \u039e, of m patterns in\nall 2m ways, then Hshatters \u039e.\nAs an example, consider a set \u039e of m patterns in the n-dimensional space,\nRn. (That is, the ncomponents of these patterns are real numbers.) We de\ufb01ne\na linear dichotomy as one implemented by an (n\u22121)-dimensional hyperplane in\nthe n-dimensional space. How many linear dichotomies of m patterns in n di-\nmensions are there? For example, as shown in Fig. 8.1, there are 14 dichotomies\n1And, of course, if a hypothesis drawn from a set that could make arbitrary classi\ufb01cations\nof a set of training patterns, there is little likelihood that such a hypothesis will generalize\nwell beyond the training set.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 122, 'page_label': '123'}, page_content='114 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nof four points in two dimensions (each separating line yields two dichotomies\ndepending on whether the points on one side of the line are classi\ufb01ed as 1 or 0).\n(Note that even though there are an in\ufb01nite number of hyperplanes, there are,\nnevertheless, only a \ufb01nite number of ways in which hyperplanes can dichotomize\na \ufb01nite number of patterns. Small movements of a hyperplane typically do not\nchange the classi\ufb01cations of any patterns.)\n12\n3\n4\n14 dichotomies of 4 points in 2 dimensions\n5\n6\n7\nFigure 8.1: Dichotomizing Points in Two Dimensions\nThe number of dichotomies achievable by hyperplanes depends on how the\npatterns are disposed. For the maximum number of linear dichotomies, the\npoints must be in what is called general position. For m>n , we say that a set\nof m points is in general position in an n-dimensional space if and only if no\nsubset of (n+1) points lies on an (n\u22121)-dimensional hyperplane. When m\u2264n,\na set of m points is in general position if no ( m\u22122)-dimensional hyperplane\ncontains the set. Thus, for example, a set of m\u22654 points is in general position\nin a three-dimensional space if no four of them lie on a (two-dimensional) plane.\nWe will denote the number of linear dichotomies of mpoints in general position\nin an n-dimensional space by the expression \u03a0 L(m,n).\nIt is not too di\ufb03cult to verify that:Include the derivation.\n\u03a0L(m,n) = 2\nn\u2211\ni=0\nC(m\u22121,i) for m>n, and\n= 2m for m\u2264n'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 123, 'page_label': '124'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 115\nwhere C(m\u22121,i) is the binomial coe\ufb03cient (m\u22121)!\n(m\u22121\u2212i)!i! .\nThe table below shows some values for \u03a0 L(m,n).\nm n\n(no. of patterns) (dimension)\n1 2 3 4 5\n1 2 2 2 2 2\n2 4 4 4 4 4\n3 6 8 8 8 8\n4 8 14 16 16 16\n5 10 22 30 32 32\n6 12 32 52 62 64\n7 14 44 84 114 126\n8 16 58 128 198 240\nNote that the class of linear dichotomies shatters the m patterns if m\u2264n+ 1.\nThe bold-face entries in the table correspond to the highest values of m for\nwhich linear dichotomies shatter m patterns in n dimensions.\n8.3.2 Capacity\nLet Pm,n = \u03a0L(m,n)\n2m = the probability that a randomly selected dichotomy (out\nof the 2 m possible dichotomies of m patterns in n dimensions) will be linearly\nseparable. In Fig. 8.2 we plot P\u03bb(n+1),n versus \u03bb and n, where \u03bb= m/(n+ 1).\nNote that for large n (say n >30) how quickly Pm,n falls from 1 to 0 as\nm goes above 2( n+ 1). For m <2(n+ 1), any dichotomy of the m points is\nalmost certainly linearly separable. But for m> 2(n+ 1), a randomly selected\ndichotomy of the m points is almost certainly not linearly separable. For this\nreason m= 2(n+ 1) is called the capacity of a TLU [Cover, 1965]. Unless the\nnumber of training patterns exceeds the capacity, the fact that a TLU separates\nthose training patterns according to their labels means nothing in terms of how\nwell that TLU will generalize to new patterns. There is nothing special about\na separation found for m <2(n+ 1) patternsalmost any dichotomy of those\npatterns would have been linearly separable. To make sure that the separation\nfound is forced by the training set and thus generalizes well, it has to be the\ncase that there are very few linearly separable functions that would separate\nthe m training patterns.\nAnalogous results about the generalizing abilities of neural networks have\nbeen developed by [Baum & Haussler, 1989] and given intuitive and experimen-\ntal justi\ufb01cation in [Baum, 1994, page 438]:\nThe results seemed to indicate the following heuristic rule holds. If\nM examples [can be correctly classi\ufb01ed by] a net withW weights (for\nM >>W), the net will make a fraction \u03b5of errors on new examples\nchosen from the same [uniform] distribution where \u03b5= W/M.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 124, 'page_label': '125'}, page_content='116 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n0.25\n0.5\n0.75\n1\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n25\n.5\n75\n1\nPh(n + 1), n\nh\nn\nFigure 8.2: Probability that a Random Dichotomy is Linearly Separable\n8.3.3 A More General Capacity Result\nCorollary 7.2 gave us an expression for the number of training patterns su\ufb03cient\nto guarantee a required level of generalizationassuming that the function we\nwere guessing was a function belonging to a class of known and \ufb01nite cardinality.\nThe capacity result just presented applies to linearly separable functions for non-\nbinary patterns. We can extend these ideas to general dichotomies of non-binary\npatterns.\nIn general, let us denote the maximum number of dichotomies of any set\nof m n-dimensional patterns by hypotheses in Has \u03a0H(m,n). The number of\ndichotomies will, of course, depend on the disposition of the m points in the\nn-dimensional space; we take \u03a0 H(m,n) to be the maximum over all possible\narrangements of the m points. (In the case of the class of linearly separable\nfunctions, the maximum number is achieved when the m points are in general\nposition.) For each class, H, there will be some maximum value of mfor which\n\u03a0H(m,n) = 2m, that is, for which Hshatters the m patterns. This maximum\nnumber is called the Vapnik-Chervonenkis (VC) dimension and is denoted by\nVCdim(H) [Vapnik & Chervonenkis, 1971].\nWe saw that for the class of linear dichotomies, VCdim( Linear) = (n+ 1).\nAs another example, let us calculate the VC dimension of the hypothesis space\nof single intervals on the real lineused to classify points on the real line. We\nshow an example of how points on the line might be dichotomized by a single\ninterval in Fig. 8.3. The set \u039e could be, for example, {0.5, 2.5, - 2.3, 3.14}, and\none of the hypotheses in our set would be [1, 4.5]. This hypothesis would label\nthe points 2.5 and 3.14 with a 1 and the points - 2.3 and 0.5 with a 0. This'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 125, 'page_label': '126'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 117\nset of hypotheses (single intervals on the real line) can arbitrarily classify any\ntwo points. But no single interval can classify three points such that the outer\ntwo are classi\ufb01ed as 1 and the inner one as 0. Therefore the VC dimension of\nsingle intervals on the real line is 2. As soon as we have many more than 2\ntraining patterns on the real line and provided we know that the classi\ufb01cation\nfunction we are trying to guess is a single interval, then we begin to have good\ngeneralization.\nFigure 8.3: Dichotomizing Points by an Interval\nThe VC dimension is a useful measure of the expressive power of a hypothesis\nset. Since any dichotomy of VCdim(H) or fewer patterns in general position inn\ndimensions can be achieved by some hypothesis in H, we must have many more\nthan VCdim(H) patterns in the training set in order that a hypothesis consistent\nwith the training set is su\ufb03ciently constrained to imply good generalization.\nOur examples have shown that the concept of VC dimension is not restricted\nto Boolean functions.\n8.3.4 Some Facts and Speculations About the VC Dimen-\nsion\n If there are a \ufb01nite number, |H|, of hypotheses in H, then:\nVCdim(H) \u2264log(|H|)\n The VC dimension of terms in n dimensions is n.\n Suppose we generalize our example that used a hypothesis set of single\nintervals on the real line. Now let us consider an n-dimensional feature\nspace and tests of the form Li \u2264xi \u2264Hi. We allow only one such test per\ndimension. A hypothesis space consisting of conjunctions of these tests\n(called axis-parallel hyper-rectangles) has VC dimension bounded by:\nn\u2264 VCdim \u22642n\n As we have already seen, TLUs with n inputs have a VC dimension of\nn+ 1.\n [Baum, 1994, page 438] gives experimental evidence for the proposition\nthat  ... multilayer [neural] nets have a VC dimension roughly equal to\ntheir total number of [adjustable] weights.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 126, 'page_label': '127'}, page_content='118 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n8.4 VC Dimension and PAC Learning\nThere are two theorems that connect the idea of VC dimension with PAC learn-\ning [Blumer, et al., 1990]. We state these here without proof.\nTheorem 8.3 (Blumer, et al.) A hypothesis space His PAC learnable i\ufb00 it\nhas \ufb01nite VC dimension.\nTheorem 8.4 A set of hypotheses, H, is properly PAC learnable if:\na. m\u2265(1/\u03b5) max [4 lg(2/\u03b4), 8 VCdim lg(13 /\u03b5)], and\nb. if there is an algorithm that outputs a hypothesis h\u03f5 Hconsistent with the\ntraining set in polynomial (in m and n) time.\nThe second of these two theorems improves the bound on the number of\ntraining patterns needed for linearly separable functions to one that is linear\nin n. In our previous example of how many training patterns were needed to\nensure PAC learnability of a linearly separable function if n= 50, \u03b5= 0.01, and\n\u03b4 = 0.01, we obtained m \u2265173,748. Using the Blumer, et al. result we would\nget m\u226552,756.\nAs another example of the second theorem, let us take Hto be the set of\nclosed intervals on the real line. The VC dimension is 2 (as shown previously).\nWith n= 50, \u03b5= 0.01, and \u03b4= 0.01, m\u226516,551 ensures PAC learnability.\nThere is also a theorem that gives a lower (necessary) bound on the number\nof training patterns required for PAC learning [Ehrenfeucht, et al., 1988]:\nTheorem 8.5 Any PAC learning algorithm must examine at least\n\u2126(1/\u03b5lg(1/\u03b4) + VCdim(H)) training patterns.\nThe di\ufb00erence between the lower and upper bounds is\nO(log(1/\u03b5)VCdim(H)/\u03b5).\n8.5 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 127, 'page_label': '128'}, page_content='Chapter 9\nUnsupervised Learning\n9.1 What is Unsupervised Learning?\nConsider the various sets of points in a two-dimensional space illustrated in Fig.\n9.1. The \ufb01rst set (a) seems naturally partitionable into two classes, while the\nsecond (b) seems di\ufb03cult to partition at all, and the third (c) is problematic.\nUnsupervised learning uses procedures that attempt to \ufb01nd natural partitions\nof patterns. There are two stages:\n Form an R-way partition of a set \u039e of unlabeled training patterns (where\nthe value of R, itself, may need to be induced from the patterns). The\npartition separates \u039e into R mutually exclusive and exhaustive subsets,\n\u039e1,..., \u039eR, called clusters.\n Design a classi\ufb01er based on the labels assigned to the training patterns by\nthe partition.\nWe will explain shortly various methods for deciding how many clusters there\nshould be and for separating a set of patterns into that many clusters. We can\nbase some of these methods, and their motivation, on minimum-description-\nlength (MDL) principles. In that setting, we assume that we want to encode\na description of a set of points, \u039e, into a message of minimal length. One\nencoding involves a description of each point separately; other, perhaps shorter,\nencodings might involve a description of clusters of points together with how\neach point in a cluster can be described given the cluster it belongs to. The\nspeci\ufb01c techniques described in this chapter do not explicitly make use of MDL\nprinciples, but the MDL method has been applied with success. One of the\nMDL-based methods, Autoclass II [Cheeseman, et al., 1988] discovered a new\nclassi\ufb01cation of stars based on the properties of infrared sources.\nAnother type of unsupervised learning involves \ufb01nding hierarchies of par-\ntitionings or clusters of clusters. A hierarchical partition is one in which \u039e is\n119'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 128, 'page_label': '129'}, page_content='120 CHAPTER 9. UNSUPERVISED LEARNING\na)  two clusters\nb) one cluster\nc) ?\nFigure 9.1: Unlabeled Patterns\ndivided into mutually exclusive and exhaustive subsets, \u039e 1,..., \u039eR; each set,\n\u039ei, ( i = 1 ,...,R ) is divided into mutually exclusive and exhaustive subsets,\nand so on. We show an example of such a hierarchical partition in Fig. 9.2.\nThe hierarchical form is best displayed as a tree, as shown in Fig. 9.3. The tip\nnodes of the tree can further be expanded into their individual pattern elements.\nOne application of such hierarchical partitions is in organizing individuals into\ntaxonomic hierarchies such as those used in botany and zoology.\n9.2 Clustering Methods\n9.2.1 A Method Based on Euclidean Distance\nMost of the unsupervised learning methods use a measure of similarity between\npatterns in order to group them into clusters. The simplest of these involves\nde\ufb01ning a distance between patterns. For patterns whose features are numeric,\nthe distance measure can be ordinary Euclidean distance between two points in\nan n-dimensional space.\nThere is a simple, iterative clustering method based on distance. It can\nbe described as follows. Suppose we have R randomly chosen cluster seekers,\nC1,..., CR. These are points in an n-dimensional space that we want to adjust\nso that they each move toward the center of one of the clusters of patterns.\nWe present the (unlabeled) patterns in the training set, \u039e, to the algorithm'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 129, 'page_label': '130'}, page_content='9.2. CLUSTERING METHODS 121\nU11\nU12\nU21\nU22\nU23\nU31\nU32\nU11 F U12 = U1\nU21 F U22 F U23 = U2\nU31 F U32 = U3\nU1 F U2 F U3 = U\nFigure 9.2: A Hierarchy of Clusters\none-by-one. For each pattern, Xi, presented, we \ufb01nd that cluster seeker, Cj,\nthat is closest to Xi and move it closer to Xi:\nCj \u2190\u2212(1 \u2212\u03b1j)Cj + \u03b1jXi\nwhere \u03b1j is a learning rate parameter for the j-th cluster seeker; it determines\nhow far Cj is moved toward Xi.\nRe\ufb01nements on this procedure make the cluster seekers move less far as\ntraining proceeds. Suppose each cluster seeker, Cj, has a mass, mj, equal to\nthe number of times that it has moved. As a cluster seekers mass increases it\nmoves less far towards a pattern. For example, we might set \u03b1j = 1/(1 + mj)\nand use the above rule together with mj \u2190\u2212mj+1. With this adjustment rule,\na cluster seeker is always at the center of gravity (sample mean) of the set of\npatterns toward which it has so far moved. Intuitively, if a cluster seeker ever\ngets within some reasonably well clustered set of patterns (and if that cluster\nseeker is the only one so located), it will converge to the center of gravity of\nthat cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 130, 'page_label': '131'}, page_content='122 CHAPTER 9. UNSUPERVISED LEARNING\nU\nU2\nU11 U12 U31 U32 U21 U22 U23\nU1 U3\nFigure 9.3: Displaying a Hierarchy as a Tree\nOnce the cluster seekers have converged, the classi\ufb01er implied by the now-\nlabeled patterns in \u039e can be based on a Voronoi partitioning of the space (based\non distances to the various cluster seekers). This kind of classi\ufb01cation, an ex-\nample of which is shown in Fig. 9.4, can be implemented by a linear machine.\nGeorgy Fedoseevich Voronoi, was a\nRussian mathematician who lived\nfrom 1868 to 1909. When basing partitioning on distance, we seek clusters whose patterns are\nas close together as possible. We can measure the badness, V, of a cluster of\npatterns, {Xi}, by computing its sample variance de\ufb01ned by:\nV = (1/K)\n\u2211\ni\n(Xi \u2212M)2\nwhere M is the sample mean of the cluster, which is de\ufb01ned to be:\nM = (1/K)\n\u2211\ni\nXi\nand K is the number of points in the cluster.\nWe would like to partition a set of patterns into clusters such that the sum of\nthe sample variances (badnesses) of these clusters is small. Of course if we have\none cluster for each pattern, the sample variances will all be zero, so we must\narrange that our measure of the badness of a partition must increase with the\nnumber of clusters. In this way, we can seek a trade-o\ufb00 between the variances of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 131, 'page_label': '132'}, page_content='9.2. CLUSTERING METHODS 123\nC1\nC2\nC3\nSeparating boundaries\nFigure 9.4: Minimum-Distance Classi\ufb01cation\nthe clusters and the number of them in a way somewhat similar to the principle\nof minimal description length discussed earlier.\nElaborations of our basic cluster-seeking procedure allow the number of clus-\nter seekers to vary depending on the distances between them and depending on\nthe sample variances of the clusters. For example, if the distance, dij, between\ntwo cluster seekers, Ci and Cj, ever falls below some threshold \u03b5, then we can\nreplace them both by a single cluster seeker placed at their center of gravity\n(taking into account their respective masses). In this way we can decrease the\noverall badness of a partition by reducing the number of clusters for compara-\ntively little penalty in increased variance.\nOn the other hand, if any of the cluster seekers, say Ci, de\ufb01nes a cluster\nwhose sample variance is larger than some amount \u03b4, then we can place a new\ncluster seeker, Cj, at some random location somewhat adjacent to Ci and reset\nthe masses of both Ci and Cj to zero. In this way the badness of the par-\ntition might ultimately decrease by decreasing the total sample variance with\ncomparatively little penalty for the additional cluster seeker. The values of the\nparameters \u03b5 and \u03b4 are set depending on the relative weights given to sample\nvariances and numbers of clusters.\nIn distance-based methods, it is important to scale the components of the\npattern vectors. The variation of values along some dimensions of the pattern\nvector may be much di\ufb00erent than that of other dimensions. One commonly\nused technique is to compute the standard deviation (i.e., the square root of the\nvariance) of each of the components over the entire training set and normalize\nthe values of the components so that their adjusted standard deviations are\nequal.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 132, 'page_label': '133'}, page_content='124 CHAPTER 9. UNSUPERVISED LEARNING\n9.2.2 A Method Based on Probabilities\nSuppose we have a partition of the training set, \u039e, into R mutually exclusive\nand exhaustive clusters, C1,...,C R. We can decide to which of these clusters\nsome arbitrary pattern, X, should be assigned by selecting the Ci for which\nthe probability, p(Ci|X), is largest, providing p(Ci|X) is larger than some \ufb01xed\nthreshold, \u03b4. As we saw earlier, we can use Bayes rule and base our decision on\nmaximizing p(X|Ci)p(Ci). Assuming conditional independence of the pattern\ncomponents, xi, the quantity to be maximized is:\nS(X,Ci) = p(x1|Ci)p(x2|Ci) ···p(xn|Ci)p(Ci)\nThe p(xj|Ci) can be estimated from the sample statistics of the patterns in the\nclusters and then used in the above expression. (Recall the linear form that this\nformula took in the case of binary-valued components.)\nWe call S(X,Ci) the similarity of X to a cluster, Ci, of patterns. Thus, we\nassign X to the cluster to which it is most similar, providing the similarity is\nlarger than \u03b4.\nJust as before, we can de\ufb01ne the sample mean of a cluster, Ci, to be:\nMi = (1/Ki)\n\u2211\nXj\u03f5 Ci\nXj\nwhere Ki is the number of patterns in Ci.\nWe can base an iterative clustering algorithm on this measure of similarity\n[Mahadevan & Connell, 1992]. It can be described as follows:\na. Begin with a set of unlabeled patterns \u039e and an empty list, L, of clusters.\nb. For the next pattern, X, in \u039e, compute S(X,Ci) for each cluster, Ci.\n(Initially, these similarities are all zero.) Suppose the largest of these\nsimilarities is S(X,Cmax).\n(a) If S(X,Cmax) >\u03b4, assign X to Cmax. That is,\nCmax \u2190\u2212Cmax \u222a{X}\nUpdate the sample statisticsp(x1|Cmax),p(x2|Cmax),...,p (xn|Cmax),\nand p(Cmax) to take the new pattern into account. Go to 3.\n(b) If S(X,Cmax) \u2264\u03b4, create a new cluster, Cnew = {X}and add Cnew\nto L. Go to 3.\nc. Merge any existing clusters, Ci and Cj if ( Mi \u2212Mj)2 < \u03b5. Compute\nnew sample statistics p(x1|Cmerge),p(x2|Cmerge),...,p (xn|Cmerge), and\np(Cmerge) for the merged cluster, Cmerge = Ci \u222aCj.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 133, 'page_label': '134'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 125\nd. If the sample statistics of the clusters have not changed during an entire\niteration through \u039e, then terminate with the clusters in L; otherwise go\nto 2.\nThe value of the parameter \u03b4 controls the number of clusters. If \u03b4 is high,\nthere will be a large number of clusters with few patterns in each cluster. For\nsmall values of \u03b4, there will be a small number of clusters with many patterns in\neach cluster. Similarly, the larger the value of \u03b5, the smaller the number clusters\nthat will be found.\nDesigning a classi\ufb01er based on the patterns labeled by the partitioning is\nstraightforward. We assign any pattern, X, to that category that maximizes\nS(X,Ci). Mention k-means and EM\nmethods.\n9.3 Hierarchical Clustering Methods\n9.3.1 A Method Based on Euclidean Distance\nSuppose we have a set, \u039e, of unlabeled training patterns. We can form a hi-\nerarchical classi\ufb01cation of the patterns in \u039e by a simple agglomerative method.\n(The description of this algorithm is based on an unpublished manuscript by\nPat Langley.) Our description here gives the general idea; we leave it to the\nreader to generate a precise algorithm.\nWe \ufb01rst compute the Euclidean distance between all pairs of patterns in \u039e.\n(Again, appropriate scaling of the dimensions is assumed.) Suppose the smallest\ndistance is between patterns Xi and Xj. We collect Xi and Xj into a cluster,\nC, eliminate Xi and Xj from \u039e and replace them by a cluster vector, C, equal\nto the average of Xi and Xj. Next we compute the Euclidean distance again\nbetween all pairs of points in \u039e. If the smallest distance is between pairs of\npatterns, we form a new cluster, C, as before and replace the pair of patterns\nin \u039e by their average. If the shortest distance is between a pattern, Xi, and\na cluster vector, Cj (representing a cluster, Cj), we form a new cluster, C,\nconsisting of the union of Cj and {Xi}. In this case, we replace Cj and Xi\nin \u039e by their (appropriately weighted) average and continue. If the shortest\ndistance is between two cluster vectors, Ci and Cj, we form a new cluster, C,\nconsisting of the union of Ci and Cj. In this case, we replace Ci and Cj by their\n(appropriately weighted) average and continue. Since we reduce the number of\npoints in \u039e by one each time, we ultimately terminate with a tree of clusters\nrooted in the cluster containing all of the points in the original training set.\nAn example of how this method aggregates a set of two dimensional patterns\nis shown in Fig. 9.5. The numbers associated with each cluster indicate the order\nin which they were formed. These clusters can be organized hierarchically in a\nbinary tree with cluster 9 as root, clusters 7 and 8 as the two descendants of the\nroot, and so on. A ternary tree could be formed instead if one searches for the\nthree points in \u039e whose triangle de\ufb01ned by those patterns has minimal area.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 134, 'page_label': '135'}, page_content='126 CHAPTER 9. UNSUPERVISED LEARNING\n1\n2 3\n5\n4\n6\n7\n8\n9\nFigure 9.5: Agglommerative Clustering\n9.3.2 A Method Based on Probabilities\nA probabilistic quality measure for partitions\nWe can develop a measure of the goodness of a partitioning based on how\naccurately we can guess a pattern given only what partition it is in. Suppose\nwe are given a partitioning of \u039e into R classes, C1,...,C R. As before, we can\ncompute the sample statistics p(xi|Ck) which give probability values for each\ncomponent given the class assigned to it by the partitioning. Suppose each\ncomponent xi of X can take on the values vij, where the index j steps over the\ndomain of that component. We use the notation pi(vij|Ck) = probability(xi =\nvij|Ck).\nSuppose we use the following probabilistic guessing rule about the values\nof the components of a vector X given only that it is in class k. Guess that\nxi = vij with probability pi(vij|Ck). Then, the probability that we guess the\ni-th component correctly is:\n\u2211\nj\nprobability(guess is vij)pi(vij|Ck) =\n\u2211\nj\n[pi(vij|Ck)]2\nThe average number of (the n) components whose values are guessed correctly\nby this method is then given by the sum of these probabilities over all of the\ncomponents of X:\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 135, 'page_label': '136'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 127\nGiven our partitioning into R classes, the goodness measure, G, of this parti-\ntioning is the average of the above expression over all classes:\nG=\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nwhere p(Ck) is the probability that a pattern is in class Ck. In order to penalize\nthis measure for having a large number of classes, we divide it by R to get an\noverall quality measure of a partitioning:\nZ = (1/R)\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nWe give an example of the use of this measure for a trivially simple\nclustering of the four three-dimensional patterns shown in Fig. 9.6. There\nare several di\ufb00erent partitionings. Lets evaluate Z values for the follow-\ning ones: P1 = {a,b,c,d }, P2 = {{a,b},{c,d}}, P3 = {{a,c},{b,d}}, and\nP4 = {{a},{b},{c},{d}}. The \ufb01rst, P1, puts all of the patterns into a single\ncluster. The sample probabilities pi(vi1 = 1) and pi(vi0 = 0) are all equal to 1/2\nfor each of the three components. Summing over the values of the components\n(0 and 1) gives (1 /2)2 + (1/2)2 = 1 /2. Summing over the three components\ngives 3/2. Averaging over all of the clusters (there is just one) also gives 3 /2.\nFinally, dividing by the number of clusters produces the \ufb01nal Z value of this\npartition, Z(P1) = 3/2.\nThe second partition, P2, gives the following sample probabilities:\np1(v11 = 1|C1) = 1\np2(v21 = 1|C1) = 1/2\np3(v31 = 1|C1) = 1\nSumming over the values of the components (0 and 1) gives (1) 2 + (0)2 = 1 for\ncomponent 1, (1 /2)2 + (1/2)2 = 1/2 for component 2, and (1) 2 + (0)2 = 1 for\ncomponent 3. Summing over the three components gives 2 1 /2 for class 1. A\nsimilar calculation also gives 2 1 /2 for class 2. Averaging over the two clusters\nalso gives 2 1 /2. Finally, dividing by the number of clusters produces the \ufb01nal\nZ value of this partition, Z(P2) = 1 1/4, not quite as high as Z(P1).\nSimilar calculations yield Z(P3) = 1 and Z(P4) = 3 /4, so this method of\nevaluating partitions would favor placing all patterns in a single cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 136, 'page_label': '137'}, page_content='128 CHAPTER 9. UNSUPERVISED LEARNING\nx2\nx3\nx1\nab\ncd\nFigure 9.6: Patterns in 3-Dimensional Space\nAn iterative method for hierarchical clustering\nEvaluating all partitionings of mpatterns and then selecting the best would be\ncomputationally intractable. The following iterative method is based on a hi-\nerarchical clustering procedure called COBWEB [Fisher, 1987]. The procedure\ngrows a tree each node of which is labeled by a set of patterns. At the end\nof the process, the root node contains all of the patterns in \u039e. The successors\nof the root node will contain mutually exclusive and exhaustive subsets of \u039e.\nIn general, the successors of a node, \u03b7, are labeled by mutually exclusive and\nexhaustive subsets of the pattern set labelling node \u03b7. The tips of the tree will\ncontain singleton sets. The method uses Z values to place patterns at the vari-\nous nodes; sample statistics are used to update the Z values whenever a pattern\nis placed at a node. The algorithm is as follows:\na. We start with a tree whose root node contains all of the patterns in \u039e\nand a single empty successor node. We arrange that at all times dur-\ning the process every non-empty node in the tree has (besides any other\nsuccessors) exactly one empty successor.\nb. Select a pattern Xi in \u039e (if there are no more patterns to select, terminate).\nc. Set µ to the root node.\nd. For each of the successors of µ(including the empty successor!), calculate\nthe best host for Xi. A best host is determined by tentatively placing\nXi in one of the successors and calculating the resulting Z value for each'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 137, 'page_label': '138'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 129\none of these ways of accomodating Xi. The best host corresponds to the\nassignment with the highest Z value.\ne. If the best host is an empty node, \u03b7, we place Xi in \u03b7, generate an empty\nsuccessor node of \u03b7, generate an empty sibling node of \u03b7, and go to 2.\nf. If the best host is a non-empty, singleton (tip) node, \u03b7, we place Xi in \u03b7,\ncreate one successor node of \u03b7 containing the singleton pattern that was\nin \u03b7, create another successor node of \u03b7 containing Xi, create an empty\nsuccessor node of \u03b7, create empty successor nodes of the new non-empty\nsuccessors of \u03b7, and go to 2.\ng. If the best host is a non-empty, non-singleton node, \u03b7, we place Xi in \u03b7,\nset µ to \u03b7, and go to 4.\nThis process is rather sensitive to the order in which patterns are presented.\nTo make the \ufb01nal classi\ufb01cation tree less order dependent, the COBWEB proce-\ndure incorporates node merging and splitting.\nNode merging:\nIt may happen that two nodes having the same parent could be merged with\nan overall increase in the quality of the resulting classi\ufb01cation performed by the\nsuccessors of that parent. Rather than try all pairs to merge, a good heuristic\nis to attempt to merge the two best hosts. When such a merging improves the\nZ value, a new node containing the union of the patterns in the merged nodes\nreplaces the merged nodes, and the two nodes that were merged are installed\nas successors of the new node.\nNode splitting:\nA heuristic for node splitting is to consider replacing the best host among a\ngroup of siblings by that hosts successors. This operation is performed only if\nit increases the Z value of the classi\ufb01cation performed by a group of siblings.\nExample results from COBWEB\nWe mention two experiments with COBWEB. In the \ufb01rst, the program at-\ntempted to \ufb01nd two categories (we will call them Class 1 and Class 2) of United\nStates Senators based on their votes ( yes or no) on six issues. After the clus-\nters were established, the majority vote in each class was computed. These are\nshown in the table below.\nIssue Class 1 Class 2\nToxic Waste yes no\nBudget Cuts yes no\nSDI Reduction no yes\nContra Aid yes no\nLine-Item Veto yes no\nMX Production yes no'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 138, 'page_label': '139'}, page_content='130 CHAPTER 9. UNSUPERVISED LEARNING\nIn the second experiment, the program attempted to classify soybean dis-\neases based on various characteristics. COBWEB grouped the diseases in the\ntaxonomy shown in Fig. 9.7.\nN0\nsoybean\ndiseases\nN1\n  Diaporthe\nStem Canker\nN2\nCharcoal\n     Rot\nN3\nN31\nRhizoctonia\n       Rot\nN32\nPhytophthora\n       Rot\nFigure 9.7: Taxonomy Induced for Soybean Diseases\n9.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 139, 'page_label': '140'}, page_content='Chapter 10\nTemporal-Di\ufb00erence\nLearning\n10.1 Temporal Patterns and Prediction Prob-\nlems\nIn this chapter, we consider problems in which we wish to learn to predict the\nfuture value of some quantity, say z, from an n-dimensional input pattern, X.\nIn many of these problems, the patterns occur in temporal sequence, X1, X2,\n. . ., Xi, Xi+1, ... , Xm, and are generated by a dynamical process. The\ncomponents of Xi are features whose values are available at time, t = i. We\ndistinguish two kinds of prediction problems. In one, we desire to predict the\nvalue of z at time t = i+ 1 based on input Xi for every i. For example, we\nmight wish to predict some aspects of tomorrows weather based on a set of\nmeasurements made today. In the other kind of prediction problem, we desire\nto make a sequence of predictions about the value of z at some \ufb01xed time, say\nt= m+ 1, based on each of the Xi, i= 1,...,m . For example, we might wish\nto make a series of predictions about some aspect of the weather on next New\nYears Day, based on measurements taken every day before New Years. Sutton\n[Sutton, 1988] has called this latter problem, multi-step prediction, and that is\nthe problem we consider here. In multi-step prediction, we might expect that\nthe prediction accuracy should get better and better as i increases toward m.\n10.2 Supervised and Temporal-Di\ufb00erence Meth-\nods\nA training method that naturally suggests itself is to use the actual value of\nz at time m+ 1 (once it is known) in a supervised learning procedure using a\n131'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 140, 'page_label': '141'}, page_content='132 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nsequence of training patterns, {X1, X2, ... , Xi, Xi+1, ... , Xm}. That is, we\nseek to learn a function, f, such that f(Xi) is as close as possible to zfor each i.\nTypically, we would need a training set, \u039e, consisting of several such sequences.\nWe will show that a method that is better than supervised learning for some\nimportant problems is to base learning on the di\ufb00erence between f(Xi+1) and\nf(Xi) rather than on the di\ufb00erence between zand f(Xi). Such methods involve\nwhat is called temporal-di\ufb00erence (TD) learning.\nWe assume that our prediction, f(X), depends on a vector of modi\ufb01able\nweights, W. To make that dependence explicit, we write f(X,W). For su-\npervised learning, we consider procedures of the following type: For each Xi,\nthe prediction f(Xi,W) is computed and compared to z, and the learning rule\n(whatever it is) computes the change, (\u2206 Wi), to be made to W. Then, taking\ninto account the weight changes for each pattern in a sequence all at once after\nhaving made all of the predictions with the old weight vector, we change W as\nfollows:\nW \u2190\u2212W +\nm\u2211\ni=1\n(\u2206W)i\nWhenever we are attempting to minimize the squared error between z and\nf(Xi,W) by gradient descent, the weight-changing rule for each pattern is:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nwhere c is a learning rate parameter, fi is our prediction of z, f(Xi,W),\nat time t = i, and \u2202fi\n\u2202W is, by de\ufb01nition, the vector of partial derivatives\n( \u2202fi\n\u2202w1\n,..., \u2202fi\n\u2202wi\n,..., \u2202fi\n\u2202wn\n) in which the wi are the individual components of W.\n(The expression \u2202fi\n\u2202W is sometimes written \u2207Wfi.) The reader will recall that\nwe used an equivalent expression for (\u2206 W)i in deriving the backpropagation\nformulas used in training multi-layer neural networks.\nThe Widrow-Ho\ufb00 rule results when f(X,W) = X W. Then:\n(\u2206W)i = c(z\u2212fi)Xi\nAn interesting form for (\u2206 W)i can be developed if we note that\n(z\u2212fi) =\nm\u2211\nk=i\n(fk+1 \u2212fk)\nwhere we de\ufb01ne fm+1 = z. Substituting in our formula for (\u2206 W)i yields:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 141, 'page_label': '142'}, page_content='10.2. SUPERVISED AND TEMPORAL-DIFFERENCE METHODS 133\n= c\u2202fi\n\u2202W\nm\u2211\nk=i\n(fk+1 \u2212fk)\nIn this form, instead of using the di\ufb00erence between a prediction and the value\nof z, we use the di\ufb00erences between successive predictionsthus the phrase\ntemporal-di\ufb00erence (TD) learning.\nIn the case when f(X,W) = X W, the temporal di\ufb00erence form of the\nWidrow-Ho\ufb00 rule is:\n(\u2206W)i = cXi\nm\u2211\nk=i\n(fk+1 \u2212fk)\nOne reason for writing (\u2206 W)i in temporal-di\ufb00erence form is to permit an\ninteresting generalization as follows:\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nwhere 0 < \u03bb\u22641. Here, the \u03bb term gives exponentially decreasing weight to\ndi\ufb00erences later in time than t = i. When \u03bb = 1, we have the same rule with\nwhich we beganweighting all di\ufb00erences equally, but as\u03bb\u21920, we weight only\nthe (fi+1 \u2212fi) di\ufb00erence. With the \u03bb term, the method is called TD( \u03bb).\nIt is interesting to compare the two extreme cases:\nFor TD(0):\n(\u2206W)i = c(fi+1 \u2212fi) \u2202fi\n\u2202W\nFor TD(1):\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nBoth extremes can be handled by the same learning mechanism; only the error\nterm is di\ufb00erent. In TD(0), the error is the di\ufb00erence between successive predic-\ntions, and in TD(1), the error is the di\ufb00erence between the \ufb01nally revealed value\nof z and the prediction. Intermediate values of \u03bb take into account di\ufb00erently\nweighted di\ufb00erences between future pairs of successive predictions.\nOnly TD(1) can be considered a puresupervised learning procedure, sensitive\nto the \ufb01nal value ofzprovided by the teacher. For\u03bb< 1, we have various degrees\nof unsupervised learning, in which the prediction function strives to make each\nprediction more like successive ones (whatever they might be). We shall soon\nsee that these unsupervised procedures result in better learning than do the\nsupervised ones for an important class of problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 142, 'page_label': '143'}, page_content='134 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n10.3 Incremental Computation of the (\u2206W)i\nWe can rewrite our formula for (\u2206 W)i, namely\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nto allow a type of incremental computation. First we write the expression for\nthe weight change rule that takes into account all of the (\u2206 W)i:\nW \u2190\u2212W +\nm\u2211\ni=1\nc\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nInterchanging the order of the summations yields:\nW \u2190\u2212W +\nm\u2211\nk=1\nc\nk\u2211\ni=1\n\u03bb(k\u2212i)(fk+1 \u2212fk) \u2202fi\n\u2202W\n= W +\nm\u2211\nk=1\nc(fk+1 \u2212fk)\nk\u2211\ni=1\n\u03bb(k\u2212i) \u2202fi\n\u2202W\nInterchanging the indices k and i \ufb01nally yields:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nIf, as earlier, we want to use an expression of the formW \u2190\u2212W+\u2211m\ni=1(\u2206W)i,\nwe see that we can write:\n(\u2206W)i = c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nNow, if we let ei = \u2211i\nk=1 \u03bb(i\u2212k) \u2202fk\n\u2202W , we can develop a computationally e\ufb03cient\nrecurrence equation for ei+1 as follows:\nei+1 =\ni+1\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W\n= \u2202fi+1\n\u2202W +\ni\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 143, 'page_label': '144'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 135\n= \u2202fi+1\n\u2202W + \u03bbei\nRewriting (\u2206W)i in these terms, we obtain:\n(\u2206W)i = c(fi+1 \u2212fi)ei\nwhere:\ne1 = \u2202f1\n\u2202W\ne2 = \u2202f2\n\u2202W + \u03bbe1\netc.\nQuoting Sutton [Sutton, 1988, page 15] (about a di\ufb00erent equation, but the\nquote applies equally well to this one):\n... this equation can be computed incrementally, because each\n(\u2206W)i depends only on a pair of successive predictions and on the\n[weighted] sum of all past values for \u2202fi\n\u2202W . This saves substantially on\nmemory, because it is no longer necessary to individually remember\nall past values of \u2202fi\n\u2202W .\n10.4 An Experiment with TD Methods\nTD prediction methods [especially TD(0)] are well suited to situations in which\nthe patterns are generated by a dynamic process. In that case, sequences of\ntemporally presented patterns contain important information that is ignored\nby a conventional supervised method such as the Widrow-Ho\ufb00 rule. Sutton\n[Sutton, 1988, page 19] gives an interesting example involving a random walk,\nwhich we repeat here. In Fig. 10.1, sequences of vectors, X, are generated as\nfollows: We start with vector XD; the next vector in the sequence is equally\nlikely to be one of the adjacent vectors in the diagram. If the next vector is\nXC (or XE), the next one after that is equally likely to be one of the vectors\nadjacent to XC (or XE). When XB is in the sequence, it is equally likely that\nthe sequence terminates with z = 0 or that the next vector is XC. Similarly,\nwhen XF is in the sequence, it is equally likely that the sequence terminates\nwith z= 1 or that the next vector is XE. Thus the sequences are random, but\nthey always start with XD. Some sample sequences are shown in the \ufb01gure.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 144, 'page_label': '145'}, page_content='136 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\nz = 0 z = 1\nXB XC XD XE XF\nTypical Sequences:\nXDXCXDXEXF  1\nXDXCXBXCXDXEXDXEXF  1\nXDXEXDXCXB  0\nFigure 10.1: A Markov Process\nThis random walk is an example of a Markov process; transitions from state i\nto state j occur with probabilities that depend only on i and j.\nGiven a set of sequences generated by this process as a training set, we want\nto be able to predict the value of z for each X in a test sequence. We assume\nthat the learning system does not know the transition probabilities.\nFor his experiments with this process, Sutton used a linear predictor, that\nis f(X,W) = X W. The learning problem is to \ufb01nd a weight vector, W, that\nminimizes the mean-squared error betweenzand the predicted value of z. Given\nthe \ufb01ve di\ufb00erent values that X can take on, we have the following predictions:\nf(XB) = w1, f(XC) = w2, f(XD) = w3, f(XE) = w4, f(XF) = w5, where\nwi is the i-th component of the weight vector. (Note that the values of the\npredictions are not limited to 1 or 0even though z can only have one of\nthose valuesbecause we are minimizing mean-squared error.) After training,\nthese predictions will be compared with the optimal onesgiven the transition\nprobabilities.\nThe experimental setup was as follows: ten random sequences were generated\nusing the transition probabilities. Each of these sequences was presented in turn\nto a TD(\u03bb) method for various values of \u03bb. Weight vector increments, (\u2206 W)i,\nwere computed after each pattern presentation but no weight changes were\nmade until all ten sequences were presented. The weight vector increments were\nsummed after all ten sequences were presented, and this sum was used to change\nthe weight vector to be used for the next pass through the ten sequences. This\nprocess was repeated over and over (using the same training sequences) until\n(quoting Sutton) the procedure no longer produced any signi\ufb01cant changes in\nthe weight vector. For small c, the weight vector always converged in this way,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 145, 'page_label': '146'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 137\nand always to the same \ufb01nal value [for 100 di\ufb00erent training sets of ten random\nsequences], independent of its initial value. (Even though, for \ufb01xed, small c,\nthe weight vector always converged to the same vector, it might converge to a\nsomewhat di\ufb00erent vector for di\ufb00erent values of c.)\nAfter convergence, the predictions made by the \ufb01nal weight vector are com-\npared with the optimal predictions made using the transition probabilities.\nThese optimal predictions are simply p(z= 1|X). We can compute these proba-\nbilities to be 1/6, 1/3, 1/2, 2/3, and 5/6 forXB, XC, XD, XE, XF, respectively.\nThe root-mean-squared di\ufb00erences between the best learned predictions (over\nall c) and these optimal ones are plotted in Fig. 10.2 for seven di\ufb00erent values\nof \u03bb. (For each data point, the standard error is approximately \u03c3= 0.01.)\n0.10\n0.12\n0.14\n0.16\n0.18\n0.20\n0.0 0.1 0.3 0.5 0.7 0.9 1.0\nh\nError using\nbest c\nWidrow-Hoff\nTD(1)\nTD(0)\n(Adapted from Sutton, p. 20, 1988)\nFigure 10.2: Prediction Errors for TD( \u03bb)\nNotice that the Widrow-Ho\ufb00 procedure does not perform as well as other\nversions of TD(\u03bb) for \u03bb< 1! Quoting [Sutton, 1988, page 21]:\nThis result contradicts conventional wisdom. It is well known that,\nunder repeated presentations, the Widrow-Ho\ufb00 procedure minimizes\nthe RMS error between its predictions and the actual outcomes in\nthe training set ([Widrow & Stearns, 1985]). How can it be that this\noptimal method peformed worse than all the TD methods for \u03bb <\n1? The answer is that the Widrow-Ho\ufb00 procedure only minimizes\nerror on the training set ; it does not necessarily minimize error for\nfuture experience. [Later] we prove that in fact it is linear TD(0)\nthat converges to what can be considered the optimal estimates for'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 146, 'page_label': '147'}, page_content='138 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nmatching future experiencethose consistent with the maximum-\nlikelihood estimate of the underlying Markov process.\n10.5 Theoretical Results\nIt is possible to analyze the performance of the linear-prediction TD(\u03bb) methods\non Markov processes. We state some theorems here without proof.\nTheorem 10.1 (Sutton, page 24, 1988) For any absorbing Markov chain,\nand for any linearly independent set of observation vectors {Xi}for the non-\nterminal states, there exists an \u03b5> 0 such that for all positive c<\u03b5 and for any\ninitial weight vector, the predictions of linear TD(0) (with weight updates after\neach sequence) converge in expected value to the optimal (maximum likelihood)\npredictions of the true process.\nEven though the expected values of the predictions converge, the predictions\nthemselves do not converge but vary around their expected values depending on\ntheir most recent experience. Sutton conjectures that if c is made to approach\n0 as training progresses, the variance of the predictions will approach 0 also.\nDayan [Dayan, 1992] has extended the result of Theorem 9.1 to TD( \u03bb) for\narbitrary \u03bb between 0 and 1. (Also see [Dayan & Sejnowski, 1994].)\n10.6 Intra-Sequence Weight Updating\nOur standard weight updating rule for TD( \u03bb) methods is:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere the weight update occurs after an entire sequence is observed. To make\nthe method truly incremental (in analogy with weight updating rules for neural\nnets), it would be desirable to change the weight vector after every pattern\npresentation. The obvious extension is:\nWi+1 \u2190\u2212Wi + c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere fi+1 is computed before making the weight change; that is, fi+1 =\nf(Xi+1,Wi). But that would make fi = f(Xi,Wi\u22121), and such a rule would\nmake the prediction di\ufb00erence, namely ( fi+1 \u2212fi), sensitive both to changes in\nX and changes in W and could lead to instabilities. Instead, we modify the rule\nso that, for every pair of predictions, fi+1 = f(Xi+1,Wi) and fi = f(Xi,Wi).\nThis version of the rule has been used in practice with excellent results.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 147, 'page_label': '148'}, page_content='10.6. INTRA-SEQUENCE WEIGHT UPDATING 139\nFor TD(0) and linear predictors, the rule is:\nWi+1 = Wi + c(fi+1 \u2212fi)Xi\nThe rule is implemented as follows:\na. Initialize the weight vector, W, arbitrarily.\nb. For i= 1,...,m , do:\n(a) fi \u2190\u2212Xi W\n(We compute fi anew each time through rather than use the value\nof fi+1 the previous time through.)\n(b) fi+1 \u2190\u2212Xi+1 W\n(c) di+1 \u2190\u2212fi+1 \u2212fi\n(d) W \u2190\u2212W + c di+1Xi\n(If fi were computed again with this changed weight vector, its value\nwould be closer to fi+1 as desired.)\nThe linear TD(0) method can be regarded as a technique for training a\nvery simple network consisting of a single dot product unit (and no threshold\nor sigmoid function). TD methods can also be used in combination with back-\npropagation to train neural networks. For TD(0) we change the network weights\naccording to the expression:\nWi+1 = Wi + c(fi+1 \u2212fi) \u2202fi\n\u2202W\nThe only change that must be made to the standard backpropagation weight-\nchanging rule is that the di\ufb00erence term between the desired output and the\noutput of the unit in the \ufb01nal ( k-th) layer, namely (d\u2212f(k)), must be replaced\nby a di\ufb00erence term between successive outputs, ( fi+1 \u2212fi). This change has a\ndirect e\ufb00ect only on the expression for \u03b4(k) which becomes:\n\u03b4(k) = 2(f\u2032(k) \u2212f(k))f(k)(1 \u2212f(k))\nwhere f\u2032(k) and f(k) are two successive outputs of the network.\nThe weight changing rule for the i-th weight vector in the j-th layer of weights\nhas the same form as before, namely:\nW(j)\ni \u2190\u2212W(j)\ni + c\u03b4(j)\ni X(j\u22121)\nwhere the \u03b4(j)\ni are given recursively by:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nand w(j+1)\nil is the l-th component of the i-th weight vector in the (j+1)-th layer\nof weights. Of course, here also it is assumed that f\u2032(k) and f(k) are computed\nusing the same weights and then the weights are changed. In the next section\nwe shall see an interesting example of this application of TD learning.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 148, 'page_label': '149'}, page_content='140 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n10.7 An Example Application: TD-gammon\nA program called TD-gammon [Tesauro, 1992] learns to play backgammon by\ntraining a neural network via temporal-di\ufb00erence methods. The structure of\nthe neural net, and its coding is as shown in Fig. 10.3. The network is trained\nto minimize the error between actual payo\ufb00 and estimated payo\ufb00, where the\nactual payo\ufb00 is de\ufb01ned to be df = p1 + 2p2 \u2212p3 \u22122p4, and the pi are the actual\nprobabilities of the various outcomes as de\ufb01ned in the \ufb01gure.\n. . . p3 = pr(black wins)\np4 = pr(black gammons)\np1 = pr(white wins)\np2 = pr(white gammons)\nestimated payoff:\nd = p1 + 2p2 < p3 < 2p4\nno. of white\non cell 1\nno. on bar,\noff board,\nand who\nmoves\n198 inputs\n1\n2\n3\n# > 3\n. . .\nup to 40 hidden units\n2 x 24\ncells\n4 output units\nhidden and output units are sigmoids\nlearning rate:  c = 0.1; initial weights chosen\nrandomly between <0.5 and +0.5.\nestimated probabilities:\nFigure 10.3: The TD-gammon Network\nTD-gammon learned by using the network to select that move that results\nin the best predicted payo\ufb00. That is, at any stage of the game some \ufb01nite set of\nmoves is possible and these lead to the set, {X}, of new board positions. Each\nmember of this set is evaluated by the network, and the one with the largest'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 149, 'page_label': '150'}, page_content='10.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 141\npredicted payo\ufb00 is selected if it is whites move (and the smallest if it is blacks).\nThe move is made, and the network weights are adjusted to make the predicted\npayo\ufb00 from the original position closer to that of the resulting position.\nThe weight adjustment procedure combines temporal-di\ufb00erence (TD( \u03bb))\nlearning with backpropagation. If dt is the networks estimate of the payo\ufb00\nat time t (before a move is made), and dt+1 is the estimate at time t+ 1 (after\na move is made), the weight adjustment rule is:\n\u2206Wt = c(dt+1 \u2212dt)\nt\u2211\nk=1\n\u03bbt\u2212k \u2202dk\n\u2202W\nwhere Wt is a vector of all weights in the network at time t, and \u2202dk\n\u2202W is the\ngradient of dk in this weight space. (For a layered, feedforward network, such\nas that of TD-gammon, the weight changes for the weight vectors in each layer\ncan be expressed in the usual manner.)\nTo make the special cases clear, recall that for TD(0), the network would be\ntrained so that, for all t, its output, dt, for input Xt tended toward its expected\noutput, dt+1, for input Xt+1. For TD(1), the network would be trained so that,\nfor all t, its output, dt, for input Xt tended toward the expected \ufb01nal payo\ufb00,\ndf, given that input. The latter case is the same as the Widrow-Ho\ufb00 rule.\nAfter about 200,000 games the following results were obtained. TD-gammon\n(with 40 hidden units, \u03bb= 0.7, and c= 0.1) won 66.2% of 10,000 games against\nSUN Microsystems Gammontool and 55% of 10,000 games against a neural\nnetwork trained using expert moves. Commenting on a later version of TD-\ngammon, incorporating special features as inputs, Tesauro said: It appears to\nbe the strongest program ever seen by this author.\n10.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 150, 'page_label': '151'}, page_content='142 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 151, 'page_label': '152'}, page_content='Chapter 11\nDelayed-Reinforcement\nLearning\n11.1 The General Problem\nImagine a robot that exists in an environment in which it can sense and act.\nSuppose (as an extreme case) that it has no idea about the e\ufb00ects of its actions.\nThat is, it doesnt know how acting will change its sensory inputs. Along with\nits sensory inputs are rewards, which it occasionally receives. How should it\nchoose its actions so as to maximize its rewards over the long run? To maximize\nrewards, it will need to be able to predict how actions change inputs, and in\nparticular, how actions lead to rewards.\nWe formalize the problem in the following way: The robot exists in an\nenvironment consisting of a set,S, of states. We assume that the robots sensory\napparatus constructs an input vector, X, from the environment, which informs\nthe robot about which state the environment is in. For the moment, we will\nassume that the mapping from states to vectors is one-to-one, and, in fact, will\nuse the notation X to refer to the state of the environment as well as to the\ninput vector. When presented with an input vector, the robot decides which\naction from a set, A, of actions to perform. Performing the action produces an\ne\ufb00ect on the environmentmoving it to a new state. The new state results in\nthe robot perceiving a new input vector, and the cycle repeats. We assume a\ndiscrete time model; the input vector at time t = i is Xi, the action taken at\nthat time is ai, and the expected reward, ri, received at t = i depends on the\naction taken and on the state, that is ri = r(Xi,ai). The learners goal is to \ufb01nd\na policy, \u03c0(X), that maps input vectors to actions in such a way that maximizes\nrewards accumulated over time. This type of learning is called reinforcement\nlearning. The learner must \ufb01nd the policy by trial and error; it has no initial\nknowledge of the e\ufb00ects of its actions. The situation is as shown in Fig. 11.1.\n143'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 152, 'page_label': '153'}, page_content='144 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nXi\nri\nLearner\nEnvironment\n(reward)\n(state)\n(action)\nai\nFigure 11.1: Reinforcement Learning\n11.2 An Example\nA grid world, such as the one shown in Fig. 11.2 is often used to illustrate\nreinforcement learning. Imagine a robot initially in cell (2,3). The robot receives\ninput vector ( x1,x2) telling it what cell it is in; it is capable of four actions,\nn,e,s,w moving the robot one cell up, right, down, or left, respectively. It is\nrewarded one negative unit whenever it bumps into the wall or into the blocked\ncells. For example, if the input to the robot is (1,3), and the robot chooses\naction w, the next input to the robot is still (1,3) and it receives a reward of\n\u22121. If the robot lands in the cell marked G (for goal), it receives a reward of\n+10. Lets suppose that whenever the robot lands in the goal cell and gets its\nreward, it is immediately transported out to some random cell, and the quest\nfor reward continues.\nA policy for our robot is a speci\ufb01cation of what action to take for every one\nof its inputs, that is, for every one of the cells in the grid. For example, a com-\nponent of such a policy would be when in cell (3,1), move right. An optimal\npolicy is a policy that maximizes long-term reward. One way of displaying a\npolicy for our grid-world robot is by an arrow in each cell indicating the direc-\ntion the robot should move when in that cell. In Fig. 11.3, we show an optimal\npolicy displayed in this manner. In this chapter we will describe methods for\nlearning optimal policies based on reward values received by the learner.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 153, 'page_label': '154'}, page_content='11.3. TEMPORAL DISCOUNTING AND OPTIMAL POLICIES 145\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.2: A Grid World\n11.3 Temporal Discounting and Optimal Poli-\ncies\nIn delayed reinforcement learning, one often assumes that rewards in the distant\nfuture are not as valuable as are more immediate rewards. This preference can\nbe accomodated by a temporal discount factor, 0 \u2264\u03b3 <1. The present value of\na reward, ri, occuring i time units in the future, is taken to be \u03b3iri. Suppose\nwe have a policy \u03c0(X) that maps input vectors into actions, and let r\u03c0(X)\ni be\nthe reward that will be received on the i-th time step after one begins executing\npolicy \u03c0 starting in state X. Then the total reward accumulated over all time\nsteps by policy \u03c0 beginning in state X is:\nV\u03c0(X) =\n\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\nOne reason for using a temporal discount factor is so that the above sum will\nbe \ufb01nite. An optimal policy is one that maximizes V\u03c0(X) for all inputs, X.\nIn general, we want to consider the case in which the rewards,ri, are random\nvariables and in which the e\ufb00ects of actions on environmental states are random.\nIn Markovian environments, for example, the probability that action a in state\nXi will lead to state Xj is given by a transition probability p[Xj|Xi,a]. Then,\nwe will want to maximize expected future reward and would de\ufb01ne V\u03c0(X) as:\nV\u03c0(X) = E\n[\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\n]\nIn either case, we call V\u03c0(X) the value of policy \u03c0 for input X.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 154, 'page_label': '155'}, page_content='146 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.3: An Optimal Policy in the Grid World\nIf the action prescribed by \u03c0 taken in state X leads to state X\u2032 (randomly\naccording to the transition probabilities), then we can write V\u03c0(X) in terms of\nV\u03c0(X\u2032) as follows:\nV\u03c0(X) = r[X,\u03c0(X)] + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,\u03c0(X)]V\u03c0(X\u2032)\nwhere (in summary):\n\u03b3 = the discount factor,\nV\u03c0(X) = the value of state X under policy \u03c0,\nr[X,\u03c0(X)] = the expected immediate reward received when we execute the\naction prescribed by \u03c0 in state X, and\np[X\u2032|X,\u03c0(X)] = the probability that the environment transitions to state\nX\u2032when we execute the action prescribed by \u03c0 in state X.\nIn other words, the value of state X under policy \u03c0 is the expected value of\nthe immediate reward received when executing the action recommended by \u03c0\nplus the average value (under \u03c0) of all of the states accessible from X.\nFor an optimal policy, \u03c0\u2217(and no others!), we have the famous optimality\nequation:\nV\u03c0\u2217\n(X) = max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nThe theory of dynamic programming (DP) [Bellman, 1957, Ross, 1983] assures\nus that there is at least one optimal policy, \u03c0\u2217, that satis\ufb01es this equation. DP'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 155, 'page_label': '156'}, page_content='11.4. Q-LEARNING 147\nalso provides methods for calculating V\u03c0\u2217\n(X) and at least one \u03c0\u2217, assuming\nthat we know the average rewards and the transition probabilities. If we knew\nthe transition probabilities, the average rewards, and V\u03c0\u2217\n(X) for all X and a,\nthen it would be easy to implement an optimal policy. We would simply select\nthat a that maximizes r(X,a) + \u03b3\u2211\nX\u2032p[X\u2032|X,a]V\u03c0\u2217\n(X\u2032). That is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nBut, of course, we are assuming that we do not know these average rewards nor\nthe transition probabilities, so we have to \ufb01nd a method that e\ufb00ectively learns\nthem.\nIf we had a model of actions, that is, if we knew for every state, X, and\naction a, which state, X\u2032 resulted, then we could use a method called value\niteration to \ufb01nd an optimal policy. Value iteration works as follows: We begin\nby assigning, randomly, an estimated value V(X) to every state, X. On the i-th\nstep of the process, suppose we are at state Xi (that is, our input on the i-th\nstep is Xi), and that the estimated value of state Xi on the i-th step is Vi(Xi).\nWe then select that actionathat maximizes the estimated value of the predicted\nsubsequent state. Suppose this subsequent state having the highest estimated\nvalue is X\u2032\ni. Then we update the estimated value, Vi(Xi), of state Xi as follows:\nVi(X) = (1 \u2212ci) Vi\u22121(X) + ci\n[\nri + \u03b3Vi\u22121(X\u2032\ni)\n]\nif X = Xi,\n= Vi\u22121(X)\notherwise.\nWe see that this adjustment moves the value ofVi(Xi) an increment (depend-\ning on ci) closer to\n[\nri + \u03b3Vi(X\u2032\ni)\n]\n. Assuming that Vi(X\u2032\ni) is a good estimate for\nVi(X\u2032\ni), then this adjustment helps to make the two estimates more consistent.\nProviding that 0 < ci < 1 and that we visit each state in\ufb01nitely often, this\nprocess of value iteration will converge to the optimal values. Discuss synchronous dynamic\nprogramming, asynchronous\ndynamic programming, and policy\niteration.\n11.4 Q-Learning\nWatkins [Watkins, 1989] has proposed a technique that he calls incremental\ndynamic programming. Let a; \u03c0 stand for the policy that chooses action aonce,\nand thereafter chooses actions according to policy \u03c0. We de\ufb01ne:\nQ\u03c0(X,a) = Va;\u03c0(X)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 156, 'page_label': '157'}, page_content='148 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nThen the optimal value from state X is given by:\nV\u03c0\u2217\n(X) = max\na\nQ\u03c0\u2217\n(X,a)\nThis equation holds only for an optimal policy, \u03c0\u2217. The optimal policy is given\nby:\n\u03c0\u2217(X) = arg max\na\nQ\u03c0\u2217\n(X,a)\nNote that if an actionamakes Q\u03c0(X,a) larger than V\u03c0(X), then we can improve\n\u03c0 by changing it so that \u03c0(X) = a. Making such a change is the basis for a\npowerful learning rule that we shall describe shortly.\nSuppose action ain state X leads to state X\u2032. Then using the de\ufb01nitions of\nQ and V, it is easy to show that:\nQ\u03c0(X,a) = r(X,a) + \u03b3E[V\u03c0(X\u2032)]\nwhere r(X,a) is the average value of the immediate reward received when we\nexecute action a in state X. For an optimal policy (and no others), we have\nanother version of the optimality equation in terms of Q values:\nQ\u03c0\u2217\n(X,a) = max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nfor all actions, a, and states, X. Now, if we had the optimal Q values (for all\na and X), then we could implement an optimal policy simply by selecting that\naction that maximized r(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]\n.\nThat is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nWatkins proposal amounts to a TD(0) method of learning the Q values.\nWe quote (with minor notational changes) from [Watkins & Dayan, 1992, page\n281]:\nIn Q-Learning, the agents experience consists of a sequence of dis-\ntinct stages or episodes. In the i-th episode, the agent:\n observes its current state Xi,\n selects [using the method described below] and performs an\naction ai,\n observes the subsequent state X\u2032\ni,\n receives an immediate reward ri, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 157, 'page_label': '158'}, page_content='11.4. Q-LEARNING 149\n adjusts its Qi\u22121 values using a learning factor ci, according to:\nQi(X,a) = (1 \u2212ci)Qi\u22121(X,a) + ci[ri + \u03b3Vi\u22121(X\u2032\ni)]\nif X = Xi and a= ai,\n= Qi\u22121(X,a)\notherwise,\nwhere\nVi\u22121(X\u2032) = max\nb\n[Qi\u22121(X\u2032,b)]\nis the best the agent thinks it can do from state X\u2032. ... The\ninitial Qvalues, Q0(X,a), for all states and actions are assumed\ngiven.\nUsing the current Q values, Qi(X,a), the agent always selects that action\nthat maximizes Qi(X,a). Note that only the Q value corresponding to the\nstate just exited and the action just taken is adjusted. And that Q value is\nadjusted so that it is closer (by an amount determined by ci) to the sum of\nthe immediate reward plus the discounted maximum (over all actions) of the Q\nvalues of the state just entered. If we imagine the Qvalues to be predictions of\nultimate (in\ufb01nite horizon) total reward, then the learning procedure described\nabove is exactly a TD(0) method of learning how to predict these Q values.\nQ learning strengthens the usual TD methods, however, because TD (applied\nto reinforcement problems using value iteration) requires a one-step lookahead,\nusing a model of the e\ufb00ects of actions, whereas Q learning does not.\nA convenient notation (proposed by [Schwartz, 1993]) for representing the\nchange in Q value is:\nQ(X,a)\n\u03b2\n\u2190\u2212r+ \u03b3V(X\u2032)\nwhere Q(X,a) is the new Qvalue for input X and action a, r is the immediate\nreward when action a is taken in response to input X, V(X\u2032) is the maximum\n(over all actions) of the Qvalue of the state next reached when action ais taken\nfrom state X, and \u03b2 is the fraction of the way toward which the new Q value,\nQ(X,a), is adjusted to equal r+ \u03b3V(X\u2032).\nWatkins and Dayan [Watkins & Dayan, 1992] prove that, under certain con-\nditions, the Q values computed by this learning procedure converge to optimal\nones (that is, to ones on which an optimal policy can be based).\nWe de\ufb01ne ni(X,a) as the index (episode number) of thei-th time that action\na is tried in state X. Then, we have:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 158, 'page_label': '159'}, page_content='150 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nTheorem 11.1 (Watkins and Dayan) For Markov problems with states{X}\nand actions {a}, and given bounded rewards |rn|\u2264 R, learning rates 0 \u2264cn <1,\nand\n\u221e\u2211\ni=0\ncni(X,a) = \u221e,\n\u221e\u2211\ni=0\n[\ncni(X,a)\n]2\n<\u221e\nfor all X and a, then\nQn(X,a) \u2192Q\u2217\nn(X,a) as n \u2192\u221e, for all X and a, with probability 1, where\nQ\u2217\nn(X,a) corresponds to the Q values of an optimal policy.\nAgain, we quote from [Watkins & Dayan, 1992, page 281]:\nThe most important condition implicit in the convergence theorem\n... is that the sequence of episodes that forms the basis of learning\nmust include an in\ufb01nite number of episodes for each starting state\nand action. This may be considered a strong condition on the way\nstates and actions are selectedhowever, under the stochastic con-\nditions of the theorem, no method could be guaranteed to \ufb01nd an\noptimal policy under weaker conditions. Note, however, that the\nepisodes need not form a continuous sequencethat is the X\u2032of one\nepisode need not be the X of the next episode.\nThe relationships among Q learning, dynamic programming, and control\nare very well described in [Barto, Bradtke, & Singh, 1994]. Q learning is best\nthought of as a stochastic approximation method for calculating the Q values.\nAlthough the de\ufb01nition of the optimalQvalues for any state depends recursively\non expected values of the Q values for subsequent states (and on the expected\nvalues of rewards), no expected values are explicitly computed by the procedure.\nInstead, these values are approximated by iterative sampling using the actual\nstochastic mechanism that produces successor states.\n11.5 Discussion, Limitations, and Extensions of\nQ-Learning\n11.5.1 An Illustrative Example\nThe Q-learning procedure requires that we maintain a table of Q(X,a) values\nfor all state-action pairs. In the grid world that we described earlier, such a\ntable would not be excessively large. We might start with random entries in the\ntable; a portion of such an intial table might be as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 159, 'page_label': '160'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING151\nX a Q(X,a) r(X,a)\n(2,3) w 7 0\n(2,3) n 4 0\n(2,3) e 3 0\n(2,3) s 6 0\n(1,3) w 4 -1\n(1,3) n 5 0\n(1,3) e 2 0\n(1,3) s 4 0\nSuppose the robot is in cell (2,3). The maximumQvalue occurs fora= w, so the\nrobot moves west to cell (1,3)receiving no immediate reward. The maximum\nQ value in cell (1,3) is 5, and the learning mechanism attempts to make the\nvalue of Q((2,3),w) closer to the discounted value of 5 plus the immediate\nreward (which was 0 in this case). With a learning rate parameter c = 0 .5\nand \u03b3 = 0.9, the Q value of Q((2,3),w) is adjusted from 7 to 5.75. No other\nchanges are made to the table at this episode. The reader might try this learning\nprocedure on the grid world with a simple computer program. Notice that an\noptimal policy might not be discovered if some cells are not visited nor some\nactions not tried frequently enough.\nThe learning problem faced by the agent is to associate speci\ufb01c actions with\nspeci\ufb01c input patterns. Q learning gradually reinforces those actions that con-\ntribute to positive rewards by increasing the associated Q values. Typically, as\nin this example, rewards occur somewhat after the actions that lead to them\nhence the phrase delayed-reinforcement learning. One can imagine that better\nand better approximations to the optimal Q values gradually propagate back\nfrom states producing rewards toward all of the other states that the agent fre-\nquently visits. With random Qvalues to begin, the agents actions amount to a\nrandom walk through its space of states. Only when this random walk happens\nto stumble into rewarding states does Q learning begin to produce Q values\nthat are useful, and, even then, the Q values have to work their way outward\nfrom these rewarding states. The general problem of associating rewards with\nstate-action pairs is called the temporal credit assignment problemhow should\ncredit for a reward be apportioned to the actions leading up to it? Qlearning is,\nto date, the most successful technique for temporal credit assignment, although\na related method, called the bucket brigade algorithm , has been proposed by\n[Holland, 1986].\nLearning problems similar to that faced by the agent in our grid world have\nbeen thoroughly studied by Sutton who has proposed an architecture, called\nDYNA, for solving them [Sutton, 1990]. DYNA combines reinforcement learning\nwith planning. Sutton characterizes planning as learning in a simulated world\nthat models the world that the agent inhabits. The agents model of the world\nis obtained by Q learning in its actual world, and planning is accomplished by\nQ learning in its model of the world.\nWe should note that the learning problem faced by our grid-world robot'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 160, 'page_label': '161'}, page_content='152 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\ncould be modi\ufb01ed to have several places in the grid that give positive rewards.\nThis possibility presents an interesting way to generalize the classical notion of\na goal in AI planning systemseven in those that do no learning. Instead of\nrepresenting a goal as a condition to be achieved, we represent a goal struc-\nture as a set of rewards to be given for achieving various conditions. Then,\nthe generalized goal becomes maximizing discounted future reward instead of\nsimply achieving some particular condition. This generalization can be made to\nencompass so-called goals of maintenance and goals of avoidance. The exam-\nple presented above included avoiding bumping into the grid-world boundary.\nA goal of maintenance, of a particular state, could be expressed in terms of a\nreward that was earned whenever the agent was in that state and performed an\naction that transitioned back to that state in one step.\n11.5.2 Using Random Actions\nWhen the next pattern presentation in a sequence of patterns is the one caused\nby the agents own action in response to the last pattern, we have what is called\nan on-line learning method. In Watkins and Dayans terminology, in on-line\nlearning the episodes form a continous sequence. As already mentioned, the\nconvergence theorem for Q learning does not require on-line learning; indeed,\nspecial precautions must be taken to ensure that on-line learning meets the\nconditions of the theorem. If on-line learning discovers some good paths to\nrewards, the agent may \ufb01xate on these and never discover a policy that leads\nto a possibly greater long-term reward. In reinforcement learning phraseology,\nthis problem is referred to as the problem of exploitation (of already learned\nbehavior) versus exploration (of possibly better behavior).\nOne way to force exploration is to perform occasional random actions (in-\nstead of that single action prescribed by the current Q values). For example,\nin the grid-world problem, one could imagine selecting an action randomly ac-\ncording to a probability distribution over the actions ( n,e,s, and w). This\ndistribution, in turn, could depend on the Q values. For example, we might\n\ufb01rst \ufb01nd that action prescribed by the Q values and then choose that action\nwith probability 1/2, choose the two orthogonal actions with probability 3/16\neach, and choose the opposite action with probability 1/8. This policy might be\nmodi\ufb01ed by simulated annealing which would gradually increase the probabil-\nity of the action prescribed by theQvalues more and more as time goes on. This\nstrategy would favor exploration at the beginning of learning and exploitation\nlater.\nOther methods, also, have been proposed for dealing with exploration, in-\ncluding making unvisited states intrinsically rewarding and using an interval\nestimate, which is related to the uncertainty in the estimate of a states value\n[Kaelbling, 1993].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 161, 'page_label': '162'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING153\n11.5.3 Generalizing Over Inputs\nFor large problems it would be impractical to maintain a table like that used\nin our grid-world example. Various researchers have suggested mechanisms for\ncomputing Q values, given pattern inputs and actions. One method that sug-\ngests itself is to use a neural network. For example, consider the simple linear\nmachine shown in Fig. 11.4.\nX\n. . .\n. . .\nY\nY\nY\ntrainable weights\nY\nWi\nR dot product units\nQ(ai, X) = X . Wi\nQ(a1, X)\nQ(a2, X)\nQ(aR, X)\nFigure 11.4: A Net that Computes Q Values\nSuch a neural net could be used by an agent that has R actions to select\nfrom. The Qvalues (as a function of the input pattern X and the action ai) are\ncomputed as dot products of weight vectors (one for each action) and the input\nvector. Weight adjustments are made according to a TD(0) procedure to bring\nthe Qvalue for the action last selected closer to the sum of the immediate reward\n(if any) and the (discounted) maximum Q value for the next input pattern.\nIf the optimum Qvalues for the problem (whatever they might be) are more\ncomplex than those that can be computed by a linear machine, a layered neural\nnetwork might be used. Sigmoid units in the \ufb01nal layer would compute Qvalues\nin the range 0 to 1. The TD(0) method for updatingQvalues would then have to\nbe combined with a multi-layer weight-changing rule, such as backpropagation.\nNetworks of this sort are able to aggregate di\ufb00erent input vectors into regions\nfor which the same action should be performed. This kind of aggregation is an\nexample of what has been calledstructural credit assignment. Combining TD(\u03bb)\nand backpropagation is a method for dealing with both the temporal and the\nstructural credit assignment problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 162, 'page_label': '163'}, page_content='154 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nInteresting examples of delayed-reinforcement training of simulated and\nactual robots requiring structural credit assignment have been reported by\n[Lin, 1992, Mahadevan & Connell, 1992].\n11.5.4 Partially Observable States\nSo far, we have identi\ufb01ed the input vector, X, with the actual state of the envi-\nronment. When the input vector results from an agents perceptual apparatus\n(as we assume it does), there is no reason to suppose that it uniquely identi\ufb01es\nthe environmental state. Because of inevitable perceptual limitations, several\ndi\ufb00erent environmental states might give rise to the same input vector. This\nphenomenon has been referred to as perceptual aliasing. With perceptual alias-\ning, we can no longer guarantee that Qlearning will result in even useful action\npolicies, let alone optimal ones. Several researchers have attempted to deal with\nthis problem using a variety of methods including attempting to model hid-\nden states by using internal memory [Lin, 1993]. That is, if some aspect of\nthe environment cannot be sensed currently, perhaps it was sensed once and\ncan be remembered by the agent. When such is the case, we no longer have a\nMarkov problem; that is, the next X vector, given any action, may depend on\na sequence of previous ones rather than just the immediately preceding one. It\nmight be possible to reinstate a Markov framework (over the Xs) if X includes\nnot only current sensory precepts but information from the agents memory.\n11.5.5 Scaling Problems\nSeveral di\ufb03culties have so far prohibited wide application of reinforcement learn-\ning to large problems. (The TD-gammon program, mentioned in the last chap-\nter, is probably unique in terms of success on a high-dimensional problem.)\nWe have already touched on some di\ufb03culties; these and others are summarized\nbelow with references to attempts to overcome them.\na. Exploration versus exploitation.\n use random actions\n favor states not visited recently\n separate the learning phase from the use phase\n employ a teacher to guide exploration\nb. Slow time to convergence\n combine learning with prior knowledge; use estimates of Q values\n(rather than random values) initially\n use a hierarchy of actions; learn primitive actions \ufb01rst and freeze the\nuseful sequences into macros and then learn how to use the macros'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 163, 'page_label': '164'}, page_content='11.6. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 155\n employ a teacher; use graded lessonsstarting near the rewards\nand then backing away, and use examples of good behavior [Lin, 1992]\n use more e\ufb03cient computations; e.g. do several updates per episode\n[Moore & Atkeson, 1993]\nc. Large state spaces\n use hand-coded features\n use neural networks\n use nearest-neighbor methods [Moore, 1990]\nd. Temporal discounting problems. Using small \u03b3 can make the learner too\ngreedy for present rewards and indi\ufb00erent to the future; but using large \u03b3\nslows down learning.\n use a learning method based on average rewards [Schwartz, 1993]\ne. No transfer of learning . What is learned depends on the reward struc-\nture; if the rewards change, learning has to start over.\n Separate the learning into two parts: learn an action model which\npredicts how actions change states (and is constant over all prob-\nlems), and then learn the values of states by reinforcement learn-\ning for each di\ufb00erent set of rewards. Sometimes the reinforcement\nlearning part can be replaced by a planner that uses the action\nmodel to produce plans to achieve goals.\nAlso see other articles in the special issue on reinforcement learning:Machine\nLearning, 8, May, 1992.\n11.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 164, 'page_label': '165'}, page_content='156 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 165, 'page_label': '166'}, page_content='Chapter 12\nExplanation-Based\nLearning\n12.1 Deductive Learning\nIn the learning methods studied so far, typically the training set does not ex-\nhaust the version space. Using logical terminology, we could say that the classi-\n\ufb01ers output does not logically follow from the training set. In this sense, these\nmethods are inductive. In logic, a deductive system is one whose conclusions\nlogically follow from a set of input facts, if the system is sound. 1\nTo contrast inductive with deductive systems in a logical setting, suppose\nwe have a set of facts (the training set) that includes the following formulas:\n{Round(Obj1),Round(Obj2),Round(Obj3),Round(Obj4),\nBall(Obj1),Ball(Obj2),Ball(Obj3),Ball(Obj4)}\nA learning system that forms the conclusion ( \u2200x)[Ball(x) \u2283Round(x)] is in-\nductive. This conclusion may be useful (if there are no facts of the form\nBall(\u03c3) \u2227¬Round(\u03c3)), but it does not logically follow from the facts. On the\nother hand, if we had the facts Green(Obj5) and Green(Obj5) \u2283Round(Obj5),\nthen we could logically conclude Round(Obj5). Making this conclusion and sav-\ning it is an instance of deductive learninga topic we study in this chapter.\nSuppose that some logical proposition, \u03c6, logically follows from some set of\nfacts, \u2206. Under what circumstances might we say that the process of deducing\n\u03c6 from \u2206 results in our learning \u03c6? In a sense, we implicitly knew \u03c6 all along,\nsince it was inherent in knowing \u2206. Yet, \u03c6 might not be obvious given \u2206, and\n1Logical reasoning systems that are not sound, for example those using non-monotonic\nreasoning, themselves might produce inductive conclusions that do not logically follow from\nthe input facts.\n157'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 166, 'page_label': '167'}, page_content='158 CHAPTER 12. EXPLANATION-BASED LEARNING\nthe deduction process to establish \u03c6might have been arduous. Rather than have\nto deduce \u03c6 again, we might want to save it, perhaps along with its deduction,\nin case it is needed later. Shouldnt that process count as learning? Dietterich\n[Dietterich, 1990] has called this type of learning speed-up learning.\nStrictly speaking, speed-up learning does not result in a system being able to\nmake decisions that, in principle, could not have been made before the learning\ntook place. Speed-up learning simply makes it possible to make those decisions\nmore e\ufb03ciently. But, in practice, this type of learning might make possible\ncertain decisions that might otherwise have been infeasible.\nTo take an extreme case, a chess player can be said to learn chess even though\noptimal play is inherent in the rules of chess. On the surface, there seems to be\nno real di\ufb00erence between the experience-based hypotheses that a chess player\nmakes about what constitutes good play and the kind of learning we have been\nstudying so far.\nAs another example, suppose we are given some theorems about geometry\nand are asked to prove that the sum of the angles of a right triangle is 180\ndegrees. Let us further suppose that the proof we constructed did not depend\non the given triangle being a right triangle; in that case we can learn a more\ngeneral fact. The learning technique that we are going to study next is related\nto this example. It is called explanation-based learning (EBL) . EBL can be\nthought of as a process in which implicit knowledge is converted into explicit\nknowledge.\nIn EBL, we specialize parts of a domain theory to explain a particular ex-\nample, then we generalize the explanation to produce another element of the\ndomain theory that will be useful on similar examples. This process is illustrated\nin Fig. 12.1.\n12.2 Domain Theories\nTwo types of information were present in the inductive methods we have studied:\nthe information inherent in the training samples and the information about the\ndomain that is implied by the bias (for example, the hypothesis set from which\nwe choose functions). The learning methods are successful only if the hypothesis\nset is appropriate for the problem. Typically, the smaller the hypothesis set (that\nis, the more a priori information we have about the function being sought), the\nless dependent we are on information being supplied by a training set (that\nis, fewer samples). A priori information about a problem can be expressed in\nseveral ways. The methods we have studied so far restrict the hypotheses in a\nrather direct way. A less direct method involves making assertions in a logical\nlanguage about the property we are trying to learn. A set of such assertions is\nusually called a domain theory.\nSuppose, for example, that we wanted to classify people according to whether\nor not they were good credit risks. We might represent a person by a set of\nproperties (income, marital status, type of employment, etc.), assemble such'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 167, 'page_label': '168'}, page_content='12.3. AN EXAMPLE 159\nDomain\nTheory\nExample\n(X is P) Prove: X is P\nspecialize\nExplanation\n(Proof)\ngeneralize\nA New Domain Rule:\nThings "like" X are P\nY is like X\nComplex Proof\nProcess\nTrivial  Proof\nY is P\nFigure 12.1: The EBL Process\ndata about people who are known to be good and bad credit risks and train a\nclassi\ufb01er to make decisions. Or, we might go to a loan o\ufb03cer of a bank, ask him\nor her what sorts of things s/he looks for in making a decision about a loan,\nencode this knowledge into a set of rules for an expert system, and then use\nthe expert system to make decisions. The knowledge used by the loan o\ufb03cer\nmight have originated as a set of policies (the domain theory), but perhaps the\napplication of these policies were specialized and made more e\ufb03cient through\nexperience with the special cases of loans made in his or her district.\n12.3 An Example\nTo make our discussion more concrete, lets consider the following fanciful exam-\nple. We want to \ufb01nd a way to classify robots as robust or not. The attributes\nthat we use to represent a robot might include some that are relevant to this\ndecision and some that are not.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 168, 'page_label': '169'}, page_content='160 CHAPTER 12. EXPLANATION-BASED LEARNING\nSuppose we have a domain theory of logical sentences that taken together,\nhelp to de\ufb01ne whether or not a robot can be classi\ufb01ed as robust. (The same\ndomain theory may be useful for several other purposes also, but among other\nthings, it describes the concept robust.)\nIn this example, lets suppose that our domain theory includes the sentences:\nFixes(u,u) \u2283Robust(u)\n(An individual that can \ufb01x itself is robust.)\nSees(x,y) \u2227Habile(x) \u2283Fixes(x,y)\n(A habile individual that can see another entity can \ufb01x that entity.)\nRobot(w) \u2283Sees(w,w)\n(All robots can see themselves.)\nR2D2(x) \u2283Habile(x)\n(R2D2-class individuals are habile.)\nC3PO(x) \u2283Habile(x)\n(C3PO-class individuals are habile.)\n...\n(By convention, variables are assumed to be universally quanti\ufb01ed.) We could\nuse theorem-proving methods operating on this domain theory to conclude\nwhether certain robots are robust. These methods might be computationally\nquite expensive because extensive search may have to be performed to derive a\nconclusion. But after having found a proof for some particular robot, we might\nbe able to derive some new sentence whose use allows a much faster conclusion.\nWe next show how such a new rule might be derived in this example. Suppose\nwe are given a number of facts about Num5, such as:\nRobot(Num5)\nR2D2(Num5)\nAge(Num5,5)\nManufacturer(Num5,GR)\n...'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 169, 'page_label': '170'}, page_content='12.3. AN EXAMPLE 161\nFixes(u, u) => Robust(u)\nRobust(Num5)\nFixes(Num5, Num5)\nSees(Num5,Num5) Habile(Num5)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nRobot(w)\n     => Sees(w,w)\nRobot(Num5)\nR2D2(x)\n         => Habile(x)\nR2D2(Num5)\nFigure 12.2: A Proof Tree\nWe are also told that Robust(Num5) is true, but we nevertheless attempt to\n\ufb01nd a proof of that assertion using these facts about Num5 and the domain\ntheory. The facts about Num5 correspond to the features that we might use\nto represent Num5. In this example, not all of them are relevant to a decision\nabout Robust(Num5). The relevant ones are those used or needed in proving\nRobust(Num5) using the domain theory. The proof tree in Fig. 12.2 is one that\na typical theorem-proving system might produce.\nIn the language of EBL, this proof is an explanation for the fact\nRobust(Num5). We see from this explanation that the only facts about Num5\nthat were used were Robot(Num5) and R2D2(Num5). In fact, we could con-\nstruct the following rule from this explanation:\nRobot(Num5) \u2227R2D2(Num5) \u2283Robust(Num5)\nThe explanation has allowed us to prune some attributes about Num5 that are\nirrelevant (at least for decidingRobust(Num5)). This type of pruning is the \ufb01rst\nsense in which an explanation is used to generalize the classi\ufb01cation problem.\n([DeJong & Mooney, 1986] call this aspect of explanation-based learning feature\nelimination.) But the rule we extracted from the explanation applies only to\nNum5. There might be little value in learning that rule since it is so speci\ufb01c.\nCan it be generalized so that it can be applied to other individuals as well?'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 170, 'page_label': '171'}, page_content='162 CHAPTER 12. EXPLANATION-BASED LEARNING\nExamination of the proof shows that the same proof structure, using the\nsame sentences from the domain theory, could be used independently of whether\nwe are talking about Num5 or some other individual. We can generalize the\nproof by a process that replaces constants in the tip nodes of the proof tree\nwith variables and works upwardusing uni\ufb01cation to constrain the values of\nvariables as needed to obtain a proof.\nIn this example, we replace Robot(Num5) by Robot(r) and R2D2(Num5)\nby R2D2(s) and redo the proofusing the explanation proof as a template.\nNote that we use di\ufb00erent values for the two di\ufb00erent occurrences of Num5 at\nthe tip nodes. Doing so sometimes results in more general, but nevertheless\nvalid rules. We now apply the rules used in the proof in the forward direction,\nkeeping track of the substitutions imposed by the most general uni\ufb01ers used in\nthe proof. (Note that we always substitute terms that are already in the tree for\nvariables in rules.) This process results in the generalized proof tree shown in\nFig. 12.3. Note that the occurrence of Sees(r,r) as a node in the tree forces the\nuni\ufb01cation of xwith yin the domain rule, Sees(x,y)\u2227Habile(y) \u2283Fixes(x,y).\nThe substitutions are then applied to the variables in the tip nodes and the root\nnode to yield the general rule: Robot(r) \u2227R2D2(r) \u2283Robust(r).\nThis rule is the end result of EBL for this example. The process\nby which Num5 in this example was generalized to a variable is what\n[DeJong & Mooney, 1986] call identity elimination (the precise identity of Num5\nturned out to be irrelevant). (The generalization process described in this ex-\nample is based on that of [DeJong & Mooney, 1986] and di\ufb00ers from that of\n[Mitchell, et al., 1986]. It is also similar to that used in [Fikes, et al., 1972].)\nClearly, under certain assumptions, this general rule is more easily used to con-\nclude Robust about an individual than the original proof process was.\nIt is important to note that we could have derived the general rule from the\ndomain theory without using the example. (In the literature, doing so is called\nstatic analysis [Etzioni, 1991].) In fact, the example told us nothing new other\nthan what it told us about Num5. The sole role of the example in this instance\nof EBL was to provide a template for a proof to help guide the generalization\nprocess. Basing the generalization process on examples helps to insure that we\nlearn rules matched to the distribution of problems that occur.\nThere are a number of quali\ufb01cations and elaborations about EBL that need\nto be mentioned.\n12.4 Evaluable Predicates\nThe domain theory includes a number of predicates other than the one occuring\nin the formula we are trying to prove and other than those that might custom-\narily be used to describe an individual. One might note, for example, that if we\nused Habile(Num5) to describe Num5, the proof would have been shorter. Why\ndidnt we? The situation is analogous to that of using a data base augmented\nby logical rules. In the latter application, the formulas in the actual data base'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 171, 'page_label': '172'}, page_content='12.4. EVALUABLE PREDICATES 163\nRobust(r)\nFixes(r, r)\nSees(r,r) Habile(s)\nRobot(r) R2D2(s)\n{r/w}\n{s/x}\n{r/x, r/y, r/s}\n{r/u}\nRobot(w)\n     => Sees(w,w)\nR2D2(x)\n         => Habile(x)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nFixes(u, u) => Robust(u)\nbecomes R2D2(r) after\napplying {r/s}\nFigure 12.3: A Generalized Proof Tree\nare extensional, and those in the logical rules are intensional. This usage\nre\ufb02ects the fact that the predicates in the data base part are de\ufb01ned by their\nextensionwe explicitly list all the tuples sastisfying a relation. The logical\nrules serve to connect the data base predicates with higher level abstractions\nthat are described (if not de\ufb01ned) by the rules. We typically cannot look up\nthe truth values of formulas containing these intensional predicates; they have\nto be derived using the rules and the database.\nThe EBL process assumes something similar. The domain theory is useful\nfor connecting formulas that we might want to prove with those whose truth\nvalues can be looked up or otherwise evaluated. In the EBL literature, such\nformulas satisfy what is called the operationality criterion. Perhaps another\nanalogy might be to neural networks. The evaluable predicates correspond to\nthe components of the input pattern vector; the predicates in the domain theory\ncorrespond to the hidden units. Finding the new rule corresponds to \ufb01nding a\nsimpler expression for the formula to be proved in terms only of the evaluable\npredicates.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 172, 'page_label': '173'}, page_content='164 CHAPTER 12. EXPLANATION-BASED LEARNING\n12.5 More General Proofs\nExamining the domain theory for our example reveals that an alternative rule\nmight have been: Robot(u) \u2227C3PO(u) \u2283 Robust(u). Such a rule might\nhave resulted if we were given {C3PO(Num6),Robot(Num6),... }and proved\nRobust(Num6). After considering these two examples (Num5 and Num6),\nthe question arises, do we want to generalize the two rules to something like:\nRobot(u)\u2227[C3PO(u)\u2228R2D2(u)] \u2283Robust(u)? Doing so is an example of what\n[DeJong & Mooney, 1986] call structural generalization (via disjunctive augmen-\ntation ).\nAdding disjunctions for every alternative proof can soon become cumbersome\nand destroy any e\ufb03ciency advantage of EBL. In our example, the e\ufb03ciency\nmight be retrieved if there were another evaluable predicate, say,Bionic(u) such\nthat the domain theory also contained R2D2(x) \u2283Bionic(x) and C3PO(x) \u2283\nBionic(x). After seeing a number of similar examples, we might be willing to\ninduce the formula Bionic(u) \u2283[C3PO(u) \u2228R2D2(u)] in which case the rule\nwith the disjunction could be replaced with Robot(u) \u2227Bionic(u) \u2283Robust(u).\n12.6 Utility of EBL\nIt is well known in theorem proving that the complexity of \ufb01nding a proof\ndepends both on the number of formulas in the domain theory and on the depth\nof the shortest proof. Adding a new rule decreases the depth of the shortest\nproof but it also increases the number of formulas in the domain theory. In\nrealistic applications, the added rules will be relevant for some tasks and not for\nothers. Thus, it is unclear whether the overall utility of the new rules will turn\nout to be positive. EBL methods have been applied in several settings, usually\nwith positive utility. (See [Minton, 1990] for an analysis).\n12.7 Applications\nThere have been several applications of EBL methods. We mention two here,\nnamely the formation of macro-operators in automatic plan generation and\nlearning how to control search.\n12.7.1 Macro-Operators in Planning\nIn automatic planning systems, e\ufb03ciency can sometimes be enhanced by chain-\ning together a sequence of operators into macro-operators. We show an exam-\nple of a process for creating macro-operators based on techniques explored by\n[Fikes, et al., 1972].\nReferring to Fig. 12.4, consider the problem of \ufb01nding a plan for a robot in\nroom R1 to fetch a box, B1, by going to an adjacent room, R2, and pushing it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 173, 'page_label': '174'}, page_content='12.7. APPLICATIONS 165\nback to R1. The goal for the robot is INROOM (B1,R1), and the facts that\nare true in the initial state are listed in the \ufb01gure.\nR1 R2\nR3\nD1\nD2\nB1\nInitial State:\nINROOM(ROBOT, R1)\nINROOM(B1,R2)\nCONNECTS(D1,R1,R2)\nCONNECTS(D1,R2,R1)\n. . .\nFigure 12.4: Initial State of a Robot Problem\nWe will construct the plan from a set of STRIPS operators that include:\nGOTHRU(d,r1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2)\nDelete list: INROOM (ROBOT,r 1)\nAdd list: INROOM (ROBOT,r 2)\nPUSHTHRU(b,d,r 1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2),INROOM (b,r1)\nDelete list: INROOM (ROBOT,r 1),INROOM (b,r1)\nAdd list: INROOM (ROBOT,r 2),INROOM (b,r2)\nA backward-reasoning STRIPS system might produce the plan shown in\nFig. 12.5. We show there the main goal and the subgoals along a solution path.\n(The conditions in each subgoal that are true in the initial state are shown\nunderlined.) The preconditions for this plan, true in the initial state, are:\nINROOM (ROBOT,R 1)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 174, 'page_label': '175'}, page_content='166 CHAPTER 12. EXPLANATION-BASED LEARNING\nCONNECTS (D1,R1,R2)\nCONNECTS (D1,R2,R1)\nINROOM (B1,R2)\nSaving this speci\ufb01c plan, valid only for the speci\ufb01c constants it mentions, would\nnot be as useful as would be saving a more general one. We \ufb01rst generalize\nthese preconditions by substituting variables for constants. We then follow the\nstructure of the speci\ufb01c plan to produce the generalized plan shown in Fig. 12.6\nthat achievesINROOM (b1,r4). Note that the generalized plan does not require\npushing the box back to the place where the robot started. The preconditions\nfor the generalized plan are:\nINROOM (ROBOT,r 1)\nCONNECTS (d1,r1,r2)\nCONNECTS (d2,r2,r4)\nINROOM (b,r4)\nINROOM(B1,R1)\nPUSHTHRU(B1,d,r1,R1)\nINROOM(ROBOT, r1),\nCONNECTS(d, r1, R1),\nINROOM(B1, r1)\nINROOM(ROBOT, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2){R2/r1,\nD1/d}\nGOTHRU(d2, r3, R2)\nINROOM(ROBOT, r3),\nCONNECTS(d2, r3, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\n{R1/r3, D1/d2}\nINROOM(ROBOT, R1),\nCONNECTS(D1, R1, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\nR1 R2\nR3\nD1\nD2\nGOTHRU(D1,R1,R2)\nPUSHTHRU(B1,D1,R2,R1)\nB1\nPLAN:\nFigure 12.5: A Plan for the Robot Problem\nAnother related technique that chains together sequences of operators to\nform more general ones is the chunking mechanism in Soar [Laird, et al., 1986].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 175, 'page_label': '176'}, page_content='12.7. APPLICATIONS 167\nINROOM(b1,r4)\nPUSHTHRU(b1,d2,r2,r4)\nINROOM(ROBOT, r2),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nGOTHRU(d1, r1, r2)\nINROOM(ROBOT, r1),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nFigure 12.6: A Generalized Plan\n12.7.2 Learning Search Control Knowledge\nBesides their use in creating macro-operators, EBL methods can be used to\nimprove the e\ufb03ciency of planning in another way also. In his system called\nPRODIGY, Minton proposed using EBL to learn e\ufb00ective ways to control\nsearch [Minton, 1988]. PRODIGY is a STRIPS-like system that solves planning\nproblems in the blocks-world, in a simple mobile robot world, and in job-shop\nscheduling. PRODIGY has a domain theory involving both the domain of the\nproblem and a simple (meta) theory about planning. Its meta theory includes\nstatements about whether a control choice about a subgoal to work on, an oper-\nator to apply, etc. either succeedsor fails. After producing a plan, it analyzes its\nsuccessful and its unsuccessful choices and attempts to explain them in terms\nof its domain theory. Using an EBL-like process, it is able to produce useful\ncontrol rules such as:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 176, 'page_label': '177'}, page_content='168 CHAPTER 12. EXPLANATION-BASED LEARNING\nIF (AND (CURRENT \u2212NODE node)\n(CANDIDATE \u2212GOAL node (ON x y))\n(CANDIDATE \u2212GOAL node (ON y z)))\nTHEN (PREFER GOAL (ON y z) TO (ON x y))\nPRODIGY keeps statistics on how often these learned rules are used, their\nsavings (in time to \ufb01nd plans), and their cost of application. It saves only the\nrules whose utility, thus measured, is judged to be high. Minton [Minton, 1990]\nhas shown that there is an overall advantage of using these rules (as against not\nhaving any rules and as against hand-coded search control rules).\n12.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 177, 'page_label': '178'}, page_content='Bibliography\n[Acorn & Walden, 1992] Acorn, T., and Walden, S., SMART: Support Man-\nagement Automated Reasoning Technology for COMPAQ Customer Ser-\nvice, Proc. Fourth Annual Conf. on Innovative Applications of Arti\ufb01cial\nIntelligence, Menlo Park, CA: AAAI Press, 1992.\n[Aha, 1991] Aha, D., Kibler, D., and Albert, M., Instance-Based Learning\nAlgorithms, Machine Learning, 6, 37-66, 1991.\n[Anderson & Bower, 1973] Anderson, J. R., and Bower, G. H., Human Asso-\nciative Memory, Hillsdale, NJ: Erlbaum, 1973.\n[Anderson, 1958] Anderson, T. W., An Introduction to Multivariate Statistical\nAnalysis, New York: John Wiley, 1958.\n[Barto, Bradtke, & Singh, 1994] Barto, A., Bradtke, S., and Singh, S., Learn-\ning to Act Using Real-Time Dynamic Programming, to appear in Ar-\nti\ufb01cial Intelligence, 1994.\n[Baum & Haussler, 1989] Baum, E, and Haussler, D., What Size Net Gives\nValid Generalization? Neural Computation, 1, pp. 151-160, 1989.\n[Baum, 1994] Baum, E., When Are k-Nearest Neighbor and Backpropagation\nAccurate for Feasible-Sized Sets of Examples? in Hanson, S., Drastal,\nG., and Rivest, R., (eds.), Computational Learning Theory and Natural\nLearning Systems, Volume 1: Constraints and Prospects , pp. 415-442,\nCambridge, MA: MIT Press, 1994.\n[Bellman, 1957] Bellman, R. E., Dynamic Programming, Princeton: Princeton\nUniversity Press, 1957.\n[Blumer, et al., 1987] Blumer, A., et al., Occams Razor, Info. Process. Lett.,\nvol 24, pp. 377-80, 1987.\n[Blumer, et al., 1990] Blumer, A., et al ., Learnability and the Vapnik-\nChervonenkis Dimension, JACM, 1990.\n[Bollinger & Du\ufb03e, 1988] Bollinger, J., and Du\ufb03e, N., Computer Control of\nMachines and Processes, Reading, MA: Addison-Wesley, 1988.\n169'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 178, 'page_label': '179'}, page_content='170 BIBLIOGRAPHY\n[Brain, et al., 1962] Brain, A. E., et al. , Graphical Data Processing Research\nStudy and Experimental Investigation, Report No. 8 (pp. 9-13) and No.\n9 (pp. 3-10), Contract DA 36-039 SC-78343, SRI International, Menlo\nPark, CA, June 1962 and September 1962.\n[Breiman, et al., 1984] Breiman, L., Friedman, J., Olshen, R., and Stone, C.,\nClassi\ufb01cation and Regression Trees, Monterey, CA: Wadsworth, 1984.\n[Brent, 1990] Brent, R. P., Fast Training Algorithms for Multi-Layer Neural\nNets, Numerical Analysis Project Manuscript NA-90-03, Computer Sci-\nence Department, Stanford University, Stanford, CA 94305, March 1990.\n[Bryson & Ho 1969] Bryson, A., and Ho, Y.-C., Applied Optimal Control, New\nYork: Blaisdell.\n[Buchanan & Wilkins, 1993] Buchanan, B. and Wilkins, D., (eds.), Readings in\nKnowledge Acquisition and Learning, San Francisco: Morgan Kaufmann,\n1993.\n[Carbonell, 1983] Carbonell, J., Learning by Analogy, in Machine Learning:\nAn Arti\ufb01cial Intelligence Approach , Michalski, R., Carbonell, J., and\nMitchell, T., (eds.), San Francisco: Morgan Kaufmann, 1983.\n[Cheeseman, et al., 1988] Cheeseman, P., et al., AutoClass: A Bayesian Clas-\nsi\ufb01cation System, Proc. Fifth Intl. Workshop on Machine Learning ,\nMorgan Kaufmann, San Mateo, CA, 1988. Reprinted in Shavlik, J. and\nDietterich, T., Readings in Machine Learning , Morgan Kaufmann, San\nFrancisco, pp. 296-306, 1990.\n[Cover & Hart, 1967] Cover, T., and Hart, P., Nearest Neighbor Pattern Clas-\nsi\ufb01cation, IEEE Trans. on Information Theory , 13, 21-27, 1967.\n[Cover, 1965] Cover, T., Geometrical and Statistical Properties of Systems\nof Linear Inequalities with Applications in Pattern Recognition, IEEE\nTrans. Elec. Comp., EC-14, 326-334, June, 1965.\n[Dasarathy, 1991] Dasarathy, B. V., Nearest Neighbor Pattern Classi\ufb01cation\nTechniques, IEEE Computer Society Press, 1991.\n[Dayan & Sejnowski, 1994] Dayan, P., and Sejnowski, T.,  TD(\u03bb) Converges\nwith Probability 1, Machine Learning, 14, pp. 295-301, 1994.\n[Dayan, 1992] Dayan, P., The Convergence of TD( \u03bb) for General \u03bb, Machine\nLearning, 8, 341-362, 1992.\n[DeJong & Mooney, 1986] DeJong, G., and Mooney, R., Explanation-Based\nLearning: An Alternative View, Machine Learning, 1:145-176, 1986.\nReprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 452-467.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 179, 'page_label': '180'}, page_content='BIBLIOGRAPHY 171\n[Dietterich & Bakiri, 1991] Dietterich, T. G., and Bakiri, G., Error-Correcting\nOutput Codes: A General Method for Improving Multiclass Induc-\ntive Learning Programs, Proc. Ninth Nat. Conf. on A.I. , pp. 572-577,\nAAAI-91, MIT Press, 1991.\n[Dietterich, et al., 1990] Dietterich, T., Hild, H., and Bakiri, G., A Compara-\ntive Study of ID3 and Backpropagation for English Text-to-Speech Map-\nping, Proc. Seventh Intl. Conf. Mach. Learning, Porter, B. and Mooney,\nR. (eds.), pp. 24-31, San Francisco: Morgan Kaufmann, 1990.\n[Dietterich, 1990] Dietterich, T., Machine Learning, Annu. Rev. Comput.\nSci., 4:255-306, Palo Alto: Annual Reviews Inc., 1990.\n[Duda & Fossum, 1966] Duda, R. O., and Fossum, H., Pattern Classi\ufb01cation\nby Iteratively Determined Linear and Piecewise Linear Discriminant\nFunctions, IEEE Trans. on Elect. Computers , vol. EC-15, pp. 220-232,\nApril, 1966.\n[Duda & Hart, 1973] Duda, R. O., and Hart, P.E., Pattern Classi\ufb01cation and\nScene Analysis, New York: Wiley, 1973.\n[Duda, 1966] Duda, R. O., Training a Linear Machine on Mislabeled Patterns,\nSRI Tech. Report prepared for ONR under Contract 3438(00), SRI In-\nternational, Menlo Park, CA, April 1966.\n[Efron, 1982] Efron, B., The Jackknife, the Bootstrap and Other Resampling\nPlans, Philadelphia: SIAM, 1982.\n[Ehrenfeucht, et al., 1988] Ehrenfeucht, A., et al., A General Lower Bound on\nthe Number of Examples Needed for Learning, in Proc. 1988 Workshop\non Computational Learning Theory, pp. 110-120, San Francisco: Morgan\nKaufmann, 1988.\n[Etzioni, 1991] Etzioni, O., STATIC: A Problem-Space Compiler for\nPRODIGY, Proc. of Ninth National Conf. on Arti\ufb01cial Intelligence ,\npp. 533-540, Menlo Park: AAAI Press, 1991.\n[Etzioni, 1993] Etzioni, O., A Structural Theory of Explanation-Based Learn-\ning, Arti\ufb01cial Intelligence, 60:1, pp. 93-139, March, 1993.\n[Evans & Fisher, 1992] Evans, B., and Fisher, D., Process Delay Analyses Using\nDecision-Tree Induction, Tech. Report CS92-06, Department of Com-\nputer Science, Vanderbilt University, TN, 1992.\n[Fahlman & Lebiere, 1990] Fahlman, S., and Lebiere, C., The Cascade-\nCorrelation Learning Architecture, in Touretzky, D., (ed.), Advances in\nNeural Information Processing Systems, 2 , pp. 524-532, San Francisco:\nMorgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 180, 'page_label': '181'}, page_content='172 BIBLIOGRAPHY\n[Fayyad, et al., 1993] Fayyad, U. M., Weir, N., and Djorgovski, S., SKICAT:\nA Machine Learning System for Automated Cataloging of Large Scale\nSky Surveys, in Proc. Tenth Intl. Conf. on Machine Learning , pp. 112-\n119, San Francisco: Morgan Kaufmann, 1993. (For a longer version of\nthis paper see: Fayyad, U. Djorgovski, G., and Weir, N., Automating\nthe Analysis and Cataloging of Sky Surveys, in Fayyad, U., et al.(eds.),\nAdvances in Knowledge Discovery and Data Mining , Chapter 19, pp.\n471\ufb00., Cambridge: The MIT Press, March, 1996.)\n[Feigenbaum, 1961] Feigenbaum, E. A., The Simulation of Verbal Learning Be-\nhavior, Proceedings of the Western Joint Computer Conference, 19:121-\n132, 1961.\n[Fikes, et al., 1972] Fikes, R., Hart, P., and Nilsson, N., Learning and Execut-\ning Generalized Robot Plans, Arti\ufb01cial Intelligence, pp 251-288, 1972.\nReprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 468-486.\n[Fisher, 1987] Fisher, D., Knowledge Acquisition via Incremental Conceptual\nClustering, Machine Learning, 2:139-172, 1987. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 267283.\n[Friedman, et al., 1977] Friedman, J. H., Bentley, J. L., and Finkel, R. A., An\nAlgorithm for Finding Best Matches in Logarithmic Expected Time,\nACM Trans. on Math. Software , 3(3):209-226, September 1977.\n[Fu, 1994] Fu, L., Neural Networks in Arti\ufb01cial Intelligence , New York:\nMcGraw-Hill, 1994.\n[Gallant, 1986] Gallant, S. I., Optimal Linear Discriminants, in Eighth Inter-\nnational Conf. on Pattern Recognition , pp. 849-852, New York: IEEE,\n1986.\n[Genesereth & Nilsson, 1987] Genesereth, M., and Nilsson, N., Logical Founda-\ntions of Arti\ufb01cial Intelligence , San Francisco: Morgan Kaufmann, 1987.\n[Gluck & Rumelhart, 1989] Gluck, M. and Rumelhart, D., Neuroscience and\nConnectionist Theory, The Developments in Connectionist Theory, Hills-\ndale, NJ: Erlbaum Associates, 1989.\n[Hammerstrom, 1993] Hammerstrom, D., Neural Networks at Work, IEEE\nSpectrum, pp. 26-32, June 1993.\n[Haussler, 1988] Haussler, D., Quantifying Inductive Bias: AI Learning Al-\ngorithms and Valiants Learning Framework, Arti\ufb01cial Intelligence ,\n36:177-221, 1988. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96-107.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 181, 'page_label': '182'}, page_content='BIBLIOGRAPHY 173\n[Haussler, 1990] Haussler, D., Probably Approximately Correct Learning,\nProc. Eighth Nat. Conf. on AI , pp. 1101-1108. Cambridge, MA: MIT\nPress, 1990.\n[Hebb, 1949] Hebb, D. O., The Organization of Behaviour , New York: John\nWiley, 1949.\n[Hertz, Krogh, & Palmer, 1991] Hertz, J., Krogh, A, and Palmer, R., Introduc-\ntion to the Theory of Neural Computation , Lecture Notes, vol. 1, Santa\nFe Inst. Studies in the Sciences of Complexity, New York: Addison-\nWesley, 1991.\n[Hirsh, 1994] Hirsh, H., Generalizing Version Spaces, Machine Learning, 17,\n5-45, 1994.\n[Holland, 1975] Holland, J., Adaptation in Natural and Arti\ufb01cial Systems , Ann\nArbor: The University of Michigan Press, 1975. (Second edition printed\nin 1992 by MIT Press, Cambridge, MA.)\n[Holland, 1986] Holland, J. H., Escaping Brittleness; The Possibilities of\nGeneral-Purpose Learning Algorithms Applied to Parallel Rule-Based\nSystems. In Michalski, R., Carbonell, J., and Mitchell, T. (eds.) , Ma-\nchine Learning: An Arti\ufb01cial Intelligence Approach, Volume 2 , chapter\n20, San Francisco: Morgan Kaufmann, 1986.\n[Hunt, Marin, & Stone, 1966] Hunt, E., Marin, J., and Stone, P., Experiments\nin Induction, New York: Academic Press, 1966.\n[Jabbour, K., et al., 1987] Jabbour, K., et al. , ALFA: Automated Load Fore-\ncasting Assistant, Proc. of the IEEE Pwer Engineering Society Summer\nMeeting, San Francisco, CA, 1987.\n[John, 1995] John, G., Robust Linear Discriminant Trees, Proc. of the Conf.\non Arti\ufb01cial Intelligence and Statistics , Ft. Lauderdale, FL, January,\n1995.\n[Kaelbling, 1993] Kaelbling, L. P., Learning in Embedded Systems, Cambridge,\nMA: MIT Press, 1993.\n[Kohavi, 1994] Kohavi, R., Bottom-Up Induction of Oblivious Read-Once De-\ncision Graphs, Proc. of European Conference on Machine Learning\n(ECML-94), 1994.\n[Kolodner, 1993] Kolodner, J., Case-Based Reasoning, San Francisco: Morgan\nKaufmann, 1993.\n[Koza, 1992] Koza, J., Genetic Programming: On the Programming of Comput-\ners by Means of Natural Selection , Cambridge, MA: MIT Press, 1992.\n[Koza, 1994] Koza, J., Genetic Programming II: Automatic Discovery of\nReusable Programs, Cambridge, MA: MIT Press, 1994.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 182, 'page_label': '183'}, page_content='174 BIBLIOGRAPHY\n[Laird, et al., 1986] Laird, J., Rosenbloom, P., and Newell, A., Chunking in\nSoar: The Anatomy of a General Learning Mechanism, Machine Learn-\ning, 1, pp. 11-46, 1986. Reprinted in Buchanan, B. and Wilkins, D.,\n(eds.), Readings in Knowledge Acquisition and Learning , pp. 518-535,\nMorgan Kaufmann, San Francisco, CA, 1993.\n[Langley, 1992] Langley, P., Areas of Application for Machine Learning,Proc.\nof Fifth Intl. Symp. on Knowledge Engineering , Sevilla, 1992.\n[Langley, 1996] Langley, P., Elements of Machine Learning , San Francisco:\nMorgan Kaufmann, 1996.\n[Lavra\u02c7 c & D\u02c7 zeroski, 1994] Lavra\u02c7 c, N., and D\u02c7 zeroski, S.,Inductive Logic Pro-\ngramming, Chichester, England: Ellis Horwood, 1994.\n[Lin, 1992] Lin, L., Self-Improving Reactive Agents Based on Reinforcement\nLearning, Planning, and Teaching, Machine Learning, 8, 293-321, 1992.\n[Lin, 1993] Lin, L., Scaling Up Reinforcement Learning for Robot Control,\nProc. Tenth Intl. Conf. on Machine Learning, pp. 182-189, San Francisco:\nMorgan Kaufmann, 1993.\n[Littlestone, 1988] Littlestone, N., Learning Quickly When Irrelevant At-\ntributes Abound: A New Linear-Threshold Algorithm, Machine Learn-\ning 2: 285-318, 1988.\n[Maass & Tur´ an, 1994] Maass, W., and Tur´ an, G., How Fast Can a Thresh-\nold Gate Learn?, in Hanson, S., Drastal, G., and Rivest, R., (eds.),\nComputational Learning Theory and Natural Learning Systems, Volume\n1: Constraints and Prospects , pp. 381-414, Cambridge, MA: MIT Press,\n1994.\n[Mahadevan & Connell, 1992] Mahadevan, S., and Connell, J., Automatic\nProgramming of Behavior-Based Robots Using Reinforcement Learn-\ning, Arti\ufb01cial Intelligence, 55, pp. 311-365, 1992.\n[Marchand & Golea, 1993] Marchand, M., and Golea, M., On Learning Sim-\nple Neural Concepts: From Halfspace Intersections to Neural Decision\nLists, Network, 4:67-85, 1993.\n[McCulloch & Pitts, 1943] McCulloch, W. S., and Pitts, W. H., A Logical Cal-\nculus of the Ideas Immanent in Nervous Activity, Bulletin of Mathe-\nmatical Biophysics, Vol. 5, pp. 115-133, Chicago: University of Chicago\nPress, 1943.\n[Michie, 1992] Michie, D., Some Directions in Machine Intelligence, unpub-\nlished manuscript, The Turing Institute, Glasgow, Scotland, 1992.\n[Minton, 1988] Minton, S., Learning Search Control Knowledge: An\nExplanation-Based Approach , Kluwer Academic Publishers, Boston,\nMA, 1988.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 183, 'page_label': '184'}, page_content='BIBLIOGRAPHY 175\n[Minton, 1990] Minton, S., Quantitative Results Concerning the Utility of\nExplanation-Based Learning, Arti\ufb01cial Intelligence , 42, pp. 363-392,\n1990. Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine\nLearning, San Francisco: Morgan Kaufmann, 1990, pp. 573-587.\n[Mitchell, et al., 1986] Mitchell, T., et al., Explanation-Based Generalization:\nA Unifying View, Machine Learning, 1:1, 1986. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 435-451.\n[Mitchell, 1982] Mitchell, T., Generalization as Search, Arti\ufb01cial Intelligence,\n18:203-226, 1982. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96107.\n[Moore & Atkeson, 1993] Moore, A., and Atkeson, C., Prioritized Sweeping:\nReinforcement Learning with Less Data and Less Time,Machine Learn-\ning, 13, pp. 103-130, 1993.\n[Moore, et al., 1994] Moore, A. W., Hill, D. J., and Johnson, M. P., An Em-\npirical Investigation of Brute Force to Choose Features, Smoothers, and\nFunction Approximators, in Hanson, S., Judd, S., and Petsche, T.,\n(eds.), Computational Learning Theory and Natural Learning Systems ,\nVol. 3, Cambridge: MIT Press, 1994.\n[Moore, 1990] Moore, A., E\ufb03cient Memory-based Learning for Robot Control ,\nPhD. Thesis; Technical Report No. 209, Computer Laboratory, Univer-\nsity of Cambridge, October, 1990.\n[Moore, 1992] Moore, A., Fast, Robust Adaptive Control by Learning Only\nForward Models, in Moody, J., Hanson, S., and Lippman, R., (eds.),\nAdvances in Neural Information Processing Systems 4 , San Francisco:\nMorgan Kaufmann, 1992.\n[Mueller & Page, 1988] Mueller, R. and Page, R., Symbolic Computing with\nLisp and Prolog, New York: John Wiley & Sons, 1988.\n[Muggleton, 1991] Muggleton, S., Inductive Logic Programming, New Gen-\neration Computing, 8, pp. 295-318, 1991.\n[Muggleton, 1992] Muggleton, S., Inductive Logic Programming, London: Aca-\ndemic Press, 1992.\n[Muroga, 1971] Muroga, S., Threshold Logic and its Applications , New York:\nWiley, 1971.\n[Natarjan, 1991] Natarajan, B., Machine Learning: A Theoretical Approach ,\nSan Francisco: Morgan Kaufmann, 1991.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 184, 'page_label': '185'}, page_content='176 BIBLIOGRAPHY\n[Nilsson, 1965] Nilsson, N. J., Theoretical and Experimental Investigations in\nTrainable Pattern-Classifying Systems, Tech. Report No. RADC-TR-\n65-257, Final Report on Contract AF30(602)-3448, Rome Air Develop-\nment Center (Now Rome Laboratories), Gri\ufb03ss Air Force Base, New\nYork, September, 1965.\n[Nilsson, 1990] Nilsson, N. J., The Mathematical Foundations of Learning Ma-\nchines, San Francisco: Morgan Kaufmann, 1990. (This book is a reprint\nof Learning Machines: Foundations of Trainable Pattern-Classifying\nSystems, New York: McGraw-Hill, 1965.)\n[Oliver, Dowe, & Wallace, 1992] Oliver, J., Dowe, D., and Wallace, C., Infer-\nring Decision Graphs using the Minimum Message Length Principle,\nProc. 1992 Australian Arti\ufb01cial Intelligence Conference , 1992.\n[Pagallo & Haussler, 1990] Pagallo, G. and Haussler, D., Boolean Feature Dis-\ncovery in Empirical Learning, Machine Learning, vol.5, no.1, pp. 71-99,\nMarch 1990.\n[Pazzani & Kibler, 1992] Pazzani, M., and Kibler, D., The Utility of Knowl-\nedge in Inductive Learning, Machine Learning, 9, 57-94, 1992.\n[Peterson, 1961] Peterson, W., Error Correcting Codes, New York: John Wiley,\n1961.\n[Pomerleau, 1991] Pomerleau, D., Rapidly Adapting Arti\ufb01cial Neural Net-\nworks for Autonomous Navigation, in Lippmann, P., et al. (eds.), Ad-\nvances in Neural Information Processing Systems, 3 , pp. 429-435, San\nFrancisco: Morgan Kaufmann, 1991.\n[Pomerleau, 1993] Pomerleau, D, Neural Network Perception for Mobile Robot\nGuidance, Boston: Kluwer Academic Publishers, 1993.\n[Quinlan & Rivest, 1989] Quinlan, J. Ross, and Rivest, Ron, Inferring Deci-\nsion Trees Using the Minimum Description Length Principle, Informa-\ntion and Computation , 80:227248, March, 1989.\n[Quinlan, 1986] Quinlan, J. Ross, Induction of Decision Trees, Machine\nLearning, 1:81106, 1986. Reprinted in Shavlik, J. and Dietterich, T.,\nReadings in Machine Learning, San Francisco: Morgan Kaufmann, 1990,\npp. 5769.\n[Quinlan, 1987] Quinlan, J. R., Generating Production Rules from Decision\nTrees, In IJCAI-87: Proceedings of the Tenth Intl. Joint Conf. on Ar-\nti\ufb01cial Intelligence, pp. 304-7, San Francisco: Morgan-Kaufmann, 1987.\n[Quinlan, 1990] Quinlan, J. R., Learning Logical De\ufb01nitions from Relations,\nMachine Learning, 5, 239-266, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 185, 'page_label': '186'}, page_content='BIBLIOGRAPHY 177\n[Quinlan, 1993] Quinlan, J. Ross, C4.5: Programs for Machine Learning , San\nFrancisco: Morgan Kaufmann, 1993.\n[Quinlan, 1994] Quinlan, J. R., Comparing Connectionist and Symbolic Learn-\ning Methods, in Hanson, S., Drastal, G., and Rivest, R., (eds.), Com-\nputational Learning Theory and Natural Learning Systems, Volume 1:\nConstraints and Prospects , pp. 445-456,, Cambridge, MA: MIT Press,\n1994.\n[Ridgway, 1962] Ridgway, W. C., An Adaptive Logic System with Generalizing\nProperties, PhD thesis, Tech. Rep. 1556-1, Stanford Electronics Labs.,\nStanford, CA, April 1962.\n[Rissanen, 1978] Rissanen, J., Modeling by Shortest Data Description, Auto-\nmatica, 14:465-471, 1978.\n[Rivest, 1987] Rivest, R. L., Learning Decision Lists, Machine Learning, 2,\n229-246, 1987.\n[Rosenblatt, 1958] Rosenblatt, F., Principles of Neurodynamics , Washington:\nSpartan Books, 1961.\n[Ross, 1983] Ross, S., Introduction to Stochastic Dynamic Programming , New\nYork: Academic Press, 1983.\n[Rumelhart, Hinton, & Williams, 1986] Rumelhart, D. E., Hinton, G. E., and\nWilliams, R. J., Learning Internal Representations by Error Propa-\ngation, In Rumelhart, D. E., and McClelland, J. L., (eds.) Parallel\nDistributed Processing, Vol 1, 318362, 1986.\n[Russell & Norvig 1995] Russell, S., and Norvig, P., Arti\ufb01cial Intelligence: A\nModern Approach, Englewood Cli\ufb00s, NJ: Prentice Hall, 1995.\n[Samuel, 1959] Samuel, A., Some Studies in Machine Learning Using the Game\nof Checkers,IBM Journal of Research and Development, 3:211-229, July\n1959.\n[Schwartz, 1993] Schwartz, A., A Reinforcement Learning Method for Max-\nimizing Undiscounted Rewards, Proc. Tenth Intl. Conf. on Machine\nLearning, pp. 298-305, San Francisco: Morgan Kaufmann, 1993.\n[Sejnowski, Koch, & Churchland, 1988] Sejnowski, T., Koch, C., and Church-\nland, P., Computational Neuroscience, Science, 241: 1299-1306, 1988.\n[Shavlik, Mooney, & Towell, 1991] Shavlik, J., Mooney, R., and Towell, G.,\nSymbolic and Neural Learning Algorithms: An Experimental Compar-\nison, Machine Learning, 6, pp. 111-143, 1991.\n[Shavlik & Dietterich, 1990] Shavlik, J. and Dietterich, T., Readings in Ma-\nchine Learning, San Francisco: Morgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 186, 'page_label': '187'}, page_content='178 BIBLIOGRAPHY\n[Sutton & Barto, 1987] Sutton, R. S., and Barto, A. G., A Temporal-\nDi\ufb00erence Model of Classical Conditioning, in Proceedings of the Ninth\nAnnual Conference of the Cognitive Science Society , Hillsdale, NJ: Erl-\nbaum, 1987.\n[Sutton, 1988] Sutton, R. S., Learning to Predict by the Methods of Temporal\nDi\ufb00erences, Machine Learning 3: 9-44, 1988.\n[Sutton, 1990] Sutton, R., Integrated Architectures for Learning, Planning,\nand Reacting Based on Approximating Dynamic Programming,Proc. of\nthe Seventh Intl. Conf. on Machine Learning, pp. 216-224, San Francisco:\nMorgan Kaufmann, 1990.\n[Taylor, Michie, & Spiegalhalter, 1994] Taylor, C., Michie, D., and Spiegal-\nhalter, D., Machine Learning, Neural and Statistical Classi\ufb01cation ,\nParamount Publishing International.\n[Tesauro, 1992] Tesauro, G., Practical Issues in Temporal Di\ufb00erence Learn-\ning, Machine Learning, 8, nos. 3/4, pp. 257-277, 1992.\n[Towell & Shavlik, 1992] Towell G., and Shavlik, J., Interpretation of Arti\ufb01-\ncial Neural Networks: Mapping Knowledge-Based Neural Networks into\nRules, in Moody, J., Hanson, S., and Lippmann, R., (eds.), Advances in\nNeural Information Processing Systems, 4 , pp. 977-984, San Francisco:\nMorgan Kaufmann, 1992.\n[Towell, Shavlik, & Noordweier, 1990] Towell, G., Shavlik, J., and Noordweier,\nM., Re\ufb01nement of Approximate Domain Theories by Knowledge-Based\nArti\ufb01cial Neural Networks, Proc. Eighth Natl., Conf. on Arti\ufb01cial In-\ntelligence, pp. 861-866, 1990.\n[Unger, 1989] Unger, S., The Essence of Logic Circuits , Englewood Cli\ufb00s, NJ:\nPrentice-Hall, 1989.\n[Utgo\ufb00, 1989] Utgo\ufb00, P., Incremental Induction of Decision Trees, Machine\nLearning, 4:161186, Nov., 1989.\n[Valiant, 1984] Valiant, L., A Theory of the Learnable, Communications of\nthe ACM, Vol. 27 , pp. 1134-1142, 1984.\n[Vapnik & Chervonenkis, 1971] Vapnik, V., and Chervonenkis, A., On the\nUniform Convergence of Relative Frequencies, Theory of Probability and\nits Applications, Vol. 16 , No. 2, pp. 264-280, 1971.\n[Various Editors, 1989-1994] Advances in Neural Information Processing Sys-\ntems, vols 1 through 6, San Francisco: Morgan Kaufmann, 1989 -1994.\n[Watkins & Dayan, 1992] Watkins, C. J. C. H., and Dayan, P., Technical Note:\nQ-Learning, Machine Learning, 8, 279-292, 1992.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 187, 'page_label': '188'}, page_content='BIBLIOGRAPHY 179\n[Watkins, 1989] Watkins, C. J. C. H., Learning From Delayed Rewards , PhD\nThesis, University of Cambridge, England, 1989.\n[Weiss & Kulikowski, 1991] Weiss, S., and Kulikowski, C., Computer Systems\nthat Learn, San Francisco: Morgan Kaufmann, 1991.\n[Werbos, 1974] Werbos, P., Beyond Regression: New Tools for Prediction and\nAnalysis in the Behavioral Sciences , Ph.D. Thesis, Harvard University,\n1974.\n[Widrow & Lehr, 1990] Widrow, B., and Lehr, M. A., 30 Years of Adaptive\nNeural Networks: Perceptron, Madaline and Backpropagation, Proc.\nIEEE, vol. 78, no. 9, pp. 1415-1442, September, 1990.\n[Widrow & Stearns, 1985] Widrow, B., and Stearns, S., Adaptive Signal Pro-\ncessing, Englewood Cli\ufb00s, NJ: Prentice-Hall.\n[Widrow, 1962] Widrow, B., Generalization and Storage in Networks of Ada-\nline Neurons, in Yovits, Jacobi, and Goldstein (eds.), Self-organizing\nSystems1962, pp. 435-461, Washington, DC: Spartan Books, 1962.\n[Winder, 1961] Winder, R., Single Stage Threshold Logic, Proc. of the AIEE\nSymp. on Switching Circuits and Logical Design , Conf. paper CP-60-\n1261, pp. 321-332, 1961.\n[Winder, 1962] Winder, R., Threshold Logic, PhD Dissertation, Princeton Uni-\nversity, Princeton, NJ, 1962.\n[Wnek, et al., 1990] Wnek, J., et al., Comparing Learning Paradigms via Di-\nagrammatic Visualization, in Proc. Fifth Intl. Symp. on Methodologies\nfor Intelligent Systems , pp. 428-437, 1990. (Also Tech. Report MLI90-2,\nUniversity of Illinois at Urbana-Champaign.)')]
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 401 Unauthorized"
ERROR:root:Error indexing document: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************zh0A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized with HuggingFace embeddings
INFO:root:Documents to return: ()
INFO:root:Documents to return: ()
INFO:root:File ID: 5, Temp file path: temp_MLpdf.pdf
INFO:root:File ID: 5, file path: temp_MLpdf.pdf
INFO:root:PDF file loaded: temp_MLpdf.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 0, 'page_label': '1'}, page_content='INTRODUCTION\nTO\nMACHINE LEARNING\nAN EARLY DRAFT OF A PROPOSED\nTEXTBOOK\nNils J. Nilsson\nRobotics Laboratory\nDepartment of Computer Science\nStanford University\nStanford, CA 94305\ne-mail: nilsson@cs.stanford.edu\nNovember 3, 1998\nCopyright c\u20dd2005 Nils J. Nilsson\nThis material may not be copied, reproduced, or distributed without the\nwritten permission of the copyright holder.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 1, 'page_label': '2'}, page_content='ii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='Contents\n1 Preliminaries 1\n1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1.1 What is Machine Learning? . . . . . . . . . . . . . . . . . 1\n1.1.2 Wellsprings of Machine Learning . . . . . . . . . . . . . . 3\n1.1.3 Varieties of Machine Learning . . . . . . . . . . . . . . . . 4\n1.2 Learning Input-Output Functions . . . . . . . . . . . . . . . . . . 5\n1.2.1 Types of Learning . . . . . . . . . . . . . . . . . . . . . . 5\n1.2.2 Input Vectors . . . . . . . . . . . . . . . . . . . . . . . . . 7\n1.2.3 Outputs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.4 Training Regimes . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.5 Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.2.6 Performance Evaluation . . . . . . . . . . . . . . . . . . . 9\n1.3 Learning Requires Bias . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.4 Sample Applications . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.5 Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 13\n2 Boolean Functions 15\n2.1 Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1.1 Boolean Algebra . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1.2 Diagrammatic Representations . . . . . . . . . . . . . . . 16\n2.2 Classes of Boolean Functions . . . . . . . . . . . . . . . . . . . . 17\n2.2.1 Terms and Clauses . . . . . . . . . . . . . . . . . . . . . . 17\n2.2.2 DNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.2.3 CNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.2.4 Decision Lists . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.2.5 Symmetric and Voting Functions . . . . . . . . . . . . . . 23\n2.2.6 Linearly Separable Functions . . . . . . . . . . . . . . . . 23\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 25\niii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='3 Using Version Spaces for Learning 27\n3.1 Version Spaces and Mistake Bounds . . . . . . . . . . . . . . . . 27\n3.2 Version Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n3.3 Learning as Search of a Version Space . . . . . . . . . . . . . . . 32\n3.4 The Candidate Elimination Method . . . . . . . . . . . . . . . . 32\n3.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 34\n4 Neural Networks 35\n4.1 Threshold Logic Units . . . . . . . . . . . . . . . . . . . . . . . . 35\n4.1.1 De\ufb01nitions and Geometry . . . . . . . . . . . . . . . . . . 35\n4.1.2 Special Cases of Linearly Separable Functions . . . . . . . 37\n4.1.3 Error-Correction Training of a TLU . . . . . . . . . . . . 38\n4.1.4 Weight Space . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4.1.5 The Widrow-Ho\ufb00 Procedure . . . . . . . . . . . . . . . . . 42\n4.1.6 Training a TLU on Non-Linearly-Separable Training Sets 44\n4.2 Linear Machines . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.3 Networks of TLUs . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n4.3.1 Motivation and Examples . . . . . . . . . . . . . . . . . . 46\n4.3.2 Madalines . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.3.3 Piecewise Linear Machines . . . . . . . . . . . . . . . . . . 50\n4.3.4 Cascade Networks . . . . . . . . . . . . . . . . . . . . . . 51\n4.4 Training Feedforward Networks by Backpropagation . . . . . . . 52\n4.4.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.4.2 The Backpropagation Method . . . . . . . . . . . . . . . . 53\n4.4.3 Computing Weight Changes in the Final Layer . . . . . . 56\n4.4.4 Computing Changes to the Weights in Intermediate Layers 58\n4.4.5 Variations on Backprop . . . . . . . . . . . . . . . . . . . 59\n4.4.6 An Application: Steering a Van . . . . . . . . . . . . . . . 60\n4.5 Synergies Between Neural Network and Knowledge-Based Methods 61\n4.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 61\n5 Statistical Learning 63\n5.1 Using Statistical Decision Theory . . . . . . . . . . . . . . . . . . 63\n5.1.1 Background and General Method . . . . . . . . . . . . . . 63\n5.1.2 Gaussian (or Normal) Distributions . . . . . . . . . . . . 65\n5.1.3 Conditionally Independent Binary Components . . . . . . 68\n5.2 Learning Belief Networks . . . . . . . . . . . . . . . . . . . . . . 70\n5.3 Nearest-Neighbor Methods . . . . . . . . . . . . . . . . . . . . . . 70\n5.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 72\niv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='6 Decision Trees 73\n6.1 De\ufb01nitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n6.2 Supervised Learning of Univariate Decision Trees . . . . . . . . . 74\n6.2.1 Selecting the Type of Test . . . . . . . . . . . . . . . . . . 75\n6.2.2 Using Uncertainty Reduction to Select Tests . . . . . . . 75\n6.2.3 Non-Binary Attributes . . . . . . . . . . . . . . . . . . . . 79\n6.3 Networks Equivalent to Decision Trees . . . . . . . . . . . . . . . 79\n6.4 Over\ufb01tting and Evaluation . . . . . . . . . . . . . . . . . . . . . 80\n6.4.1 Over\ufb01tting . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n6.4.2 Validation Methods . . . . . . . . . . . . . . . . . . . . . 81\n6.4.3 Avoiding Over\ufb01tting in Decision Trees . . . . . . . . . . . 82\n6.4.4 Minimum-Description Length Methods . . . . . . . . . . . 83\n6.4.5 Noise in Data . . . . . . . . . . . . . . . . . . . . . . . . . 84\n6.5 The Problem of Replicated Subtrees . . . . . . . . . . . . . . . . 84\n6.6 The Problem of Missing Attributes . . . . . . . . . . . . . . . . . 86\n6.7 Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n6.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 87\n7 Inductive Logic Programming 89\n7.1 Notation and De\ufb01nitions . . . . . . . . . . . . . . . . . . . . . . . 90\n7.2 A Generic ILP Algorithm . . . . . . . . . . . . . . . . . . . . . . 91\n7.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n7.4 Inducing Recursive Programs . . . . . . . . . . . . . . . . . . . . 98\n7.5 Choosing Literals to Add . . . . . . . . . . . . . . . . . . . . . . 100\n7.6 Relationships Between ILP and Decision Tree Induction . . . . . 101\n7.7 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 104\n8 Computational Learning Theory 107\n8.1 Notation and Assumptions for PAC Learning Theory . . . . . . . 107\n8.2 PAC Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n8.2.1 The Fundamental Theorem . . . . . . . . . . . . . . . . . 109\n8.2.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n8.2.3 Some Properly PAC-Learnable Classes . . . . . . . . . . . 112\n8.3 The Vapnik-Chervonenkis Dimension . . . . . . . . . . . . . . . . 113\n8.3.1 Linear Dichotomies . . . . . . . . . . . . . . . . . . . . . . 113\n8.3.2 Capacity . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n8.3.3 A More General Capacity Result . . . . . . . . . . . . . . 116\n8.3.4 Some Facts and Speculations About the VC Dimension . 117\n8.4 VC Dimension and PAC Learning . . . . . . . . . . . . . . . . . 118\n8.5 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 118\nv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='9 Unsupervised Learning 119\n9.1 What is Unsupervised Learning? . . . . . . . . . . . . . . . . . . 119\n9.2 Clustering Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n9.2.1 A Method Based on Euclidean Distance . . . . . . . . . . 120\n9.2.2 A Method Based on Probabilities . . . . . . . . . . . . . . 124\n9.3 Hierarchical Clustering Methods . . . . . . . . . . . . . . . . . . 125\n9.3.1 A Method Based on Euclidean Distance . . . . . . . . . . 125\n9.3.2 A Method Based on Probabilities . . . . . . . . . . . . . . 126\n9.4 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 130\n10 Temporal-Di\ufb00erence Learning 131\n10.1 Temporal Patterns and Prediction Problems . . . . . . . . . . . . 131\n10.2 Supervised and Temporal-Di\ufb00erence Methods . . . . . . . . . . . 131\n10.3 Incremental Computation of the (\u2206 W)i . . . . . . . . . . . . . . 134\n10.4 An Experiment with TD Methods . . . . . . . . . . . . . . . . . 135\n10.5 Theoretical Results . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n10.6 Intra-Sequence Weight Updating . . . . . . . . . . . . . . . . . . 138\n10.7 An Example Application: TD-gammon . . . . . . . . . . . . . . . 140\n10.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 141\n11 Delayed-Reinforcement Learning 143\n11.1 The General Problem . . . . . . . . . . . . . . . . . . . . . . . . 143\n11.2 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n11.3 Temporal Discounting and Optimal Policies . . . . . . . . . . . . 145\n11.4 Q-Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n11.5 Discussion, Limitations, and Extensions of Q-Learning . . . . . . 150\n11.5.1 An Illustrative Example . . . . . . . . . . . . . . . . . . . 150\n11.5.2 Using Random Actions . . . . . . . . . . . . . . . . . . . 152\n11.5.3 Generalizing Over Inputs . . . . . . . . . . . . . . . . . . 153\n11.5.4 Partially Observable States . . . . . . . . . . . . . . . . . 154\n11.5.5 Scaling Problems . . . . . . . . . . . . . . . . . . . . . . . 154\n11.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 155\nvi'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='12 Explanation-Based Learning 157\n12.1 Deductive Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 157\n12.2 Domain Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n12.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n12.4 Evaluable Predicates . . . . . . . . . . . . . . . . . . . . . . . . . 162\n12.5 More General Proofs . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.6 Utility of EBL . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.7 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.7.1 Macro-Operators in Planning . . . . . . . . . . . . . . . . 164\n12.7.2 Learning Search Control Knowledge . . . . . . . . . . . . 167\n12.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 168\nvii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 7, 'page_label': '8'}, page_content='viii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 8, 'page_label': '9'}, page_content='Preface\nThese notes are in the process of becoming a textbook. The process is quite\nun\ufb01nished, and the author solicits corrections, criticisms, and suggestions from\nstudents and other readers. Although I have tried to eliminate errors, some un-\ndoubtedly remaincaveat lector. Many typographical infelicities will no doubt\npersist until the \ufb01nal version. More material has yet to be added. Please let Some of my plans for additions and\nother reminders are mentioned in\nmarginal notes.me have your suggestions about topics that are too important to be left out.\nI hope that future versions will cover Hop\ufb01eld nets, Elman nets and other re-\ncurrent nets, radial basis functions, grammar and automata learning, genetic\nalgorithms, and Bayes networks ... . I am also collecting exercises and project\nsuggestions which will appear in future versions.\nMy intention is to pursue a middle ground between a theoretical textbook\nand one that focusses on applications. The book concentrates on the important\nideas in machine learning. I do not give proofs of many of the theorems that I\nstate, but I do give plausibility arguments and citations to formal proofs. And, I\ndo not treat many matters that would be of practical importance in applications;\nthe book is not a handbook of machine learning practice. Instead, my goal is\nto give the reader su\ufb03cient preparation to make the extensive literature on\nmachine learning accessible.\nStudents in my Stanford courses on machine learning have already made\nseveral useful suggestions, as have my colleague, Pat Langley, and my teaching\nassistants, Ron Kohavi, Karl P\ufb02eger, Robert Allen, and Lise Getoor.\nix'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 9, 'page_label': '10'}, page_content='Chapter 1\nPreliminaries\n1.1 Introduction\n1.1.1 What is Machine Learning?\nLearning, like intelligence, covers such a broad range of processes that it is dif-\n\ufb01cult to de\ufb01ne precisely. A dictionary de\ufb01nition includes phrases such as to\ngain knowledge, or understanding of, or skill in, by study, instruction, or expe-\nrience, and modi\ufb01cation of a behavioral tendency by experience. Zoologists\nand psychologists study learning in animals and humans. In this book we fo-\ncus on learning in machines. There are several parallels between animal and\nmachine learning. Certainly, many techniques in machine learning derive from\nthe e\ufb00orts of psychologists to make more precise their theories of animal and\nhuman learning through computational models. It seems likely also that the\nconcepts and techniques being explored by researchers in machine learning may\nilluminate certain aspects of biological learning.\nAs regards machines, we might say, very broadly, that a machine learns\nwhenever it changes its structure, program, or data (based on its inputs or in\nresponse to external information) in such a manner that its expected future\nperformance improves. Some of these changes, such as the addition of a record\nto a data base, fall comfortably within the province of other disciplines and are\nnot necessarily better understood for being called learning. But, for example,\nwhen the performance of a speech-recognition machine improves after hearing\nseveral samples of a persons speech, we feel quite justi\ufb01ed in that case to say\nthat the machine has learned.\nMachine learning usually refers to the changes in systems that perform tasks\nassociated with arti\ufb01cial intelligence (AI) . Such tasks involve recognition, diag-\nnosis, planning, robot control, prediction, etc. The changes might be either\nenhancements to already performing systems or ab initio synthesis of new sys-\ntems. To be slightly more speci\ufb01c, we show the architecture of a typical AI\n1'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 10, 'page_label': '11'}, page_content='2 CHAPTER 1. PRELIMINARIES\nagent in Fig. 1.1. This agent perceives and models its environment and com-\nputes appropriate actions, perhaps by anticipating their e\ufb00ects. Changes made\nto any of the components shown in the \ufb01gure might count as learning. Di\ufb00erent\nlearning mechanisms might be employed depending on which subsystem is being\nchanged. We will study several di\ufb00erent learning methods in this book.\nSensory signals\nPerception\nActions\nAction\nComputation\nModel\nPlanning and\nReasoning\nGoals\nFigure 1.1: An AI System\nOne might ask Why should machines have to learn? Why not design ma-\nchines to perform as desired in the \ufb01rst place? There are several reasons why\nmachine learning is important. Of course, we have already mentioned that the\nachievement of learning in machines might help us understand how animals and\nhumans learn. But there are important engineering reasons as well. Some of\nthese are:\n Some tasks cannot be de\ufb01ned well except by example; that is, we might be\nable to specify input/output pairs but not a concise relationship between\ninputs and desired outputs. We would like machines to be able to adjust\ntheir internal structure to produce correct outputs for a large number of\nsample inputs and thus suitably constrain their input/output function to\napproximate the relationship implicit in the examples.\n It is possible that hidden among large piles of data are important rela-\ntionships and correlations. Machine learning methods can often be used\nto extract these relationships ( data mining).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 11, 'page_label': '12'}, page_content='1.1. INTRODUCTION 3\n Human designers often produce machines that do not work as well as\ndesired in the environments in which they are used. In fact, certain char-\nacteristics of the working environment might not be completely known\nat design time. Machine learning methods can be used for on-the-job\nimprovement of existing machine designs.\n The amount of knowledge available about certain tasks might be too large\nfor explicit encoding by humans. Machines that learn this knowledge\ngradually might be able to capture more of it than humans would want to\nwrite down.\n Environments change over time. Machines that can adapt to a changing\nenvironment would reduce the need for constant redesign.\n New knowledge about tasks is constantly being discovered by humans.\nVocabulary changes. There is a constant stream of new events in the\nworld. Continuing redesign of AI systems to conform to new knowledge is\nimpractical, but machine learning methods might be able to track much\nof it.\n1.1.2 Wellsprings of Machine Learning\nWork in machine learning is now converging from several sources. These dif-\nferent traditions each bring di\ufb00erent methods and di\ufb00erent vocabulary which\nare now being assimilated into a more uni\ufb01ed discipline. Here is a brief listing\nof some of the separate disciplines that have contributed to machine learning;\nmore details will follow in the the appropriate chapters:\n Statistics: A long-standing problem in statistics is how best to use sam-\nples drawn from unknown probability distributions to help decide from\nwhich distribution some new sample is drawn. A related problem is how\nto estimate the value of an unknown function at a new point given the\nvalues of this function at a set of sample points. Statistical methods\nfor dealing with these problems can be considered instances of machine\nlearning because the decision and estimation rules depend on a corpus of\nsamples drawn from the problem environment. We will explore some of\nthe statistical methods later in the book. Details about the statistical the-\nory underlying these methods can be found in statistical textbooks such\nas [Anderson, 1958].\n Brain Models: Non-linear elements with weighted inputs\nhave been suggested as simple models of biological neu-\nrons. Networks of these elements have been studied by sev-\neral researchers including [McCulloch & Pitts, 1943, Hebb, 1949,\nRosenblatt, 1958] and, more recently by [Gluck & Rumelhart, 1989,\nSejnowski, Koch, & Churchland, 1988]. Brain modelers are interested\nin how closely these networks approximate the learning phenomena of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 12, 'page_label': '13'}, page_content='4 CHAPTER 1. PRELIMINARIES\nliving brains. We shall see that several important machine learning\ntechniques are based on networks of nonlinear elementsoften called\nneural networks . Work inspired by this school is sometimes called\nconnectionism, brain-style computation, or sub-symbolic processing.\n Adaptive Control Theory: Control theorists study the problem of con-\ntrolling a process having unknown parameters which must be estimated\nduring operation. Often, the parameters change during operation, and the\ncontrol process must track these changes. Some aspects of controlling a\nrobot based on sensory inputs represent instances of this sort of problem.\nFor an introduction see [Bollinger & Du\ufb03e, 1988].\n Psychological Models: Psychologists have studied the performance of\nhumans in various learning tasks. An early example is the EPAM net-\nwork for storing and retrieving one member of a pair of words when\ngiven another [Feigenbaum, 1961]. Related work led to a number of\nearly decision tree [Hunt, Marin, & Stone, 1966] and semantic network\n[Anderson & Bower, 1973] methods. More recent work of this sort has\nbeen in\ufb02uenced by activities in arti\ufb01cial intelligence which we will be pre-\nsenting.\nSome of the work in reinforcement learning can be traced to e\ufb00orts to\nmodel how reward stimuli in\ufb02uence the learning of goal-seeking behavior in\nanimals [Sutton & Barto, 1987]. Reinforcement learning is an important\ntheme in machine learning research.\n Arti\ufb01cial Intelligence: From the beginning, AI research has been con-\ncerned with machine learning. Samuel developed a prominent early pro-\ngram that learned parameters of a function for evaluating board posi-\ntions in the game of checkers [Samuel, 1959]. AI researchers have also\nexplored the role of analogies in learning [Carbonell, 1983] and how fu-\nture actions and decisions can be based on previous exemplary cases\n[Kolodner, 1993]. Recent work has been directed at discovering rules\nfor expert systems using decision-tree methods [Quinlan, 1990] and in-\nductive logic programming [Muggleton, 1991, Lavra\u02c7 c & D\u02c7 zeroski, 1994].\nAnother theme has been saving and generalizing the results of prob-\nlem solving using explanation-based learning [DeJong & Mooney, 1986,\nLaird, et al., 1986, Minton, 1988, Etzioni, 1993].\n Evolutionary Models:\nIn nature, not only do individual animals learn to perform better, but\nspecies evolve to be better \ufb01t in their individual niches. Since the distinc-\ntion between evolving and learning can be blurred in computer systems,\ntechniques that model certain aspects of biological evolution have been\nproposed as learning methods to improve the performance of computer\nprograms. Genetic algorithms [Holland, 1975] and genetic programming\n[Koza, 1992, Koza, 1994] are the most prominent computational tech-\nniques for evolution.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 13, 'page_label': '14'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 5\n1.1.3 Varieties of Machine Learning\nOrthogonal to the question of the historical source of any learning technique is\nthe more important question of what is to be learned. In this book, we take it\nthat the thing to be learned is a computational structure of some sort. We will\nconsider a variety of di\ufb00erent computational structures:\n Functions\n Logic programs and rule sets\n Finite-state machines\n Grammars\n Problem solving systems\nWe will present methods both for the synthesis of these structures from examples\nand for changing existing structures. In the latter case, the change to the\nexisting structure might be simply to make it more computationally e\ufb03cient\nrather than to increase the coverage of the situations it can handle. Much of\nthe terminology that we shall be using throughout the book is best introduced\nby discussing the problem of learning functions, and we turn to that matter\n\ufb01rst.\n1.2 Learning Input-Output Functions\nWe use Fig. 1.2 to help de\ufb01ne some of the terminology used in describing the\nproblem of learning a function. Imagine that there is a function, f, and the task\nof the learner is to guess what it is. Our hypothesis about the function to be\nlearned is denoted by h. Both f and h are functions of a vector-valued input\nX = (x1,x2,...,x i,...,x n) which has n components. We think of h as being\nimplemented by a device that has X as input and h(X) as output. Both f and\nh themselves may be vector-valued. We assume a priori that the hypothesized\nfunction, h, is selected from a class of functions H. Sometimes we know that\nf also belongs to this class or to a subset of this class. We select h based on a\ntraining set, \u039e, of minput vector examples. Many important details depend on\nthe nature of the assumptions made about all of these entities.\n1.2.1 Types of Learning\nThere are two major settings in which we wish to learn a function. In one,\ncalled supervised learning, we know (sometimes only approximately) the values\nof f for the m samples in the training set, \u039e. We assume that if we can \ufb01nd\na hypothesis, h, that closely agrees with f for the members of \u039e, then this\nhypothesis will be a good guess for fespecially if \u039e is large.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 14, 'page_label': '15'}, page_content='6 CHAPTER 1. PRELIMINARIES\nh(X)\nh\nU = {X1, X2, . . . Xi, . . ., Xm}\nTraining Set:\nX =\nx1\n.\n.\n.\nxi\n.\n.\n.\nxn h D H\nFigure 1.2: An Input-Output Function\nCurve-\ufb01tting is a simple example of supervised learning of a function. Sup-\npose we are given the values of a two-dimensional function,f, at the four sample\npoints shown by the solid circles in Fig. 1.3. We want to \ufb01t these four points\nwith a function, h, drawn from the set, H, of second-degree functions. We show\nthere a two-dimensional parabolic surface above the x1, x2 plane that \ufb01ts the\npoints. This parabolic function, h, is our hypothesis about the function, f, that\nproduced the four samples. In this case, h= f at the four samples, but we need\nnot have required exact matches.\nIn the other setting, termed unsupervised learning, we simply have a train-\ning set of vectors without function values for them. The problem in this case,\ntypically, is to partition the training set into subsets, \u039e 1, . . . , \u039eR, in some ap-\npropriate way. (We can still regard the problem as one of learning a function;\nthe value of the function is the name of the subset to which an input vector be-\nlongs.) Unsupervised learning methods have application in taxonomic problems\nin which it is desired to invent ways to classify data into meaningful categories.\nWe shall also describe methods that are intermediate between supervised\nand unsupervised learning.\nWe might either be trying to \ufb01nd a new function, h, or to modify an existing\none. An interesting special case is that of changing an existing function into an\nequivalent one that is computationally more e\ufb03cient. This type of learning is\nsometimes called speed-uplearning. A very simple example of speed-up learning\ninvolves deduction processes. From the formulas A \u2283B and B \u2283C, we can\ndeduce C if we are given A. From this deductive process, we can create the\nformula A\u2283Ca new formula but one that does not sanction any more con-'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 15, 'page_label': '16'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 7\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n500\n1000\n1500\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n00\n00\n0\nx1\nx2\nh sample f-value\nFigure 1.3: A Surface that Fits Four Points\nclusions than those that could be derived from the formulas that we previously\nhad. But with this new formula we can derive C more quickly, given A, than\nwe could have done before. We can contrast speed-up learning with methods\nthat create genuinely new functionsones that might give di\ufb00erent results after\nlearning than they did before. We say that the latter methods involve inductive\nlearning. As opposed to deduction, there are no correct inductionsonly useful\nones.\n1.2.2 Input Vectors\nBecause machine learning methods derive from so many di\ufb00erent traditions, its\nterminology is rife with synonyms, and we will be using most of them in this\nbook. For example, the input vector is called by a variety of names. Some\nof these are: input vector, pattern vector, feature vector, sample, example, and\ninstance. The components, xi, of the input vector are variously called features,\nattributes, input variables, and components.\nThe values of the components can be of three main types. They might\nbe real-valued numbers, discrete-valued numbers, or categorical values. As an\nexample illustrating categorical values, information about a student might be\nrepresented by the values of the attributes class, major, sex, adviser . A par-\nticular student would then be represented by a vector such as: (sophomore,\nhistory, male, higgins). Additionally, categorical values may be ordered (as in\n{small, medium, large}) or unordered (as in the example just given). Of course,\nmixtures of all these types of values are possible.\nIn all cases, it is possible to represent the input in unordered form by listing\nthe names of the attributes together with their values. The vector form assumes\nthat the attributes are ordered and given implicitly by a form. As an example\nof an attribute-value representation, we might have: (major: history, sex: male,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 16, 'page_label': '17'}, page_content='8 CHAPTER 1. PRELIMINARIES\nclass: sophomore, adviser: higgins, age: 19). We will be using the vector form\nexclusively.\nAn important specialization uses Boolean values, which can be regarded as\na special case of either discrete numbers (1,0) or of categorical variables ( True,\nFalse).\n1.2.3 Outputs\nThe output may be a real number, in which case the process embodying the\nfunction, h, is called a function estimator , and the output is called an output\nvalue or estimate.\nAlternatively, the output may be a categorical value, in which case the pro-\ncess embodying h is variously called a classi\ufb01er, a recognizer, or a categorizer,\nand the output itself is called a label, a class, a category, or a decision. Classi-\n\ufb01ers have application in a number of recognition problems, for example in the\nrecognition of hand-printed characters. The input in that case is some suitable\nrepresentation of the printed character, and the classi\ufb01er maps this input into\none of, say, 64 categories.\nVector-valued outputs are also possible with components being real numbers\nor categorical values.\nAn important special case is that of Boolean output values. In that case,\na training pattern having value 1 is called a positive instance, and a training\nsample having value 0 is called a negative instance. When the input is also\nBoolean, the classi\ufb01er implements a Boolean function. We study the Boolean\ncase in some detail because it allows us to make important general points in\na simpli\ufb01ed setting. Learning a Boolean function is sometimes called concept\nlearning, and the function is called a concept.\n1.2.4 Training Regimes\nThere are several ways in which the training set, \u039e, can be used to produce a\nhypothesized function. In the batch method, the entire training set is available\nand used all at once to compute the function, h. A variation of this method\nuses the entire training set to modify a current hypothesis iteratively until an\nacceptable hypothesis is obtained. By contrast, in the incremental method, we\nselect one member at a time from the training set and use this instance alone\nto modify a current hypothesis. Then another member of the training set is\nselected, and so on. The selection method can be random (with replacement)\nor it can cycle through the training set iteratively. If the entire training set\nbecomes available one member at a time, then we might also use an incremental\nmethodselecting and using training set members as they arrive. (Alterna-\ntively, at any stage all training set members so far available could be used in a\nbatch process.) Using the training set members as they become available is\ncalled an online method. Online methods might be used, for example, when the'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 17, 'page_label': '18'}, page_content='1.3. LEARNING REQUIRES BIAS 9\nnext training instance is some function of the current hypothesis and the previ-\nous instanceas it would be when a classi\ufb01er is used to decide on a robots next\naction given its current set of sensory inputs. The next set of sensory inputs\nwill depend on which action was selected.\n1.2.5 Noise\nSometimes the vectors in the training set are corrupted by noise. There are two\nkinds of noise. Class noise randomly alters the value of the function; attribute\nnoise randomly alters the values of the components of the input vector. In either\ncase, it would be inappropriate to insist that the hypothesized function agree\nprecisely with the values of the samples in the training set.\n1.2.6 Performance Evaluation\nEven though there is no correct answer in inductive learning, it is important\nto have methods to evaluate the result of learning. We will discuss this matter\nin more detail later, but, brie\ufb02y, in supervised learning the induced function is\nusually evaluated on a separate set of inputs and function values for them called\nthe testing set . A hypothesized function is said to generalize when it guesses\nwell on the testing set. Both mean-squared-error and the total number of errors\nare common measures.\n1.3 Learning Requires Bias\nLong before now the reader has undoubtedly asked why is learning a function\npossible at all? Certainly, for example, there are an uncountable number of\ndi\ufb00erent functions having values that agree with the four samples shown in Fig.\n1.3. Why would a learning procedure happen to select the quadratic one shown\nin that \ufb01gure? In order to make that selection we had at least to limit a priori\nthe set of hypotheses to quadratic functions and then to insist that the one we\nchose passed through all four sample points. This kind of a priori information\nis called bias, and useful learning without bias is impossible.\nWe can gain more insight into the role of bias by considering the special case\nof learning a Boolean function of n dimensions. There are 2 n di\ufb00erent Boolean\ninputs possible. Suppose we had no bias; that is His the set of all 22n\nBoolean\nfunctions, and we have no preference among those that \ufb01t the samples in the\ntraining set. In this case, after being presented with one member of the training\nset and its value we can rule out precisely one-half of the members of Hthose\nBoolean functions that would misclassify this labeled sample. The remaining\nfunctions constitute what is called a version space; well explore that concept\nin more detail later. As we present more members of the training set, the graph\nof the number of hypotheses not yet ruled out as a function of the number of\ndi\ufb00erent patterns presented is as shown in Fig. 1.4. At any stage of the process,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 18, 'page_label': '19'}, page_content='10 CHAPTER 1. PRELIMINARIES\nhalf of the remaining Boolean functions have value 1 and half have value 0 for\nany training pattern not yet seen. No generalization is possible in this case\nbecause the training patterns give no clue about the value of a pattern not yet\nseen. Only memorization is possible here, which is a trivial sort of learning.\nlog2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n2n < j\n(generalization is not possible)\n|Hv| = no. of functions not ruled out\nFigure 1.4: Hypotheses Remaining as a Function of Labeled Patterns Presented\nBut suppose we limited Hto some subset, Hc, of all Boolean functions.\nDepending on the subset and on the order of presentation of training patterns,\na curve of hypotheses not yet ruled out might look something like the one\nshown in Fig. 1.5. In this case it is even possible that after seeing fewer than\nall 2 n labeled samples, there might be only one hypothesis that agrees with\nthe training set. Certainly, even if there is more than one hypothesis remaining,\nmost of them may have the same value formost of the patterns not yet seen! The\ntheory of Probably Approximately Correct (PAC) learning makes this intuitive\nidea precise. Well examine that theory later.\nLets look at a speci\ufb01c example of how bias aids learning. A Boolean function\ncan be represented by a hypercube each of whose vertices represents a di\ufb00erent\ninput pattern. We show a 3-dimensional version in Fig. 1.6. There, we show a\ntraining set of six sample patterns and have marked those having a value of 1 by\na small square and those having a value of 0 by a small circle. If the hypothesis\nset consists of just the linearly separable functionsthose for which the positive\nand negative instances can be separated by a linear surface, then there is only\none function remaining in this hypothsis set that is consistent with the training\nset. So, in this case, even though the training set does not contain all possible\npatterns, we can already pin down what the function must begiven the bias.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 19, 'page_label': '20'}, page_content='1.4. SAMPLE APPLICATIONS 11\nlog2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n|Hv| = no. of functions not ruled out\ndepends on order\nof presentation\nlog2|Hc|\nFigure 1.5: Hypotheses Remaining From a Restricted Subset\nMachine learning researchers have identi\ufb01ed two main varieties of bias, ab-\nsolute and preference. In absolute bias (also called restricted hypothesis-space\nbias), one restricts Hto a de\ufb01nite subset of functions. In our example of Fig. 1.6,\nthe restriction was to linearly separable Boolean functions. In preference bias,\none selects that hypothesis that is minimal according to some ordering scheme\nover all hypotheses. For example, if we had some way of measuring thecomplex-\nity of a hypothesis, we might select the one that was simplest among those that\nperformed satisfactorily on the training set. The principle of Occams razor,\nused in science to prefer simple explanations to more complex ones, is a type\nof preference bias. (William of Occam, 1285-?1349, was an English philosopher\nwho said:  non sunt multiplicanda entia praeter necessitatem , which means\nentities should not be multiplied unnecessarily.)\n1.4 Sample Applications\nOur main emphasis in this book is on the concepts of machine learningnot\non its applications. Nevertheless, if these concepts were irrelevant to real-world\nproblems they would probably not be of much interest. As motivation, we give\na short summary of some areas in which machine learning techniques have been\nsuccessfully applied. [Langley, 1992] cites some of the following applications and\nothers:\na. Rule discovery using a variant of ID3 for a printing industry problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 20, 'page_label': '21'}, page_content='12 CHAPTER 1. PRELIMINARIES\nx1\nx2\nx3\nFigure 1.6: A Training Set That Completely Determines a Linearly Separable\nFunction\n[Evans & Fisher, 1992].\nb. Electric power load forecasting using a k-nearest-neighbor rule system\n[Jabbour, K., et al., 1987].\nc. Automatic help desk assistant using a nearest-neighbor system\n[Acorn & Walden, 1992].\nd. Planning and scheduling for a steel mill using ExpertEase, a marketed\n(ID3-like) system [Michie, 1992].\ne. Classi\ufb01cation of stars and galaxies [Fayyad, et al., 1993].\nMany application-oriented papers are presented at the annual conferences\non Neural Information Processing Systems. Among these are papers on: speech\nrecognition, dolphin echo recognition, image processing, bio-engineering, diag-\nnosis, commodity trading, face recognition, music composition, optical character\nrecognition, and various control applications [Various Editors, 1989-1994].\nAs additional examples, [Hammerstrom, 1993] mentions:\na. Sharps Japanese kanji character recognition system processes 200 char-\nacters per second with 99+% accuracy. It recognizes 3000+ characters.\nb. NeuroForecasting Centres (London Business School and University Col-\nlege London) trading strategy selection network earned an average annual\npro\ufb01t of 18% against a conventional systems 12.3%.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 21, 'page_label': '22'}, page_content='1.5. SOURCES 13\nc. Fujitsus (plus a partners) neural network for monitoring a continuous\nsteel casting operation has been in successful operation since early 1990.\nIn summary, it is rather easy nowadays to \ufb01nd applications of machine learn-\ning techniques. This fact should come as no surprise inasmuch as many machine\nlearning techniques can be viewed as extensions of well known statistical meth-\nods which have been successfully applied for many years.\n1.5 Sources\nBesides the rich literature in machine learning (a small part of\nwhich is referenced in the Bibliography), there are several text-\nbooks that are worth mentioning [Hertz, Krogh, & Palmer, 1991,\nWeiss & Kulikowski, 1991, Natarjan, 1991, Fu, 1994, Langley, 1996].\n[Shavlik & Dietterich, 1990, Buchanan & Wilkins, 1993] are edited vol-\numes containing some of the most important papers. A survey paper by\n[Dietterich, 1990] gives a good overview of many important topics. There are\nalso well established conferences and publications where papers are given and\nappear including:\n The Annual Conferences on Advances in Neural Information Processing\nSystems\n The Annual Workshops on Computational Learning Theory\n The Annual International Workshops on Machine Learning\n The Annual International Conferences on Genetic Algorithms\n(The Proceedings of the above-listed four conferences are published by\nMorgan Kaufmann.)\n The journal Machine Learning (published by Kluwer Academic Publish-\ners).\nThere is also much information, as well as programs and datasets, available over\nthe Internet through the World Wide Web.\n1.6 Bibliographical and Historical Remarks\nTo be added. Every chapter will\ncontain a brief survey of the history\nof the material covered in that\nchapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 22, 'page_label': '23'}, page_content='14 CHAPTER 1. PRELIMINARIES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 23, 'page_label': '24'}, page_content='Chapter 2\nBoolean Functions\n2.1 Representation\n2.1.1 Boolean Algebra\nMany important ideas about learning of functions are most easily presented\nusing the special case of Boolean functions. There are several important sub-\nclasses of Boolean functions that are used as hypothesis classes for function\nlearning. Therefore, we digress in this chapter to present a review of Boolean\nfunctions and their properties. (For a more thorough treatment see, for example,\n[Unger, 1989].)\nA Boolean function, f(x1,x2,...,x n) maps an n-tuple of (0,1) values to\n{0,1}. Boolean algebra is a convenient notation for representing Boolean func-\ntions. Boolean algebra uses the connectives ·, +, and . For example, the and\nfunction of two variables is written x1 ·x2. By convention, the connective,  ·\nis usually suppressed, and the and function is written x1x2. x1x2 has value 1 if\nand only if both x1 and x2 have value 1; if either x1 or x2 has value 0, x1x2 has\nvalue 0. The (inclusive) or function of two variables is written x1 + x2. x1 + x2\nhas value 1 if and only if either or both of x1 or x2 has value 1; if both x1 and\nx2 have value 0, x1 + x2 has value 0. The complement or negation of a variable,\nx, is written x. xhas value 1 if and only if xhas value 0; if xhas value 1, xhas\nvalue 0.\nThese de\ufb01nitions are compactly given by the following rules for Boolean\nalgebra:\n1 + 1 = 1, 1 + 0 = 1, 0 + 0 = 0,\n1 ·1 = 1, 1 ·0 = 0, 0 ·0 = 0, and\n1 = 0, 0 = 1.\nSometimes the arguments and values of Boolean functions are expressed in\nterms of the constants T (True) and F (False) instead of 1 and 0, respectively.\n15'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 24, 'page_label': '25'}, page_content='16 CHAPTER 2. BOOLEAN FUNCTIONS\nThe connectives ·and + are each commutative and associative. Thus, for\nexample, x1(x2x3) = ( x1x2)x3, and both can be written simply as x1x2x3.\nSimilarly for +.\nA Boolean formula consisting of a single variable, such as x1 is called an\natom. One consisting of either a single variable or its complement, such as x1,\nis called a literal.\nThe operators ·and + do not commute between themselves. Instead, we\nhave DeMorgans laws (which can be veri\ufb01ed by using the above de\ufb01nitions):\nx1x2 = x1 + x2, and\nx1 + x2 = x1 x2.\n2.1.2 Diagrammatic Representations\nWe saw in the last chapter that a Boolean function could be represented by\nlabeling the vertices of a cube. For a function of n variables, we would need\nan n-dimensional hypercube. In Fig. 2.1 we show some 2- and 3-dimensional\nexamples. Vertices having value 1 are labeled with a small square, and vertices\nhaving value 0 are labeled with a small circle.\nx1\nx2\nx1\nx2\nx1\nx2\nand or\nxor (exclusive or)\nx1x2 x1 + x2\nx1x2  +  x1x2\neven parity functionx1\nx2\nx3\nx1x2x3  +  x1x2x3\n+ x1x2x3 + x1x2x3\nFigure 2.1: Representing Boolean Functions on Cubes\nUsing the hypercube representations, it is easy to see how many Boolean\nfunctions of n dimensions there are. A 3-dimensional cube has 2 3 = 8 vertices,\nand each may be labeled in two di\ufb00erent ways; thus there are 2 (23) = 256'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 25, 'page_label': '26'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 17\ndi\ufb00erent Boolean functions of 3 variables. In general, there are 2 2n\nBoolean\nfunctions of n variables.\nWe will be using 2- and 3-dimensional cubes later to provide some intuition\nabout the properties of certain Boolean functions. Of course, we cannot visualize\nhypercubes (for n > 3), and there are many surprising properties of higher\ndimensional spaces, so we must be careful in using intuitions gained in low\ndimensions. One diagrammatic technique for dimensions slightly higher than\n3 is the Karnaugh map . A Karnaugh map is an array of values of a Boolean\nfunction in which the horizontal rows are indexed by the values of some of\nthe variables and the vertical columns are indexed by the rest. The rows and\ncolumns are arranged in such a way that entries that are adjacent in the map\ncorrespond to vertices that are adjacent in the hypercube representation. We\nshow an example of the 4-dimensional even parity function in Fig. 2.2. (An\neven parity function is a Boolean function that has value 1 if there are an even\nnumber of its arguments that have value 1; otherwise it has value 0.) Note\nthat all adjacent cells in the table correspond to inputs di\ufb00ering in only one\ncomponent. Also describe general logic\ndiagrams, [Wnek, et al., 1990].\n00 01 1011\n00\n01\n10\n11\n11\n1\n1\n11\n1\n10\n00\n0\n0\n0\n0\n0\nx1,x2\nx3,x4\nFigure 2.2: A Karnaugh Map\n2.2 Classes of Boolean Functions\n2.2.1 Terms and Clauses\nTo use absolute bias in machine learning, we limit the class of hypotheses. In\nlearning Boolean functions, we frequently use some of the common sub-classes of\nthose functions. Therefore, it will be important to know about these subclasses.\nOne basic subclass is called terms. A term is any function written in the\nform l1l2 ···lk, where the li are literals. Such a form is called a conjunction of\nliterals. Some example terms are x1x7 and x1x2x4. The size of a term is the\nnumber of literals it contains. The examples are of sizes 2 and 3, respectively.\n(Strictly speaking, the class of conjunctions of literals is called the monomials,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 26, 'page_label': '27'}, page_content='18 CHAPTER 2. BOOLEAN FUNCTIONS\nand a conjunction of literals itself is called a term. This distinction is a \ufb01ne one\nwhich we elect to blur here.)\nIt is easy to show that there are exactly 3 n possible terms of n variables.\nThe number of terms of size kor less is bounded from above by \u2211k\ni=0 C(2n,i) =\nO(nk), where C(i,j) = i!\n(i\u2212j)!j! is the binomial coe\ufb03cient.Probably Ill put in a simple\nterm-learning algorithm hereso\nwe can get started on learning!\nAlso for DNF functions and\ndecision listsas they are de\ufb01ned\nin the next few pages.\nA clause is any function written in the form l1 +l2 +···+lk, where the li are\nliterals. Such a form is called a disjunction of literals. Some example clauses\nare x3 + x5 + x6 and x1 + x4. The size of a clause is the number of literals it\ncontains. There are 3 n possible clauses and fewer than \u2211k\ni=0 C(2n,i) clauses of\nsize k or less. If f is a term, then (by De Morgans laws) f is a clause, and vice\nversa. Thus, terms and clauses are duals of each other.\nIn psychological experiments, conjunctions of literals seem easier for humans\nto learn than disjunctions of literals.\n2.2.2 DNF Functions\nA Boolean function is said to be in disjunctive normal form (DNF) if it can be\nwritten as adisjunction of terms. Some examples in DNF are: f = x1x2+x2x3x4\nand f = x1x3 + x2 x3 + x1x2x3. A DNF expression is called a k-term DNF\nexpression if it is a disjunction of k terms; it is in the class k-DNF if the size of\nits largest term is k. The examples above are 2-term and 3-term expressions,\nrespectively. Both expressions are in the class 3-DNF.\nEach term in a DNF expression for a function is called an implicant because\nit implies the function (if the term has value 1, so does the function). In\ngeneral, a term, t, is an implicant of a function, f, if f has value 1 whenever\nt does. A term, t, is a prime implicant of f if the term, t\u2032, formed by taking\nany literal out of an implicant t is no longer an implicant of f. (The implicant\ncannot be divided by any term and remain an implicant.)\nThus, both x2x3 and x1 x3 are prime implicants off = x2x3+x1 x3+x2x1x3,\nbut x2x1x3 is not.\nThe relationship between implicants and prime implicants can be geometri-\ncally illustrated using the cube representation for Boolean functions. Consider,\nfor example, the function f = x2x3 + x1 x3 + x2x1x3. We illustrate it in Fig.\n2.3. Note that each of the three planes in the \ufb01gure cuts o\ufb00 a group of\nvertices having value 1, but none cuts o\ufb00 any vertices having value 0. These\nplanes are pictorial devices used to isolate certain lower dimensional subfaces\nof the cube. Two of them isolate one-dimensional edges, and the third isolates\na zero-dimensional vertex. Each group of vertices on a subface corresponds to\none of the implicants of the function, f, and thus each implicant corresponds\nto a subface of some dimension. A k-dimensional subface corresponds to an\n(n\u2212k)-size implicant term. The function is written as the disjunction of the\nimplicantscorresponding to the union of all the vertices cut o\ufb00 by all of the\nplanes. Geometrically, an implicant is prime if and only if its corresponding\nsubface is the largest dimensional subface that includes all of its vertices and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 27, 'page_label': '28'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 19\nno other vertices having value 0. Note that the term x2x1x3 is not a prime\nimplicant of f. (In this case, we dont even have to include this term in the\nfunction because the vertex cut o\ufb00 by the plane corresponding to x2x1x3 is\nalready cut o\ufb00 by the plane corresponding to x2x3.) The other two implicants\nare prime because their corresponding subfaces cannot be expanded without\nincluding vertices having value 0.\nx2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x2x1x3\n   = x2x3 + x1x3\nx2x3 and  x1x3 are prime implicants\nFigure 2.3: A Function and its Implicants\nNote that all Boolean functions can be represented in DNFtrivially by\ndisjunctions of terms of size nwhere each term corresponds to one of the vertices\nwhose value is 1. Whereas there are 22n\nfunctions of ndimensions in DNF (since\nany Boolean function can be written in DNF), there are just 2 O(nk) functions\nin k-DNF.\nAll Boolean functions can also be represented in DNF in which each term is\na prime implicant, but that representation is not unique, as shown in Fig. 2.4.\nIf we can express a function in DNF form, we can use the consensus method\nto \ufb01nd an expression for the function in which each term is a prime implicant.\nThe consensus method relies on two results: We may replace this section with\none describing the\nQuine-McCluskey method instead. Consensus:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 28, 'page_label': '29'}, page_content='20 CHAPTER 2. BOOLEAN FUNCTIONS\nx2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x1x2\n   = x1x2 + x1x3\nAll of the terms are prime implicants, but there\nis not a unique representation\nFigure 2.4: Non-Uniqueness of Representation by Prime Implicants\nxi ·f1 + xi ·f2 = xi ·f1 + xi ·f2 + f1 ·f2\nwhere f1 and f2 are terms such that no literal appearing in f1 appears\ncomplemented in f2. f1 ·f2 is called the consensus of xi ·f1 and xi ·\nf2. Readers familiar with the resolution rule of inference will note that\nconsensus is the dual of resolution.\nExamples: x1 is the consensus of x1x2 and x1x2. The terms x1x2 and x1x2\nhave no consensus since each term has more than one literal appearing\ncomplemented in the other.\n Subsumption:\nxi ·f1 + f1 = f1\nwhere f1 is a term. We say that f1 subsumes xi ·f1.\nExample: x1 x4x5 subsumes x1 x4 x2x5'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 29, 'page_label': '30'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 21\nThe consensus method for \ufb01nding a set of prime implicants for a function,\nf, iterates the following operations on the terms of a DNF expression for f until\nno more such operations can be applied:\na. initialize the process with the set, T, of terms in the DNF expression of\nf,\nb. compute the consensus of a pair of terms in T and add the result to T,\nc. eliminate any terms in T that are subsumed by other terms in T.\nWhen this process halts, the terms remaining in T are all prime implicants of\nf.\nExample: Let f = x1x2 + x1 x2x3 + x1 x2 x3 x4x5. We show a derivation of\na set of prime implicants in the consensus tree of Fig. 2.5. The circled numbers\nadjoining the terms indicate the order in which the consensus and subsumption\noperations were performed. Shaded boxes surrounding a term indicate that it\nwas subsumed. The \ufb01nal form of the function in which all terms are prime\nimplicants is: f = x1x2 + x1x3 + x1 x4x5. Its terms are all of the non-subsumed\nterms in the consensus tree.\n x1x2 x1x2x3 x1x2x3x4x5\n x1x3\nx1x2x4x5\nx1x4x5\nf =  x1x2 + + x1x3 x1x4x5\n1\n2\n6\n4\n5\n3\nFigure 2.5: A Consensus Tree\n2.2.3 CNF Functions\nDisjunctive normal form has a dual: conjunctive normal form (CNF). A Boolean\nfunction is said to be in CNF if it can be written as a conjunction of clauses.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 30, 'page_label': '31'}, page_content='22 CHAPTER 2. BOOLEAN FUNCTIONS\nAn example in CNF is: f = (x1 +x2)(x2 +x3 +x4). A CNF expression is called\na k-clause CNF expression if it is a conjunction of k clauses; it is in the class\nk-CNF if the size of its largest clause is k. The example is a 2-clause expression\nin 3-CNF. If f is written in DNF, an application of De Morgans law renders f\nin CNF, and vice versa. Because CNF and DNF are duals, there are also 2 O(nk)\nfunctions in k-CNF.\n2.2.4 Decision Lists\nRivest has proposed a class of Boolean functions calleddecision lists [Rivest, 1987].\nA decision list is written as an ordered list of pairs:\n(tq,vq)\n(tq\u22121,vq\u22121)\n···\n(ti,vi)\n···\n(t2,v2)\n(T,v1)\nwhere the vi are either 0 or 1, the ti are terms in ( x1,...,x n), and T is a term\nwhose value is 1 (regardless of the values of the xi). The value of a decision list\nis the value of vi for the \ufb01rst ti in the list that has value 1. (At least one ti will\nhave value 1, because the last one does; v1 can be regarded as a default value of\nthe decision list.) The decision list is of size k, if the size of the largest term in\nit is k. The class of decision lists of size k or less is called k-DL.\nAn example decision list is:\nf =\n(x1x2,1)\n(x1 x2x3,0)\nx2x3,1)\n(1,0)\nf has value 0 for x1 = 0, x2 = 0, and x3 = 1. It has value 1 for x1 = 1, x2 = 0,\nand x3 = 1. This function is in 3-DL.\nIt has been shown that the class k-DL is a strict superset of the union of\nk-DNF and k-CNF. There are 2 O[nkklog(n)] functions in k-DL [Rivest, 1987].\nInteresting generalizations of decision lists use other Boolean functions in\nplace of the terms, ti. For example we might use linearly separable functions in\nplace of the ti (see below and [Marchand & Golea, 1993]).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 31, 'page_label': '32'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 23\n2.2.5 Symmetric and Voting Functions\nA Boolean function is called symmetric if it is invariant under permutations\nof the input variables. For example, any function that is dependent only on\nthe number of input variables whose values are 1 is a symmetric function. The\nparity functions, which have value 1 depending on whether or not the number\nof input variables with value 1 is even or odd is a symmetric function. (The\nexclusive or function, illustrated in Fig. 2.1, is an odd-parity function of two\ndimensions. The or and and functions of two dimensions are also symmetric.)\nAn important subclass of the symmetric functions is the class of voting func-\ntions (also called m-of-nfunctions). A k-voting function has value 1 if and only\nif k or more of its n inputs has value 1. If k= 1, a voting function is the same\nas an n-sized clause; if k= n, a voting function is the same as an n-sized term;\nif k = (n+ 1)/2 for n odd or k = 1 + n/2 for n even, we have the majority\nfunction.\n2.2.6 Linearly Separable Functions\nThe linearly separable functions are those that can be expressed as follows:\nf = thresh(\nn\u2211\ni=1\nwixi,\u03b8)\nwhere wi, i= 1,...,n , are real-valued numbers called weights, \u03b8is a real-valued\nnumber called the threshold, and thresh( \u03c3,\u03b8) is 1 if \u03c3 \u2265\u03b8 and 0 otherwise.\n(Note that the concept of linearly separable functions can be extended to non-\nBoolean inputs.) The k-voting functions are all members of the class of linearly\nseparable functions in which the weights all have unit value and the threshold\ndepends on k. Thus, terms and clauses are special cases of linearly separable\nfunctions.\nA convenient way to write linearly separable functions uses vector notation:\nf = thresh(X ·W,\u03b8)\nwhere X = ( x1,...,x n) is an n-dimensional vector of input variables, W =\n(w1,...,w n) is an n-dimensional vector of weight values, and X ·W is the dot\n(or inner) product of the two vectors. Input vectors for which f has value 1 lie\nin a half-space on one side of (and on) a hyperplane whose orientation is normal\nto W and whose position (with respect to the origin) is determined by \u03b8. We\nsaw an example of such a separating plane in Fig. 1.6. With this idea in mind,\nit is easy to see that two of the functions in Fig. 2.1 are linearly separable, while\ntwo are not. Also note that the terms in Figs. 2.3 and 2.4 are linearly separable\nfunctions as evidenced by the separating planes shown.\nThere is no closed-form expression for the number of linearly separable func-\ntions of n dimensions, but the following table gives the numbers for n up to 6.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 32, 'page_label': '33'}, page_content='24 CHAPTER 2. BOOLEAN FUNCTIONS\nn Boolean Linearly Separable\nFunctions Functions\n1 4 4\n2 16 14\n3 256 104\n4 65,536 1,882\n5 \u22484.3 ×109 94,572\n6 \u22481.8 ×1019 15,028,134\n[Muroga, 1971] has shown that (for n> 1) there are no more than 2 n2\nlinearly\nseparable functions of n dimensions. (See also [Winder, 1961, Winder, 1962].)\n2.3 Summary\nThe diagram in Fig. 2.6 shows some of the set inclusions of the classes of Boolean\nfunctions that we have considered. We will be confronting these classes again\nin later chapters.\nDNF\n(All)\nk-DLk-DNFk-size-\nterms\nterms\nlin sep\nFigure 2.6: Classes of Boolean Functions\nThe sizes of the various classes are given in the following table (adapted from\n[Dietterich, 1990, page 262]):'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 33, 'page_label': '34'}, page_content='2.4. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 25\nClass Size of Class\nterms 3n\nclauses 3n\nk-term DNF 2O(kn)\nk-clause CNF 2O(kn)\nk-DNF 2O(nk)\nk-CNF 2O(nk)\nk-DL 2O[nkklog(n)]\nlin sep 2O(n2)\nDNF 22n\n2.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 34, 'page_label': '35'}, page_content='26 CHAPTER 2. BOOLEAN FUNCTIONS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 35, 'page_label': '36'}, page_content='Chapter 3\nUsing Version Spaces for\nLearning\n3.1 Version Spaces and Mistake Bounds\nThe \ufb01rst learning methods we present are based on the concepts of version\nspaces and version graphs. These ideas are most clearly explained for the case\nof Boolean function learning. Given an initial hypothesis set H(a subset of\nall Boolean functions) and the values of f(X) for each X in a training set, \u039e,\nthe version space is that subset of hypotheses, Hv, that is consistent with these\nvalues. A hypothesis, h, is consistent with the values of X in \u039e if and only if\nh(X) = f(X) for all X in \u039e. We say that the hypotheses in Hthat are not\nconsistent with the values in the training set are ruled out by the training set.\nWe could imagine (conceptually only!) that we have devices for implement-\ning every function in H. An incremental training procedure could then be\nde\ufb01ned which presented each pattern in \u039e to each of these functions and then\neliminated those functions whose values for that pattern did not agree with its\ngiven value. At any stage of the process we would then have left some subset\nof functions that are consistent with the patterns presented so far; this subset\nis the version space for the patterns already presented. This idea is illustrated\nin Fig. 3.1.\nConsider the following procedure for classifying an arbitrary input pattern,\nX: the pattern is put in the same class (0 or 1) as are the majority of the\noutputs of the functions in the version space. During the learning procedure,\nif this majority is not equal to the value of the pattern presented, we say a\nmistake is made, and we revise the version space accordinglyeliminating all\nthose (majority of the) functions voting incorrectly. Thus, whenever a mistake\nis made, we rule out at least half of the functions remaining in the version space.\nHow many mistakes can such a procedure make? Obviously, we can make\nno more than log 2(|H|) mistakes, where |H|is the number of hypotheses in the\n27'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 36, 'page_label': '37'}, page_content='28 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nh1\nh2\nhi\nhK\nX\nA Subset, H,  of all\nBoolean Functions\nRule out hypotheses not\nconsistent with training patterns\nhj\nHypotheses not ruled out\nconstitute the version space\nK = |H|\n1 or 0\nFigure 3.1: Implementing the Version Space\noriginal hypothesis set, H. (Note, though, that the number of training patterns\nseen before this maximum number of mistakes is made might be much greater.)\nThis theoretical (and very impractical!) result (due to [Littlestone, 1988]) is an\nexample of a mistake boundan important concept in machine learning theory.\nIt shows that there must exist a learning procedure that makes no more mistakes\nthan this upper bound. Later, well derive other mistake bounds.\nAs a special case, if our bias was to limit Hto terms, we would make no\nmore than log2(3n) = nlog2(3) = 1.585nmistakes before exhausting the version\nspace. This result means that if f were a term, we would make no more than\n1.585nmistakes before learning f, and otherwise we would make no more than\nthat number of mistakes before being able to decide that f is not a term.\nEven if we do not have su\ufb03cient training patterns to reduce the version\nspace to a single function, it may be that there are enough training patterns\nto reduce the version space to a set of functions such that most of them assign\nthe same values to most of the patterns we will see henceforth. We could select\none of the remaining functions at random and be reasonably assured that it\nwill generalize satisfactorily. We next discuss a computationally more feasible\nmethod for representing the version space.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 37, 'page_label': '38'}, page_content='3.2. VERSION GRAPHS 29\n3.2 Version Graphs\nBoolean functions can be ordered by generality. A Boolean function, f1, is more\ngeneral than a function, f2, (and f2 is more speci\ufb01c than f1), if f1 has value 1\nfor all of the arguments for which f2 has value 1, and f1 \u0338= f2. For example, x3\nis more general than x2x3 but is not more general than x3 + x2.\nWe can form a graph with the hypotheses, {hi}, in the version space as\nnodes. A node in the graph, hi, has an arc directed to node, hj, if and only if\nhj is more general than hi. We call such a graph a version graph. In Fig. 3.2,\nwe show an example of a version graph over a 3-dimensional input space for\nhypotheses restricted to terms (with none of them yet ruled out).\n0\nx1 x2x 3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nVersion Graph for Terms\nx1\nx2\nx3\n(for simplicity, only some arcs in the graph are shown)\n(none yet ruled out)\n(k = 1)\n(k = 2)\n(k = 3)\nx1 x3\nFigure 3.2: A Version Graph for Terms\nThat function, denoted here by 1, which has value 1 for all inputs, corre-\nsponds to the node at the top of the graph. (It is more general than any other\nterm.) Similarly, the function 0 is at the bottom of the graph. Just below\n1 is a row of nodes corresponding to all terms having just one literal, and just\nbelow them is a row of nodes corresponding to terms having two literals, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 38, 'page_label': '39'}, page_content='30 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nso on. There are 3 3 = 27 functions altogether (the function 0, included in\nthe graph, is technically not a term). To make our portrayal of the graph less\ncluttered only some of the arcs are shown; each node in the actual graph has an\narc directed to all of the nodes above it that are more general.\nWe use this same example to show how the version graph changes as we\nconsider a set of labeled samples in a training set, \u039e. Suppose we \ufb01rst consider\nthe training pattern (1, 0, 1) with value 0. Some of the functions in the version\ngraph of Fig. 3.2 are inconsistent with this training pattern. These ruled out\nnodes are no longer in the version graph and are shown shaded in Fig. 3.3. We\nalso show there the three-dimensional cube representation in which the vertex\n(1, 0, 1) has value 0.\n0\nx1 x2 x3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nNew Version Graph\n1, 0, 1 has\nvalue 0\nx1x3\nx1x2 x2x3\nx1x2x3\nx1\nx2\nx3\nx1x3\n(only some arcs in the graph are shown)\nruled out nodes\nFigure 3.3: The Version Graph Upon Seeing (1, 0, 1)\nIn a version graph, there are always a set of hypotheses that are maximally\ngeneral and a set of hypotheses that are maximally speci\ufb01c. These are called\nthe general boundary set (gbs) and the speci\ufb01c boundary set (sbs) , respectively.\nIn Fig. 3.4, we have the version graph as it exists after learning that (1,0,1) has\nvalue 0 and (1, 0, 0) has value 1. The gbs and sbs are shown.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 39, 'page_label': '40'}, page_content='3.2. VERSION GRAPHS 31\n0\nx1 x2\nx3\nx2 x3\n1\nx1x2 x3\nx1\nx2x3x1x3\ngeneral boundary set\n(gbs)\nspecific boundary set (sbs)\nx1x2\nmore specific than gbs,\nmore general than sbs\n1, 0, 1 has\nvalue 0\nx1\nx2\nx3\n1, 0, 0 has\nvalue 1\nFigure 3.4: The Version Graph Upon Seeing (1, 0, 1) and (1, 0, 0)\nBoundary sets are important because they provide an alternative to repre-\nsenting the entire version space explicitly, which would be impractical. Given\nonly the boundary sets, it is possible to determine whether or not any hypoth-\nesis (in the prescribed class of Boolean functions we are using) is a member or\nnot of the version space. This determination is possible because of the fact that\nany member of the version space (that is not a member of one of the boundary\nsets) is more speci\ufb01c than some member of the general boundary set and is more\ngeneral than some member of the speci\ufb01c boundary set.\nIf we limit our Boolean functions that can be in the version space to terms,\nit is a simple matter to determine maximally general and maximally speci\ufb01c\nfunctions (assuming that there is some term that is in the version space). A\nmaximally speci\ufb01c one corresponds to a subface of minimal dimension that\ncontains all the members of the training set labelled by a 1 and no members\nlabelled by a 0. A maximally general one corresponds to a subface of maximal\ndimension that contains all the members of the training set labelled by a 1 and\nno members labelled by a 0. Looking at Fig. 3.4, we see that the subface of\nminimal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is just\nthe vertex (1, 0, 0) itselfcorresponding to the function x1x2 x3. The subface'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 40, 'page_label': '41'}, page_content='32 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nof maximal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is\nthe bottom face of the cubecorresponding to the function x3. In Figs. 3.2\nthrough 3.4 the sbs is always singular. Version spaces for terms always have\nsingular speci\ufb01c boundary sets. As seen in Fig. 3.3, however, the gbs of a\nversion space for terms need not be singular.\n3.3 Learning as Search of a Version Space\n[To be written. Relate to term learning algorithm presented in Chapter\nTwo. Also discuss best-\ufb01rst search methods. See Pat Langleys example us-\ning pseudo-cells of how to generate and eliminate hypotheses.]\nSelecting a hypothesis from the version space can be thought of as a search\nproblem. One can start with a very general function and specialize it through\nvarious specialization operators until one \ufb01nds a function that is consistent (or\nadequately so) with a set of training patterns. Such procedures are usually\ncalled top-down methods. Or, one can start with a very special function and\ngeneralize itresulting in bottom-up methods. We shall see instances of both\nstyles of learning in this book.Compare this view of top-down\nversus bottom-up with the\ndivide-and-conquer and the\ncovering (or AQ) methods of\ndecision-tree induction. 3.4 The Candidate Elimination Method\nThe candidate elimination method, is an incremental method for computing the\nboundary sets. Quoting from [Hirsh, 1994, page 6]:\nThe candidate-elimination algorithm manipulates the boundary-set\nrepresentation of a version space to create boundary sets that rep-\nresent a new version space consistent with all the previous instances\nplus the new one. For a positive exmple the algorithm generalizes\nthe elements of the [sbs] as little as possible so that they cover the\nnew instance yet remain consistent with past data, and removes\nthose elements of the [gbs] that do not cover the new instance. For\na negative instance the algorithm specializes elements of the [gbs]\nso that they no longer cover the new instance yet remain consis-\ntent with past data, and removes from the [sbs] those elements that\nmistakenly cover the new, negative instance.\nThe method uses the following de\ufb01nitions (adapted from\n[Genesereth & Nilsson, 1987]):\n a hypothesis is called su\ufb03cient if and only if it has value 1 for all training\nsamples labeled by a 1,\n a hypothesis is called necessary if and only if it has value 0 for all training\nsamples labeled by a 0.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 41, 'page_label': '42'}, page_content='3.4. THE CANDIDATE ELIMINATION METHOD 33\nHere is how to think about these de\ufb01nitions: A hypothesis implements a su\ufb03-\ncient condition that a training sample has value 1 if the hypothesis has value 1\nfor all of the positive instances; a hypothesis implements a necessary condition\nthat a training sample has value 1 if the hypothesis has value 0 for all of the\nnegative instances. A hypothesis is consistent with the training set (and thus is\nin the version space) if and only if it is both su\ufb03cient and necessary.\nWe start (before receiving any members of the training set) with the function\n0 as the singleton element of the speci\ufb01c boundary set and with the function\n1 as the singleton element of the general boundary set. Upon receiving a new\nlabeled input vector, the boundary sets are changed as follows:\na. If the new vector is labelled with a 1:\nThe new general boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not su\ufb03cient. (That is, we exclude any\nelements that have value 0 for the new vector.)\nThe new speci\ufb01c boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least generalizations.\nThe hypothesis hg is a least generalization of h if and only if: a) h is\nmore speci\ufb01c than hg, b) hg is su\ufb03cient, c) no function (including h) that\nis more speci\ufb01c than hg is su\ufb03cient, and d) hg is more speci\ufb01c than some\nmember of the new general boundary set. It might be that hg = h. Also,\nleast generalizations of two di\ufb00erent functions in the speci\ufb01c boundary set\nmay be identical.\nb. If the new vector is labelled with a 0:\nThe new speci\ufb01c boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not necessary. (That is, we exclude\nany elements that have value 1 for the new vector.)\nThe new general boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least specializations.\nThe hypothesis hs is a least specialization of hif and only if: a) his more\ngeneral than hs, b) hs is necessary, c) no function (including h) that is\nmore general than hs is necessary, and d) hs is more general than some\nmember of the new speci\ufb01c boundary set. Again, it might be that hs = h,\nand least specializations of two di\ufb00erent functions in the general boundary\nset may be identical.\nAs an example, suppose we present the vectors in the following order:\nvector label\n(1, 0, 1) 0\n(1, 0, 0) 1\n(1, 1, 1) 0\n(0, 0, 1) 0'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 42, 'page_label': '43'}, page_content='34 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nWe start with general boundary set, 1, and speci\ufb01c boundary set, 0.\nAfter seeing the \ufb01rst sample, (1, 0, 1), labeled with a 0, the speci\ufb01c boundary\nset stays at 0 (it is necessary), and we change the general boundary set to\n{x1,x2,x3}. Each of the functions, x1, x2, and x3, are least specializations of\n1 (they are necessary, 1 is not, they are more general than 0, and there\nare no functions that are more general than they and also necessary).\nThen, after seeing (1, 0, 0), labeled with a 1, the general boundary set\nchanges to {x3}(because x1 and x2 are not su\ufb03cient), and the speci\ufb01c boundary\nset is changed to {x1x2 x3}. This single function is a least generalization of 0\n(it is su\ufb03cient, 0 is more speci\ufb01c than it, no function (including 0) that is\nmore speci\ufb01c than it is su\ufb03cient, and it is more speci\ufb01c than some member of\nthe general boundary set.\nWhen we see (1, 1, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the\ngeneral boundary set either because x3 is still necessary.\nFinally, when we see (0, 0, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the general\nboundary set either because x3 is still necessary.Maybe Ill put in an example of a\nversion graph for non-Boolean\nfunctions.\n3.5 Bibliographical and Historical Remarks\nThe concept of version spaces and their role in learning was \ufb01rst investigated\nby Tom Mitchell [Mitchell, 1982]. Although these ideas are not used in prac-\ntical machine learning procedures, they do provide insight into the nature of\nhypothesis selection. In order to accomodate noisy data, version spaces have\nbeen generalized by [Hirsh, 1994] to allow hypotheses that are not necessarily\nconsistent with the training set.More to be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 43, 'page_label': '44'}, page_content='Chapter 4\nNeural Networks\nIn chapter two we de\ufb01ned several important subsets of Boolean functions. Sup-\npose we decide to use one of these subsets as a hypothesis set for supervised\nfunction learning. We next have the question of how best to implement the\nfunction as a device that gives the outputs prescribed by the function for arbi-\ntrary inputs. In this chapter we describe how networks of non-linear elements\ncan be used to implement various input-output functions and how they can be\ntrained using supervised learning methods.\nNetworks of non-linear elements, interconnected through adjustable weights,\nplay a prominent role in machine learning. They are called neural networks be-\ncause the non-linear elements have as their inputs a weighted sum of the outputs\nof other elementsmuch like networks of biological neurons do. These networks\ncommonly use the threshold element which we encountered in chapter two in\nour study of linearly separable Boolean functions. We begin our treatment of\nneural nets by studying this threshold element and how it can be used in the\nsimplest of all networks, namely ones composed of a single threshold element.\n4.1 Threshold Logic Units\n4.1.1 De\ufb01nitions and Geometry\nLinearly separable (threshold) functions are implemented in a straightforward\nway by summing the weighted inputs and comparing this sum to a threshold\nvalue as shown in Fig. 4.1. This structure we call a threshold logic unit (TLU) .\nIts output is 1 or 0 depending on whether or not the weighted sum of its inputs is\ngreater than or equal to a threshold value, \u03b8. It has also been called an Adaline\n(for ada ptive lin ear e lement) [Widrow, 1962, Widrow & Lehr, 1990], an LTU\n(linear threshold unit), a perceptron, and a neuron. (Although the word per-\nceptron is often used nowadays to refer to a single TLU, Rosenblatt originally\nde\ufb01ned it as a class of networks of threshold elements [Rosenblatt, 1958].)\n35'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 44, 'page_label': '45'}, page_content='36 CHAPTER 4. NEURAL NETWORKS\n!\nx1\nx2\nxn+1 = 1\nxi\nw1\nw2\nwn+1\nwi\nwn\nX\nthreshold weight\nxn\nW threshold  "  = 0\nf\nf = thresh( ! wi xi,  0)\ni = 1\nn+1\nFigure 4.1: A Threshold Logic Unit (TLU)\nThe n-dimensional feature or input vector is denoted by X = (x1,...,x n).\nWhen we want to distinguish among di\ufb00erent feature vectors, we will attach\nsubscripts, such as Xi. The components of X can be any real-valued numbers,\nbut we often specialize to the binary numbers 0 and 1. The weights of a TLU\nare represented by an n-dimensional weight vector , W = ( w1,...,w n). Its\ncomponents are real-valued numbers (but we sometimes specialize to integers).\nThe TLU has output 1 if \u2211n\ni=1 xiwi \u2265 \u03b8; otherwise it has output 0. The\nweighted sum that is calculated by the TLU can be simply represented as a\nvector dot product, XW. (If the pattern and weight vectors are thought of as\ncolumn vectors, this dot product is then sometimes written as XtW, where\nthe row vector Xt is the transpose of X.) Often, the threshold, \u03b8, of the TLU\nis \ufb01xed at 0; in that case, arbitrary thresholds are achieved by using ( n+ 1)-\ndimensional augmented vectors, Y, and V, whose \ufb01rst ncomponents are the\nsame as those of X and W, respectively. The ( n+ 1)-st component, xn+1, of\nthe augmented feature vector, Y, always has value 1; the (n+ 1)-st component,\nwn+1, of the augmented weight vector, V, is set equal to the negative of the\ndesired threshold value. (When we want to emphasize the use of augmented\nvectors, well use the Y,V notation; however when the context of the discussion\nmakes it clear about what sort of vectors we are talking about, well lapse back\ninto the more familiar X,W notation.) In the Y,V notation, the TLU has an\noutput of 1 if YV \u22650. Otherwise, the output is 0.\nWe can give an intuitively useful geometric description of a TLU. A TLU\ndivides the input space by a hyperplane as sketched in Fig. 4.2. The hyperplane\nis the boundary between patterns for which XW + wn+1 > 0 and patterns\nfor which XW + wn+1 < 0. Thus, the equation of the hyperplane itself is\nXW+wn+1 = 0. The unit vector that is normal to the hyperplane is n = W\n|W|,\nwhere |W|=\n\u221a\n(w2\n1 + ... + w2n) is the length of the vector W. (The normal'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 45, 'page_label': '46'}, page_content='4.1. THRESHOLD LOGIC UNITS 37\nform of the hyperplane equation is Xn + W\n|W| = 0.) The distance from the\nhyperplane to the origin is wn+1\n|W|, and the distance from an arbitrary point, X,\nto the hyperplane is XW+wn+1\n|W| . When the distance from the hyperplane to the\norigin is negative (that is, when wn+1 < 0), then the origin is on the negative\nside of the hyperplane (that is, the side for which XW + wn+1 <0).\nX.W + wn+1 > 0\non this side\nW\nX\nW\nn = W\n|W|\nOrigin\nUnit vector normal\nto hyperplane\nW + wn+1 = 0X\nn +           = 0X\nEquations of hyperplane:\nwn+1\n|W|\nwn+1 W + wn+1X\nX.W + wn+1 < 0\non this side\nFigure 4.2: TLU Geometry\nAdjusting the weight vector, W, changes the orientation of the hyperplane;\nadjusting wn+1 changes the position of the hyperplane (relative to the origin).\nThus, training of a TLU can be achieved by adjusting the values of the weights.\nIn this way the hyperplane can be moved so that the TLU implements di\ufb00erent\n(linearly separable) functions of the input.\n4.1.2 Special Cases of Linearly Separable Functions\nTerms\nAny term of size k can be implemented by a TLU with a weight from each of\nthose inputs corresponding to variables occurring in the term. A weight of +1 is\nused from an input corresponding to a positive literal, and a weight of\u22121 is used\nfrom an input corresponding to a negative literal. (Literals not mentioned in\nthe term have weights of zerothat is, no connection at allfrom their inputs.)\nThe threshold, \u03b8, is set equal to kp \u22121/2, where kp is the number of positive\nliterals in the term. Such a TLU implements a hyperplane boundary that is'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 46, 'page_label': '47'}, page_content='38 CHAPTER 4. NEURAL NETWORKS\nparallel to a subface of dimension ( n\u2212k) of the unit hypercube. We show a\nthree-dimensional example in Fig. 4.3. Thus, linearly separable functions are a\nsuperset of terms.\n(1,1,1)\n(1,1,0)\nx2\nx1\nx3 f = x1x2\nx1 + x2 - 3/2 = 0\nEquation of plane is:\nFigure 4.3: Implementing a Term\nClauses\nThe negation of a clause is a term. For example, the negation of the clause\nf = x1 + x2 + x3 is the term f = x1 x2 x3. A hyperplane can be used to\nimplement this term. If we invert the hyperplane, it will implement the\nclause instead. Inverting a hyperplane is done by multiplying all of the TLU\nweightseven wn+1by \u22121. This process simply changes the orientation of the\nhyperplane\ufb02ipping it around by 180 degrees and thus changing its positive\nside. Therefore, linearly separable functions are also a superset of clauses. We\nshow an example in Fig. 4.4.\n4.1.3 Error-Correction Training of a TLU\nThere are several procedures that have been proposed for adjusting the weights\nof a TLU. We present next a family of incremental training procedures with\nparameter c. These methods make adjustments to the weight vector only when\nthe TLU being trained makes an error on a training pattern; they are called\nerror-correction procedures. We use augmented feature and weight vectors in\ndescribing them.\na. We start with a \ufb01nite training set, \u039e, of vectors, Yi , and their binary\nlabels.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 47, 'page_label': '48'}, page_content='4.1. THRESHOLD LOGIC UNITS 39\nf = x1 + x2 + x3\nx1\nx1 + x2 + x3 < 1/2 = 0\nf = x1x2x3\nEquation of plane is:\nx2\nx3\nFigure 4.4: Implementing a Clause\nb. Compose an in\ufb01nite training sequence, \u03a3, of vectors from \u039e and their\nlabels such that each member of \u039e occurs in\ufb01nitely often in \u03a3. Set the\ninitial weight values of an TLU to arbitrary values.\nc. Repeat forever:\nPresent the next vector, Yi, in \u03a3 to the TLU and note its response.\n(a) If the TLU responds correctly, make no change in the weight vector.\n(b) If Yi is supposed to produce an output of 0 and produces an output\nof 1 instead, modify the weight vector as follows:\nV \u2190\u2212V \u2212ciYi\nwhere ci is a positive real number called the learning rate parame-\nter (whose value is di\ufb00ererent in di\ufb00erent instances of this family of\nprocedures and may depend on i).\nNote that after this adjustment the new dot product will be ( V \u2212\nciYi)Yi = VYi\u2212ciYiYi, which is smaller than it was before the\nweight adjustment.\n(c) If Yi is supposed to produce an output of 1 and produces an output\nof 0 instead, modify the weight vector as follows:\nV \u2190\u2212V + ciYi\nIn this case, the new dot product will be ( V + ciYi)Yi = VYi +\nciYiYi, which is larger than it was before the weight adjustment.\nNote that all three of these cases can be combined in the following rule:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 48, 'page_label': '49'}, page_content='40 CHAPTER 4. NEURAL NETWORKS\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere di is the desired response (1 or 0) for Yi , and fi is the actual\nresponse (1 or 0) for Yi.]\nNote also that because the weight vector V now includes the wn+1 thresh-\nold component, the threshold of the TLU is also changed by these adjust-\nments.\nWe identify two versions of this procedure:\n1) In the \ufb01xed-increment procedure, the learning rate parameter, ci, is the\nsame \ufb01xed, positive constant for all i. Depending on the value of this constant,\nthe weight adjustment may or may not correct the response to an erroneously\nclassi\ufb01ed feature vector.\n2) In the fractional-correction procedure, the parameter ci is set to \u03bbYiV\nYiYi\n,\nwhere V is the weight vector before it is changed. Note that if \u03bb = 0, no\ncorrection takes place at all. If \u03bb = 1, the correction is just su\ufb03cient to make\nYiV = 0. If \u03bb> 1, the error will be corrected.\nIt can be proved that if there is some weight vector, V, that produces a\ncorrect output for all of the feature vectors in \u039e, then after a \ufb01nite number\nof feature vector presentations, the \ufb01xed-increment procedure will \ufb01nd such a\nweight vector and thus make no more weight changes. The same result holds\nfor the fractional-correction procedure if 1 <\u03bb \u22642.\nFor additional background, proofs, and examples of error-correction proce-\ndures, see [Nilsson, 1990].See [Maass & Tur´ an, 1994] for a\nhyperplane-\ufb01nding procedure that\nmakes no more than O(n2 log n)\nmistakes.\n4.1.4 Weight Space\nWe can give an intuitive idea about how these procedures work by considering\nwhat happens to the augmented weight vector in weight space as corrections\nare made. We use augmented vectors in our discussion here so that the threshold\nfunction compares the dot product, YiV, against a threshold of 0. A particular\nweight vector, V, then corresponds to a point in ( n+ 1)-dimensional weight\nspace. Now, for any pattern vector, Yi, consider the locus of all points in\nweight space corresponding to weight vectors yielding YiV = 0. This locus is\na hyperplane passing through the origin of the ( n+ 1)-dimensional space. Each\npattern vector will have such a hyperplane corresponding to it. Weight points\nin one of the half-spaces de\ufb01ned by this hyperplane will cause the corresponding\npattern to yield a dot product less than 0, and weight points in the other half-\nspace will cause the corresponding pattern to yield a dot product greater than\n0.\nWe show a schematic representation of such a weight space in Fig. 4.5.\nThere are four pattern hyperplanes, 1, 2, 3, 4 , corresponding to patterns Y1,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 49, 'page_label': '50'}, page_content='4.1. THRESHOLD LOGIC UNITS 41\nY2, Y3, Y4, respectively, and we indicate by an arrow the half-space for each\nin which weight vectors give dot products greater than 0. Suppose we wanted\nweight values that would give positive responses for patterns Y1, Y3, and Y4,\nand a negative response for pattern Y2. The weight point, V, indicated in the\n\ufb01gure is one such set of weight values.\n23\n4\n1\nV\nFigure 4.5: Weight Space\nThe question of whether or not there exists a weight vector that gives desired\nresponses for a given set of patterns can be given a geometric interpretation. To\ndo so involves reversing the polarity of those hyperplanes corresponding to\npatterns for which a negative response is desired. If we do that for our example\nabove, we get the weight space diagram shown in Fig. 4.6.\n23\n4\n1\nV\n0\n1\n1\n23\n2\n3\n4\nFigure 4.6: Solution Region in Weight Space'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 50, 'page_label': '51'}, page_content='42 CHAPTER 4. NEURAL NETWORKS\nIf a weight vector exists that correctly classi\ufb01es a set of patterns, then the\nhalf-spaces de\ufb01ned by the correct responses for these patterns will have a non-\nempty intersection, called the solution region. The solution region will be a\nhyper-wedge region whose vertex is at the origin of weight space and whose\ncross-section increases with increasing distance from the origin. This region\nis shown shaded in Fig. 4.6. (The boxed numbers show, for later purposes,\nthe number of errors made by weight vectors in each of the regions.) The\n\ufb01xed-increment error-correction procedure changes a weight vector by moving it\nnormal to any pattern hyperplane for which that weight vector gives an incorrect\nresponse. Suppose in our example that we present the patterns in the sequence\nY1, Y2, Y3, Y4, and start the process with a weight point V1, as shown in Fig.\n4.7. Starting at V1, we see that it gives an incorrect response for pattern Y1, so\nwe move V1 to V2 in a direction normal to plane 1. (That is what adding Y1 to\nV1 does.) Y2 gives an incorrect response for pattern Y2, and so on. Ultimately,\nthe responses are only incorrect for planes bounding the solution region. Some\nof the subsequent corrections may overshoot the solution region, but eventually\nwe work our way out far enough in the solution region that corrections (for\na \ufb01xed increment size) take us within it. The proofs for convergence of the\n\ufb01xed-increment rule make this intuitive argument precise.\n23\n4\n1\nV\nV1\nV2\nV3\nV4\nV5\nV6\nFigure 4.7: Moving Into the Solution Region\n4.1.5 The Widrow-Ho\ufb00 Procedure\nThe Widrow-Ho\ufb00 procedure (also called the LMS or the delta procedure) at-\ntempts to \ufb01nd weights that minimize a squared-error function between the pat-\ntern labels and the dot product computed by a TLU. For this purpose, the\npattern labels are assumed to be either +1 or \u22121 (instead of 1 or 0). The'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 51, 'page_label': '52'}, page_content='4.1. THRESHOLD LOGIC UNITS 43\nsquared error for a pattern, Xi, with label di (for desired output) is:\n\u03b5i = (di \u2212\nn+1\u2211\nj=1\nxijwj)2\nwhere xij is the j-th component of Xi. The total squared error (over all patterns\nin a training set, \u039e, containing m patterns) is then:\n\u03b5=\nm\u2211\ni=1\n(di \u2212\nn+1\u2211\nj=1\nxijwj)2\nWe want to choose the weightswj to minimize this squared error. One way to\n\ufb01nd such a set of weights is to start with an arbitrary weight vector and move it\nalong the negative gradient of\u03b5as a function of the weights. Since \u03b5is quadratic\nin the wj, we know that it has a global minimum, and thus this steepest descent\nprocedure is guaranteed to \ufb01nd the minimum. Each component of the gradient\nis the partial derivative of \u03b5 with respect to one of the weights. One problem\nwith taking the partial derivative of \u03b5is that \u03b5depends on all the input vectors\nin \u039e. Often, it is preferable to use an incremental procedure in which we try the\nTLU on just one element, Xi, of \u039e at a time, compute the gradient of the single-\npattern squared error, \u03b5i, make the appropriate adjustment to the weights, and\nthen try another member of \u039e. Of course, the results of the incremental version\ncan only approximate those of the batch one, but the approximation is usually\nquite e\ufb00ective. We will be describing the incremental version here.\nThe j-th component of the gradient of the single-pattern error is:\n\u2202\u03b5i\n\u2202wj\n= \u22122(di \u2212\nn+1\u2211\nj=1\nxijwj)xij\nAn adjustment in the direction of the negative gradient would then change each\nweight as follows:\nwj \u2190\u2212wj + ci(di \u2212fi)xij\nwhere fi = \u2211n+1\nj=1 xijwj, and ci governs the size of the adjustment. The entire\nweight vector (in augmented, or V, notation) is thus adjusted according to the\nfollowing rule:\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere, as before, Yi is the i-th augmented pattern vector.\nThe Widrow-Ho\ufb00 procedure makes adjustments to the weight vector when-\never the dot product itself, YiV, does not equal the speci\ufb01ed desired target'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 52, 'page_label': '53'}, page_content='44 CHAPTER 4. NEURAL NETWORKS\nvalue, di (which is either 1 or \u22121). The learning-rate factor, ci, might de-\ncrease with time toward 0 to achieve asymptotic convergence. The Widrow-\nHo\ufb00 formula for changing the weight vector has the same form as the standard\n\ufb01xed-increment error-correction formula. The only di\ufb00erence is that fi is the\nthresholded response of the TLU in the error-correction case while it is the dot\nproduct itself for the Widrow-Ho\ufb00 procedure.\nFinding weight values that give the desired dot products corresponds to solv-\ning a set of linear equalities, and the Widrow-Ho\ufb00 procedure can be interpreted\nas a descent procedure that attempts to minimize the mean-squared-error be-\ntween the actual and desired values of the dot product. (For more on Widrow-\nHo\ufb00 and other related procedures, see [Duda & Hart, 1973, pp. 151\ufb00].)Examples of training curves for\nTLUs; performance on training\nset; performance on test set;\ncumulative number of corrections. 4.1.6 Training a TLU on Non-Linearly-Separable Training\nSets\nWhen the training set is not linearly separable (perhaps because of noise or\nperhaps inherently), it may still be desired to \ufb01nd a best separating hy-\nperplane. Typically, the error-correction procedures will not do well on non-\nlinearly-separable training sets because they will continue to attempt to correct\ninevitable errors, and the hyperplane will never settle into an acceptable place.\nSeveral methods have been proposed to deal with this case. First, we might\nuse the Widrow-Ho\ufb00 procedure, which (although it will not converge to zero\nerror on non-linearly separable problems) will give us a weight vector that min-\nimizes the mean-squared-error. A mean-squared-error criterion often gives un-\nsatisfactory results, however, because it prefers many small errors to a few large\nones. As an alternative, error correction with a continuous decrease toward zero\nof the value of the learning rate constant,c, will result in ever decreasing changes\nto the hyperplane. Duda [Duda, 1966] has suggested keeping track of the average\nvalue of the weight vector during error correction and using this average to give a\nseparating hyperplane that performs reasonably well on non-linearly-separable\nproblems. Gallant [Gallant, 1986] proposed what he called the pocket algo-\nrithm. As described in [Hertz, Krogh, & Palmer, 1991, p. 160]:\n. . . the pocket algorithm . . . consists simply in storing (or putting\nin your pocket) the set of weights which has had the longest un-\nmodi\ufb01ed run of successes so far. The algorithm is stopped after some\nchosen time t . . .\nAfter stopping, the weights in the pocket are used as a set that should give a\nsmall number of errors on the training set. Error-correction proceeds as usual\nwith the ordinary set of weights.Also see methods proposed by\n[John, 1995] and by\n[Marchand & Golea, 1993]. The\nlatter is claimed to outperform the\npocket algorithm. 4.2 Linear Machines\nThe natural generalization of a (two-category) TLU to an R-category classi\ufb01er\nis the structure, shown in Fig. 4.8, called a linear machine. Here, to use more'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 53, 'page_label': '54'}, page_content='4.2. LINEAR MACHINES 45\nfamiliar notation, the Ws and X are meant to be augmented vectors (with an\n(n+1)-st component). Such a structure is also sometimes called a competitive\nnet or a winner-take-all net. The output of the linear machine is one of\nthe numbers, {1,...,R }, corresponding to which dot product is largest. Note\nthat when R = 2, the linear machine reduces to a TLU with weight vector\nW = (W1 \u2212W2).\nX\nW1\nWR\n. . .\nY\nY\nARGMAX\nW1.X\nWR.X\nFigure 4.8: A Linear Machine\nThe diagram in Fig. 4.9 shows the character of the regions in a 2-dimensional\nspace created by a linear machine for R = 5. In n dimensions, every pair of\nregions is either separated by a section of a hyperplane or is non-adjacent.\nR 1\nR 3\nR 4\nR 5\nX.W4  * X.Wi for i & 4\nR 2\nIn this region:\nFigure 4.9: Regions For a Linear Machine\nTo train a linear machine, there is a straightforward generalization of the\n2-category error-correction rule. Assemble the patterns in the training set into\na sequence as before.\na. If the machine classi\ufb01es a pattern correctly, no change is made to any of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 54, 'page_label': '55'}, page_content='46 CHAPTER 4. NEURAL NETWORKS\nthe weight vectors.\nb. If the machine mistakenly classi\ufb01es a category u pattern, Xi, in category\nv (u\u0338= v), then:\nWu \u2190\u2212Wu + ciXi\nand\nWv \u2190\u2212Wv \u2212ciXi\nand all other weight vectors are not changed.\nThis correction increases the value of the u-th dot product and decreases the\nvalue of the v-th dot product. Just as in the 2-category \ufb01xed increment proce-\ndure, this procedure is guaranteed to terminate, for constant ci, if there exists\nweight vectors that make correct separations of the training set. Note that when\nR= 2, this procedure reduces to the ordinary TLU error-correction procedure.\nA proof that this procedure terminates is given in [Nilsson, 1990, pp. 88-90]\nand in [Duda & Hart, 1973, pp. 174-177].\n4.3 Networks of TLUs\n4.3.1 Motivation and Examples\nLayered Networks\nTo classify correctly all of the patterns in non-linearly-separable training sets re-\nquires separating surfaces more complex than hyperplanes. One way to achieve\nmore complex surfaces is with networks of TLUs. Consider, for example, the 2-\ndimensional, even parity function, f = x1x2 + x1 x2. No single line through the\n2-dimensional square can separate the vertices (1,1) and (0,0) from the vertices\n(1,0) and (0,1)the function is not linearly separable and thus cannot be im-\nplemented by a single TLU. But, the network of three TLUs shown in Fig. 4.10\ndoes implement this function. In the \ufb01gure, we show the weight values along\ninput lines to each TLU and the threshold value inside the circle representing\nthe TLU.\nThe function implemented by a network of TLUs depends on its topology\nas well as on the weights of the individual TLUs. Feedforward networks have\nno cycles; in a feedforward network no TLUs input depends (through zero\nor more intermediate TLUs) on that TLUs output. (Networks that are not\nfeedforward are calledrecurrentnetworks). If the TLUs of a feedforward network\nare arranged in layers, with the elements of layer j receiving inputs only from\nTLUs in layer j \u22121, then we say that the network is a layered, feedforward'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 55, 'page_label': '56'}, page_content='4.3. NETWORKS OF TLUS 47\nf\nx1\nx2\n1.5\n-0.5\n0.5\n1\n1-1\n-1 1\n1\nFigure 4.10: A Network for the Even Parity Function\nnetwork. The network shown in Fig. 4.10 is a layered, feedforward network\nhaving two layers (of weights). (Some people count the layers of TLUs and\ninclude the inputs as a layer also; they would call this network a three-layer\nnetwork.) In general, a feedforward, layered network has the structure shown\nin Fig. 4.11. All of the TLUs except the output units are called hidden units\n(they are hidden from the output).\nX\nhidden units\noutput units\nFigure 4.11: A Layered, Feedforward Network\nImplementing DNF Functions by Two-Layer Networks\nWe have already de\ufb01nedk-term DNF functionsthey are DNF functions having\nk terms. A k-term DNF function can be implemented by a two-layer network\nwith k units in the hidden layerto implement the k termsand one output\nunit to implement the disjunction of these terms. Since any Boolean function\nhas a DNF form, any Boolean function can be implemented by some two-layer\nnetwork of TLUs. As an example, consider the function f = x1x2 + x2x3 +\nx1x3. The form of the network that implements this function is shown in Fig.\n4.12. (We leave it to the reader to calculate appropriate values of weights and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 56, 'page_label': '57'}, page_content='48 CHAPTER 4. NEURAL NETWORKS\nthresholds.) The 3-cube representation of the function is shown in Fig. 4.13.\nThe network of Fig. 4.12 can be designed so that each hidden unit implements\none of the planar boundaries shown in Fig. 4.13.\nx\nconjuncts\ndisjunct\nA Feedforward, 2-layer Network\nTLUs\ndisjunction\nof terms\nconjunctions\nof literals\n(terms)\nFigure 4.12: A Two-Layer Network\nx2\nx1\nx3\nf = x1x2 + x2x3 + x1x3\nFigure 4.13: Three Planes Implemented by the Hidden Units\nTo train a two-layer network that implements a k-term DNF function, we\n\ufb01rst note that the output unit implements a disjunction, so the weights in the\n\ufb01nal layer are \ufb01xed. The weights in the \ufb01rst layer (except for the threshold\nweights) can all have values of 1, \u22121, or 0. Later, we will present a training\nprocedure for this \ufb01rst layer of weights.Discuss half-space intersections,\nhalf-space unions, NP-hardness of\noptimal versions,\nsingle-side-error-hypeplane\nmethods, relation to AQ\nmethods.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 57, 'page_label': '58'}, page_content='4.3. NETWORKS OF TLUS 49\nImportant Comment About Layered Networks\nAdding additional layers cannot compensate for an inadequate \ufb01rst layer of\nTLUs. The \ufb01rst layer of TLUs partitions the feature space so that no two dif-\nferently labeled vectors are in the same region (that is, so that no two such\nvectors yield the same set of outputs of the \ufb01rst-layer units). If the \ufb01rst layer\ndoes not partition the feature space in this way, then regardless of what subse-\nquent layers do, the \ufb01nal outputs will not be consistent with the labeled training\nset. Add diagrams showing the\nnon-linear transformation\nperformed by a layered network.\n4.3.2 Madalines\nTwo-Category Networks\nAn interesting example of a layered, feedforward network is the two-layer one\nwhich has an odd number of hidden units, and a vote-taking TLU as the\noutput unit. Such a network was called a Madaline (for m any adalines by\nWidrow. Typically, the response of the vote taking unit is de\ufb01ned to be the\nresponse of the majority of the hidden units, although other output logics are\npossible. Ridgway [Ridgway, 1962] proposed the following error-correction rule\nfor adjusting the weights of the hidden units of a Madaline:\n If the Madaline correctly classi\ufb01es a pattern, Xi, no corrections are made\nto any of the hidden units weight vectors,\n If the Madaline incorrectly classi\ufb01es a pattern, Xi, then determine the\nminimum number of hidden units whose responses need to be changed\n(from 0 to 1 or from 1 to 0depending on the type of error) in order that\nthe Madaline would correctly classify Xi. Suppose that minimum number\nis ki. Of those hidden units voting incorrectly, change the weight vectors\nof those ki of them whose dot products are closest to 0 by using the error\ncorrection rule:\nW \u2190\u2212W + ci(di \u2212fi)Xi\nwhere di is the desired response of the hidden unit (0 or 1) and fi is the\nactual response (0 or 1). (We assume augmented vectors here even though\nwe are using X, W notation.)\nThat is, we perform error-correction on just enough hidden units to correct\nthe vote to a majority voting correctly, and we change those that are easiest to\nchange. There are example problems in which even though a set of weight values\nexists for a given Madaline structure such that it could classify all members of\na training set correctly, this procedure will fail to \ufb01nd them. Nevertheless, the\nprocedure works e\ufb00ectively in most experiments with it.\nWe leave it to the reader to think about how this training procedure could\nbe modi\ufb01ed if the output TLU implemented an or function (or an and function).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 58, 'page_label': '59'}, page_content='50 CHAPTER 4. NEURAL NETWORKS\nR-Category Madalines and Error-Correcting Output Codes\nIf there are k hidden units ( k > 1) in a two-layer network, their responses\ncorrespond to vertices of ak-dimensional hypercube. The ordinary two-category\nMadaline identi\ufb01es two special points in this space, namely the vertex consisting\nof k 1s and the vertex consisting of k 0s. The Madalines response is 1 if the\npoint in hidden-unit-space is closer to the all 1s vertex than it is to the all\n0s vertex. We could design an R-category Madaline by identifying R vertices\nin hidden-unit space and then classifying a pattern according to which of these\nvertices the hidden-unit response is closest to. A machine using that idea was\nimplemented in the early 1960s at SRI [Brain, et al., 1962]. It used the fact\nthat the 2p so-called maximal-length shift-register sequences[Peterson, 1961, pp.\n147\ufb00] in a (2p\u22121)-dimensional Boolean space are mutually equidistant (for any\ninteger p). For similar, more recent work see [Dietterich & Bakiri, 1991].\n4.3.3 Piecewise Linear Machines\nA two-category training set is linearly separable if there exists a threshold func-\ntion that correctly classi\ufb01es all members of the training set. Similarly, we can\nsay that an R-category training set is linearly separable if there exists a linear\nmachine that correctly classi\ufb01es all members of the training set. When an R-\ncategory problem is not linearly separable, we need a more powerful classi\ufb01er.\nA candidate is a structure called a piecewise linear (PWL) machine illustrated\nin Fig. 4.14.\nX\nW1\nW1\n. . .\nY\nY\nMAX\n. . .\nY\nY\nMAX\n. . .\nWR\nWR\nARG\nMAX\n1\nR\n1\nN1\n1\nNR\nFigure 4.14: A Piecewise Linear Machine'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 59, 'page_label': '60'}, page_content='4.3. NETWORKS OF TLUS 51\nThe PWL machine groups its weighted summing units into R banks corre-\nsponding to the R categories. An input vector X is assigned to that category\ncorresponding to the bank with the largest weighted sum. We can use an error-\ncorrection training algorithm similar to that used for a linear machine. If a\npattern is classi\ufb01ed incorrectly, we subtract (a constant times) the pattern vec-\ntor from the weight vector producing the largest dot product (it was incorrectly\nthe largest) and add (a constant times) the pattern vector to that weight vector\nin the correct bank of weight vectors whose dot product is locally largest in\nthat bank. (Again, we use augmented vectors here.) Unfortunately, there are\nexample training sets that are separable by a given PWL machine structure\nbut for which this error-correction training method fails to \ufb01nd a solution. The\nmethod does appear to work well in some situations [Duda & Fossum, 1966], al-\nthough [Nilsson, 1965, page 89] observed that it is probably not a very e\ufb00ective\nmethod for training PWL machines having more than three [weight vectors] in\neach bank.\n4.3.4 Cascade Networks\nAnother interesting class of feedforward networks is that in which all of the TLUs\nare ordered and each TLU receives inputs from all of the pattern components\nand from all TLUs lower in the ordering. Such a network is called a cascade\nnetwork. An example is shown in Fig. 4.15 in which the TLUs are labeled by\nthe linearly separable functions (of their inputs) that they implement. Each\nTLU in the network implements a set of 2 k parallel hyperplanes, where k is\nthe number of TLUs from which it receives inputs. (Each of the k preceding\nTLUs can have an output of 1 or 0; thats 2 k di\ufb00erent combinationsresulting\nin 2k di\ufb00erent positions for the parallel hyperplanes.) We show a 3-dimensional\nsketch for a network of two TLUs in Fig. 4.16. The reader might consider how\nthe n-dimensional parity function might be implemented by a cascade network\nhaving log2 n TLUs.\nx\nL1\nL2\noutput\nL3\nFigure 4.15: A Cascade Network'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 60, 'page_label': '61'}, page_content='52 CHAPTER 4. NEURAL NETWORKS\nL1\nL2\nL2\nFigure 4.16: Planes Implemented by a Cascade Network with Two TLUs\nCascade networks might be trained by \ufb01rst training L1 to do as good a job\nas possible at separating all the training patterns (perhaps by using the pocket\nalgorithm, for example), then training L2 (including the weight from L1 to L2)\nalso to do as good a job as possible at separating all the training patterns,\nand so on until the resulting network classi\ufb01es the patterns in the training set\nsatisfactorily.Also mention the\ncascade-correlation method of\n[Fahlman & Lebiere, 1990].\n4.4 Training Feedforward Networks by Back-\npropagation\n4.4.1 Notation\nThe general problem of training a network of TLUs is di\ufb03cult. Consider, for\nexample, the layered, feedforward network of Fig. 4.11. If such a network makes\nan error on a pattern, there are usually several di\ufb00erent ways in which the error\ncan be corrected. It is di\ufb03cult to assign blame for the error to any particular\nTLU in the network. Intuitively, one looks for weight-adjusting procedures that\nmove the network in the correct direction (relative to the error) by making\nminimal changes. In this spirit, the Widrow-Ho\ufb00 method of gradient descent\nhas been generalized to deal with multilayer networks.\nIn explaining this generalization, we use Fig. 4.17 to introduce some nota-\ntion. This network has only one output unit, but, of course, it is possible to have\nseveral TLUs in the output layereach implementing a di\ufb00erent function. Each\nof the layers of TLUs will have outputs that we take to be the components of\nvectors, just as the input features are components of an input vector. The j-th\nlayer of TLUs (1 \u2264j <k) will have as their outputs the vector X(j). The input\nfeature vector is denoted by X(0), and the \ufb01nal output (of the k-th layer TLU)\nis f. Each TLU in each layer has a weight vector (connecting it to its inputs)\nand a threshold; the i-th TLU in the j-th layer has a weight vector denoted by\nW(j)\ni . (We will assume that the threshold weight is the last component of\nthe associated weight vector; we might have used V notation instead to include'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 61, 'page_label': '62'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION53\nthis threshold component, but we have chosen here to use the familiar X,W\nnotation, assuming that these vectors are augmented as appropriate.) We\ndenote the weighted sum input to the i-th threshold unit in the j-th layer by\ns(j)\ni . (That is, s(j)\ni = X(j\u22121)W(j)\ni .) The number of TLUs in the j-th layer is\ngiven by mj. The vector W(j)\ni has components w(j)\nl,i for l= 1,...,m (j\u22121) + 1.\nX(0)\n. . .\n. . .\n. . .\n. . .\nWi(1)\nW(k)\nX(1)\nm1 TLUs\n. . .\nWi(j)\n. . .\nX(j)\n. . .\nWi(k-1)\nX(k-1)\nmj TLUs m(k-1) TLUs\nwli(j)\nwl(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . .\nf\nsi(1) si(j) si(k-1)\ns(k)\nFigure 4.17: A k-layer Network\n4.4.2 The Backpropagation Method\nA gradient descent method, similar to that used in the Widrow Ho\ufb00 method,\nhas been proposed by various authors for training a multi-layer, feedforward\nnetwork. As before, we de\ufb01ne an error function on the \ufb01nal output of the\nnetwork and we adjust each weight in the network so as to minimize the error.\nIf we have a desired response, di, for the i-th input vector, Xi, in the training\nset, \u039e, we can compute the squared error over the entire training set to be:\n\u03b5=\n\u2211\nXi \u03f5 \u039e\n(di \u2212fi)2\nwhere fi is the actual response of the network for input Xi. To do gradient\ndescent on this squared error, we adjust each weight in the network by an\namount proportional to the negative of the partial derivative of \u03b5 with respect\nto that weight. Again, we use a single-pattern error function so that we can\nuse an incremental weight adjustment procedure. The squared error for a single\ninput vector, X, evoking an output of f when the desired output is d is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 62, 'page_label': '63'}, page_content='54 CHAPTER 4. NEURAL NETWORKS\n\u03b5= (d\u2212f)2\nIt is convenient to take the partial derivatives of\u03b5with respect to the various\nweights in groups corresponding to the weight vectors. We de\ufb01ne a partial\nderivative of a quantity \u03c6, say, with respect to a weight vector, W(j)\ni , thus:\n\u2202\u03c6\n\u2202W(j)\ni\ndef\n=\n[\n\u2202\u03c6\n\u2202w(j)\n1i\n,..., \u2202\u03c6\n\u2202w(j)\nli\n,..., \u2202\u03c6\n\u2202w(j)\nmj\u22121+1,i\n]\nwhere w(j)\nli is the l-th component of W(j)\ni . This vector partial derivative of \u03c6is\ncalled the gradient of \u03c6 with respect to W and is sometimes denoted by \u2207W\u03c6.\nSince \u03b5s dependence on W(j)\ni is entirely through s(j)\ni , we can use the chain\nrule to write:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\n\u2202s(j)\ni\n\u2202W(j)\ni\nBecause s(j)\ni = X(j\u22121)W(j)\ni ,\n\u2202s(j)\ni\n\u2202W(j)\ni\n= X(j\u22121). Substituting yields:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\nX(j\u22121)\nNote that \u2202\u03b5\n\u2202s(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\n. Thus,\n\u2202\u03b5\n\u2202W(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\nX(j\u22121)\nThe quantity (d\u2212f) \u2202f\n\u2202s(j)\ni\nplays an important role in our calculations; we shall\ndenote it by \u03b4(j)\ni . Each of the \u03b4(j)\ni s tells us how sensitive the squared error of\nthe network output is to changes in the input to each threshold function. Since\nwe will be changing weight vectors in directions along their negative gradient,\nour fundamental rule for weight changes throughout the network will be:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nwhere c(j)\ni is the learning rate constant for this weight vector. (Usually, the\nlearning rate constants for all weight vectors in the network are the same.) We\nsee that this rule is quite similar to that used in the error correction procedure'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 63, 'page_label': '64'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION55\nfor a single TLU. A weight vector is changed by the addition of a constant times\nits vector of (unweighted) inputs.\nNow, we must turn our attention to the calculation of the \u03b4(j)\ni s. Using the\nde\ufb01nition, we have:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nWe have a problem, however, in attempting to carry out the partial deriva-\ntives of f with respect to the ss. The network output, f, is not continuously\ndi\ufb00erentiable with respect to the ss because of the presence of the threshold\nfunctions. Most small changes in these sums do not change f at all, and when\nf does change, it changes abruptly from 1 to 0 or vice versa.\nA way around this di\ufb03culty was proposed by Werbos [Werbos, 1974] and\n(perhaps independently) pursued by several other researchers, for example\n[Rumelhart, Hinton, & Williams, 1986]. The trick involves replacing all the\nthreshold functions by di\ufb00erentiable functions called sigmoids.1 The output\nof a sigmoid function, superimposed on that of a threshold function, is shown\nin Fig. 4.18. Usually, the sigmoid function used is f(s) = 1\n1+e\u2212s , where s is\nthe input and f is the output.\nsigmoid\nthreshold function\nf (s)\ns\nf (s) = 1/[1 + e<s]\nFigure 4.18: A Sigmoid Function\n1[Russell & Norvig 1995, page 595] attributes the use of this idea to [Bryson & Ho 1969].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 64, 'page_label': '65'}, page_content='56 CHAPTER 4. NEURAL NETWORKS\nWe show the network containing sigmoid units in place of TLUs in Fig. 4.19.\nThe output of the i-th sigmoid unit in the j-th layer is denoted by f(j)\ni . (That\nis, f(j)\ni = 1\n1+e\u2212s(j)\ni\n.)\nX(0)\n. . .\n. . .\n. . .\n. . .\nWi(1)\nsi(1)\nW(k)\nX(1)\nfi(1)\nm1 sigmoids\n. . .\nWi(j) fi(j)\nsi(j)\n. . .\nX(j)\n. . .\nWi(k-1)\nfi(k-1)\nsi(k-1)\nf(k)\ns(k)\nX(k-1)\nmj sigmoids m(k-1) sigmoids\nwli(j)\nwl(k)\nbi(j)bi(1)\nbi(k-1)\nb(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . .\nFigure 4.19: A Network with Sigmoid Units\n4.4.3 Computing Weight Changes in the Final Layer\nWe \ufb01rst calculate\u03b4(k) in order to compute the weight change for the \ufb01nal sigmoid\nunit:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 65, 'page_label': '66'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION57\n\u03b4(k) = (d\u2212f(k))\u2202f(k)\n\u2202s(k)\nGiven the sigmoid function that we are using, namely f(s) = 1\n1+e\u2212s, we have\nthat \u2202f\n\u2202s = f(1 \u2212f). Substituting gives us:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nRewriting our general rule for weight vector changes, the weight vector in\nthe \ufb01nal layer is changed according to the rule:\nW(k) \u2190W(k) + c(k)\u03b4(k)X(k\u22121)\nwhere \u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nIt is interesting to compare backpropagation to the error-correction rule and\nto the Widrow-Ho\ufb00 rule. The backpropagation weight adjustment for the single\nelement in the \ufb01nal layer can be written as:\nW \u2190\u2212W + c(d\u2212f)f(1 \u2212f)X\nWritten in the same format, the error-correction rule is:\nW \u2190\u2212W + c(d\u2212f)X\nand the Widrow-Ho\ufb00 rule is:\nW \u2190\u2212W + c(d\u2212f)X\nThe only di\ufb00erence (except for the fact that f is not thresholded in Widrow-\nHo\ufb00) is the f(1 \u2212f) term due to the presence of the sigmoid function. With\nthe sigmoid function, f(1 \u2212f) can vary in value from 0 to 1. When f is 0,\nf(1 \u2212f) is also 0; when f is 1, f(1 \u2212f) is 0; f(1 \u2212f) obtains its maximum\nvalue of 1/4 when f is 1/2 (that is, when the input to the sigmoid is 0). The\nsigmoid function can be thought of as implementing a fuzzy hyperplane. For\na pattern far away from this fuzzy hyperplane, f(1 \u2212f) has value close to 0,\nand the backpropagation rule makes little or no change to the weight values\nregardless of the desired output. (Small changes in the weights will have little\ne\ufb00ect on the output for inputs far from the hyperplane.) Weight changes are\nonly made within the region of fuzz surrounding the hyperplane, and these\nchanges are in the direction of correcting the error, just as in the error-correction\nand Widrow-Ho\ufb00 rules.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 66, 'page_label': '67'}, page_content='58 CHAPTER 4. NEURAL NETWORKS\n4.4.4 Computing Changes to the Weights in Intermediate\nLayers\nUsing our expression for the \u03b4s, we can similarly compute how to change each\nof the weight vectors in the network. Recall:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nAgain we use a chain rule. The \ufb01nal output, f, depends on s(j)\ni through\neach of the summed inputs to the sigmoids in the ( j+ 1)-th layer. So:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\n= (d\u2212f)\n[\n\u2202f\n\u2202s(j+1)\n1\n\u2202s(j+1)\n1\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nmj+1\n\u2202s(j+1)\nmj+1\n\u2202s(j)\ni\n]\n=\nmj+1\u2211\nl=1\n(d\u2212f) \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\nIt remains to compute the\n\u2202s(j+1)\nl\n\u2202s(j)\ni\ns. To do that we \ufb01rst write:\ns(j+1)\nl = X(j)W(j+1)\nl\n=\nmj+1\u2211\n\u03bd=1\nf(j)\n\u03bd w(j+1)\n\u03bdl\nAnd then, since the weights do not depend on the ss:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\n\u2202\n[\u2211mj+1\n\u03bd=1 f(j)\n\u03bd w(j+1)\n\u03bdl\n]\n\u2202s(j)\ni\n=\nmj+1\u2211\n\u03bd=1\nw(j+1)\n\u03bdl\n\u2202f(j)\n\u03bd\n\u2202s(j)\ni\nNow, we note that \u2202f(j)\n\u03bd\n\u2202s(j)\ni\n= 0 unless \u03bd = i, in which case \u2202f(j)\n\u03bd\n\u2202s(j)\n\u03bd\n= f(j)\n\u03bd (1 \u2212f(j)\n\u03bd ).\nTherefore:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n= w(j+1)\nil f(j)\ni (1 \u2212f(j)\ni )'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 67, 'page_label': '68'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION59\nWe use this result in our expression for \u03b4(j)\ni to give:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nThe above equation is recursive in the \u03b4s. (It is interesting to note that\nthis expression is independent of the error function; the error function explicitly\na\ufb00ects only the computation of \u03b4(k).) Having computed the \u03b4(j+1)\ni s for layer\nj + 1, we can use this equation to compute the \u03b4(j)\ni s. The base case is \u03b4(k),\nwhich we have already computed:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nWe use this expression for the\u03b4s in our generic weight changing rule, namely:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nAlthough this rule appears complex, it has an intuitively reasonable explanation.\nThe quantity \u03b4(k) = (d\u2212f)f(1 \u2212f) controls the overall amount and sign of all\nweight adjustments in the network. (Adjustments diminish as the \ufb01nal output,\nf, approaches either 0 or 1, because they have vanishing e\ufb00ect on f then.) As\nthe recursion equation for the \u03b4s shows, the adjustments for the weights going\nin to a sigmoid unit in the j-th layer are proportional to the e\ufb00ect that such\nadjustments have on that sigmoid units output (its f(j)(1 \u2212f(j)) factor). They\nare also proportional to a kind of average e\ufb00ect that any change in the output\nof that sigmoid unit will have on the \ufb01nal output. This average e\ufb00ect depends\non the weights going out of the sigmoid unit in the j-th layer (small weights\nproduce little downstream e\ufb00ect) and the e\ufb00ects that changes in the outputs of\n(j+ 1)-th layer sigmoid units will have on the \ufb01nal output (as measured by the\n\u03b4(j+1)s). These calculations can be simply implemented by backpropagating\nthe \u03b4s through the weights in reverse direction (thus, the name backprop for\nthis algorithm).\n4.4.5 Variations on Backprop\n[To be written: problem of local minima, simulated annealing, momemtum\n(Plaut, et al., 1986, see [Hertz, Krogh, & Palmer, 1991]), quickprop, regulariza-\ntion methods]\nSimulated Annealing\nTo apply simulated annealing, the value of the learning rate constant is gradually\ndecreased with time. If we fall early into an error-function valley that is not\nvery deep (a local minimum), it typically will neither be very broad, and soon'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 68, 'page_label': '69'}, page_content='60 CHAPTER 4. NEURAL NETWORKS\na subsequent large correction will jostle us out of it. It is less likely that we will\nmove out of deep valleys, and at the end of the process (with very small values\nof the learning rate constant), we descend to its deepest point. The process\ngets its name by analogy with annealing in metallurgy, in which a materials\ntemperature is gradually decreased allowing its crystalline structure to reach a\nminimal energy state.\n4.4.6 An Application: Steering a Van\nA neural network system called ALVINN (Autonomous Land Vehicle in a Neural\nNetwork) has been trained to steer a Chevy van successfully on ordinary roads\nand highways at speeds of 55 mph [Pomerleau, 1991, Pomerleau, 1993]. The\ninput to the network is derived from a low-resolution (30 x 32) television image.\nThe TV camera is mounted on the van and looks at the road straight ahead.\nThis image is sampled and produces a stream of 960-dimensional input vectors\nto the neural network. The network is shown in Fig. 4.20.\n960 inputs\n30 x 32 retina\n. . .\n5 hidden\nunits connected\nto all 960 inputs\n30 output units\nconnected to all\nhidden units\n. . .\nsharp left\nsharp right\nstraight ahead\ncentroid\nof outputs\nsteers\nvehicle\nFigure 4.20: The ALVINN Network\nThe network has \ufb01ve hidden units in its \ufb01rst layer and 30 output units in the\nsecond layer; all are sigmoid units. The output units are arranged in a linear\norder and control the vans steering angle. If a unit near the top of the array\nof output units has a higher output than most of the other units, the van is\nsteered to the left; if a unit near the bottom of the array has a high output, the\nvan is steered to the right. The centroid of the responses of all of the output'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 69, 'page_label': '70'}, page_content='4.5. SYNERGIES BETWEEN NEURAL NETWORK AND KNOWLEDGE-BASED METHODS61\nunits is computed, and the vans steering angle is set at a corresponding value\nbetween hard left and hard right.\nThe system is trained by a modi\ufb01ed on-line training regime. A driver drives\nthe van, and his actual steering angles are taken as the correct labels for the\ncorresponding inputs. The network is trained incrementally by backprop to\nproduce the driver-speci\ufb01ed steering angles in response to each visual pattern\nas it occurs in real time while driving.\nThis simple procedure has been augmented to avoid two potential problems.\nFirst, since the driver is usually driving well, the network would never get any\nexperience with far-from-center vehicle positions and/or incorrect vehicle orien-\ntations. Also, on long, straight stretches of road, the network would be trained\nfor a long time only to produce straight-ahead steering angles; this training\nwould swamp out earlier training to follow a curved road. We wouldnt want\nto try to avoid these problems by instructing the driver to drive erratically\noccasionally, because the system would learn to mimic this erratic behavior.\nInstead, each original image is shifted and rotated in software to create 14\nadditional images in which the vehicle appears to be situated di\ufb00erently relative\nto the road. Using a model that tells the system what steering angle ought to\nbe used for each of these shifted images, given the driver-speci\ufb01ed steering angle\nfor the original image, the system constructs an additional 14 labeled training\npatterns to add to those encountered during ordinary driver training.\n4.5 Synergies Between Neural Network and\nKnowledge-Based Methods\nTo be written; discuss\nrule-generating procedures (such as\n[Towell & Shavlik, 1992]) and how\nexpert-provided rules can aid\nneural net training and vice-versa\n[Towell, Shavlik, & Noordweier, 1990].\n4.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 70, 'page_label': '71'}, page_content='62 CHAPTER 4. NEURAL NETWORKS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 71, 'page_label': '72'}, page_content='Chapter 5\nStatistical Learning\n5.1 Using Statistical Decision Theory\n5.1.1 Background and General Method\nSuppose the pattern vector, X, is a random variable whose probability distri-\nbution for category 1 is di\ufb00erent than it is for category 2. (The treatment given\nhere can easily be generalized to R-category problems.) Speci\ufb01cally, suppose we\nhave the two probability distributions (perhaps probability density functions),\np(X |1) and p(X |2). Given a pattern, X, we want to use statistical tech-\nniques to determine its categorythat is, to determine from which distribution\nit was drawn. These techniques are based on the idea of minimizing the ex-\npected value of a quantity similar to the error function we used in deriving the\nweight-changing rules for backprop.\nIn developing a decision method, it is necessary to know the relative serious-\nness of the two kinds of mistakes that might be made. (We might decide that a\npattern really in category 1 is in category 2, and vice versa.) We describe this\ninformation by a loss function, \u03bb(i|j), for i,j = 1,2. \u03bb(i|j) represents the loss\nincurred when we decide a pattern is in category i when really it is in category\nj. We assume here that \u03bb(1 |1) and \u03bb(2 |2) are both 0. For any given pattern,\nX, we want to decide its category in such a way that minimizes the expected\nvalue of this loss.\nGiven a pattern, X, if we decide category i, the expected value of the loss\nwill be:\nLX(i) = \u03bb(i|1)p(1 |X) + \u03bb(i|2)p(2 |X)\nwhere p(j |X) is the probability that given a pattern X, its category is j. Our\ndecision rule will be to decide that X belongs to category 1 if LX(1) \u2264LX(2),\nand to decide on category 2 otherwise.\n63'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 72, 'page_label': '73'}, page_content='64 CHAPTER 5. STATISTICAL LEARNING\nWe can use Bayes Rule to get expressions for p(j |X) in terms of p(X |j),\nwhich we assume to be known (or estimatible):\np(j |X) = p(X |j)p(j)\np(X)\nwhere p(j) is the (a priori) probability of category j (one category may be much\nmore probable than the other); and p(X) is the (a priori) probability of pattern\nX being the pattern we are asked to classify. Performing the substitutions given\nby Bayes Rule, our decision rule becomes:\nDecide category 1 i\ufb00:\n\u03bb(1 |1)p(X |1)p(1)\np(X) + \u03bb(1 |2)p(X |2)p(2)\np(X)\n\u2264\u03bb(2 |1)p(X |1)p(1)\np(X) + \u03bb(2 |2)p(X |2)p(2)\np(X)\nUsing the fact that \u03bb(i |i) = 0, and noticing that p(X) is common to both\nexpressions, we obtain,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nIf \u03bb(1 |2) = \u03bb(2 |1) and if p(1) = p(2), then the decision becomes particu-\nlarly simple:\nDecide category 1 i\ufb00:\np(X |2) \u2264p(X |1)\nSince p(X |j) is called the likelihood of j with respect to X, this simple decision\nrule implements what is called a maximum-likelihood decision. More generally,\nif we de\ufb01ne k(i|j) as \u03bb(i|j)p(j), then our decision rule is simply,\nDecide category1 i\ufb00:\nk(1 |2)p(X |2) \u2264k(2 |1)p(X |1)\nIn any case, we need to compare the (perhaps weighted) quantities p(X |i) for\ni= 1 and 2. The exact decision rule depends on the the probability distributions\nassumed. We will treat two interesting distributions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 73, 'page_label': '74'}, page_content='5.1. USING STATISTICAL DECISION THEORY 65\n5.1.2 Gaussian (or Normal) Distributions\nThe multivariate (n-dimensional) Gaussian distribution is given by the proba-\nbility density function:\np(X) = 1\n(2\u03c0)n/2|\u03a3|1/2 e\n\u2212(X\u2212M)t\u03a3\n\u22121\n(X\u2212M)\n2\nwhere nis the dimension of the column vector X, the column vector M is called\nthe mean vector, (X \u2212M)t is the transpose of the vector ( X \u2212M), \u03a3 is the\ncovariance matrix of the distribution (an n×n symmetric, positive de\ufb01nite\nmatrix), \u03a3\u22121 is the inverse of the covariance matrix, and |\u03a3|is the determinant\nof the covariance matrix.\nThe mean vector, M, with components ( m1,...,m n), is the expected value\nof X (using this distribution); that is, M = E[X]. The components of the\ncovariance matrix are given by:\n\u03c32\nij = E[(xi \u2212mi)(xj \u2212mj)]\nIn particular, \u03c32\nii is called the variance of xi.\nAlthough the formula appears complex, an intuitive idea for Gaussian dis-\ntributions can be given when n = 2. We show a two-dimensional Gaussian\ndistribution in Fig. 5.1. A three-dimensional plot of the distribution is shown\nat the top of the \ufb01gure, and contours of equal probability are shown at the bot-\ntom. In this case, the covariance matrix, \u03a3, is such that the elliptical contours\nof equal probability are skewed. If the covariance matrix were diagonal, that is\nif all o\ufb00-diagonal terms were 0, then the major axes of the elliptical contours\nwould be aligned with the coordinate axes. In general the principal axes are\ngiven by the eigenvectors of \u03a3. In any case, the equi-probability contours are\nall centered on the mean vector, M, which in our \ufb01gure happens to be at the\norigin. In general, the formula in the exponent in the Gaussian distribution\nis a positive de\ufb01nite quadratic form (that is, its value is always positive); thus\nequi-probability contours are hyper-ellipsoids in n-dimensional space.\nSuppose we now assume that the two classes of pattern vectors that we\nwant to distinguish are each distributed according to a Gaussian distribution\nbut with di\ufb00erent means and covariance matrices. That is, one class tends to\nhave patterns clustered around one point in the n-dimensional space, and the\nother class tends to have patterns clustered around another point. We show a\ntwo-dimensional instance of this problem in Fig. 5.2. (In that \ufb01gure, we have\nplotted the sum of the two distributions.) What decision rule should we use to\nseparate patterns into the two appropriate categories?\nSubstituting the Gaussian distributions into our maximum likelihood for-\nmula yields:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 74, 'page_label': '75'}, page_content='66 CHAPTER 5. STATISTICAL LEARNING\n-5\n0\n5\n-5\n0\n5\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n-5\n0\n5\n0\n25\n.5\n75\n1\n-6 -4 -2 0 2 4 6\n-6\n-4\n-2\n0\n2\n4\n6\nx1\nx2\np(x1,x2)\n2\n4\n6\n24 6\nx1\nx2\nFigure 5.1: The Two-Dimensional Gaussian Distribution\nDecide category 1 i\ufb00:\n1\n(2\u03c0)n/2|\u03a32|1/2 e\u22121/2(X\u2212M2)t\u03a3\n\u22121\n2 (X\u2212M2)\nis less than or equal to\n1\n(2\u03c0)n/2|\u03a31|1/2 e\u22121/2(X\u2212M1)t\u03a3\n\u22121\n1 (X\u2212M1)\nwhere the category 1 patterns are distributed with mean and covariance M1\nand \u03a31, respectively, and the category 2 patterns are distributed with mean\nand covariance M2 and \u03a32.\nThe result of the comparison isnt changed if we compare logarithms instead.\nAfter some manipulation, our decision rule is then:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 75, 'page_label': '76'}, page_content='5.1. USING STATISTICAL DECISION THEORY 67\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n25\n.5\n75\n1\nx1\nx2\np(x1,x2)\n-5 -2.5 0 2.5 5 7.5 10\n-5\n-2.5\n0\n2.5\n5\n7.5\n10\nFigure 5.2: The Sum of Two Gaussian Distributions\nDecide category 1 i\ufb00:\n(X \u2212M1)t\u03a3\u22121\n1 (X \u2212M1) <(X \u2212M2)t\u03a3\u22121\n2 (X \u2212M2) + B\nwhere B, a constant bias term, incorporates the logarithms of the fractions\npreceding the exponential, etc.\nWhen the quadratic forms are multiplied out and represented in terms of\nthe components xi, the decision rule involves a quadric surface (a hyperquadric)\nin n-dimensional space. The exact shape and position of this hyperquadric is\ndetermined by the means and the covariance matrices. The surface separates\nthe space into two parts, one of which contains points that will be assigned to\ncategory 1 and the other contains points that will be assigned to category 2.\nIt is interesting to look at a special case of this surface. If the covariance\nmatrices for each category are identical and diagonal, with all \u03c3ii equal to each\nother, then the contours of equal probability for each of the two distributions'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 76, 'page_label': '77'}, page_content='68 CHAPTER 5. STATISTICAL LEARNING\nare hyperspherical. The quadric forms then become (1 /|\u03a3|)(X\u2212Mi)t(X\u2212Mi),\nand the decision rule is:\nDecide category 1 i\ufb00:\n(X \u2212M1)t(X \u2212M1) <(X \u2212M2)t(X \u2212M2)\nMultiplying out yields:\nXX \u22122XM1 + M1M1 <XX \u22122XM2 + M2M2\nor \ufb01nally,\nDecide category 1 i\ufb00:\nXM1 \u2265XM2 + Constant\nor\nX(M1 \u2212M2) \u2265Constant\nwhere the constant depends on the lengths of the mean vectors.\nWe see that the optimal decision surface in this special case is a hyperplane.\nIn fact, the hyperplane is perpendicular to the line joining the two means. The\nweights in a TLU implementation are equal to the di\ufb00erence in the mean vectors.\nIf the parameters ( Mi,\u03a3i) of the probability distributions of the categories\nare not known, there are various techniques for estimating them, and then using\nthose estimates in the decision rule. For example, if there are su\ufb03cient training\npatterns, one can use sample means and sample covariance matrices. (Caution:\nthe sample covariance matrix will be singular if the training patterns happen to\nlie on a subspace of the whole n-dimensional spaceas they certainly will, for\nexample, if the number of training patterns is less than n.)\n5.1.3 Conditionally Independent Binary Components\nSuppose the vector X is a random variable having binary (0,1) components.\nWe continue to denote the two probability distributions by p(X |1) and p(X |\n2). Further suppose that the components of these vectors are conditionally\nindependent given the category. By conditional independence in this case, we\nmean that the formulas for the distribution can be expanded as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 77, 'page_label': '78'}, page_content='5.1. USING STATISTICAL DECISION THEORY 69\np(X |i) = p(x1 |i)p(x2 |i) ···p(xn |i)\nfor i= 1,2\nRecall the minimum-average-loss decision rule,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nAssuming conditional independence of the components and that \u03bb(1 |2) = \u03bb(2 |\n1), we obtain,\nDecide category 1 i\ufb00:\np(1)p(x1 |1)p(x2 |1) ···p(xn |1) \u2265p(x1 |2)p(x2 |2) ···p(xn |2)p(2)\nor i\ufb00:\np(x1 |1)p(x2 |1) ...p (xn |1)\np(x1 |2)p(x2 |2) ...p (xn |2) \u2265p(2)\np(1)\nor i\ufb00:\nlog p(x1 |1)\np(x1 |2) + log p(x2 |1)\np(x2 |2) + ··· + log p(xn |1)\np(xn |2) + log p(1)\np(2) \u22650\nLet us de\ufb01ne values of the components of the distribution for speci\ufb01c values of\ntheir arguments, xi :\np(xi = 1 |1) = pi\np(xi = 0 |1) = 1 \u2212pi\np(xi = 1 |2) = qi\np(xi = 0 |2) = 1 \u2212qi\nNow, we note that since xi can only assume the values of 1 or 0:\nlog p(xi |1)\np(xi |2) = xilog pi\nqi\n+ (1 \u2212xi) log (1 \u2212pi)\n(1 \u2212qi)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 78, 'page_label': '79'}, page_content='70 CHAPTER 5. STATISTICAL LEARNING\n= xilog pi(1 \u2212qi)\nqi(1 \u2212pi) + log (1 \u2212pi)\n(1 \u2212qi)\nSubstituting these expressions into our decision rule yields:\nDecide category 1 i\ufb00:\nn\u2211\ni=1\nxilog pi(1 \u2212qi)\nqi(1 \u2212pi) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi) + log p(1)\np(2) \u22650\nWe see that we can achieve this decision with a TLU with weight values as\nfollows:\nwi = log pi(1 \u2212qi)\nqi(1 \u2212pi)\nfor i= 1,...,n , and\nwn+1 = log p(1)\n1 \u2212p(1) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi)\nIf we do not know the pi,qi and p(1), we can use a sample of labeled training\npatterns to estimate these parameters.\n5.2 Learning Belief Networks\nTo be added.\n5.3 Nearest-Neighbor Methods\nAnother class of methods can be related to the statistical ones. These are called\nnearest-neighbor methods or, sometimes, memory-based methods. (A collection\nof papers on this subject is in [Dasarathy, 1991].) Given a training set \u039e of m\nlabeled patterns, a nearest-neighbor procedure decides that some new pattern,\nX, belongs to the same category as do its closest neighbors in \u039e. More precisely,\na k-nearest-neighbor method assigns a new pattern,X, to that category to which\nthe plurality of its k closest neighbors belong. Using relatively large values of\nk decreases the chance that the decision will be unduly in\ufb02uenced by a noisy\ntraining pattern close to X. But large values of k also reduce the acuity of the\nmethod. The k-nearest-neighbor method can be thought of as estimating the\nvalues of the probabilities of the classes given X. Of course the denser are the\npoints around X, and the larger the value of k, the better the estimate.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 79, 'page_label': '80'}, page_content='5.3. NEAREST-NEIGHBOR METHODS 71\nThe distance metric used in nearest-neighbor methods (for numerical at-\ntributes) can be simple Euclidean distance. That is, the distance between two\npatterns (x11,x12,...,x 1n) and (x21,x22,...,x 2n) is\n\u221a\u2211n\nj=1(x1j \u2212x2j)2. This\ndistance measure is often modi\ufb01ed by scaling the features so that the spread of\nattribute values along each dimension is approximately the same. In that case,\nthe distance between the two vectors would be\n\u221a\u2211n\nj=1 a2\nj(x1j \u2212x2j)2, where\naj is the scale factor for dimension j.\nAn example of a nearest-neighbor decision problem is shown in Fig. 5.3. In\nthe \ufb01gure the class of a training pattern is indicated by the number next to it.\nk = 8\nX (a pattern to be classified)\n1\n1\n1 1\n1\n11\n1\n2\n1\n2\n2\n2\n2\n2\n2 2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\ntraining patternclass of training pattern\nfour patterns of category 1\ntwo patterns of category 2\ntwo patterns of category 3\nplurality are in category 1, so\ndecide X is in category 1\nFigure 5.3: An 8-Nearest-Neighbor Decision\nSee [Baum, 1994] for theoretical\nanalysis of error rate as a function\nof the number of training patterns\nfor the case in which points are\nrandomly distributed on the surface\nof a unit sphere and underlying\nfunction is linearly separable.\nNearest-neighbor methods are memory intensive because a large number of\ntraining patterns must be stored to achieve good generalization. Since memory\ncost is now reasonably low, the method and its derivatives have seen several\npractical applications. (See, for example, [Moore, 1992, Moore, et al., 1994].\nAlso, the distance calculations required to \ufb01nd nearest neighbors can often be\ne\ufb03ciently computed by kd-tree methods [Friedman, et al., 1977].\nA theorem by Cover and Hart [Cover & Hart, 1967] relates the performance\nof the 1-nearest-neighbor method to the performance of a minimum-probability-\nof-error classi\ufb01er. As mentioned earlier, the minimum-probability-of-error clas-\nsi\ufb01er would assign a new patternX to that category that maximizedp(i)p(X |i),\nwhere p(i) is the a priori probability of categoryi, and p(X |i) is the probability\n(or probability density function) of X given that X belongs to category i, for\ncategories i= 1,...,R . Suppose the probability of error in classifying patterns\nof such a minimum-probability-of-error classi\ufb01er is \u03b5. The Cover-Hart theo-\nrem states that under very mild conditions (having to do with the smoothness'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 80, 'page_label': '81'}, page_content='72 CHAPTER 5. STATISTICAL LEARNING\nof probability density functions) the probability of error, \u03b5nn, of a 1-nearest-\nneighbor classi\ufb01er is bounded by:\n\u03b5\u2264\u03b5nn \u2264\u03b5\n(\n2 \u2212\u03b5 R\nR\u22121\n)\n\u22642\u03b5\nwhere R is the number of categories.Also see [Aha, 1991].\n5.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 81, 'page_label': '82'}, page_content='Chapter 6\nDecision Trees\n6.1 De\ufb01nitions\nA decision tree (generally de\ufb01ned) is a tree whose internal nodes are tests (on\ninput patterns) and whose leaf nodes are categories (of patterns). We show an\nexample in Fig. 6.1. A decision tree assigns a class number (or output) to an\ninput pattern by \ufb01ltering the pattern down through the tests in the tree. Each\ntest has mutually exclusive and exhaustive outcomes. For example, test T2 in\nthe tree of Fig. 6.1 has three outcomes; the left-most one assigns the input\npattern to class 3, the middle one sends the input pattern down to test T4, and\nthe right-most one assigns the pattern to class 1. We follow the usual convention\nof depicting the leaf nodes by the class number.1 Note that in discussing decision\ntrees we are not limited to implementing Boolean functionsthey are useful for\ngeneral, categorically valued functions.\nThere are several dimensions along which decision trees might di\ufb00er:\na. The tests might be multivariate (testing on several features of the input\nat once) or univariate (testing on only one of the features).\nb. The tests might have two outcomes or more than two. (If all of the tests\nhave two outcomes, we have a binary decision tree.)\nc. The features or attributes might be categorical or numeric. (Binary-valued\nones can be regarded as either.)\n1One of the researchers who has done a lot of work on learning decision trees is Ross\nQuinlan. Quinlan distinguishes between classes and categories. He calls the subsets of patterns\nthat \ufb01lter down to each tip categories and subsets of patterns having the same label classes.\nIn Quinlans terminology, our example tree has nine categories and three classes. We will not\nmake this distinction, however, but will use the words category and class interchangeably\nto refer to what Quinlan calls class.\n73'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 82, 'page_label': '83'}, page_content='74 CHAPTER 6. DECISION TREES\nT1\nT2 T3\nT4\nT4\nT4\n3\n1\n3 2\n1 2 3\n2 1\nFigure 6.1: A Decision Tree\nd. We might have two classes or more than two. If we have two classes and\nbinary inputs, the tree implements a Boolean function, and is called a\nBoolean decision tree.\nIt is straightforward to represent the function implemented by a univariate\nBoolean decision tree in DNF form. The DNF form implemented by such a tree\ncan be obtained by tracing down each path leading to a tip node corresponding\nto an output value of 1, forming the conjunction of the tests along this path,\nand then taking the disjunction of these conjunctions. We show an example in\nFig. 6.2. In drawing univariate decision trees, each non-leaf node is depicted by\na single attribute. If the attribute has value 0 in the input pattern, we branch\nleft; if it has value 1, we branch right.\nThe k-DL class of Boolean functions can be implemented by a multivariate\ndecision tree having the (highly unbalanced) form shown in Fig. 6.3. Each test,\nci, is a term of size k or less. The vi all have values of 0 or 1.\n6.2 Supervised Learning of Univariate Decision\nTrees\nSeveral systems for learning decision trees have been proposed. Prominent\namong these are ID3 and its new version, C4.5 [Quinlan, 1986, Quinlan, 1993],\nand CART [Breiman, et al., 1984] We discuss here only batch methods, al-\nthough incremental ones have also been proposed [Utgo\ufb00, 1989].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 83, 'page_label': '84'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES75\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.2: A Decision Tree Implementing a DNF Function\n6.2.1 Selecting the Type of Test\nAs usual, we have n features or attributes. If the attributes are binary, the\ntests are simply whether the attributes value is 0 or 1. If the attributes are\ncategorical, but non-binary, the tests might be formed by dividing the attribute\nvalues into mutually exclusive and exhaustive subsets. A decision tree with such\ntests is shown in Fig. 6.4. If the attributes are numeric, the tests might involve\ninterval tests, for example 7 \u2264xi \u226413.2.\n6.2.2 Using Uncertainty Reduction to Select Tests\nThe main problem in learning decision trees for the binary-attribute case is\nselecting the order of the tests. For categorical and numeric attributes, we\nmust also decide what the tests should be (besides selecting the order). Several\ntechniques have been tried; the most popular one is at each stage to select that\ntest that maximally reduces an entropy-like measure.\nWe show how this technique works for the simple case of tests with binary\noutcomes. Extension to multiple-outcome tests is straightforward computation-\nally but gives poor results because entropy is always decreased by having more\noutcomes.\nThe entropy or uncertainty still remaining about the class of a pattern\nknowing that it is in some set, \u039e, of patterns is de\ufb01ned as:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 84, 'page_label': '85'}, page_content='76 CHAPTER 6. DECISION TREES\ncq\ncq-1\nci\n1\nvn\nvn-1\nvi\nv1\nFigure 6.3: A Decision Tree Implementing a Decision List\nwhere p(i|\u039e) is the probability that a pattern drawn at random from \u039e belongs\nto class i, and the summation is over all of the classes. We want to select tests at\neach node such that as we travel down the decision tree, the uncertainty about\nthe class of a pattern becomes less and less.\nSince we do not in general have the probabilitiesp(i|\u039e), we estimate them by\nsample statistics. Although these estimates might be errorful, they are never-\ntheless useful in estimating uncertainties. Let p(i|\u039e) be the number of patterns\nin \u039e belonging to class idivided by the total number of patterns in \u039e. Then an\nestimate of the uncertainty is:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)\nFor simplicity, from now on well drop the hats and use sample statistics as\nif they were real probabilities.\nIf we perform a test, T, having k possible outcomes on the patterns in \u039e, we\nwill create ksubsets, \u039e1,\u039e2,..., \u039ek. Suppose that ni of the patterns in \u039e are in\n\u039ei for i= 1,...,k . (Some ni may be 0.) If we knew that T applied to a pattern\nin \u039e resulted in the j-th outcome (that is, we knew that the pattern was in \u039e j),\nthe uncertainty about its class would be:\nH(\u039ej) = \u2212\n\u2211\ni\np(i|\u039ej) log2 p(i|\u039ej)\nand the reduction in uncertainty (beyond knowing only that the pattern was in\n\u039e) would be:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 85, 'page_label': '86'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES77\nx3 = a, b, c, or d \n{a, c} {b}\nx1 = e, b, or d \n{e,b} {d}\nx4 = a, e, f, or g\n{a, g} {e, f}\nx2 = a, or g\n{a} {g}\n1\n2 1\n1 2\n{d}\n2\nFigure 6.4: A Decision Tree with Categorical Attributes\nH(\u039e) \u2212H(\u039ej)\nOf course we cannot say that the test T is guaranteed always to produce that\namount of reduction in uncertainty because we dont know that the result of\nthe test will be the j-th outcome. But we can estimate the average uncertainty\nover all the \u039ej, by:\nE[HT(\u039e)] =\n\u2211\nj\np(\u039ej)H(\u039ej)\nwhere by HT(\u039e) we mean the average uncertainty after performing test T on\nthe patterns in \u039e, p(\u039ej) is the probability that the test has outcome j, and the\nsum is taken from 1 to k. Again, we dont know the probabilities p(\u039ej), but we\ncan use sample values. The estimate p(\u039ej) of p(\u039ej) is just the number of those\npatterns in \u039e that have outcome j divided by the total number of patterns in\n\u039e. The average reduction in uncertainty achieved by test T (applied to patterns\nin \u039e) is then:\nRT(\u039e) = H(\u039e) \u2212E[HT(\u039e)]\nAn important family of decision tree learning algorithms selects for the root\nof the tree that test that gives maximum reduction of uncertainty, and then\napplies this criterion recursively until some termination condition is met (which\nwe shall discuss in more detail later). The uncertainty calculations are particu-\nlarly simple when the tests have binary outcomes and when the attributes have'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 86, 'page_label': '87'}, page_content='78 CHAPTER 6. DECISION TREES\nbinary values. Well give a simple example to illustrate how the test selection\nmechanism works in that case.\nSuppose we want to use the uncertainty-reduction method to build a decision\ntree to classify the following patterns:\npattern class\n(0, 0, 0) 0\n(0, 0, 1) 0\n(0, 1, 0) 0\n(0, 1, 1) 0\n(1, 0, 0) 0\n(1, 0, 1) 1\n(1, 1, 0) 0\n(1, 1, 1) 1\nWhat single test, x1, x2, or x3, should be performed \ufb01rst? The illustration in\nFig. 6.5 gives geometric intuition about the problem.\nx1\nx2\nx3\nThe test x1\nFigure 6.5: Eight Patterns to be Classi\ufb01ed by a Decision Tree\nThe initial uncertainty for the set, \u039e, containing all eight points is:\nH(\u039e) = \u2212(6/8) log2(6/8) \u2212(2/8) log2(2/8) = 0.81\nNext, we calculate the uncertainty reduction if we perform x1 \ufb01rst. The left-\nhand branch has only patterns belonging to class 0 (we call them the set \u039el), and\nthe right-hand-branch (\u039er) has two patterns in each class. So, the uncertainty\nof the left-hand branch is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 87, 'page_label': '88'}, page_content='6.3. NETWORKS EQUIVALENT TO DECISION TREES 79\nHx1 (\u039el) = \u2212(4/4) log2(4/4) \u2212(0/4) log2(0/4) = 0\nAnd the uncertainty of the right-hand branch is:\nHx1 (\u039er) = \u2212(2/4) log2(2/4) \u2212(2/4) log2(2/4) = 1\nHalf of the patterns go left and half go right on test x1. Thus, the average\nuncertainty after performing the x1 test is:\n1/2Hx1 (\u039el) + 1/2Hx1 (\u039er) = 0.5\nTherefore the uncertainty reduction on \u039e achieved by x1 is:\nRx1 (\u039e) = 0.81 \u22120.5 = 0.31\nBy similar calculations, we see that the test x3 achieves exactly the same\nuncertainty reduction, but x2 achieves no reduction whatsoever. Thus, our\ngreedy algorithm for selecting a \ufb01rst test would select eitherx1 or x3. Suppose\nx1 is selected. The uncertainty-reduction procedure would select x3 as the next\ntest. The decision tree that this procedure creates thus implements the Boolean\nfunction: f = x1x3. See [Quinlan, 1986, sect. 4] for\nanother example.\n6.2.3 Non-Binary Attributes\nIf the attributes are non-binary, we can still use the uncertainty-reduction tech-\nnique to select tests. But now, in addition to selecting an attribute, we must\nselect a test on that attribute. Suppose for example that the value of an at-\ntribute is a real number and that the test to be performed is to set a threshold\nand to test to see if the number is greater than or less than that threshold. In\nprinciple, given a set of labeled patterns, we can measure the uncertainty reduc-\ntion for each test that is achieved by every possible threshold (there are only\na \ufb01nite number of thresholds that give di\ufb00erent test results if there are only\na \ufb01nite number of training patterns). Similarly, if an attribute is categorical\n(with a \ufb01nite number of categories), there are only a \ufb01nite number of mutually\nexclusive and exhaustive subsets into which the values of the attribute can be\nsplit. We can calculate the uncertainty reduction for each split.\n6.3 Networks Equivalent to Decision Trees\nSince univariate Boolean decision trees are implementations of DNF functions,\nthey are also equivalent to two-layer, feedforward neural networks. We show\nan example in Fig. 6.6. The decision tree at the left of the \ufb01gure implements'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 88, 'page_label': '89'}, page_content='80 CHAPTER 6. DECISION TREES\nthe same function as the network at the right of the \ufb01gure. Of course, when\nimplemented as a network, all of the features are evaluated in parallel for any\ninput pattern, whereas when implemented as a decision tree only those features\non the branch traveled down by the input pattern need to be evaluated. The\ndecision-tree induction methods discussed in this chapter can thus be thought of\nas particular ways to establish the structure and the weight values for networks.\nX\nx1\nx2\nx3\nx4\nterms\n-1\n+1\ndisjunction\nx3x2\nx3x4x1\n+1\n-1\n+1\nf\n1.5\n0.5\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.6: A Univariate Decision Tree and its Equivalent Network\nMultivariate decision trees with linearly separable functions at each node can\nalso be implemented by feedforward networksin this case three-layer ones. We\nshow an example in Fig. 6.7 in which the linearly separable functions, each im-\nplemented by a TLU, are indicated by L1,L2,L3, and L4. Again, the \ufb01nal layer\nhas \ufb01xed weights, but the weights in the \ufb01rst two layers must be trained. Dif-\nferent approaches to training procedures have been discussed by [Brent, 1990],\nby [John, 1995], and (for a special case) by [Marchand & Golea, 1993].\n6.4 Over\ufb01tting and Evaluation\n6.4.1 Over\ufb01tting\nIn supervised learning, we must choose a function to \ufb01t the training set from\namong a set of hypotheses. We have already showed that generalization is\nimpossible without bias. When we know a priori that the function we are\ntrying to guess belongs to a small subset of all possible functions, then, even\nwith an incomplete set of training samples, it is possible to reduce the subset\nof functions that are consistent with the training set su\ufb03ciently to make useful\nguesses about the value of the function for inputs not in the training set. And,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 89, 'page_label': '90'}, page_content='6.4. OVERFITTING AND EVALUATION 81\nL1\nL2 L3\nL4\n10\n1\n1\n0 0\n0\n1\n1\n0\n0\n1 0\nX\nL1\nL2\nL3\nL4\nconjunctions\nL1L2\nL1 L3 L4\n<\n+\n++\ndisjunction\n<\nf\nFigure 6.7: A Multivariate Decision Tree and its Equivalent Network\nthe larger the training set, the more likely it is that even a randomly selected\nconsistent function will have appropriate outputs for patterns not yet seen.\nHowever, even with bias, if the training set is not su\ufb03ciently large compared\nwith the size of the hypothesis space, there will still be too many consistent\nfunctions for us to make useful guesses, and generalization performance will be\npoor. When there are too many hypotheses that are consistent with the training\nset, we say that we are over\ufb01tting the training data. Over\ufb01tting is a problem\nthat we must address for all learning methods.\nSince a decision tree of su\ufb03cient size can implement any Boolean function\nthere is a danger of over\ufb01ttingespecially if the training set is small. That\nis, even if the decision tree is synthesized to classify all the members of the\ntraining set correctly, it might perform poorly on new patterns that were not\nused to build the decision tree. Several techniques have been proposed to avoid\nover\ufb01tting, and we shall examine some of them here. They make use of methods\nfor estimating how well a given decision tree might generalizemethods we shall\ndescribe next.\n6.4.2 Validation Methods\nThe most straightforward way to estimate how well a hypothesized function\n(such as a decision tree) performs on a test set is to test it on the test set! But,\nif we are comparing several learning systems (for example, if we are comparing\ndi\ufb00erent decision trees) so that we can select the one that performs the best on\nthe test set, then such a comparison amounts to training on the test data.\nTrue, training on the test data enlarges the training set, with a consequent ex-\npected improvement in generalization, but there is still the danger of over\ufb01tting\nif we are comparing several di\ufb00erent learning systems. Another technique is to'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 90, 'page_label': '91'}, page_content='82 CHAPTER 6. DECISION TREES\nsplit the training setusing (say) two-thirds for training and the other third\nfor estimating generalization performance. But splitting reduces the size of the\ntraining set and thereby increases the possibility of over\ufb01tting. We next describe\nsome validation techniques that attempt to avoid these problems.\nCross-Validation\nIn cross-validation, we divide the training set \u039e into K mutually exclusive and\nexhaustive equal-sized subsets: \u039e 1,..., \u039eK. For each subset, \u039e i, train on the\nunion of all of the other subsets, and empirically determine the error rate, \u03b5i,\non \u039ei. (The error rate is the number of classi\ufb01cation errors made on \u039e i divided\nby the number of patterns in \u039e i.) An estimate of the error rate that can be\nexpected on new patterns of a classi\ufb01er trained on all the patterns in \u039e is then\nthe average of the \u03b5i.\nLeave-one-out Validation\nLeave-one-out validation is the same as cross validation for the special case in\nwhich K equals the number of patterns in \u039e, and each \u039e i consists of a single\npattern. When testing on each \u039e i, we simply note whether or not a mistake\nwas made. We count the total number of mistakes and divide by K to get\nthe estimated error rate. This type of validation is, of course, more expensive\ncomputationally, but useful when a more accurate estimate of the error rate for\na classi\ufb01er is needed.Describe bootstrapping also\n[Efron, 1982].\n6.4.3 Avoiding Over\ufb01tting in Decision Trees\nNear the tips of a decision tree there may be only a few patterns per node.\nFor these nodes, we are selecting a test based on a very small sample, and thus\nwe are likely to be over\ufb01tting. This problem can be dealt with by terminating\nthe test-generating procedure before all patterns are perfectly split into their\nseparate categories. That is, a leaf node may contain patterns of more than one\nclass, but we can decide in favor of the most numerous class. This procedure\nwill result in a few errors but often accepting a small number of errors on the\ntraining set results in fewer errors on a testing set.\nThis behavior is illustrated in Fig. 6.8.\nOne can use cross-validation techniques to determine when to stop splitting\nnodes. If the cross validation error increases as a consequence of a node split,\nthen dont split. One has to be careful about when to stop, though, because\nunder\ufb01tting usually leads to more errors on test sets than does over\ufb01tting. There\nis a general rule that the lowest error-rate attainable by a sub-tree of a fully\nexpanded tree can be no less than 1/2 of the error rate of the fully expanded\ntree [Weiss & Kulikowski, 1991, page 126].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 91, 'page_label': '92'}, page_content='6.4. OVERFITTING AND EVALUATION 83\n(From Weiss, S., and Kulikowski, C., Computer Systems that Learn,\nMorgan Kaufmann, 1991)\ntraining errors\nvalidation errors\n1 2 34 5 6 78 9\n0.2\n0.4\n0.6\n0.8\n1.0\n0\n0\nError Rate\nNumber of Terminal\nNodes\nIris Data Decision Tree\nFigure 6.8: Determining When Over\ufb01tting Begins\nRather than stopping the growth of a decision tree, one might grow it to\nits full size and then prune away leaf nodes and their ancestors until cross-\nvalidation accuracy no longer increases. This technique is called post-pruning.\nVarious techniques for pruning are discussed in [Weiss & Kulikowski, 1991].\n6.4.4 Minimum-Description Length Methods\nAn important tree-growing and pruning technique is based on the minimum-\ndescription-length (MDL) principle. (MDL is an important idea that extends\nbeyond decision-tree methods [Rissanen, 1978].) The idea is that the simplest\ndecision tree that can predict the classes of the training patterns is the best\none. Consider the problem of transmitting just the labels of a training set of\npatterns, assuming that the receiver of this information already has the ordered\nset of patterns. If there are m patterns, each labeled by one of R classes,\none could transmit a list of m R-valued numbers. Assuming equally probable\nclasses, this transmission would require mlog2 Rbits. Or, one could transmit a\ndecision tree that correctly labelled all of the patterns. The number of bits that\nthis transmission would require depends on the technique for encoding decision\ntrees and on the size of the tree. If the tree is small and accurately classi\ufb01es\nall of the patterns, it might be more economical to transmit the tree than to\ntransmit the labels directly. In between these extremes, we might transmit a\ntree plus a list of labels of all the patterns that the tree misclassi\ufb01es.\nIn general, the number of bits (or description length of the binary encoded\nmessage) is t+ d, where t is the length of the message required to transmit\nthe tree, and d is the length of the message required to transmit the labels of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 92, 'page_label': '93'}, page_content='84 CHAPTER 6. DECISION TREES\nthe patterns misclassi\ufb01ed by the tree. In a sense, that tree associated with the\nsmallest value of t+ d is the best or most economical tree. The MDL method\nis one way of adhering to the Occams razor principle.\nQuinlan and Rivest [Quinlan & Rivest, 1989] have proposed techniques for\nencoding decision trees and lists of exception labels and for calculating the\ndescription length (t+d) of these trees and labels. They then use the description\nlength as a measure of quality of a tree in two ways:\na. In growing a tree, they use the reduction in description length to select\ntests (instead of reduction in uncertainty).\nb. In pruning a tree after it has been grown to zero error, they prune away\nthose nodes (starting at the tips) that achieve a decrease in the description\nlength.\nThese techniques compare favorably with the uncertainty-reduction method,\nalthough they are quite sensitive to the coding schemes used.\n6.4.5 Noise in Data\nNoise in the data means that one must inevitably accept some number of\nerrorsdepending on the noise level. Refusal to tolerate errors on the training\nset when there is noise leads to the problem of \ufb01tting the noise. Dealing with\nnoise, then, requires accepting some errors at the leaf nodes just as does the\nfact that there are a small number of patterns at leaf nodes.\n6.5 The Problem of Replicated Subtrees\nDecision trees are not the most economical means of implementing some Boolean\nfunctions. Consider, for example, the function f = x1x2 +x3x4. A decision tree\nfor this function is shown in Fig. 6.9. Notice the replicated subtrees shown\ncircled. The DNF-form equivalent to the function implemented by this decision\ntree is f = x1x2 + x1x2x3x4 + x1x3x4. This DNF form is non-minimal (in the\nnumber of disjunctions) and is equivalent to f = x1x2 + x3x4.\nThe need for replication means that it takes longer to learn the tree and\nthat subtrees replicated further down the tree must be learned using a smaller\ntraining subset. This problem is sometimes called the fragmentation problem.\nSeveral approaches might be suggested for dealing with fragmenta-\ntion. One is to attempt to build a decision graph instead of a tree\n[Oliver, Dowe, & Wallace, 1992, Kohavi, 1994]. A decision graph that imple-\nments the same decisions as that of the decision tree of Fig. 6.9 is shown in Fig.\n6.10.\nAnother approach is to use multivariate (rather than univariate tests at each\nnode). In our example of learning f = x1x2 + x3x4, if we had a test for x1x2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 93, 'page_label': '94'}, page_content='6.6. THE PROBLEM OF MISSING ATTRIBUTES 85\nx1\nx3 x2\n10\nx4\n0 1\nx3\n0\nx4\n0 1\nFigure 6.9: A Decision Tree with Subtree Replication\nand a test for x3x4, the decision tree could be much simpli\ufb01ed, as shown in Fig.\n6.11. Several researchers have proposed techniques for learning decision trees in\nwhich the tests at each node are linearly separable functions. [John, 1995] gives\na nice overview (with several citations) of learning suchlinear discriminant trees\nand presents a method based on soft entropy.\nA third method for dealing with the replicated subtree problem involves ex-\ntracting propositional rules from the decision tree. The rules will have as an-\ntecedents the conjunctions that lead down to the leaf nodes, and as consequents\nthe name of the class at the corresponding leaf node. An example rule from the\ntree with the repeating subtree of our example would be: x1 \u2227¬x2 \u2227x3 \u2227x4 \u22831.\nQuinlan [Quinlan, 1987] discusses methods for reducing a set of rules to a sim-\npler set by 1) eliminating from the antecedent of each rule any unnecessary\nconjuncts, and then 2) eliminating unnecessary rules. A conjunct or rule is\ndetermined to be unnecessary if its elimination has little e\ufb00ect on classi\ufb01cation\naccuracyas determined by a chi-square test, for example. After a rule set is\nprocessed, it might be the case that more than one rule is active for any given\npattern, and care must be taken that the active rules do not con\ufb02ict in their\ndecision about the class of a pattern.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 94, 'page_label': '95'}, page_content='86 CHAPTER 6. DECISION TREES\nx1\nx3\nx2\n1\n0\nx4\n0 1\nFigure 6.10: A Decision Graph\n6.6 The Problem of Missing Attributes\nTo be added.\n6.7 Comparisons\nSeveral experimenters have compared decision-tree, neural-net, and nearest-\nneighbor classi\ufb01ers on a wide variety of problems. For a comparison of\nneural nets versus decision trees, for example, see [Dietterich, et al., 1990,\nShavlik, Mooney, & Towell, 1991, Quinlan, 1994]. In their StatLog project,\n[Taylor, Michie, & Spiegalhalter, 1994] give thorough comparisons of several\nmachine learning algorithms on several di\ufb00erent types of problems. There seems\nx1x2\n1\n0\nx3x4\n1\nFigure 6.11: A Multivariate Decision Tree'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 95, 'page_label': '96'}, page_content='6.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 87\nto be no single type of classi\ufb01er that is best for all problems. And, there do\nnot seem to be any general conclusions that would enable one to say which\nclassi\ufb01er method is best for which sorts of classi\ufb01cation problems, although\n[Quinlan, 1994] does provide some intuition about properties of problems that\nmight render them ill suited for decision trees, on the one hand, or backpropa-\ngation, on the other.\n6.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 96, 'page_label': '97'}, page_content='88 CHAPTER 6. DECISION TREES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 97, 'page_label': '98'}, page_content='Chapter 7\nInductive Logic\nProgramming\nThere are many di\ufb00erent representational forms for functions of input vari-\nables. So far, we have seen (Boolean) algebraic expressions, decision trees, and\nneural networks, plus other computational mechanisms such as techniques for\ncomputing nearest neighbors. Of course, the representation most important\nin computer science is a computer program. For example, a Lisp predicate of\nbinary-valued inputs computes a Boolean function of those inputs. Similarly, a\nlogic program (whose ordinary application is to compute bindings for variables)\ncan also be used simply to decide whether or not a predicate has value True\n(T) or False (F). For example, the Boolean exclusive-or (odd parity) function\nof two variables can be computed by the following logic program:\nParity(x,y) :- True(x), ¬ True(y)\n:- True(y), ¬ True(x)\nWe follow Prolog syntax (see, for example, [Mueller & Page, 1988]), except that\nour convention is to write variables as strings beginning with lower-case letters\nand predicates as strings beginning with upper-case letters. The unary function\nTrue returns T if and only if the value of its argument is T. (We now think\nof Boolean functions and arguments as having values of T and F instead of 0\nand 1.) Programs will be written in  typewriter font.\nIn this chapter, we consider the matter of learning logic programs given\na set of variable values for which the logic program should return T (the\npositive instances ) and a set of variable values for which it should return\nF (the negative instances). The subspecialty of machine learning that deals\nwith learning logic programs is called inductive logic programming (ILP)\n[Lavra\u02c7 c & D\u02c7 zeroski, 1994]. As with any learning problem, this one can be quite\ncomplex and intractably di\ufb03cult unless we constrain it with biases of some sort.\n89'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 98, 'page_label': '99'}, page_content='90 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nIn ILP, there are a variety of possible biases (calledlanguage biases). One might\nrestrict the program to Horn clauses, not allow recursion, not allow functions,\nand so on.\nAs an example of an ILP problem, suppose we are trying to induce a func-\ntion Nonstop(x,y), that is to have value T for pairs of cities connected by a\nnon-stop air \ufb02ight and F for all other pairs of cities. We are given a training set\nconsisting of positive and negative examples. As positive examples, we might\nhave (A,B), (A, A1), and some other pairs; as negative examples, we might\nhave (A1, A2), and some other pairs. In ILP, we usually have additional infor-\nmation about the examples, called background knowledge. In our air-\ufb02ight\nproblem, the background information might be such ground facts as Hub(A),\nHub(B), Satellite(A1,A), plus others. ( Hub(A) is intended to mean that the\ncity denoted by A is a hub city, and Satellite(A1,A) is intended to mean that\nthe city denoted by A1 is a satellite of the city denoted by A.) From these train-\ning facts, we want to induce a program Nonstop(x,y), written in terms of the\nbackground relations Hub and Satellite, that has value T for all the positive\ninstances and has value F for all the negative instances. Depending on the exact\nset of examples, we might induce the program:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nwhich would have value T if both of the two cities were hub cities or if one were\na satellite of the other. As with other learning problems, we want the induced\nprogram to generalize well; that is, if presented with arguments not represented\nin the training set (but for which we have the needed background knowledge),\nwe would like the function to guess well.\n7.1 Notation and De\ufb01nitions\nIn evaluating logic programs in ILP, we implicitly append the background facts\nto the program and adopt the usual convention that a program has value T for\na set of inputs if and only if the program interpreter returns T when actually\nrunning the program (with background facts appended) on those inputs; oth-\nerwise it has value F. Using the given background facts, the program above\nwould return T for input (A, A1), for example. If a logic program, \u03c0, returns\nT for a set of arguments X, we say that the program covers the arguments and\nwrite covers(\u03c0,X). Following our terminology introduced in connection with\nversion spaces, we will say that a program is su\ufb03cient if it covers all of the\npositive instances and that it is necessary if it does not cover any of the neg-\native instances. (That is, a program implements a su\ufb03cient condition that a\ntraining instance is positive if it covers all of the positive training instances; it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 99, 'page_label': '100'}, page_content='7.2. A GENERIC ILP ALGORITHM 91\nimplements a necessary condition if it covers none of the negative instances.) In\nthe noiseless case, we want to induce a program that is both su\ufb03cient and nec-\nessary, in which case we will call it consistent. With imperfect (noisy) training\nsets, we might relax this criterion and settle for a program that covers all but\nsome fraction of the positive instances while allowing it to cover some fraction\nof the negative instances. We illustrate these de\ufb01nitions schematically in Fig.\n7.1.\n<\n<\n<\n<<\n<\n<\n/1 is a necessary program\n/2 is a sufficient program\n/3 is a consistent program\n+\n+\n+\n+\n+ +\n+\n+\n+\n+\n<\n<\nA positive instance\n covered by /2 and /3\nFigure 7.1: Su\ufb03cient, Necessary, and Consistent Programs\nAs in version spaces, if a program is su\ufb03cient but not necessary it can be\nmade to cover fewer examples by specializing it. Conversely, if it is necessary\nbut not su\ufb03cient, it can be made to cover more examples by generalizing it.\nSuppose we are attempting to induce a logic program to compute the relation\n\u03c1. The most general logic program, which is certainly su\ufb03cient, is the one that\nhas value T for all inputs, namely a single clause with an empty body, [ \u03c1 :-\n], which is called a fact in Prolog. The most special logic program, which is\ncertainly necessary, is the one that has value F for all inputs, namely [ \u03c1 :-\nF ]. Two of the many di\ufb00erent ways to search for a consistent logic program\nare: 1) start with [ \u03c1 :- ] and specialize until the program is consistent, or 2)\nstart with [ \u03c1 :- F ] and generalize until the program is consistent. We will\nbe discussing a method that starts with [ \u03c1 :- ], specializes until the program\nis necessary (but might no longer be su\ufb03cient), then reachieves su\ufb03ciency in\nstages by generalizingensuring within each stage that the program remains\nnecessary (by specializing).\n7.2 A Generic ILP Algorithm\nSince the primary operators in our search for a consistent program are special-\nization and generalization, we must next discuss those operations. There are'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 100, 'page_label': '101'}, page_content='92 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nthree major ways in which a logic program might be generalized:\na. Replace some terms in a program clause by variables. (Readers familiar\nwith substitutions in the predicate calculus will note that this process is\nthe inverse of substitution.)\nb. Remove literals from the body of a clause.\nc. Add a clause to the program\nAnalogously, there are three ways in which a logic program might be specialized:\na. Replace some variables in a program clause by terms (a substitution).\nb. Add literals to the body of a clause.\nc. Remove a clause from the program\nWe will be presenting an ILP learning method that adds clauses to a program\nwhen generalizing and that adds literals to the body of a clause when special-\nizing. When we add a clause, we will always add the clause [ \u03c1 :- ] and then\nspecialize it by adding literals to the body. Thus, we need only describe the\nprocess for adding literals.\nClauses can be partially ordered by the specialization relation. In general,\nclause c1 is more special than clause c2 if c2 |= c1. A special case, which is what\nwe use here, is that a clause c1 is more special than a clause c2 if the set of\nliterals in the body of c2 is a subset of those in c1. This ordering relation can\nbe used in a structure of partially ordered clauses, called the re\ufb01nement graph,\nthat is similar to a version space. Clause c1 is an immediate successor of clause\nc2 in this graph if and only if clause c1 can be obtained from clause c2 by adding\na literal to the body of c2. A re\ufb01nement graph then tells us the ways in which\nwe can specialize a clause by adding a literal to it.\nOf course there are unlimited possible literals we might add to the body of\na clause. Practical ILP systems restrict the literals in various ways. Typical\nallowed additions are:\na. Literals used in the background knowledge.\nb. Literals whose arguments are a subset of those in the head of the clause.\nc. Literals that introduce a new distinct variable di\ufb00erent from those in the\nhead of the clause.\nd. A literal that equates a variable in the head of the clause with another\nsuch variable or with a term mentioned in the background knowledge.\n(This possibility is equivalent to forming a specialization by making a\nsubstitution.)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 101, 'page_label': '102'}, page_content='7.2. A GENERIC ILP ALGORITHM 93\ne. A literal that is the same (except for its arguments) as that in the head\nof the clause. (This possibility admits recursive programs, which are dis-\nallowed in some systems.)\nWe can illustrate these possibilities using our air-\ufb02ight example. We start\nwith the program [ Nonstop(x,y) :- ]. The literals used in the background\nknowledge are Hub and Satellite. Thus the literals that we might consider\nadding are:\nHub(x)\nHub(y)\nHub(z)\nSatellite(x,y)\nSatellite(y,x)\nSatellite(x,z)\nSatellite(z,y)\n(x = y)\n(If recursive programs are allowed, we could also add the literals Nonstop(x,z)\nand Nonstop(z,y).) These possibilities are among those illustrated in the re-\n\ufb01nement graph shown in Fig. 7.2. Whatever restrictions on additional literals\nare imposed, they are all syntactic ones from which the successors in the re\ufb01ne-\nment graph are easily computed. ILP programs that follow the approach we\nare discussing (of specializing clauses by adding a literal) thus have well de\ufb01ned\nmethods of computing the possible literals to add to a clause.\nNow we are ready to write down a simple generic algorithm for inducing a\nlogic program, \u03c0 for inducing a relation \u03c1. We are given a training set, \u039e of\nargument sets some known to be in the relation \u03c1 and some not in \u03c1; \u039e+ are\nthe positive instances, and \u039e \u2212 are the negative instances. The algorithm has\nan outer loop in which it successively adds clauses to make \u03c0 more and more\nsu\ufb03cient. It has an inner loop for constructing a clause, c, that is more and\nmore necessary and in which it refers only to a subset, \u039e cur, of the training\ninstances. (The positive instances in \u039e cur will be denoted by \u039e +\ncur, and the\nnegative ones by \u039e \u2212\ncur.) The algorithm is also given background relations and\nthe means for adding literals to a clause. It uses a logic program interpreter to\ncompute whether or not the program it is inducing covers training instances.\nThe algorithm can be written as follows:\nGeneric ILP Algorithm\n(Adapted from [Lavra\u02c7 c & D\u02c7 zeroski, 1994, p. 60].)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 102, 'page_label': '103'}, page_content='94 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nNonstop(x,y) :-\nNonstop(x,y) :-\n   Hub(x)\nNonstop(x,y) :-\n   Satellite(x,y)\nNonstop(x,y) :-\n   (x = y)\n. . .\n. . .\n. . . . . .\nNonstop(x,y) :- Hub(x), Hub(y)\n. . .\n. . .\n. . .\nFigure 7.2: Part of a Re\ufb01nement Graph\nInitialize \u039ecur := \u039e.\nInitialize \u03c0:= empty set of clauses.\nrepeat [The outer loop works to make \u03c0 su\ufb03cient.]\nInitialize c := \u03c1 : \u2212.\nrepeat [The inner loop makes c necessary.]\nSelect a literal l to add to c. [This is a nondeterministic choice point.]\nAssign c:= c,l.\nuntil c is necessary. [That is, until c covers no negative instances in \u039e cur.]\nAssign \u03c0:= \u03c0,c. [We add the clause c to the program.]\nAssign \u039ecur := \u039ecur \u2212(the positive instances in \u039e cur covered by \u03c0).\nuntil \u03c0 is su\ufb03cient.\n(The termination tests for the inner and outer loops can be relaxed as appro-\npriate for the case of noisy instances.)\n7.3 An Example\nWe illustrate how the algorithm works by returning to our example of airline\n\ufb02ights. Consider the portion of an airline route map, shown in Fig. 7.3. Cities\nA, B, and C are hub cities, and we know that there are nonstop \ufb02ights between\nall hub cities (even those not shown on this portion of the route map). The other'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 103, 'page_label': '104'}, page_content='7.3. AN EXAMPLE 95\ncities are satellites of one of the hubs, and we know that there are nonstop\n\ufb02ights between each satellite city and its hub. The learning program is given a\nset of positive instances, \u039e +, of pairs of cities between which there are nonstop\n\ufb02ights and a set of negative instances, \u039e\u2212, of pairs of cities between which there\nare not nonstop \ufb02ights. \u039e + contains just the pairs:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nFor our example, we will assume that \u039e\u2212contains all those pairs of cities shown\nin Fig. 7.3 that are not in \u039e + (a type of closed-world assumption). These are:\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<B,C 1 >,<B,C 2 >,\n<B,A 1 >,<B,A 2 >,<C,A 1 >,<C,A 2 >,<C,B 1 >,<C,B 2 >,\n<B 1,A>,<B 2,A>,<C 1,A>,<C 2,A>,<C 1,B >,<C 2,B >,\n<A1,B >,<A2,B >,<A1,C >,<A2,C >,<B 1,C >,<B 2,C >}\nThere may be other cities not shown on this map, so the training set does not\nnecessarily exhaust all the cities.\nA\nB\nC\nC1\nC2\nB1 B2\nA1\nA2\nFigure 7.3: Part of an Airline Route Map\nWe want the learning program to induce a program for computing the value\nof the relation Nonstop. The training set, \u039e, can be thought of as a partial'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 104, 'page_label': '105'}, page_content='96 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\ndescription of this relation in extensional formit explicitly names some pairs\nin the relation and some pairs not in the relation. We desire to learn the\nNonstop relation as a logic program in terms of the background relations, Hub\nand Satellite, which are also given in extensional form. Doing so will give us\na more compact, intensional, description of the relation, and this description\ncould well generalize usefully to other cities not mentioned in the map.\nWe assume the learning program has the following extensional de\ufb01nitions of\nthe relations Hub and Satellite:\nHub\n{<A>,<B >,<C > }\nAll other cities mentioned in the map are assumed not in the relation Hub. We\nwill use the notation Hub(x) to express that the city named xis in the relation\nHub.\nSatellite\n{<A1,A,>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nAll other pairs of cities mentioned in the map are not in the relation Satellite.\nWe will use the notation Satellite(x,y) to express that the pair < x,y >is\nin the relation Satellite.\nKnowing that the predicate Nonstop is a two-place predicate, the inner loop\nof our algorithm initializes the \ufb01rst clause to Nonstop(x,y) :- . This clause\nis not necessary because it covers all the negative examples (since it covers all\nexamples). So we must add a literal to its (empty) body. Suppose (selecting\na literal from the re\ufb01nement graph) the algorithm adds Hub(x). The following\npositive instances in \u039e are covered by Nonstop(x,y) :- Hub(x):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}\nTo compute this covering, we interpret the logic program Nonstop(x,y) :-\nHub(x) for all pairs of cities in \u039e, using the pairs given in the background\nrelation Hub as ground facts. The following negative instances are also covered:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 105, 'page_label': '106'}, page_content='7.3. AN EXAMPLE 97\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<C,A 1 >,<C,A 2 >,\n<C,B 1 >,<C,B 2 >,<B,A 1 >,<B,A 2 >,<B,C 1 >,<B,C 2 >}\nThus, the clause is not yet necessary and another literal must be added. Sup-\npose we next add Hub(y). The following positive instances are covered by\nNonstop(x,y) :- Hub(x), Hub(y):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B > }\nThere are no longer any negative instances in \u039e covered so the clause\nNonstop(x,y) :- Hub(x), Hub(y) is necessary, and we can terminate the \ufb01rst\npass through the inner loop.\nBut the program, \u03c0, consisting of just this clause is not su\ufb03cient. These\npositive instances are not covered by the clause:\n{<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nThe positive instances that were covered byNonstop(x,y) :- Hub(x), Hub(y)\nare removed from \u039e to form the \u039e cur to be used in the next pass through the\ninner loop. \u039e cur consists of all the negative instances in \u039e plus the positive\ninstances (listed above) that are not yet covered. In order to attempt to cover\nthem, the inner loop creates another clause c, initially set to Nonstop(x,y)\n:- . This clause covers all the negative instances, and so we must add liter-\nals to make it necessary. Suppose we add the literal Satellite(x,y). The\nclause Nonstop(x,y) :- Satellite(x,y) covers no negative instances, so it is\nnecessary. It does cover the following positive instances in \u039e cur:\n{<A1,A>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nThese instances are removed from \u039ecur for the next pass through the inner loop.\nThe program now contains two clauses:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\nThis program is not yet su\ufb03cient since it does not cover the following positive\ninstances:\n{<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 106, 'page_label': '107'}, page_content='98 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nDuring the next pass through the inner loop, we add the clauseNonstop(x,y)\n:- Satellite(y,x). This clause is necessary, and since the program containing\nall three clauses is now su\ufb03cient, the procedure terminates with:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nSince each clause is necessary, and the whole program is su\ufb03cient, the pro-\ngram is also consistent with all instances of the training set. Note that this\nprogram can be applied (perhaps with good generalization) to other cities be-\nsides those in our partial mapso long as we can evaluate the relations Hub and\nSatellite for these other cities. In the next section, we show how the technique\ncan be extended to use recursion on the relation we are inducing. With that\nextension, the method can be used to induce more general logic programs.\n7.4 Inducing Recursive Programs\nTo induce a recursive program, we allow the addition of a literal having the\nsame predicate letter as that in the head of the clause. Various mechanisms\nmust be used to ensure that such a program will terminate; one such is to make\nsure that the new literal has di\ufb00erent variables than those in the head literal.\nThe process is best illustrated with another example. Our example continues\nthe one using the airline map, but we make the map somewhat simpler in order\nto reduce the size of the extensional relations used. Consider the map shown\nin Fig. 7.4. Again, B and C are hub cities, B1 and B2 are satellites of B, C1\nand C2 are satellites of C. We have introduced two new cities, B3 and C3. No\n\ufb02ights exist between these cities and any other citiesperhaps there are only\nbus routes as shown by the grey lines in the map.\nWe now seek to learn a program for Canfly(x,y) that covers only those\npairs of cities that can be reached by one or more nonstop \ufb02ights. The relation\nCanfly is satis\ufb01ed by the following pairs of postive instances:\n{<B 1,B >,<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,\n<B,B 1 >,<B 2,B1 >,<C,B 1 >,<C 1,B1 >,<C 2,B1 >,\n<B 2,B >,<B 2,C >,<B 2,C1 >,<B 2,C2 >,<B,B 2 >,\n<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C >,<B,C 1 >,\n<B,C 2 >,<C,B >,<C 1,B >,<C 2,B >,<C,C 1 >,\n<C,C 2 >,<C 1,C >,<C 2,C >,<C 1,C2 >,<C 2,C1 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 107, 'page_label': '108'}, page_content='7.4. INDUCING RECURSIVE PROGRAMS 99\nB\nC\nC1\nC2\nB1\nB2\nB3\nC3\nFigure 7.4: Another Airline Route Map\nUsing a closed-world assumption on our map, we take the negative instances of\nCanfly to be:\n{<B 3,B2 >,<B 3,B >,<B 3,B1 >,<B 3,C >,<B 3,C1 >,\n<B 3,C2 >,<B 3,C3 >,<B 2,B3 >,<B,B 3 >,<B 1,B3 >,\n<C,B 3 >,<C 1,B3 >,<C 2,B3 >,<C 3,B3 >,<C 3,B2 >,\n<C 3,B >,<C 3,B1 >,<C 3,C >,<C 3,C1 >,<C 3,C2 >,\n<B 2,C3 >,<B,C 3 >,<B 1,C3 >,<C,C 3 >,<C 1,C3 >,\n<C 2,C3 >}\nWe will induce Canfly(x,y) using the extensionally de\ufb01ned background\nrelation Nonstop given earlier (modi\ufb01ed as required for our reduced airline map)\nand Canfly itself (recursively).\nAs before, we start with the empty program and proceed to the inner loop\nto construct a clause that is necessary. Suppose that the inner loop adds the\nbackground literal Nonstop(x,y). The clause Canfly(x,y) :- Nonstop(x,y)\nis necessary; it covers no negative instances. But it is not su\ufb03cient because it\ndoes not cover the following positive instances:\n{<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,<B 2,B1 >,\n<C,B 1 >,<C 1,B1 >,<C 2,B1 >,<B 2,C >,<B 2,C1 >,\n<B 2,C2 >,<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C 1 >,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 108, 'page_label': '109'}, page_content='100 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n<B,C 2 >,<C 1,B >,<C 2,B >,<C 1,C2 >,<C 2,C1 >}\nThus, we must add another clause to the program. In the inner loop, we \ufb01rst\ncreate the clause Canfly(x,y) :- Nonstop(x,z) which introduces the new\nvariable z. We digress brie\ufb02y to describe how a program containing a clause\nwith unbound variables in its body is interpreted. Suppose we try to inter-\npret it for the positive instance Canfly(B1,B2). The interpreter attempts to\nestablish Nonstop(B1,z) for some z. Since Nonstop(B1, B), for example, is\na background fact, the interpreter returns Twhich means that the instance\n< B1,B2 > is covered. Suppose now, we attempt to interpret the clause\nfor the negative instance Canfly(B3,B). The interpreter attempts to estab-\nlish Nonstop(B3,z) for some z. There are no background facts that match, so\nthe clause does not cover < B3,B >. Using the interpreter, we see that the\nclause Canfly(x,y) :- Nonstop(x,z) covers all of the positive instances not\nalready covered by the \ufb01rst clause, but it also covers many negative instances\nsuch as <B 2,B3 >, and <B,B 3 >. So the inner loop must add another literal.\nThis time, suppose it adds Canfly(z,y) to yield the clause Canfly(x,y) :-\nNonstop(x,z), Canfly(z,y). This clause is necessary; no negative instances\nare covered. The program is now su\ufb03cient and consistent; it is:\nCanfly(x,y) :- Nonstop(x,y)\n:- Nonstop(x,z), Canfly(z,y)\n7.5 Choosing Literals to Add\nOne of the \ufb01rst practical ILP systems was Quinlans FOIL [Quinlan, 1990]. A\nmajor problem involves deciding how to select a literal to add in the inner loop\n(from among the literals that are allowed). In FOIL, Quinlan suggested that\ncandidate literals can be compared using an information-like measuresimilar\nto the measures used in inducing decision trees. A measure that gives the same\ncomparison as does Quinlans is based on the amount by which adding a literal\nincreases the odds that an instance drawn at random from those covered by the\nnew clause is a positive instance beyond what these odds were before adding\nthe literal.\nLet p be an estimate of the probability that an instance drawn at random\nfrom those covered by a clause before adding the literal is a positive instance.\nThat is, p=(number of positive instances covered by the clause)/(total number\nof instances covered by the clause). It is convenient to express this probability\nin odds form. The odds, o, that a covered instance is positive is de\ufb01ned to\nbe o = p/(1 \u2212p). Expressing the probability in terms of the odds, we obtain\np= o/(1 + o).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 109, 'page_label': '110'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION101\nAfter selecting a literal, l, to add to a clause, some of the instances previously\ncovered are still covered; some of these are positive and some are negative. Let\npl denote the probability that an instance drawn at random from the instances\ncovered by the new clause (with l added) is positive. The odds will be denoted\nby ol. We want to select a literal, l, that gives maximal increase in these\nodds. That is, if we de\ufb01ne \u03bbl = ol/o, we want a literal that gives a high\nvalue of \u03bbl. Specializing the clause in such a way that it fails to cover many of\nthe negative instances previously covered but still covers most of the positive\ninstances previously covered will result in a high value of \u03bbl. (It turns out that\nthe value of Quinlans information theoretic measure increases monotonically\nwith \u03bbl, so we could just as well use the latter instead.)\nBesides \ufb01nding a literal with a high value of \u03bbl, Quinlans FOIL system also\nrestricts the choice to literals that:\na) contain at least one variable that has already been used,\nb) place further restrictions on the variables if the literal selected has the\nsame predicate letter as the literal being induced (in order to prevent in\ufb01nite\nrecursion), and\nc) survive a pruning test based on the values of \u03bbl for those literals selected\nso far.\nWe refer the reader to Quinlans paper for further discussion of these points.\nQuinlan also discusses post-processing pruning methods and presents experi-\nmental results of the method applied to learning recursive relations on lists, on\nlearning rules for chess endgames and for the card game Eleusis, and for some\nother standard tasks mentioned in the machine learning literature.\nThe reader should also refer to [Pazzani & Kibler, 1992,\nLavra\u02c7 c & D\u02c7 zeroski, 1994, Muggleton, 1991, Muggleton, 1992]. Discuss preprocessing,\npostprocessing, bottom-up\nmethods, and LINUS.\n7.6 Relationships Between ILP and Decision\nTree Induction\nThe generic ILP algorithm can also be understood as a type of decision tree\ninduction. Recall the problem of inducing decision trees when the values of\nattributes are categorical. When splitting on a single variable, the split at\neach node involves asking to which of several mutually exclusive and exhaustive\nsubsets the value of a variable belongs. For example, if a node tested the variable\nxi, and if xi could have values drawn from {A,B,C,D,E,F }, then one possible\nsplit (among many) might be according to whether the value of xi had as value\none of {A,B,C }or one of {D,E,F }.\nIt is also possible to make a multi-variate splittesting the values of two or\nmore variables at a time. With categorical variables, an n-variable split would\nbe based on which of several n-ary relations the values of the variables satis\ufb01ed.\nFor example, if a node tested the variables xi and xj, and if xi and xj both\ncould have values drawn from {A,B,C,D,E,F }, then one possible binary split'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 110, 'page_label': '111'}, page_content='102 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n(among many) might be according to whether or not < xi,xj > satis\ufb01ed the\nrelation {<A,C >,<C,D> }. (Note that our subset method of forming single-\nvariable splits could equivalently have been framed using 1-ary relationswhich\nare usually called properties.)\nIn this framework, the ILP problem is as follows: We are given a training set,\n\u039e, of positively and negatively labeled patterns whose components are drawn\nfrom a set of variables {x,y,z,... }. The positively labeled patterns in \u039e form an\nextensional de\ufb01nition of a relation, R. We are also given background relations,\nR1,...,R k, on various subsets of these variables. (That is, we are given sets\nof tuples that are in these relations.) We desire to construct an intensional\nde\ufb01nition of Rin terms of the R1,...,R k, such that all of the positively labeled\npatterns in \u039e are satis\ufb01ed by R and none of the negatively labeled patterns\nare. The intensional de\ufb01nition will be in terms of a logic program in which the\nrelation R is the head of a set of clauses whose bodies involve the background\nrelations.\nThe generic ILP algorithm can be understood as decision tree induction,\nwhere each node of the decision tree is itself a sub-decision tree, and each sub-\ndecision tree consists of nodes that make binary splits on several variables using\nthe background relations, Ri. Thus we will speak of a top-level decision tree\nand various sub-decision trees. (Actually, our decision trees will be decision\nlistsa special case of decision trees, but we will refer to them as trees in our\ndiscussions.)\nIn broad outline, the method for inducing an intensional version of the rela-\ntion R is illustrated by considering the decision tree shown in Fig. 7.5. In this\ndiagram, the patterns in \u039e are \ufb01rst \ufb01ltered through the decision tree in top-\nlevel node 1. The background relation R1 is satis\ufb01ed by some of these patterns;\nthese are \ufb01ltered to the right (to relation R2), and the rest are \ufb01ltered to the\nleft (more on what happens to these later). Right-going patterns are \ufb01ltered\nthrough a sequence of relational tests until only positively labeled patterns sat-\nisfy the last relationin this case R3. That is, the subset of patterns satisfying\nall the relations, R1, R2, and R3 contains only positive instances from \u039e. (We\nmight say that this combination of tests is necessary. They correspond to the\nclause created in the \ufb01rst pass through the inner loop of the generic ILP algo-\nrithm.) Let us call the subset of patterns satisfying these relations, \u039e 1; these\nsatisfy Node 1 at the top level. All other patterns, that is {\u039e \u2212\u039e1}= \u039e2 are\n\ufb01ltered to the left by Node 1.\n\u039e2 is then \ufb01ltered by top-level Node 2 in much the same manner, so that\nNode 2 is satis\ufb01ed only by the positively labeled samples in \u039e 2. We continue\n\ufb01ltering through top-level nodes until only the negatively labeled patterns fail to\nsatisfy a top node. In our example, \u039e 4 contains only negatively labeled patterns\nand the union of \u039e 1 and \u039e3 contains all the positively labeled patterns. The\nrelation, R, that distinguishes positive from negative patterns in \u039e is then given\nin terms of the following logic program:\nR :- R1, R2, R3'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 111, 'page_label': '112'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION103\nR1\nR2\nR3\nT\nT\nT\nF\nF\nF\nT\nF\nR4\nR5\nT\nT\nF\nF\nTF\nU\nU1\nU2 = U < U1\nU3U4= U2 < U3\nNode 1\nNode 2\n(only positive\ninstances\nsatisfy all three\ntests)\n(only positivel\ninstances satisfy\nthese two tests)\n(only negative\ninstances)\nFigure 7.5: A Decision Tree for ILP\n:- R4, R5\nIf we apply this sort of decision-tree induction procedure to the problem\nof generating a logic program for the relation Nonstop (refer to Fig. 7.3), we\nobtain the decision tree shown in Fig. 7.6. The logic program resulting from\nthis decision tree is the same as that produced by the generic ILP algorithm.\nIn setting up the problem, the training set, \u039e can be expressed as a set of 2-\ndimensional vectors with components xand y. The values of these components\nrange over the cities {A,B,C,A 1,A2,B1,B2,C1,C2}except (for simplicity)\nwe do not allow patterns in which x and y have the same value. As before, the\nrelation, Nonstop, contains the following pairs of cities, which are the positive\ninstances:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nAll other pairs of cities named in the map of Fig. 7.3 (using the closed world\nassumption) are not in the relation Nonstop and thus are negative instances.\nBecause the values of xand y are categorical, decision-tree induction would\nbe a very di\ufb03cult taskinvolving as it does the need to invent relations on'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 112, 'page_label': '113'}, page_content='104 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nx and y to be used as tests. But with the background relations, Ri (in this\ncase Hub and Satellite), the problem is made much easier. We select these\nrelations in the same way that we select literals; from among the available tests,\nwe make a selection based on which leads to the largest value of \u03bbRi.\n7.7 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 113, 'page_label': '114'}, page_content='7.7. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 105\nHub(x) T\nF\nU\nNode 1\n(top level)\n{<A,B>, <A,C>,\n<B,C>, <B,A>,\n<C,A>, <C,B>}\nHub(y) T\nT\nFNode 2\n(top level)\nSatellite(x,y)\nF T\nT {<A1,A>, <A2,A>, <B1,B>,\n<B2,B>, <C1,C>, <C2,C>}\nF\n{<A,A1>, <A,A2>,<B,B1>,\n<B,B2>,  <C,C1>, <C,C2>}\nSatellite(y,x)\nF\nF\nT\nNode 3\n(top level)\nT\n{Only negative instances}\n(Only positive instances)\n(Only positive instances)\n(Only positive instances)\nF\nFigure 7.6: A Decision Tree for the Airline Route Problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 114, 'page_label': '115'}, page_content='106 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 115, 'page_label': '116'}, page_content='Chapter 8\nComputational Learning\nTheory\nIn chapter one we posed the problem of guessing a function given a set of\nsample inputs and their values. We gave some intuitive arguments to support\nthe claim that after seeing only a small fraction of the possible inputs (and\ntheir values) that we could guess almost correctly the values of most subsequent\ninputsif we knew that the function we were trying to guess belonged to an\nappropriately restricted subset of functions. That is, a given training set of\nsample patterns might be adequate to allow us to select a function, consistent\nwith the labeled samples , from among a restricted set of hypotheses such that\nwith high probability the function we select will be approximately correct (small\nprobability of error) on subsequent samples drawn at random according to the\nsame distribution from which the labeled samples were drawn. This insight\nled to the theory of probably approximately correct (PAC) learninginitially\ndeveloped by Leslie Valiant [Valiant, 1984]. We present here a brief description\nof the theory for the case of Boolean functions. [Dietterich, 1990, Haussler, 1988,\nHaussler, 1990] give nice surveys of the important results. Other overviews?\n8.1 Notation and Assumptions for PAC Learn-\ning Theory\nWe assume a training set \u039e of n-dimensional vectors, Xi, i = 1 ,...,m , each\nlabeled (by 1 or 0) according to a target function, f, which is unknown to\nthe learner. The probability of any given vector X being in \u039e, or later being\npresented to the learner, is P(X). The probability distribution, P, can be\narbitrary. (In the literature of PAC learning theory, the target function is usually\ncalled the target concept and is denoted by c, but to be consistent with our\nprevious notation we will continue to denote it by f.) Our problem is to guess\n107'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 116, 'page_label': '117'}, page_content='108 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\na function, h(X), based on the labeled samples in \u039e. In PAC theory such a\nguessed function is called the hypothesis. We assume that the target function\nis some element of a set of functions, C. We also assume that the hypothesis,\nh, is an element of a set, H, of hypotheses, which includes the set, C, of target\nfunctions. His called the hypothesis space.\nIn general, h wont be identical to f, but we can strive to have the value of\nh(X) = the value of f(X) for most Xs. That is, we want hto be approximately\ncorrect. To quantify this notion, we de\ufb01ne the error of h, \u03b5h, as the probability\nthat an X drawn randomly according to P will be misclassi\ufb01ed:\n\u03b5h =\n\u2211\n[X:h(X)\u0338=f(X)]\nP(X)\nBoldface symbols need to be\nsmaller when they are subscripts in\nmath environments. We say that h is approximately (except for \u03b5 ) correct if \u03b5h \u2264\u03b5, where \u03b5 is the\naccuracy parameter.\nSuppose we are able to \ufb01nd anhthat classi\ufb01es all mrandomly drawn training\nsamples correctly; that is, h is consistent with this randomly selected training\nset, \u039e. If m is large enough, will such an h be approximately correct (and\nfor what value of \u03b5)? On some training occasions, using m randomly drawn\ntraining samples, such an h might turn out to be approximately correct (for a\ngiven value of \u03b5), and on others it might not. We say that his probably (except\nfor \u03b4) approximately correct (PAC) if the probability that it is approximately\ncorrect is greater than 1\u2212\u03b4, where \u03b4is the con\ufb01dence parameter. We shall show\nthat if m is greater than some bound whose value depends on \u03b5 and \u03b4, such an\nh is guaranteed to be probably approximately correct.\nIn general, we say that a learning algorithm PAC-learns functions from Cin\nterms of Hi\ufb00 for every function f\u03f5 C, it outputs a hypothesis h\u03f5 H, such that\nwith probability at least (1 \u2212\u03b4), \u03b5h \u2264\u03b5. Such a hypothesis is called probably\n(except for \u03b4) approximately (except for \u03b5) correct.\nWe want learning algorithms that are tractable, so we want an algorithm\nthat PAC-learns functions in polynomial time. This can only be done for certain\nclasses of functions. If there are a \ufb01nite number of hypotheses in a hypothesis\nset (as there are for many of the hypothesis sets we have considered), we could\nalways produce a consistent hypothesis from this set by testing all of them\nagainst the training data. But if there are an exponential number of hypotheses,\nthat would take exponential time. We seek training methods that produce\nconsistent hypotheses in less time. The time complexities for various hypothesis\nsets have been determined, and these are summarized in a table to be presented\nlater.\nA class, C, is polynomially PAC learnable in terms of Hprovided there exists\na polynomial-time learning algorithm (polynomial in the number of samples\nneeded, m, in the dimension, n, in 1 /\u03b5, and in 1 /\u03b4) that PAC-learns functions\nin Cin terms of H.\nInitial work on PAC assumed H= C, but it was later shown that some func-\ntions cannot be polynomially PAC-learned under such an assumption (assuming'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 117, 'page_label': '118'}, page_content='8.2. PAC LEARNING 109\nP \u0338= NP)but can be polynomially PAC-learned if His a strict superset of C!\nAlso our de\ufb01nition does not specify the distribution, P, from which patterns\nare drawn nor does it say anything about the properties of the learning algo-\nrithm. Since Cand Hdo not have to be identical, we have the further restrictive\nde\ufb01nition:\nA properly PAC-learnableclass is a classCfor which there exists an algorithm\nthat polynomially PAC-learns functions from Cin terms of C.\n8.2 PAC Learning\n8.2.1 The Fundamental Theorem\nSuppose our learning algorithm selects some hrandomly from among those that\nare consistent with the values of f on the mtraining patterns. The probability\nthat the error of this randomly selected his greater than some \u03b5, with hconsis-\ntent with the values of f(X) for minstances of X (drawn according to arbitrary\nP), is less than or equal to |H|e\u2212\u03b5m, where |H|is the number of hypotheses in\nH. We state this result as a theorem [Blumer, et al., 1987]:\nTheorem 8.1 (Blumer, et al.) Let Hbe any set of hypotheses, \u039e be a set of\nm \u22651 training examples drawn independently according to some distribution\nP, f be any classi\ufb01cation function in H, and \u03b5> 0. Then, the probability that\nthere exists a hypothesis hconsistent with f for the members of \u039e but with error\ngreater than \u03b5 is at most |H|e\u2212\u03b5m.\nProof:\nConsider the set of all hypotheses, {h1,h2,...,h i,...,h S}, in H, where S =\n|H|. The error for hi is \u03b5hi= the probability that hi will classify a pattern in\nerror (that is, di\ufb00erently than f would classify it). The probability that hi will\nclassify a pattern correctly is (1\u2212\u03b5hi). A subset, HB, of Hwill have error greater\nthan \u03b5. We will call the hypotheses in this subset bad. The probability that any\nparticular one of these bad hypotheses, sayhb, would classify a pattern correctly\nis (1\u2212\u03b5hb). Since \u03b5hb >\u03b5, the probability that hb (or any other bad hypothesis)\nwould classify a pattern correctly is less than (1 \u2212\u03b5). The probability that it\nwould classify all m independently drawn patterns correctly is then less than\n(1 \u2212\u03b5)m.\nThat is,\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB] \u2264(1 \u2212\u03b5)m.\nprob[some h \u03f5HB classi\ufb01es all m patterns correctly]\n= \u2211\nhb \u03f5 HB\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB]\n\u2264K(1 \u2212\u03b5)m, where K = |HB|.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 118, 'page_label': '119'}, page_content='110 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nThat is,\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n\u2264K(1 \u2212\u03b5)m.\nSince K \u2264|H| and (1 \u2212\u03b5)m \u2264e\u2212\u03b5m, we have:\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n= prob[there is a hypothesis with error >\u03b5 and that classi\ufb01es all mpatterns\ncorrectly] \u2264|H|e\u2212\u03b5m.\nQED\nA corollary of this theorem is:\nCorollary 8.2 Given m \u2265 (1/\u03b5)(ln |H|+ ln(1/\u03b4)) independent samples, the\nprobability that there exists a hypothesis in Hthat is consistent with f on these\nsamples and has error greater than \u03b5 is at most \u03b4.\nProof: We are to \ufb01nd a bound on m that guarantees that\nprob[there is a hypothesis with error > \u03b5and that classi\ufb01es all m patterns\ncorrectly] \u2264 \u03b4. Thus, using the result of the theorem, we must show that\n|H|e\u2212\u03b5m \u2264\u03b4. Taking the natural logarithm of both sides yields:\nln |H|\u2212\u03b5m\u2264ln \u03b4\nor\nm\u2265(1/\u03b5)(ln |H|+ ln(1/\u03b4))\nQED\nThis corollary is important for two reasons. First it clearly states that we\ncan select any hypothesis consistent with the m samples and be assured that\nwith probability (1 \u2212\u03b4) its error will be less than \u03b5. Also, it shows that in\norder for mto increase no more than polynomially with n, |H|can be no larger\nthan 2O(nk). No class larger than that can be guaranteed to be properly PAC\nlearnable.\nHere is a possible point of confusion: The bound given in the corollary is\nan upper bound on the value of mneeded to guarantee polynomial probably ap-\nproximately correct learning. Values of mgreater than that bound are su\ufb03cient\n(but might not be necessary). We will present a lower (necessary) bound later\nin the chapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 119, 'page_label': '120'}, page_content='8.2. PAC LEARNING 111\n8.2.2 Examples\nTerms\nLet Hbe the set of terms (conjunctions of literals). Then, |H|= 3n, and\nm\u2265(1/\u03b5)(ln(3n) + ln(1/\u03b4))\n\u2265(1/\u03b5)(1.1n+ ln(1/\u03b4))\nNote that the bound on m increases only polynomially with n, 1/\u03b5, and 1/\u03b4.\nFor n= 50, \u03b5= 0.01 and \u03b4= 0.01, m\u22655,961 guarantees PAC learnability.\nIn order to show that terms are properly PAC learnable , we additionally\nhave to show that one can \ufb01nd in time polynomial in m and n a hypothesis\nh consistent with a set of m patterns labeled by the value of a term. The\nfollowing procedure for \ufb01nding such a consistent hypothesis requires O(nm)\nsteps (adapted from [Dietterich, 1990, page 268]):\nWe are given a training sequence, \u039e, of m examples. Find the \ufb01rst pattern,\nsay X1, in that list that is labeled with a 1. Initialize a Boolean function,\nh, to the conjunction of the n literals corresponding to the values of the n\ncomponents of X1. (Components with value 1 will have corresponding positive\nliterals; components with value 0 will have corresponding negative literals.) If\nthere are no patterns labeled by a 1, we exit with the null concept ( h \u22610 for\nall patterns). Then, for each additional pattern, Xi, that is labeled with a 1,\nwe delete from h any Boolean variables appearing in Xi with a sign di\ufb00erent\nfrom their sign in h. After processing all the patterns labeled with a 1, we check\nall of the patterns labeled with a 0 to make sure that none of them is assigned\nvalue 1 by h. If, at any stage of the algorithm, any patterns labeled with a 0\nare assigned a 1 by h, then there exists no term that consistently classi\ufb01es the\npatterns in \u039e, and we exit with failure. Otherwise, we exit with h. Change this paragraph if this\nalgorithm was presented in Chapter\nThree.As an example, consider the following patterns, all labeled with a 1 (from\n[Dietterich, 1990]):\n(0,1,1,0)\n(1,1,1,0)\n(1,1,0,0)\nAfter processing the \ufb01rst pattern, we have h = x1x2x3x4; after processing the\nsecond pattern, we have h = x2x3x4; \ufb01nally, after the third pattern, we have\nh= x2x4.\nLinearly Separable Functions\nLet Hbe the set of all linearly separable functions. Then, |H|\u2264 2n2\n, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 120, 'page_label': '121'}, page_content='112 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nm\u2265(1/\u03b5)\n(\nn2 ln 2 + ln(1/\u03b4)\n)\nAgain, note that the bound on m increases only polynomially with n, 1/\u03b5, and\n1/\u03b4.\nFor n= 50, \u03b5= 0.01 and \u03b4 = 0.01, m\u2265173,748 guarantees PAC learnabil-\nity.\nTo show that linearly separable functions are properly PAC learnable , we\nwould have additionally to show that one can \ufb01nd in time polynomial in mand\nna hypothesis hconsistent with a set of mlabeled linearly separable patterns.Linear programming is polynomial.\n8.2.3 Some Properly PAC-Learnable Classes\nSome properly PAC-learnable classes of functions are given in the following\ntable. (Adapted from [Dietterich, 1990, pages 262 and 268] which also gives\nreferences to proofs of some of the time complexities.)\nH |H| Time Complexity P. Learnable?\nterms 3n polynomial yes\nk-term DNF 2O(kn) NP-hard no\n(k disjunctive terms)\nk-DNF 2O(nk) polynomial yes\n(a disjunction of k-sized terms)\nk-CNF 2O(nk) polynomial yes\n(a conjunction of k-sized clauses)\nk-DL 2O(nkklg n) polynomial yes\n(decision lists with k-sized terms)\nlin. sep. 2O(n2) polynomial yes\nlin. sep. with (0,1) weights ? NP-hard no\nk-2NN ? NP-hard no\nDNF 22n\npolynomial no\n(all Boolean functions)\n(Members of the class k-2NN are two-layer, feedforward neural networks with\nexactly k hidden units and one output unit.)\nSummary: In order to show that a class of functions is Properly PAC-\nLearnable :\na. Show that there is an algorithm that produces a consistent hypothesis on\nm n-dimensional samples in time polynomial in m and n.\nb. Show that the sample size, m, needed to ensure PAC learnability is polyno-\nmial (or better) in (1/\u03b5), (1/\u03b4), and nby showing that ln|H|is polynomial\nor better in the number of dimensions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 121, 'page_label': '122'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 113\nAs hinted earlier, sometimes enlarging the class of hypotheses makes learning\neasier. For example, the table above shows that k-CNF is PAC learnable, but\nk-term-DNF is not. And yet, k-term-DNF is a subclass of k-CNF! So, even if\nthe target function were in k-term-DNF, one would be able to \ufb01nd a hypothesis\nin k-CNF that is probably approximately correct for the target function. Sim-\nilarly, linearly separable functions implemented by TLUs whose weight values\nare restricted to 0 and 1 are not properly PAC learnable, whereas unrestricted\nlinearly separable functions are. It is possible that enlarging the space of hy-\npotheses makes \ufb01nding one that is consistent with the training examples easier.\nAn interesting question is whether or not the class of functions ink-2NN is poly-\nnomially PAC learnable if the hypotheses are drawn from k\u2032-2NN with k\u2032>k .\n(At the time of writing, this matter is still undecided.)\nAlthough PAC learning theory is a powerful analytic tool, it (like complexity\ntheory) deals mainly with worst-case results. The fact that the class of two-\nlayer, feedforward neural networks is not polynomially PAC learnable is more an\nattack on the theory than it is on the networks, which have had many successful\napplications. As [Baum, 1994, page 416-17] says:  ... humans are capable of\nlearning in the natural world. Therefore, a proof within some model of learning\nthat learning is not feasible is an indictment of the model. We should examine\nthe model to see what constraints can be relaxed and made more realistic.\n8.3 The Vapnik-Chervonenkis Dimension\n8.3.1 Linear Dichotomies\nConsider a set, H, of functions, and a set, \u039e, of (unlabeled) patterns. One\nmeasure of the expressive power of a set of hypotheses, relative to \u039e, is its\nability to make arbitrary classi\ufb01cations of the patterns in \u039e. 1 If there are m\npatterns in \u039e, there are 2 m di\ufb00erent ways to divide these patterns into two\ndisjoint and exhaustive subsets. We say there are 2 m di\ufb00erent dichotomies of\n\u039e. If \u039e were to include all of the 2 n Boolean patterns, for example, there are\n22n\nways to dichotomize them, and (of course) the set of all possible Boolean\nfunctions dichotomizes them in all of these ways. But a subset,H, of the Boolean\nfunctions might not be able to dichotomize an arbitrary set, \u039e, of m Boolean\npatterns in all 2 m ways. In general (that is, even in the non-Boolean case), we\nsay that if a subset, H, of functions can dichotomize a set, \u039e, of m patterns in\nall 2m ways, then Hshatters \u039e.\nAs an example, consider a set \u039e of m patterns in the n-dimensional space,\nRn. (That is, the ncomponents of these patterns are real numbers.) We de\ufb01ne\na linear dichotomy as one implemented by an (n\u22121)-dimensional hyperplane in\nthe n-dimensional space. How many linear dichotomies of m patterns in n di-\nmensions are there? For example, as shown in Fig. 8.1, there are 14 dichotomies\n1And, of course, if a hypothesis drawn from a set that could make arbitrary classi\ufb01cations\nof a set of training patterns, there is little likelihood that such a hypothesis will generalize\nwell beyond the training set.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 122, 'page_label': '123'}, page_content='114 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nof four points in two dimensions (each separating line yields two dichotomies\ndepending on whether the points on one side of the line are classi\ufb01ed as 1 or 0).\n(Note that even though there are an in\ufb01nite number of hyperplanes, there are,\nnevertheless, only a \ufb01nite number of ways in which hyperplanes can dichotomize\na \ufb01nite number of patterns. Small movements of a hyperplane typically do not\nchange the classi\ufb01cations of any patterns.)\n12\n3\n4\n14 dichotomies of 4 points in 2 dimensions\n5\n6\n7\nFigure 8.1: Dichotomizing Points in Two Dimensions\nThe number of dichotomies achievable by hyperplanes depends on how the\npatterns are disposed. For the maximum number of linear dichotomies, the\npoints must be in what is called general position. For m>n , we say that a set\nof m points is in general position in an n-dimensional space if and only if no\nsubset of (n+1) points lies on an (n\u22121)-dimensional hyperplane. When m\u2264n,\na set of m points is in general position if no ( m\u22122)-dimensional hyperplane\ncontains the set. Thus, for example, a set of m\u22654 points is in general position\nin a three-dimensional space if no four of them lie on a (two-dimensional) plane.\nWe will denote the number of linear dichotomies of mpoints in general position\nin an n-dimensional space by the expression \u03a0 L(m,n).\nIt is not too di\ufb03cult to verify that:Include the derivation.\n\u03a0L(m,n) = 2\nn\u2211\ni=0\nC(m\u22121,i) for m>n, and\n= 2m for m\u2264n'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 123, 'page_label': '124'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 115\nwhere C(m\u22121,i) is the binomial coe\ufb03cient (m\u22121)!\n(m\u22121\u2212i)!i! .\nThe table below shows some values for \u03a0 L(m,n).\nm n\n(no. of patterns) (dimension)\n1 2 3 4 5\n1 2 2 2 2 2\n2 4 4 4 4 4\n3 6 8 8 8 8\n4 8 14 16 16 16\n5 10 22 30 32 32\n6 12 32 52 62 64\n7 14 44 84 114 126\n8 16 58 128 198 240\nNote that the class of linear dichotomies shatters the m patterns if m\u2264n+ 1.\nThe bold-face entries in the table correspond to the highest values of m for\nwhich linear dichotomies shatter m patterns in n dimensions.\n8.3.2 Capacity\nLet Pm,n = \u03a0L(m,n)\n2m = the probability that a randomly selected dichotomy (out\nof the 2 m possible dichotomies of m patterns in n dimensions) will be linearly\nseparable. In Fig. 8.2 we plot P\u03bb(n+1),n versus \u03bb and n, where \u03bb= m/(n+ 1).\nNote that for large n (say n >30) how quickly Pm,n falls from 1 to 0 as\nm goes above 2( n+ 1). For m <2(n+ 1), any dichotomy of the m points is\nalmost certainly linearly separable. But for m> 2(n+ 1), a randomly selected\ndichotomy of the m points is almost certainly not linearly separable. For this\nreason m= 2(n+ 1) is called the capacity of a TLU [Cover, 1965]. Unless the\nnumber of training patterns exceeds the capacity, the fact that a TLU separates\nthose training patterns according to their labels means nothing in terms of how\nwell that TLU will generalize to new patterns. There is nothing special about\na separation found for m <2(n+ 1) patternsalmost any dichotomy of those\npatterns would have been linearly separable. To make sure that the separation\nfound is forced by the training set and thus generalizes well, it has to be the\ncase that there are very few linearly separable functions that would separate\nthe m training patterns.\nAnalogous results about the generalizing abilities of neural networks have\nbeen developed by [Baum & Haussler, 1989] and given intuitive and experimen-\ntal justi\ufb01cation in [Baum, 1994, page 438]:\nThe results seemed to indicate the following heuristic rule holds. If\nM examples [can be correctly classi\ufb01ed by] a net withW weights (for\nM >>W), the net will make a fraction \u03b5of errors on new examples\nchosen from the same [uniform] distribution where \u03b5= W/M.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 124, 'page_label': '125'}, page_content='116 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n0.25\n0.5\n0.75\n1\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n25\n.5\n75\n1\nPh(n + 1), n\nh\nn\nFigure 8.2: Probability that a Random Dichotomy is Linearly Separable\n8.3.3 A More General Capacity Result\nCorollary 7.2 gave us an expression for the number of training patterns su\ufb03cient\nto guarantee a required level of generalizationassuming that the function we\nwere guessing was a function belonging to a class of known and \ufb01nite cardinality.\nThe capacity result just presented applies to linearly separable functions for non-\nbinary patterns. We can extend these ideas to general dichotomies of non-binary\npatterns.\nIn general, let us denote the maximum number of dichotomies of any set\nof m n-dimensional patterns by hypotheses in Has \u03a0H(m,n). The number of\ndichotomies will, of course, depend on the disposition of the m points in the\nn-dimensional space; we take \u03a0 H(m,n) to be the maximum over all possible\narrangements of the m points. (In the case of the class of linearly separable\nfunctions, the maximum number is achieved when the m points are in general\nposition.) For each class, H, there will be some maximum value of mfor which\n\u03a0H(m,n) = 2m, that is, for which Hshatters the m patterns. This maximum\nnumber is called the Vapnik-Chervonenkis (VC) dimension and is denoted by\nVCdim(H) [Vapnik & Chervonenkis, 1971].\nWe saw that for the class of linear dichotomies, VCdim( Linear) = (n+ 1).\nAs another example, let us calculate the VC dimension of the hypothesis space\nof single intervals on the real lineused to classify points on the real line. We\nshow an example of how points on the line might be dichotomized by a single\ninterval in Fig. 8.3. The set \u039e could be, for example, {0.5, 2.5, - 2.3, 3.14}, and\none of the hypotheses in our set would be [1, 4.5]. This hypothesis would label\nthe points 2.5 and 3.14 with a 1 and the points - 2.3 and 0.5 with a 0. This'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 125, 'page_label': '126'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 117\nset of hypotheses (single intervals on the real line) can arbitrarily classify any\ntwo points. But no single interval can classify three points such that the outer\ntwo are classi\ufb01ed as 1 and the inner one as 0. Therefore the VC dimension of\nsingle intervals on the real line is 2. As soon as we have many more than 2\ntraining patterns on the real line and provided we know that the classi\ufb01cation\nfunction we are trying to guess is a single interval, then we begin to have good\ngeneralization.\nFigure 8.3: Dichotomizing Points by an Interval\nThe VC dimension is a useful measure of the expressive power of a hypothesis\nset. Since any dichotomy of VCdim(H) or fewer patterns in general position inn\ndimensions can be achieved by some hypothesis in H, we must have many more\nthan VCdim(H) patterns in the training set in order that a hypothesis consistent\nwith the training set is su\ufb03ciently constrained to imply good generalization.\nOur examples have shown that the concept of VC dimension is not restricted\nto Boolean functions.\n8.3.4 Some Facts and Speculations About the VC Dimen-\nsion\n If there are a \ufb01nite number, |H|, of hypotheses in H, then:\nVCdim(H) \u2264log(|H|)\n The VC dimension of terms in n dimensions is n.\n Suppose we generalize our example that used a hypothesis set of single\nintervals on the real line. Now let us consider an n-dimensional feature\nspace and tests of the form Li \u2264xi \u2264Hi. We allow only one such test per\ndimension. A hypothesis space consisting of conjunctions of these tests\n(called axis-parallel hyper-rectangles) has VC dimension bounded by:\nn\u2264 VCdim \u22642n\n As we have already seen, TLUs with n inputs have a VC dimension of\nn+ 1.\n [Baum, 1994, page 438] gives experimental evidence for the proposition\nthat  ... multilayer [neural] nets have a VC dimension roughly equal to\ntheir total number of [adjustable] weights.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 126, 'page_label': '127'}, page_content='118 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n8.4 VC Dimension and PAC Learning\nThere are two theorems that connect the idea of VC dimension with PAC learn-\ning [Blumer, et al., 1990]. We state these here without proof.\nTheorem 8.3 (Blumer, et al.) A hypothesis space His PAC learnable i\ufb00 it\nhas \ufb01nite VC dimension.\nTheorem 8.4 A set of hypotheses, H, is properly PAC learnable if:\na. m\u2265(1/\u03b5) max [4 lg(2/\u03b4), 8 VCdim lg(13 /\u03b5)], and\nb. if there is an algorithm that outputs a hypothesis h\u03f5 Hconsistent with the\ntraining set in polynomial (in m and n) time.\nThe second of these two theorems improves the bound on the number of\ntraining patterns needed for linearly separable functions to one that is linear\nin n. In our previous example of how many training patterns were needed to\nensure PAC learnability of a linearly separable function if n= 50, \u03b5= 0.01, and\n\u03b4 = 0.01, we obtained m \u2265173,748. Using the Blumer, et al. result we would\nget m\u226552,756.\nAs another example of the second theorem, let us take Hto be the set of\nclosed intervals on the real line. The VC dimension is 2 (as shown previously).\nWith n= 50, \u03b5= 0.01, and \u03b4= 0.01, m\u226516,551 ensures PAC learnability.\nThere is also a theorem that gives a lower (necessary) bound on the number\nof training patterns required for PAC learning [Ehrenfeucht, et al., 1988]:\nTheorem 8.5 Any PAC learning algorithm must examine at least\n\u2126(1/\u03b5lg(1/\u03b4) + VCdim(H)) training patterns.\nThe di\ufb00erence between the lower and upper bounds is\nO(log(1/\u03b5)VCdim(H)/\u03b5).\n8.5 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 127, 'page_label': '128'}, page_content='Chapter 9\nUnsupervised Learning\n9.1 What is Unsupervised Learning?\nConsider the various sets of points in a two-dimensional space illustrated in Fig.\n9.1. The \ufb01rst set (a) seems naturally partitionable into two classes, while the\nsecond (b) seems di\ufb03cult to partition at all, and the third (c) is problematic.\nUnsupervised learning uses procedures that attempt to \ufb01nd natural partitions\nof patterns. There are two stages:\n Form an R-way partition of a set \u039e of unlabeled training patterns (where\nthe value of R, itself, may need to be induced from the patterns). The\npartition separates \u039e into R mutually exclusive and exhaustive subsets,\n\u039e1,..., \u039eR, called clusters.\n Design a classi\ufb01er based on the labels assigned to the training patterns by\nthe partition.\nWe will explain shortly various methods for deciding how many clusters there\nshould be and for separating a set of patterns into that many clusters. We can\nbase some of these methods, and their motivation, on minimum-description-\nlength (MDL) principles. In that setting, we assume that we want to encode\na description of a set of points, \u039e, into a message of minimal length. One\nencoding involves a description of each point separately; other, perhaps shorter,\nencodings might involve a description of clusters of points together with how\neach point in a cluster can be described given the cluster it belongs to. The\nspeci\ufb01c techniques described in this chapter do not explicitly make use of MDL\nprinciples, but the MDL method has been applied with success. One of the\nMDL-based methods, Autoclass II [Cheeseman, et al., 1988] discovered a new\nclassi\ufb01cation of stars based on the properties of infrared sources.\nAnother type of unsupervised learning involves \ufb01nding hierarchies of par-\ntitionings or clusters of clusters. A hierarchical partition is one in which \u039e is\n119'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 128, 'page_label': '129'}, page_content='120 CHAPTER 9. UNSUPERVISED LEARNING\na)  two clusters\nb) one cluster\nc) ?\nFigure 9.1: Unlabeled Patterns\ndivided into mutually exclusive and exhaustive subsets, \u039e 1,..., \u039eR; each set,\n\u039ei, ( i = 1 ,...,R ) is divided into mutually exclusive and exhaustive subsets,\nand so on. We show an example of such a hierarchical partition in Fig. 9.2.\nThe hierarchical form is best displayed as a tree, as shown in Fig. 9.3. The tip\nnodes of the tree can further be expanded into their individual pattern elements.\nOne application of such hierarchical partitions is in organizing individuals into\ntaxonomic hierarchies such as those used in botany and zoology.\n9.2 Clustering Methods\n9.2.1 A Method Based on Euclidean Distance\nMost of the unsupervised learning methods use a measure of similarity between\npatterns in order to group them into clusters. The simplest of these involves\nde\ufb01ning a distance between patterns. For patterns whose features are numeric,\nthe distance measure can be ordinary Euclidean distance between two points in\nan n-dimensional space.\nThere is a simple, iterative clustering method based on distance. It can\nbe described as follows. Suppose we have R randomly chosen cluster seekers,\nC1,..., CR. These are points in an n-dimensional space that we want to adjust\nso that they each move toward the center of one of the clusters of patterns.\nWe present the (unlabeled) patterns in the training set, \u039e, to the algorithm'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 129, 'page_label': '130'}, page_content='9.2. CLUSTERING METHODS 121\nU11\nU12\nU21\nU22\nU23\nU31\nU32\nU11 F U12 = U1\nU21 F U22 F U23 = U2\nU31 F U32 = U3\nU1 F U2 F U3 = U\nFigure 9.2: A Hierarchy of Clusters\none-by-one. For each pattern, Xi, presented, we \ufb01nd that cluster seeker, Cj,\nthat is closest to Xi and move it closer to Xi:\nCj \u2190\u2212(1 \u2212\u03b1j)Cj + \u03b1jXi\nwhere \u03b1j is a learning rate parameter for the j-th cluster seeker; it determines\nhow far Cj is moved toward Xi.\nRe\ufb01nements on this procedure make the cluster seekers move less far as\ntraining proceeds. Suppose each cluster seeker, Cj, has a mass, mj, equal to\nthe number of times that it has moved. As a cluster seekers mass increases it\nmoves less far towards a pattern. For example, we might set \u03b1j = 1/(1 + mj)\nand use the above rule together with mj \u2190\u2212mj+1. With this adjustment rule,\na cluster seeker is always at the center of gravity (sample mean) of the set of\npatterns toward which it has so far moved. Intuitively, if a cluster seeker ever\ngets within some reasonably well clustered set of patterns (and if that cluster\nseeker is the only one so located), it will converge to the center of gravity of\nthat cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 130, 'page_label': '131'}, page_content='122 CHAPTER 9. UNSUPERVISED LEARNING\nU\nU2\nU11 U12 U31 U32 U21 U22 U23\nU1 U3\nFigure 9.3: Displaying a Hierarchy as a Tree\nOnce the cluster seekers have converged, the classi\ufb01er implied by the now-\nlabeled patterns in \u039e can be based on a Voronoi partitioning of the space (based\non distances to the various cluster seekers). This kind of classi\ufb01cation, an ex-\nample of which is shown in Fig. 9.4, can be implemented by a linear machine.\nGeorgy Fedoseevich Voronoi, was a\nRussian mathematician who lived\nfrom 1868 to 1909. When basing partitioning on distance, we seek clusters whose patterns are\nas close together as possible. We can measure the badness, V, of a cluster of\npatterns, {Xi}, by computing its sample variance de\ufb01ned by:\nV = (1/K)\n\u2211\ni\n(Xi \u2212M)2\nwhere M is the sample mean of the cluster, which is de\ufb01ned to be:\nM = (1/K)\n\u2211\ni\nXi\nand K is the number of points in the cluster.\nWe would like to partition a set of patterns into clusters such that the sum of\nthe sample variances (badnesses) of these clusters is small. Of course if we have\none cluster for each pattern, the sample variances will all be zero, so we must\narrange that our measure of the badness of a partition must increase with the\nnumber of clusters. In this way, we can seek a trade-o\ufb00 between the variances of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 131, 'page_label': '132'}, page_content='9.2. CLUSTERING METHODS 123\nC1\nC2\nC3\nSeparating boundaries\nFigure 9.4: Minimum-Distance Classi\ufb01cation\nthe clusters and the number of them in a way somewhat similar to the principle\nof minimal description length discussed earlier.\nElaborations of our basic cluster-seeking procedure allow the number of clus-\nter seekers to vary depending on the distances between them and depending on\nthe sample variances of the clusters. For example, if the distance, dij, between\ntwo cluster seekers, Ci and Cj, ever falls below some threshold \u03b5, then we can\nreplace them both by a single cluster seeker placed at their center of gravity\n(taking into account their respective masses). In this way we can decrease the\noverall badness of a partition by reducing the number of clusters for compara-\ntively little penalty in increased variance.\nOn the other hand, if any of the cluster seekers, say Ci, de\ufb01nes a cluster\nwhose sample variance is larger than some amount \u03b4, then we can place a new\ncluster seeker, Cj, at some random location somewhat adjacent to Ci and reset\nthe masses of both Ci and Cj to zero. In this way the badness of the par-\ntition might ultimately decrease by decreasing the total sample variance with\ncomparatively little penalty for the additional cluster seeker. The values of the\nparameters \u03b5 and \u03b4 are set depending on the relative weights given to sample\nvariances and numbers of clusters.\nIn distance-based methods, it is important to scale the components of the\npattern vectors. The variation of values along some dimensions of the pattern\nvector may be much di\ufb00erent than that of other dimensions. One commonly\nused technique is to compute the standard deviation (i.e., the square root of the\nvariance) of each of the components over the entire training set and normalize\nthe values of the components so that their adjusted standard deviations are\nequal.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 132, 'page_label': '133'}, page_content='124 CHAPTER 9. UNSUPERVISED LEARNING\n9.2.2 A Method Based on Probabilities\nSuppose we have a partition of the training set, \u039e, into R mutually exclusive\nand exhaustive clusters, C1,...,C R. We can decide to which of these clusters\nsome arbitrary pattern, X, should be assigned by selecting the Ci for which\nthe probability, p(Ci|X), is largest, providing p(Ci|X) is larger than some \ufb01xed\nthreshold, \u03b4. As we saw earlier, we can use Bayes rule and base our decision on\nmaximizing p(X|Ci)p(Ci). Assuming conditional independence of the pattern\ncomponents, xi, the quantity to be maximized is:\nS(X,Ci) = p(x1|Ci)p(x2|Ci) ···p(xn|Ci)p(Ci)\nThe p(xj|Ci) can be estimated from the sample statistics of the patterns in the\nclusters and then used in the above expression. (Recall the linear form that this\nformula took in the case of binary-valued components.)\nWe call S(X,Ci) the similarity of X to a cluster, Ci, of patterns. Thus, we\nassign X to the cluster to which it is most similar, providing the similarity is\nlarger than \u03b4.\nJust as before, we can de\ufb01ne the sample mean of a cluster, Ci, to be:\nMi = (1/Ki)\n\u2211\nXj\u03f5 Ci\nXj\nwhere Ki is the number of patterns in Ci.\nWe can base an iterative clustering algorithm on this measure of similarity\n[Mahadevan & Connell, 1992]. It can be described as follows:\na. Begin with a set of unlabeled patterns \u039e and an empty list, L, of clusters.\nb. For the next pattern, X, in \u039e, compute S(X,Ci) for each cluster, Ci.\n(Initially, these similarities are all zero.) Suppose the largest of these\nsimilarities is S(X,Cmax).\n(a) If S(X,Cmax) >\u03b4, assign X to Cmax. That is,\nCmax \u2190\u2212Cmax \u222a{X}\nUpdate the sample statisticsp(x1|Cmax),p(x2|Cmax),...,p (xn|Cmax),\nand p(Cmax) to take the new pattern into account. Go to 3.\n(b) If S(X,Cmax) \u2264\u03b4, create a new cluster, Cnew = {X}and add Cnew\nto L. Go to 3.\nc. Merge any existing clusters, Ci and Cj if ( Mi \u2212Mj)2 < \u03b5. Compute\nnew sample statistics p(x1|Cmerge),p(x2|Cmerge),...,p (xn|Cmerge), and\np(Cmerge) for the merged cluster, Cmerge = Ci \u222aCj.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 133, 'page_label': '134'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 125\nd. If the sample statistics of the clusters have not changed during an entire\niteration through \u039e, then terminate with the clusters in L; otherwise go\nto 2.\nThe value of the parameter \u03b4 controls the number of clusters. If \u03b4 is high,\nthere will be a large number of clusters with few patterns in each cluster. For\nsmall values of \u03b4, there will be a small number of clusters with many patterns in\neach cluster. Similarly, the larger the value of \u03b5, the smaller the number clusters\nthat will be found.\nDesigning a classi\ufb01er based on the patterns labeled by the partitioning is\nstraightforward. We assign any pattern, X, to that category that maximizes\nS(X,Ci). Mention k-means and EM\nmethods.\n9.3 Hierarchical Clustering Methods\n9.3.1 A Method Based on Euclidean Distance\nSuppose we have a set, \u039e, of unlabeled training patterns. We can form a hi-\nerarchical classi\ufb01cation of the patterns in \u039e by a simple agglomerative method.\n(The description of this algorithm is based on an unpublished manuscript by\nPat Langley.) Our description here gives the general idea; we leave it to the\nreader to generate a precise algorithm.\nWe \ufb01rst compute the Euclidean distance between all pairs of patterns in \u039e.\n(Again, appropriate scaling of the dimensions is assumed.) Suppose the smallest\ndistance is between patterns Xi and Xj. We collect Xi and Xj into a cluster,\nC, eliminate Xi and Xj from \u039e and replace them by a cluster vector, C, equal\nto the average of Xi and Xj. Next we compute the Euclidean distance again\nbetween all pairs of points in \u039e. If the smallest distance is between pairs of\npatterns, we form a new cluster, C, as before and replace the pair of patterns\nin \u039e by their average. If the shortest distance is between a pattern, Xi, and\na cluster vector, Cj (representing a cluster, Cj), we form a new cluster, C,\nconsisting of the union of Cj and {Xi}. In this case, we replace Cj and Xi\nin \u039e by their (appropriately weighted) average and continue. If the shortest\ndistance is between two cluster vectors, Ci and Cj, we form a new cluster, C,\nconsisting of the union of Ci and Cj. In this case, we replace Ci and Cj by their\n(appropriately weighted) average and continue. Since we reduce the number of\npoints in \u039e by one each time, we ultimately terminate with a tree of clusters\nrooted in the cluster containing all of the points in the original training set.\nAn example of how this method aggregates a set of two dimensional patterns\nis shown in Fig. 9.5. The numbers associated with each cluster indicate the order\nin which they were formed. These clusters can be organized hierarchically in a\nbinary tree with cluster 9 as root, clusters 7 and 8 as the two descendants of the\nroot, and so on. A ternary tree could be formed instead if one searches for the\nthree points in \u039e whose triangle de\ufb01ned by those patterns has minimal area.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 134, 'page_label': '135'}, page_content='126 CHAPTER 9. UNSUPERVISED LEARNING\n1\n2 3\n5\n4\n6\n7\n8\n9\nFigure 9.5: Agglommerative Clustering\n9.3.2 A Method Based on Probabilities\nA probabilistic quality measure for partitions\nWe can develop a measure of the goodness of a partitioning based on how\naccurately we can guess a pattern given only what partition it is in. Suppose\nwe are given a partitioning of \u039e into R classes, C1,...,C R. As before, we can\ncompute the sample statistics p(xi|Ck) which give probability values for each\ncomponent given the class assigned to it by the partitioning. Suppose each\ncomponent xi of X can take on the values vij, where the index j steps over the\ndomain of that component. We use the notation pi(vij|Ck) = probability(xi =\nvij|Ck).\nSuppose we use the following probabilistic guessing rule about the values\nof the components of a vector X given only that it is in class k. Guess that\nxi = vij with probability pi(vij|Ck). Then, the probability that we guess the\ni-th component correctly is:\n\u2211\nj\nprobability(guess is vij)pi(vij|Ck) =\n\u2211\nj\n[pi(vij|Ck)]2\nThe average number of (the n) components whose values are guessed correctly\nby this method is then given by the sum of these probabilities over all of the\ncomponents of X:\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 135, 'page_label': '136'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 127\nGiven our partitioning into R classes, the goodness measure, G, of this parti-\ntioning is the average of the above expression over all classes:\nG=\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nwhere p(Ck) is the probability that a pattern is in class Ck. In order to penalize\nthis measure for having a large number of classes, we divide it by R to get an\noverall quality measure of a partitioning:\nZ = (1/R)\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nWe give an example of the use of this measure for a trivially simple\nclustering of the four three-dimensional patterns shown in Fig. 9.6. There\nare several di\ufb00erent partitionings. Lets evaluate Z values for the follow-\ning ones: P1 = {a,b,c,d }, P2 = {{a,b},{c,d}}, P3 = {{a,c},{b,d}}, and\nP4 = {{a},{b},{c},{d}}. The \ufb01rst, P1, puts all of the patterns into a single\ncluster. The sample probabilities pi(vi1 = 1) and pi(vi0 = 0) are all equal to 1/2\nfor each of the three components. Summing over the values of the components\n(0 and 1) gives (1 /2)2 + (1/2)2 = 1 /2. Summing over the three components\ngives 3/2. Averaging over all of the clusters (there is just one) also gives 3 /2.\nFinally, dividing by the number of clusters produces the \ufb01nal Z value of this\npartition, Z(P1) = 3/2.\nThe second partition, P2, gives the following sample probabilities:\np1(v11 = 1|C1) = 1\np2(v21 = 1|C1) = 1/2\np3(v31 = 1|C1) = 1\nSumming over the values of the components (0 and 1) gives (1) 2 + (0)2 = 1 for\ncomponent 1, (1 /2)2 + (1/2)2 = 1/2 for component 2, and (1) 2 + (0)2 = 1 for\ncomponent 3. Summing over the three components gives 2 1 /2 for class 1. A\nsimilar calculation also gives 2 1 /2 for class 2. Averaging over the two clusters\nalso gives 2 1 /2. Finally, dividing by the number of clusters produces the \ufb01nal\nZ value of this partition, Z(P2) = 1 1/4, not quite as high as Z(P1).\nSimilar calculations yield Z(P3) = 1 and Z(P4) = 3 /4, so this method of\nevaluating partitions would favor placing all patterns in a single cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 136, 'page_label': '137'}, page_content='128 CHAPTER 9. UNSUPERVISED LEARNING\nx2\nx3\nx1\nab\ncd\nFigure 9.6: Patterns in 3-Dimensional Space\nAn iterative method for hierarchical clustering\nEvaluating all partitionings of mpatterns and then selecting the best would be\ncomputationally intractable. The following iterative method is based on a hi-\nerarchical clustering procedure called COBWEB [Fisher, 1987]. The procedure\ngrows a tree each node of which is labeled by a set of patterns. At the end\nof the process, the root node contains all of the patterns in \u039e. The successors\nof the root node will contain mutually exclusive and exhaustive subsets of \u039e.\nIn general, the successors of a node, \u03b7, are labeled by mutually exclusive and\nexhaustive subsets of the pattern set labelling node \u03b7. The tips of the tree will\ncontain singleton sets. The method uses Z values to place patterns at the vari-\nous nodes; sample statistics are used to update the Z values whenever a pattern\nis placed at a node. The algorithm is as follows:\na. We start with a tree whose root node contains all of the patterns in \u039e\nand a single empty successor node. We arrange that at all times dur-\ning the process every non-empty node in the tree has (besides any other\nsuccessors) exactly one empty successor.\nb. Select a pattern Xi in \u039e (if there are no more patterns to select, terminate).\nc. Set µ to the root node.\nd. For each of the successors of µ(including the empty successor!), calculate\nthe best host for Xi. A best host is determined by tentatively placing\nXi in one of the successors and calculating the resulting Z value for each'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 137, 'page_label': '138'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 129\none of these ways of accomodating Xi. The best host corresponds to the\nassignment with the highest Z value.\ne. If the best host is an empty node, \u03b7, we place Xi in \u03b7, generate an empty\nsuccessor node of \u03b7, generate an empty sibling node of \u03b7, and go to 2.\nf. If the best host is a non-empty, singleton (tip) node, \u03b7, we place Xi in \u03b7,\ncreate one successor node of \u03b7 containing the singleton pattern that was\nin \u03b7, create another successor node of \u03b7 containing Xi, create an empty\nsuccessor node of \u03b7, create empty successor nodes of the new non-empty\nsuccessors of \u03b7, and go to 2.\ng. If the best host is a non-empty, non-singleton node, \u03b7, we place Xi in \u03b7,\nset µ to \u03b7, and go to 4.\nThis process is rather sensitive to the order in which patterns are presented.\nTo make the \ufb01nal classi\ufb01cation tree less order dependent, the COBWEB proce-\ndure incorporates node merging and splitting.\nNode merging:\nIt may happen that two nodes having the same parent could be merged with\nan overall increase in the quality of the resulting classi\ufb01cation performed by the\nsuccessors of that parent. Rather than try all pairs to merge, a good heuristic\nis to attempt to merge the two best hosts. When such a merging improves the\nZ value, a new node containing the union of the patterns in the merged nodes\nreplaces the merged nodes, and the two nodes that were merged are installed\nas successors of the new node.\nNode splitting:\nA heuristic for node splitting is to consider replacing the best host among a\ngroup of siblings by that hosts successors. This operation is performed only if\nit increases the Z value of the classi\ufb01cation performed by a group of siblings.\nExample results from COBWEB\nWe mention two experiments with COBWEB. In the \ufb01rst, the program at-\ntempted to \ufb01nd two categories (we will call them Class 1 and Class 2) of United\nStates Senators based on their votes ( yes or no) on six issues. After the clus-\nters were established, the majority vote in each class was computed. These are\nshown in the table below.\nIssue Class 1 Class 2\nToxic Waste yes no\nBudget Cuts yes no\nSDI Reduction no yes\nContra Aid yes no\nLine-Item Veto yes no\nMX Production yes no'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 138, 'page_label': '139'}, page_content='130 CHAPTER 9. UNSUPERVISED LEARNING\nIn the second experiment, the program attempted to classify soybean dis-\neases based on various characteristics. COBWEB grouped the diseases in the\ntaxonomy shown in Fig. 9.7.\nN0\nsoybean\ndiseases\nN1\n  Diaporthe\nStem Canker\nN2\nCharcoal\n     Rot\nN3\nN31\nRhizoctonia\n       Rot\nN32\nPhytophthora\n       Rot\nFigure 9.7: Taxonomy Induced for Soybean Diseases\n9.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 139, 'page_label': '140'}, page_content='Chapter 10\nTemporal-Di\ufb00erence\nLearning\n10.1 Temporal Patterns and Prediction Prob-\nlems\nIn this chapter, we consider problems in which we wish to learn to predict the\nfuture value of some quantity, say z, from an n-dimensional input pattern, X.\nIn many of these problems, the patterns occur in temporal sequence, X1, X2,\n. . ., Xi, Xi+1, ... , Xm, and are generated by a dynamical process. The\ncomponents of Xi are features whose values are available at time, t = i. We\ndistinguish two kinds of prediction problems. In one, we desire to predict the\nvalue of z at time t = i+ 1 based on input Xi for every i. For example, we\nmight wish to predict some aspects of tomorrows weather based on a set of\nmeasurements made today. In the other kind of prediction problem, we desire\nto make a sequence of predictions about the value of z at some \ufb01xed time, say\nt= m+ 1, based on each of the Xi, i= 1,...,m . For example, we might wish\nto make a series of predictions about some aspect of the weather on next New\nYears Day, based on measurements taken every day before New Years. Sutton\n[Sutton, 1988] has called this latter problem, multi-step prediction, and that is\nthe problem we consider here. In multi-step prediction, we might expect that\nthe prediction accuracy should get better and better as i increases toward m.\n10.2 Supervised and Temporal-Di\ufb00erence Meth-\nods\nA training method that naturally suggests itself is to use the actual value of\nz at time m+ 1 (once it is known) in a supervised learning procedure using a\n131'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 140, 'page_label': '141'}, page_content='132 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nsequence of training patterns, {X1, X2, ... , Xi, Xi+1, ... , Xm}. That is, we\nseek to learn a function, f, such that f(Xi) is as close as possible to zfor each i.\nTypically, we would need a training set, \u039e, consisting of several such sequences.\nWe will show that a method that is better than supervised learning for some\nimportant problems is to base learning on the di\ufb00erence between f(Xi+1) and\nf(Xi) rather than on the di\ufb00erence between zand f(Xi). Such methods involve\nwhat is called temporal-di\ufb00erence (TD) learning.\nWe assume that our prediction, f(X), depends on a vector of modi\ufb01able\nweights, W. To make that dependence explicit, we write f(X,W). For su-\npervised learning, we consider procedures of the following type: For each Xi,\nthe prediction f(Xi,W) is computed and compared to z, and the learning rule\n(whatever it is) computes the change, (\u2206 Wi), to be made to W. Then, taking\ninto account the weight changes for each pattern in a sequence all at once after\nhaving made all of the predictions with the old weight vector, we change W as\nfollows:\nW \u2190\u2212W +\nm\u2211\ni=1\n(\u2206W)i\nWhenever we are attempting to minimize the squared error between z and\nf(Xi,W) by gradient descent, the weight-changing rule for each pattern is:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nwhere c is a learning rate parameter, fi is our prediction of z, f(Xi,W),\nat time t = i, and \u2202fi\n\u2202W is, by de\ufb01nition, the vector of partial derivatives\n( \u2202fi\n\u2202w1\n,..., \u2202fi\n\u2202wi\n,..., \u2202fi\n\u2202wn\n) in which the wi are the individual components of W.\n(The expression \u2202fi\n\u2202W is sometimes written \u2207Wfi.) The reader will recall that\nwe used an equivalent expression for (\u2206 W)i in deriving the backpropagation\nformulas used in training multi-layer neural networks.\nThe Widrow-Ho\ufb00 rule results when f(X,W) = X W. Then:\n(\u2206W)i = c(z\u2212fi)Xi\nAn interesting form for (\u2206 W)i can be developed if we note that\n(z\u2212fi) =\nm\u2211\nk=i\n(fk+1 \u2212fk)\nwhere we de\ufb01ne fm+1 = z. Substituting in our formula for (\u2206 W)i yields:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 141, 'page_label': '142'}, page_content='10.2. SUPERVISED AND TEMPORAL-DIFFERENCE METHODS 133\n= c\u2202fi\n\u2202W\nm\u2211\nk=i\n(fk+1 \u2212fk)\nIn this form, instead of using the di\ufb00erence between a prediction and the value\nof z, we use the di\ufb00erences between successive predictionsthus the phrase\ntemporal-di\ufb00erence (TD) learning.\nIn the case when f(X,W) = X W, the temporal di\ufb00erence form of the\nWidrow-Ho\ufb00 rule is:\n(\u2206W)i = cXi\nm\u2211\nk=i\n(fk+1 \u2212fk)\nOne reason for writing (\u2206 W)i in temporal-di\ufb00erence form is to permit an\ninteresting generalization as follows:\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nwhere 0 < \u03bb\u22641. Here, the \u03bb term gives exponentially decreasing weight to\ndi\ufb00erences later in time than t = i. When \u03bb = 1, we have the same rule with\nwhich we beganweighting all di\ufb00erences equally, but as\u03bb\u21920, we weight only\nthe (fi+1 \u2212fi) di\ufb00erence. With the \u03bb term, the method is called TD( \u03bb).\nIt is interesting to compare the two extreme cases:\nFor TD(0):\n(\u2206W)i = c(fi+1 \u2212fi) \u2202fi\n\u2202W\nFor TD(1):\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nBoth extremes can be handled by the same learning mechanism; only the error\nterm is di\ufb00erent. In TD(0), the error is the di\ufb00erence between successive predic-\ntions, and in TD(1), the error is the di\ufb00erence between the \ufb01nally revealed value\nof z and the prediction. Intermediate values of \u03bb take into account di\ufb00erently\nweighted di\ufb00erences between future pairs of successive predictions.\nOnly TD(1) can be considered a puresupervised learning procedure, sensitive\nto the \ufb01nal value ofzprovided by the teacher. For\u03bb< 1, we have various degrees\nof unsupervised learning, in which the prediction function strives to make each\nprediction more like successive ones (whatever they might be). We shall soon\nsee that these unsupervised procedures result in better learning than do the\nsupervised ones for an important class of problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 142, 'page_label': '143'}, page_content='134 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n10.3 Incremental Computation of the (\u2206W)i\nWe can rewrite our formula for (\u2206 W)i, namely\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nto allow a type of incremental computation. First we write the expression for\nthe weight change rule that takes into account all of the (\u2206 W)i:\nW \u2190\u2212W +\nm\u2211\ni=1\nc\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nInterchanging the order of the summations yields:\nW \u2190\u2212W +\nm\u2211\nk=1\nc\nk\u2211\ni=1\n\u03bb(k\u2212i)(fk+1 \u2212fk) \u2202fi\n\u2202W\n= W +\nm\u2211\nk=1\nc(fk+1 \u2212fk)\nk\u2211\ni=1\n\u03bb(k\u2212i) \u2202fi\n\u2202W\nInterchanging the indices k and i \ufb01nally yields:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nIf, as earlier, we want to use an expression of the formW \u2190\u2212W+\u2211m\ni=1(\u2206W)i,\nwe see that we can write:\n(\u2206W)i = c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nNow, if we let ei = \u2211i\nk=1 \u03bb(i\u2212k) \u2202fk\n\u2202W , we can develop a computationally e\ufb03cient\nrecurrence equation for ei+1 as follows:\nei+1 =\ni+1\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W\n= \u2202fi+1\n\u2202W +\ni\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 143, 'page_label': '144'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 135\n= \u2202fi+1\n\u2202W + \u03bbei\nRewriting (\u2206W)i in these terms, we obtain:\n(\u2206W)i = c(fi+1 \u2212fi)ei\nwhere:\ne1 = \u2202f1\n\u2202W\ne2 = \u2202f2\n\u2202W + \u03bbe1\netc.\nQuoting Sutton [Sutton, 1988, page 15] (about a di\ufb00erent equation, but the\nquote applies equally well to this one):\n... this equation can be computed incrementally, because each\n(\u2206W)i depends only on a pair of successive predictions and on the\n[weighted] sum of all past values for \u2202fi\n\u2202W . This saves substantially on\nmemory, because it is no longer necessary to individually remember\nall past values of \u2202fi\n\u2202W .\n10.4 An Experiment with TD Methods\nTD prediction methods [especially TD(0)] are well suited to situations in which\nthe patterns are generated by a dynamic process. In that case, sequences of\ntemporally presented patterns contain important information that is ignored\nby a conventional supervised method such as the Widrow-Ho\ufb00 rule. Sutton\n[Sutton, 1988, page 19] gives an interesting example involving a random walk,\nwhich we repeat here. In Fig. 10.1, sequences of vectors, X, are generated as\nfollows: We start with vector XD; the next vector in the sequence is equally\nlikely to be one of the adjacent vectors in the diagram. If the next vector is\nXC (or XE), the next one after that is equally likely to be one of the vectors\nadjacent to XC (or XE). When XB is in the sequence, it is equally likely that\nthe sequence terminates with z = 0 or that the next vector is XC. Similarly,\nwhen XF is in the sequence, it is equally likely that the sequence terminates\nwith z= 1 or that the next vector is XE. Thus the sequences are random, but\nthey always start with XD. Some sample sequences are shown in the \ufb01gure.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 144, 'page_label': '145'}, page_content='136 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\nz = 0 z = 1\nXB XC XD XE XF\nTypical Sequences:\nXDXCXDXEXF  1\nXDXCXBXCXDXEXDXEXF  1\nXDXEXDXCXB  0\nFigure 10.1: A Markov Process\nThis random walk is an example of a Markov process; transitions from state i\nto state j occur with probabilities that depend only on i and j.\nGiven a set of sequences generated by this process as a training set, we want\nto be able to predict the value of z for each X in a test sequence. We assume\nthat the learning system does not know the transition probabilities.\nFor his experiments with this process, Sutton used a linear predictor, that\nis f(X,W) = X W. The learning problem is to \ufb01nd a weight vector, W, that\nminimizes the mean-squared error betweenzand the predicted value of z. Given\nthe \ufb01ve di\ufb00erent values that X can take on, we have the following predictions:\nf(XB) = w1, f(XC) = w2, f(XD) = w3, f(XE) = w4, f(XF) = w5, where\nwi is the i-th component of the weight vector. (Note that the values of the\npredictions are not limited to 1 or 0even though z can only have one of\nthose valuesbecause we are minimizing mean-squared error.) After training,\nthese predictions will be compared with the optimal onesgiven the transition\nprobabilities.\nThe experimental setup was as follows: ten random sequences were generated\nusing the transition probabilities. Each of these sequences was presented in turn\nto a TD(\u03bb) method for various values of \u03bb. Weight vector increments, (\u2206 W)i,\nwere computed after each pattern presentation but no weight changes were\nmade until all ten sequences were presented. The weight vector increments were\nsummed after all ten sequences were presented, and this sum was used to change\nthe weight vector to be used for the next pass through the ten sequences. This\nprocess was repeated over and over (using the same training sequences) until\n(quoting Sutton) the procedure no longer produced any signi\ufb01cant changes in\nthe weight vector. For small c, the weight vector always converged in this way,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 145, 'page_label': '146'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 137\nand always to the same \ufb01nal value [for 100 di\ufb00erent training sets of ten random\nsequences], independent of its initial value. (Even though, for \ufb01xed, small c,\nthe weight vector always converged to the same vector, it might converge to a\nsomewhat di\ufb00erent vector for di\ufb00erent values of c.)\nAfter convergence, the predictions made by the \ufb01nal weight vector are com-\npared with the optimal predictions made using the transition probabilities.\nThese optimal predictions are simply p(z= 1|X). We can compute these proba-\nbilities to be 1/6, 1/3, 1/2, 2/3, and 5/6 forXB, XC, XD, XE, XF, respectively.\nThe root-mean-squared di\ufb00erences between the best learned predictions (over\nall c) and these optimal ones are plotted in Fig. 10.2 for seven di\ufb00erent values\nof \u03bb. (For each data point, the standard error is approximately \u03c3= 0.01.)\n0.10\n0.12\n0.14\n0.16\n0.18\n0.20\n0.0 0.1 0.3 0.5 0.7 0.9 1.0\nh\nError using\nbest c\nWidrow-Hoff\nTD(1)\nTD(0)\n(Adapted from Sutton, p. 20, 1988)\nFigure 10.2: Prediction Errors for TD( \u03bb)\nNotice that the Widrow-Ho\ufb00 procedure does not perform as well as other\nversions of TD(\u03bb) for \u03bb< 1! Quoting [Sutton, 1988, page 21]:\nThis result contradicts conventional wisdom. It is well known that,\nunder repeated presentations, the Widrow-Ho\ufb00 procedure minimizes\nthe RMS error between its predictions and the actual outcomes in\nthe training set ([Widrow & Stearns, 1985]). How can it be that this\noptimal method peformed worse than all the TD methods for \u03bb <\n1? The answer is that the Widrow-Ho\ufb00 procedure only minimizes\nerror on the training set ; it does not necessarily minimize error for\nfuture experience. [Later] we prove that in fact it is linear TD(0)\nthat converges to what can be considered the optimal estimates for'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 146, 'page_label': '147'}, page_content='138 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nmatching future experiencethose consistent with the maximum-\nlikelihood estimate of the underlying Markov process.\n10.5 Theoretical Results\nIt is possible to analyze the performance of the linear-prediction TD(\u03bb) methods\non Markov processes. We state some theorems here without proof.\nTheorem 10.1 (Sutton, page 24, 1988) For any absorbing Markov chain,\nand for any linearly independent set of observation vectors {Xi}for the non-\nterminal states, there exists an \u03b5> 0 such that for all positive c<\u03b5 and for any\ninitial weight vector, the predictions of linear TD(0) (with weight updates after\neach sequence) converge in expected value to the optimal (maximum likelihood)\npredictions of the true process.\nEven though the expected values of the predictions converge, the predictions\nthemselves do not converge but vary around their expected values depending on\ntheir most recent experience. Sutton conjectures that if c is made to approach\n0 as training progresses, the variance of the predictions will approach 0 also.\nDayan [Dayan, 1992] has extended the result of Theorem 9.1 to TD( \u03bb) for\narbitrary \u03bb between 0 and 1. (Also see [Dayan & Sejnowski, 1994].)\n10.6 Intra-Sequence Weight Updating\nOur standard weight updating rule for TD( \u03bb) methods is:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere the weight update occurs after an entire sequence is observed. To make\nthe method truly incremental (in analogy with weight updating rules for neural\nnets), it would be desirable to change the weight vector after every pattern\npresentation. The obvious extension is:\nWi+1 \u2190\u2212Wi + c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere fi+1 is computed before making the weight change; that is, fi+1 =\nf(Xi+1,Wi). But that would make fi = f(Xi,Wi\u22121), and such a rule would\nmake the prediction di\ufb00erence, namely ( fi+1 \u2212fi), sensitive both to changes in\nX and changes in W and could lead to instabilities. Instead, we modify the rule\nso that, for every pair of predictions, fi+1 = f(Xi+1,Wi) and fi = f(Xi,Wi).\nThis version of the rule has been used in practice with excellent results.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 147, 'page_label': '148'}, page_content='10.6. INTRA-SEQUENCE WEIGHT UPDATING 139\nFor TD(0) and linear predictors, the rule is:\nWi+1 = Wi + c(fi+1 \u2212fi)Xi\nThe rule is implemented as follows:\na. Initialize the weight vector, W, arbitrarily.\nb. For i= 1,...,m , do:\n(a) fi \u2190\u2212Xi W\n(We compute fi anew each time through rather than use the value\nof fi+1 the previous time through.)\n(b) fi+1 \u2190\u2212Xi+1 W\n(c) di+1 \u2190\u2212fi+1 \u2212fi\n(d) W \u2190\u2212W + c di+1Xi\n(If fi were computed again with this changed weight vector, its value\nwould be closer to fi+1 as desired.)\nThe linear TD(0) method can be regarded as a technique for training a\nvery simple network consisting of a single dot product unit (and no threshold\nor sigmoid function). TD methods can also be used in combination with back-\npropagation to train neural networks. For TD(0) we change the network weights\naccording to the expression:\nWi+1 = Wi + c(fi+1 \u2212fi) \u2202fi\n\u2202W\nThe only change that must be made to the standard backpropagation weight-\nchanging rule is that the di\ufb00erence term between the desired output and the\noutput of the unit in the \ufb01nal ( k-th) layer, namely (d\u2212f(k)), must be replaced\nby a di\ufb00erence term between successive outputs, ( fi+1 \u2212fi). This change has a\ndirect e\ufb00ect only on the expression for \u03b4(k) which becomes:\n\u03b4(k) = 2(f\u2032(k) \u2212f(k))f(k)(1 \u2212f(k))\nwhere f\u2032(k) and f(k) are two successive outputs of the network.\nThe weight changing rule for the i-th weight vector in the j-th layer of weights\nhas the same form as before, namely:\nW(j)\ni \u2190\u2212W(j)\ni + c\u03b4(j)\ni X(j\u22121)\nwhere the \u03b4(j)\ni are given recursively by:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nand w(j+1)\nil is the l-th component of the i-th weight vector in the (j+1)-th layer\nof weights. Of course, here also it is assumed that f\u2032(k) and f(k) are computed\nusing the same weights and then the weights are changed. In the next section\nwe shall see an interesting example of this application of TD learning.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 148, 'page_label': '149'}, page_content='140 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n10.7 An Example Application: TD-gammon\nA program called TD-gammon [Tesauro, 1992] learns to play backgammon by\ntraining a neural network via temporal-di\ufb00erence methods. The structure of\nthe neural net, and its coding is as shown in Fig. 10.3. The network is trained\nto minimize the error between actual payo\ufb00 and estimated payo\ufb00, where the\nactual payo\ufb00 is de\ufb01ned to be df = p1 + 2p2 \u2212p3 \u22122p4, and the pi are the actual\nprobabilities of the various outcomes as de\ufb01ned in the \ufb01gure.\n. . . p3 = pr(black wins)\np4 = pr(black gammons)\np1 = pr(white wins)\np2 = pr(white gammons)\nestimated payoff:\nd = p1 + 2p2 < p3 < 2p4\nno. of white\non cell 1\nno. on bar,\noff board,\nand who\nmoves\n198 inputs\n1\n2\n3\n# > 3\n. . .\nup to 40 hidden units\n2 x 24\ncells\n4 output units\nhidden and output units are sigmoids\nlearning rate:  c = 0.1; initial weights chosen\nrandomly between <0.5 and +0.5.\nestimated probabilities:\nFigure 10.3: The TD-gammon Network\nTD-gammon learned by using the network to select that move that results\nin the best predicted payo\ufb00. That is, at any stage of the game some \ufb01nite set of\nmoves is possible and these lead to the set, {X}, of new board positions. Each\nmember of this set is evaluated by the network, and the one with the largest'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 149, 'page_label': '150'}, page_content='10.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 141\npredicted payo\ufb00 is selected if it is whites move (and the smallest if it is blacks).\nThe move is made, and the network weights are adjusted to make the predicted\npayo\ufb00 from the original position closer to that of the resulting position.\nThe weight adjustment procedure combines temporal-di\ufb00erence (TD( \u03bb))\nlearning with backpropagation. If dt is the networks estimate of the payo\ufb00\nat time t (before a move is made), and dt+1 is the estimate at time t+ 1 (after\na move is made), the weight adjustment rule is:\n\u2206Wt = c(dt+1 \u2212dt)\nt\u2211\nk=1\n\u03bbt\u2212k \u2202dk\n\u2202W\nwhere Wt is a vector of all weights in the network at time t, and \u2202dk\n\u2202W is the\ngradient of dk in this weight space. (For a layered, feedforward network, such\nas that of TD-gammon, the weight changes for the weight vectors in each layer\ncan be expressed in the usual manner.)\nTo make the special cases clear, recall that for TD(0), the network would be\ntrained so that, for all t, its output, dt, for input Xt tended toward its expected\noutput, dt+1, for input Xt+1. For TD(1), the network would be trained so that,\nfor all t, its output, dt, for input Xt tended toward the expected \ufb01nal payo\ufb00,\ndf, given that input. The latter case is the same as the Widrow-Ho\ufb00 rule.\nAfter about 200,000 games the following results were obtained. TD-gammon\n(with 40 hidden units, \u03bb= 0.7, and c= 0.1) won 66.2% of 10,000 games against\nSUN Microsystems Gammontool and 55% of 10,000 games against a neural\nnetwork trained using expert moves. Commenting on a later version of TD-\ngammon, incorporating special features as inputs, Tesauro said: It appears to\nbe the strongest program ever seen by this author.\n10.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 150, 'page_label': '151'}, page_content='142 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 151, 'page_label': '152'}, page_content='Chapter 11\nDelayed-Reinforcement\nLearning\n11.1 The General Problem\nImagine a robot that exists in an environment in which it can sense and act.\nSuppose (as an extreme case) that it has no idea about the e\ufb00ects of its actions.\nThat is, it doesnt know how acting will change its sensory inputs. Along with\nits sensory inputs are rewards, which it occasionally receives. How should it\nchoose its actions so as to maximize its rewards over the long run? To maximize\nrewards, it will need to be able to predict how actions change inputs, and in\nparticular, how actions lead to rewards.\nWe formalize the problem in the following way: The robot exists in an\nenvironment consisting of a set,S, of states. We assume that the robots sensory\napparatus constructs an input vector, X, from the environment, which informs\nthe robot about which state the environment is in. For the moment, we will\nassume that the mapping from states to vectors is one-to-one, and, in fact, will\nuse the notation X to refer to the state of the environment as well as to the\ninput vector. When presented with an input vector, the robot decides which\naction from a set, A, of actions to perform. Performing the action produces an\ne\ufb00ect on the environmentmoving it to a new state. The new state results in\nthe robot perceiving a new input vector, and the cycle repeats. We assume a\ndiscrete time model; the input vector at time t = i is Xi, the action taken at\nthat time is ai, and the expected reward, ri, received at t = i depends on the\naction taken and on the state, that is ri = r(Xi,ai). The learners goal is to \ufb01nd\na policy, \u03c0(X), that maps input vectors to actions in such a way that maximizes\nrewards accumulated over time. This type of learning is called reinforcement\nlearning. The learner must \ufb01nd the policy by trial and error; it has no initial\nknowledge of the e\ufb00ects of its actions. The situation is as shown in Fig. 11.1.\n143'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 152, 'page_label': '153'}, page_content='144 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nXi\nri\nLearner\nEnvironment\n(reward)\n(state)\n(action)\nai\nFigure 11.1: Reinforcement Learning\n11.2 An Example\nA grid world, such as the one shown in Fig. 11.2 is often used to illustrate\nreinforcement learning. Imagine a robot initially in cell (2,3). The robot receives\ninput vector ( x1,x2) telling it what cell it is in; it is capable of four actions,\nn,e,s,w moving the robot one cell up, right, down, or left, respectively. It is\nrewarded one negative unit whenever it bumps into the wall or into the blocked\ncells. For example, if the input to the robot is (1,3), and the robot chooses\naction w, the next input to the robot is still (1,3) and it receives a reward of\n\u22121. If the robot lands in the cell marked G (for goal), it receives a reward of\n+10. Lets suppose that whenever the robot lands in the goal cell and gets its\nreward, it is immediately transported out to some random cell, and the quest\nfor reward continues.\nA policy for our robot is a speci\ufb01cation of what action to take for every one\nof its inputs, that is, for every one of the cells in the grid. For example, a com-\nponent of such a policy would be when in cell (3,1), move right. An optimal\npolicy is a policy that maximizes long-term reward. One way of displaying a\npolicy for our grid-world robot is by an arrow in each cell indicating the direc-\ntion the robot should move when in that cell. In Fig. 11.3, we show an optimal\npolicy displayed in this manner. In this chapter we will describe methods for\nlearning optimal policies based on reward values received by the learner.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 153, 'page_label': '154'}, page_content='11.3. TEMPORAL DISCOUNTING AND OPTIMAL POLICIES 145\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.2: A Grid World\n11.3 Temporal Discounting and Optimal Poli-\ncies\nIn delayed reinforcement learning, one often assumes that rewards in the distant\nfuture are not as valuable as are more immediate rewards. This preference can\nbe accomodated by a temporal discount factor, 0 \u2264\u03b3 <1. The present value of\na reward, ri, occuring i time units in the future, is taken to be \u03b3iri. Suppose\nwe have a policy \u03c0(X) that maps input vectors into actions, and let r\u03c0(X)\ni be\nthe reward that will be received on the i-th time step after one begins executing\npolicy \u03c0 starting in state X. Then the total reward accumulated over all time\nsteps by policy \u03c0 beginning in state X is:\nV\u03c0(X) =\n\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\nOne reason for using a temporal discount factor is so that the above sum will\nbe \ufb01nite. An optimal policy is one that maximizes V\u03c0(X) for all inputs, X.\nIn general, we want to consider the case in which the rewards,ri, are random\nvariables and in which the e\ufb00ects of actions on environmental states are random.\nIn Markovian environments, for example, the probability that action a in state\nXi will lead to state Xj is given by a transition probability p[Xj|Xi,a]. Then,\nwe will want to maximize expected future reward and would de\ufb01ne V\u03c0(X) as:\nV\u03c0(X) = E\n[\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\n]\nIn either case, we call V\u03c0(X) the value of policy \u03c0 for input X.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 154, 'page_label': '155'}, page_content='146 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.3: An Optimal Policy in the Grid World\nIf the action prescribed by \u03c0 taken in state X leads to state X\u2032 (randomly\naccording to the transition probabilities), then we can write V\u03c0(X) in terms of\nV\u03c0(X\u2032) as follows:\nV\u03c0(X) = r[X,\u03c0(X)] + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,\u03c0(X)]V\u03c0(X\u2032)\nwhere (in summary):\n\u03b3 = the discount factor,\nV\u03c0(X) = the value of state X under policy \u03c0,\nr[X,\u03c0(X)] = the expected immediate reward received when we execute the\naction prescribed by \u03c0 in state X, and\np[X\u2032|X,\u03c0(X)] = the probability that the environment transitions to state\nX\u2032when we execute the action prescribed by \u03c0 in state X.\nIn other words, the value of state X under policy \u03c0 is the expected value of\nthe immediate reward received when executing the action recommended by \u03c0\nplus the average value (under \u03c0) of all of the states accessible from X.\nFor an optimal policy, \u03c0\u2217(and no others!), we have the famous optimality\nequation:\nV\u03c0\u2217\n(X) = max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nThe theory of dynamic programming (DP) [Bellman, 1957, Ross, 1983] assures\nus that there is at least one optimal policy, \u03c0\u2217, that satis\ufb01es this equation. DP'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 155, 'page_label': '156'}, page_content='11.4. Q-LEARNING 147\nalso provides methods for calculating V\u03c0\u2217\n(X) and at least one \u03c0\u2217, assuming\nthat we know the average rewards and the transition probabilities. If we knew\nthe transition probabilities, the average rewards, and V\u03c0\u2217\n(X) for all X and a,\nthen it would be easy to implement an optimal policy. We would simply select\nthat a that maximizes r(X,a) + \u03b3\u2211\nX\u2032p[X\u2032|X,a]V\u03c0\u2217\n(X\u2032). That is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nBut, of course, we are assuming that we do not know these average rewards nor\nthe transition probabilities, so we have to \ufb01nd a method that e\ufb00ectively learns\nthem.\nIf we had a model of actions, that is, if we knew for every state, X, and\naction a, which state, X\u2032 resulted, then we could use a method called value\niteration to \ufb01nd an optimal policy. Value iteration works as follows: We begin\nby assigning, randomly, an estimated value V(X) to every state, X. On the i-th\nstep of the process, suppose we are at state Xi (that is, our input on the i-th\nstep is Xi), and that the estimated value of state Xi on the i-th step is Vi(Xi).\nWe then select that actionathat maximizes the estimated value of the predicted\nsubsequent state. Suppose this subsequent state having the highest estimated\nvalue is X\u2032\ni. Then we update the estimated value, Vi(Xi), of state Xi as follows:\nVi(X) = (1 \u2212ci) Vi\u22121(X) + ci\n[\nri + \u03b3Vi\u22121(X\u2032\ni)\n]\nif X = Xi,\n= Vi\u22121(X)\notherwise.\nWe see that this adjustment moves the value ofVi(Xi) an increment (depend-\ning on ci) closer to\n[\nri + \u03b3Vi(X\u2032\ni)\n]\n. Assuming that Vi(X\u2032\ni) is a good estimate for\nVi(X\u2032\ni), then this adjustment helps to make the two estimates more consistent.\nProviding that 0 < ci < 1 and that we visit each state in\ufb01nitely often, this\nprocess of value iteration will converge to the optimal values. Discuss synchronous dynamic\nprogramming, asynchronous\ndynamic programming, and policy\niteration.\n11.4 Q-Learning\nWatkins [Watkins, 1989] has proposed a technique that he calls incremental\ndynamic programming. Let a; \u03c0 stand for the policy that chooses action aonce,\nand thereafter chooses actions according to policy \u03c0. We de\ufb01ne:\nQ\u03c0(X,a) = Va;\u03c0(X)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 156, 'page_label': '157'}, page_content='148 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nThen the optimal value from state X is given by:\nV\u03c0\u2217\n(X) = max\na\nQ\u03c0\u2217\n(X,a)\nThis equation holds only for an optimal policy, \u03c0\u2217. The optimal policy is given\nby:\n\u03c0\u2217(X) = arg max\na\nQ\u03c0\u2217\n(X,a)\nNote that if an actionamakes Q\u03c0(X,a) larger than V\u03c0(X), then we can improve\n\u03c0 by changing it so that \u03c0(X) = a. Making such a change is the basis for a\npowerful learning rule that we shall describe shortly.\nSuppose action ain state X leads to state X\u2032. Then using the de\ufb01nitions of\nQ and V, it is easy to show that:\nQ\u03c0(X,a) = r(X,a) + \u03b3E[V\u03c0(X\u2032)]\nwhere r(X,a) is the average value of the immediate reward received when we\nexecute action a in state X. For an optimal policy (and no others), we have\nanother version of the optimality equation in terms of Q values:\nQ\u03c0\u2217\n(X,a) = max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nfor all actions, a, and states, X. Now, if we had the optimal Q values (for all\na and X), then we could implement an optimal policy simply by selecting that\naction that maximized r(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]\n.\nThat is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nWatkins proposal amounts to a TD(0) method of learning the Q values.\nWe quote (with minor notational changes) from [Watkins & Dayan, 1992, page\n281]:\nIn Q-Learning, the agents experience consists of a sequence of dis-\ntinct stages or episodes. In the i-th episode, the agent:\n observes its current state Xi,\n selects [using the method described below] and performs an\naction ai,\n observes the subsequent state X\u2032\ni,\n receives an immediate reward ri, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 157, 'page_label': '158'}, page_content='11.4. Q-LEARNING 149\n adjusts its Qi\u22121 values using a learning factor ci, according to:\nQi(X,a) = (1 \u2212ci)Qi\u22121(X,a) + ci[ri + \u03b3Vi\u22121(X\u2032\ni)]\nif X = Xi and a= ai,\n= Qi\u22121(X,a)\notherwise,\nwhere\nVi\u22121(X\u2032) = max\nb\n[Qi\u22121(X\u2032,b)]\nis the best the agent thinks it can do from state X\u2032. ... The\ninitial Qvalues, Q0(X,a), for all states and actions are assumed\ngiven.\nUsing the current Q values, Qi(X,a), the agent always selects that action\nthat maximizes Qi(X,a). Note that only the Q value corresponding to the\nstate just exited and the action just taken is adjusted. And that Q value is\nadjusted so that it is closer (by an amount determined by ci) to the sum of\nthe immediate reward plus the discounted maximum (over all actions) of the Q\nvalues of the state just entered. If we imagine the Qvalues to be predictions of\nultimate (in\ufb01nite horizon) total reward, then the learning procedure described\nabove is exactly a TD(0) method of learning how to predict these Q values.\nQ learning strengthens the usual TD methods, however, because TD (applied\nto reinforcement problems using value iteration) requires a one-step lookahead,\nusing a model of the e\ufb00ects of actions, whereas Q learning does not.\nA convenient notation (proposed by [Schwartz, 1993]) for representing the\nchange in Q value is:\nQ(X,a)\n\u03b2\n\u2190\u2212r+ \u03b3V(X\u2032)\nwhere Q(X,a) is the new Qvalue for input X and action a, r is the immediate\nreward when action a is taken in response to input X, V(X\u2032) is the maximum\n(over all actions) of the Qvalue of the state next reached when action ais taken\nfrom state X, and \u03b2 is the fraction of the way toward which the new Q value,\nQ(X,a), is adjusted to equal r+ \u03b3V(X\u2032).\nWatkins and Dayan [Watkins & Dayan, 1992] prove that, under certain con-\nditions, the Q values computed by this learning procedure converge to optimal\nones (that is, to ones on which an optimal policy can be based).\nWe de\ufb01ne ni(X,a) as the index (episode number) of thei-th time that action\na is tried in state X. Then, we have:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 158, 'page_label': '159'}, page_content='150 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nTheorem 11.1 (Watkins and Dayan) For Markov problems with states{X}\nand actions {a}, and given bounded rewards |rn|\u2264 R, learning rates 0 \u2264cn <1,\nand\n\u221e\u2211\ni=0\ncni(X,a) = \u221e,\n\u221e\u2211\ni=0\n[\ncni(X,a)\n]2\n<\u221e\nfor all X and a, then\nQn(X,a) \u2192Q\u2217\nn(X,a) as n \u2192\u221e, for all X and a, with probability 1, where\nQ\u2217\nn(X,a) corresponds to the Q values of an optimal policy.\nAgain, we quote from [Watkins & Dayan, 1992, page 281]:\nThe most important condition implicit in the convergence theorem\n... is that the sequence of episodes that forms the basis of learning\nmust include an in\ufb01nite number of episodes for each starting state\nand action. This may be considered a strong condition on the way\nstates and actions are selectedhowever, under the stochastic con-\nditions of the theorem, no method could be guaranteed to \ufb01nd an\noptimal policy under weaker conditions. Note, however, that the\nepisodes need not form a continuous sequencethat is the X\u2032of one\nepisode need not be the X of the next episode.\nThe relationships among Q learning, dynamic programming, and control\nare very well described in [Barto, Bradtke, & Singh, 1994]. Q learning is best\nthought of as a stochastic approximation method for calculating the Q values.\nAlthough the de\ufb01nition of the optimalQvalues for any state depends recursively\non expected values of the Q values for subsequent states (and on the expected\nvalues of rewards), no expected values are explicitly computed by the procedure.\nInstead, these values are approximated by iterative sampling using the actual\nstochastic mechanism that produces successor states.\n11.5 Discussion, Limitations, and Extensions of\nQ-Learning\n11.5.1 An Illustrative Example\nThe Q-learning procedure requires that we maintain a table of Q(X,a) values\nfor all state-action pairs. In the grid world that we described earlier, such a\ntable would not be excessively large. We might start with random entries in the\ntable; a portion of such an intial table might be as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 159, 'page_label': '160'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING151\nX a Q(X,a) r(X,a)\n(2,3) w 7 0\n(2,3) n 4 0\n(2,3) e 3 0\n(2,3) s 6 0\n(1,3) w 4 -1\n(1,3) n 5 0\n(1,3) e 2 0\n(1,3) s 4 0\nSuppose the robot is in cell (2,3). The maximumQvalue occurs fora= w, so the\nrobot moves west to cell (1,3)receiving no immediate reward. The maximum\nQ value in cell (1,3) is 5, and the learning mechanism attempts to make the\nvalue of Q((2,3),w) closer to the discounted value of 5 plus the immediate\nreward (which was 0 in this case). With a learning rate parameter c = 0 .5\nand \u03b3 = 0.9, the Q value of Q((2,3),w) is adjusted from 7 to 5.75. No other\nchanges are made to the table at this episode. The reader might try this learning\nprocedure on the grid world with a simple computer program. Notice that an\noptimal policy might not be discovered if some cells are not visited nor some\nactions not tried frequently enough.\nThe learning problem faced by the agent is to associate speci\ufb01c actions with\nspeci\ufb01c input patterns. Q learning gradually reinforces those actions that con-\ntribute to positive rewards by increasing the associated Q values. Typically, as\nin this example, rewards occur somewhat after the actions that lead to them\nhence the phrase delayed-reinforcement learning. One can imagine that better\nand better approximations to the optimal Q values gradually propagate back\nfrom states producing rewards toward all of the other states that the agent fre-\nquently visits. With random Qvalues to begin, the agents actions amount to a\nrandom walk through its space of states. Only when this random walk happens\nto stumble into rewarding states does Q learning begin to produce Q values\nthat are useful, and, even then, the Q values have to work their way outward\nfrom these rewarding states. The general problem of associating rewards with\nstate-action pairs is called the temporal credit assignment problemhow should\ncredit for a reward be apportioned to the actions leading up to it? Qlearning is,\nto date, the most successful technique for temporal credit assignment, although\na related method, called the bucket brigade algorithm , has been proposed by\n[Holland, 1986].\nLearning problems similar to that faced by the agent in our grid world have\nbeen thoroughly studied by Sutton who has proposed an architecture, called\nDYNA, for solving them [Sutton, 1990]. DYNA combines reinforcement learning\nwith planning. Sutton characterizes planning as learning in a simulated world\nthat models the world that the agent inhabits. The agents model of the world\nis obtained by Q learning in its actual world, and planning is accomplished by\nQ learning in its model of the world.\nWe should note that the learning problem faced by our grid-world robot'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 160, 'page_label': '161'}, page_content='152 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\ncould be modi\ufb01ed to have several places in the grid that give positive rewards.\nThis possibility presents an interesting way to generalize the classical notion of\na goal in AI planning systemseven in those that do no learning. Instead of\nrepresenting a goal as a condition to be achieved, we represent a goal struc-\nture as a set of rewards to be given for achieving various conditions. Then,\nthe generalized goal becomes maximizing discounted future reward instead of\nsimply achieving some particular condition. This generalization can be made to\nencompass so-called goals of maintenance and goals of avoidance. The exam-\nple presented above included avoiding bumping into the grid-world boundary.\nA goal of maintenance, of a particular state, could be expressed in terms of a\nreward that was earned whenever the agent was in that state and performed an\naction that transitioned back to that state in one step.\n11.5.2 Using Random Actions\nWhen the next pattern presentation in a sequence of patterns is the one caused\nby the agents own action in response to the last pattern, we have what is called\nan on-line learning method. In Watkins and Dayans terminology, in on-line\nlearning the episodes form a continous sequence. As already mentioned, the\nconvergence theorem for Q learning does not require on-line learning; indeed,\nspecial precautions must be taken to ensure that on-line learning meets the\nconditions of the theorem. If on-line learning discovers some good paths to\nrewards, the agent may \ufb01xate on these and never discover a policy that leads\nto a possibly greater long-term reward. In reinforcement learning phraseology,\nthis problem is referred to as the problem of exploitation (of already learned\nbehavior) versus exploration (of possibly better behavior).\nOne way to force exploration is to perform occasional random actions (in-\nstead of that single action prescribed by the current Q values). For example,\nin the grid-world problem, one could imagine selecting an action randomly ac-\ncording to a probability distribution over the actions ( n,e,s, and w). This\ndistribution, in turn, could depend on the Q values. For example, we might\n\ufb01rst \ufb01nd that action prescribed by the Q values and then choose that action\nwith probability 1/2, choose the two orthogonal actions with probability 3/16\neach, and choose the opposite action with probability 1/8. This policy might be\nmodi\ufb01ed by simulated annealing which would gradually increase the probabil-\nity of the action prescribed by theQvalues more and more as time goes on. This\nstrategy would favor exploration at the beginning of learning and exploitation\nlater.\nOther methods, also, have been proposed for dealing with exploration, in-\ncluding making unvisited states intrinsically rewarding and using an interval\nestimate, which is related to the uncertainty in the estimate of a states value\n[Kaelbling, 1993].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 161, 'page_label': '162'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING153\n11.5.3 Generalizing Over Inputs\nFor large problems it would be impractical to maintain a table like that used\nin our grid-world example. Various researchers have suggested mechanisms for\ncomputing Q values, given pattern inputs and actions. One method that sug-\ngests itself is to use a neural network. For example, consider the simple linear\nmachine shown in Fig. 11.4.\nX\n. . .\n. . .\nY\nY\nY\ntrainable weights\nY\nWi\nR dot product units\nQ(ai, X) = X . Wi\nQ(a1, X)\nQ(a2, X)\nQ(aR, X)\nFigure 11.4: A Net that Computes Q Values\nSuch a neural net could be used by an agent that has R actions to select\nfrom. The Qvalues (as a function of the input pattern X and the action ai) are\ncomputed as dot products of weight vectors (one for each action) and the input\nvector. Weight adjustments are made according to a TD(0) procedure to bring\nthe Qvalue for the action last selected closer to the sum of the immediate reward\n(if any) and the (discounted) maximum Q value for the next input pattern.\nIf the optimum Qvalues for the problem (whatever they might be) are more\ncomplex than those that can be computed by a linear machine, a layered neural\nnetwork might be used. Sigmoid units in the \ufb01nal layer would compute Qvalues\nin the range 0 to 1. The TD(0) method for updatingQvalues would then have to\nbe combined with a multi-layer weight-changing rule, such as backpropagation.\nNetworks of this sort are able to aggregate di\ufb00erent input vectors into regions\nfor which the same action should be performed. This kind of aggregation is an\nexample of what has been calledstructural credit assignment. Combining TD(\u03bb)\nand backpropagation is a method for dealing with both the temporal and the\nstructural credit assignment problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 162, 'page_label': '163'}, page_content='154 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nInteresting examples of delayed-reinforcement training of simulated and\nactual robots requiring structural credit assignment have been reported by\n[Lin, 1992, Mahadevan & Connell, 1992].\n11.5.4 Partially Observable States\nSo far, we have identi\ufb01ed the input vector, X, with the actual state of the envi-\nronment. When the input vector results from an agents perceptual apparatus\n(as we assume it does), there is no reason to suppose that it uniquely identi\ufb01es\nthe environmental state. Because of inevitable perceptual limitations, several\ndi\ufb00erent environmental states might give rise to the same input vector. This\nphenomenon has been referred to as perceptual aliasing. With perceptual alias-\ning, we can no longer guarantee that Qlearning will result in even useful action\npolicies, let alone optimal ones. Several researchers have attempted to deal with\nthis problem using a variety of methods including attempting to model hid-\nden states by using internal memory [Lin, 1993]. That is, if some aspect of\nthe environment cannot be sensed currently, perhaps it was sensed once and\ncan be remembered by the agent. When such is the case, we no longer have a\nMarkov problem; that is, the next X vector, given any action, may depend on\na sequence of previous ones rather than just the immediately preceding one. It\nmight be possible to reinstate a Markov framework (over the Xs) if X includes\nnot only current sensory precepts but information from the agents memory.\n11.5.5 Scaling Problems\nSeveral di\ufb03culties have so far prohibited wide application of reinforcement learn-\ning to large problems. (The TD-gammon program, mentioned in the last chap-\nter, is probably unique in terms of success on a high-dimensional problem.)\nWe have already touched on some di\ufb03culties; these and others are summarized\nbelow with references to attempts to overcome them.\na. Exploration versus exploitation.\n use random actions\n favor states not visited recently\n separate the learning phase from the use phase\n employ a teacher to guide exploration\nb. Slow time to convergence\n combine learning with prior knowledge; use estimates of Q values\n(rather than random values) initially\n use a hierarchy of actions; learn primitive actions \ufb01rst and freeze the\nuseful sequences into macros and then learn how to use the macros'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 163, 'page_label': '164'}, page_content='11.6. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 155\n employ a teacher; use graded lessonsstarting near the rewards\nand then backing away, and use examples of good behavior [Lin, 1992]\n use more e\ufb03cient computations; e.g. do several updates per episode\n[Moore & Atkeson, 1993]\nc. Large state spaces\n use hand-coded features\n use neural networks\n use nearest-neighbor methods [Moore, 1990]\nd. Temporal discounting problems. Using small \u03b3 can make the learner too\ngreedy for present rewards and indi\ufb00erent to the future; but using large \u03b3\nslows down learning.\n use a learning method based on average rewards [Schwartz, 1993]\ne. No transfer of learning . What is learned depends on the reward struc-\nture; if the rewards change, learning has to start over.\n Separate the learning into two parts: learn an action model which\npredicts how actions change states (and is constant over all prob-\nlems), and then learn the values of states by reinforcement learn-\ning for each di\ufb00erent set of rewards. Sometimes the reinforcement\nlearning part can be replaced by a planner that uses the action\nmodel to produce plans to achieve goals.\nAlso see other articles in the special issue on reinforcement learning:Machine\nLearning, 8, May, 1992.\n11.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 164, 'page_label': '165'}, page_content='156 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 165, 'page_label': '166'}, page_content='Chapter 12\nExplanation-Based\nLearning\n12.1 Deductive Learning\nIn the learning methods studied so far, typically the training set does not ex-\nhaust the version space. Using logical terminology, we could say that the classi-\n\ufb01ers output does not logically follow from the training set. In this sense, these\nmethods are inductive. In logic, a deductive system is one whose conclusions\nlogically follow from a set of input facts, if the system is sound. 1\nTo contrast inductive with deductive systems in a logical setting, suppose\nwe have a set of facts (the training set) that includes the following formulas:\n{Round(Obj1),Round(Obj2),Round(Obj3),Round(Obj4),\nBall(Obj1),Ball(Obj2),Ball(Obj3),Ball(Obj4)}\nA learning system that forms the conclusion ( \u2200x)[Ball(x) \u2283Round(x)] is in-\nductive. This conclusion may be useful (if there are no facts of the form\nBall(\u03c3) \u2227¬Round(\u03c3)), but it does not logically follow from the facts. On the\nother hand, if we had the facts Green(Obj5) and Green(Obj5) \u2283Round(Obj5),\nthen we could logically conclude Round(Obj5). Making this conclusion and sav-\ning it is an instance of deductive learninga topic we study in this chapter.\nSuppose that some logical proposition, \u03c6, logically follows from some set of\nfacts, \u2206. Under what circumstances might we say that the process of deducing\n\u03c6 from \u2206 results in our learning \u03c6? In a sense, we implicitly knew \u03c6 all along,\nsince it was inherent in knowing \u2206. Yet, \u03c6 might not be obvious given \u2206, and\n1Logical reasoning systems that are not sound, for example those using non-monotonic\nreasoning, themselves might produce inductive conclusions that do not logically follow from\nthe input facts.\n157'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 166, 'page_label': '167'}, page_content='158 CHAPTER 12. EXPLANATION-BASED LEARNING\nthe deduction process to establish \u03c6might have been arduous. Rather than have\nto deduce \u03c6 again, we might want to save it, perhaps along with its deduction,\nin case it is needed later. Shouldnt that process count as learning? Dietterich\n[Dietterich, 1990] has called this type of learning speed-up learning.\nStrictly speaking, speed-up learning does not result in a system being able to\nmake decisions that, in principle, could not have been made before the learning\ntook place. Speed-up learning simply makes it possible to make those decisions\nmore e\ufb03ciently. But, in practice, this type of learning might make possible\ncertain decisions that might otherwise have been infeasible.\nTo take an extreme case, a chess player can be said to learn chess even though\noptimal play is inherent in the rules of chess. On the surface, there seems to be\nno real di\ufb00erence between the experience-based hypotheses that a chess player\nmakes about what constitutes good play and the kind of learning we have been\nstudying so far.\nAs another example, suppose we are given some theorems about geometry\nand are asked to prove that the sum of the angles of a right triangle is 180\ndegrees. Let us further suppose that the proof we constructed did not depend\non the given triangle being a right triangle; in that case we can learn a more\ngeneral fact. The learning technique that we are going to study next is related\nto this example. It is called explanation-based learning (EBL) . EBL can be\nthought of as a process in which implicit knowledge is converted into explicit\nknowledge.\nIn EBL, we specialize parts of a domain theory to explain a particular ex-\nample, then we generalize the explanation to produce another element of the\ndomain theory that will be useful on similar examples. This process is illustrated\nin Fig. 12.1.\n12.2 Domain Theories\nTwo types of information were present in the inductive methods we have studied:\nthe information inherent in the training samples and the information about the\ndomain that is implied by the bias (for example, the hypothesis set from which\nwe choose functions). The learning methods are successful only if the hypothesis\nset is appropriate for the problem. Typically, the smaller the hypothesis set (that\nis, the more a priori information we have about the function being sought), the\nless dependent we are on information being supplied by a training set (that\nis, fewer samples). A priori information about a problem can be expressed in\nseveral ways. The methods we have studied so far restrict the hypotheses in a\nrather direct way. A less direct method involves making assertions in a logical\nlanguage about the property we are trying to learn. A set of such assertions is\nusually called a domain theory.\nSuppose, for example, that we wanted to classify people according to whether\nor not they were good credit risks. We might represent a person by a set of\nproperties (income, marital status, type of employment, etc.), assemble such'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 167, 'page_label': '168'}, page_content='12.3. AN EXAMPLE 159\nDomain\nTheory\nExample\n(X is P) Prove: X is P\nspecialize\nExplanation\n(Proof)\ngeneralize\nA New Domain Rule:\nThings "like" X are P\nY is like X\nComplex Proof\nProcess\nTrivial  Proof\nY is P\nFigure 12.1: The EBL Process\ndata about people who are known to be good and bad credit risks and train a\nclassi\ufb01er to make decisions. Or, we might go to a loan o\ufb03cer of a bank, ask him\nor her what sorts of things s/he looks for in making a decision about a loan,\nencode this knowledge into a set of rules for an expert system, and then use\nthe expert system to make decisions. The knowledge used by the loan o\ufb03cer\nmight have originated as a set of policies (the domain theory), but perhaps the\napplication of these policies were specialized and made more e\ufb03cient through\nexperience with the special cases of loans made in his or her district.\n12.3 An Example\nTo make our discussion more concrete, lets consider the following fanciful exam-\nple. We want to \ufb01nd a way to classify robots as robust or not. The attributes\nthat we use to represent a robot might include some that are relevant to this\ndecision and some that are not.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 168, 'page_label': '169'}, page_content='160 CHAPTER 12. EXPLANATION-BASED LEARNING\nSuppose we have a domain theory of logical sentences that taken together,\nhelp to de\ufb01ne whether or not a robot can be classi\ufb01ed as robust. (The same\ndomain theory may be useful for several other purposes also, but among other\nthings, it describes the concept robust.)\nIn this example, lets suppose that our domain theory includes the sentences:\nFixes(u,u) \u2283Robust(u)\n(An individual that can \ufb01x itself is robust.)\nSees(x,y) \u2227Habile(x) \u2283Fixes(x,y)\n(A habile individual that can see another entity can \ufb01x that entity.)\nRobot(w) \u2283Sees(w,w)\n(All robots can see themselves.)\nR2D2(x) \u2283Habile(x)\n(R2D2-class individuals are habile.)\nC3PO(x) \u2283Habile(x)\n(C3PO-class individuals are habile.)\n...\n(By convention, variables are assumed to be universally quanti\ufb01ed.) We could\nuse theorem-proving methods operating on this domain theory to conclude\nwhether certain robots are robust. These methods might be computationally\nquite expensive because extensive search may have to be performed to derive a\nconclusion. But after having found a proof for some particular robot, we might\nbe able to derive some new sentence whose use allows a much faster conclusion.\nWe next show how such a new rule might be derived in this example. Suppose\nwe are given a number of facts about Num5, such as:\nRobot(Num5)\nR2D2(Num5)\nAge(Num5,5)\nManufacturer(Num5,GR)\n...'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 169, 'page_label': '170'}, page_content='12.3. AN EXAMPLE 161\nFixes(u, u) => Robust(u)\nRobust(Num5)\nFixes(Num5, Num5)\nSees(Num5,Num5) Habile(Num5)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nRobot(w)\n     => Sees(w,w)\nRobot(Num5)\nR2D2(x)\n         => Habile(x)\nR2D2(Num5)\nFigure 12.2: A Proof Tree\nWe are also told that Robust(Num5) is true, but we nevertheless attempt to\n\ufb01nd a proof of that assertion using these facts about Num5 and the domain\ntheory. The facts about Num5 correspond to the features that we might use\nto represent Num5. In this example, not all of them are relevant to a decision\nabout Robust(Num5). The relevant ones are those used or needed in proving\nRobust(Num5) using the domain theory. The proof tree in Fig. 12.2 is one that\na typical theorem-proving system might produce.\nIn the language of EBL, this proof is an explanation for the fact\nRobust(Num5). We see from this explanation that the only facts about Num5\nthat were used were Robot(Num5) and R2D2(Num5). In fact, we could con-\nstruct the following rule from this explanation:\nRobot(Num5) \u2227R2D2(Num5) \u2283Robust(Num5)\nThe explanation has allowed us to prune some attributes about Num5 that are\nirrelevant (at least for decidingRobust(Num5)). This type of pruning is the \ufb01rst\nsense in which an explanation is used to generalize the classi\ufb01cation problem.\n([DeJong & Mooney, 1986] call this aspect of explanation-based learning feature\nelimination.) But the rule we extracted from the explanation applies only to\nNum5. There might be little value in learning that rule since it is so speci\ufb01c.\nCan it be generalized so that it can be applied to other individuals as well?'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 170, 'page_label': '171'}, page_content='162 CHAPTER 12. EXPLANATION-BASED LEARNING\nExamination of the proof shows that the same proof structure, using the\nsame sentences from the domain theory, could be used independently of whether\nwe are talking about Num5 or some other individual. We can generalize the\nproof by a process that replaces constants in the tip nodes of the proof tree\nwith variables and works upwardusing uni\ufb01cation to constrain the values of\nvariables as needed to obtain a proof.\nIn this example, we replace Robot(Num5) by Robot(r) and R2D2(Num5)\nby R2D2(s) and redo the proofusing the explanation proof as a template.\nNote that we use di\ufb00erent values for the two di\ufb00erent occurrences of Num5 at\nthe tip nodes. Doing so sometimes results in more general, but nevertheless\nvalid rules. We now apply the rules used in the proof in the forward direction,\nkeeping track of the substitutions imposed by the most general uni\ufb01ers used in\nthe proof. (Note that we always substitute terms that are already in the tree for\nvariables in rules.) This process results in the generalized proof tree shown in\nFig. 12.3. Note that the occurrence of Sees(r,r) as a node in the tree forces the\nuni\ufb01cation of xwith yin the domain rule, Sees(x,y)\u2227Habile(y) \u2283Fixes(x,y).\nThe substitutions are then applied to the variables in the tip nodes and the root\nnode to yield the general rule: Robot(r) \u2227R2D2(r) \u2283Robust(r).\nThis rule is the end result of EBL for this example. The process\nby which Num5 in this example was generalized to a variable is what\n[DeJong & Mooney, 1986] call identity elimination (the precise identity of Num5\nturned out to be irrelevant). (The generalization process described in this ex-\nample is based on that of [DeJong & Mooney, 1986] and di\ufb00ers from that of\n[Mitchell, et al., 1986]. It is also similar to that used in [Fikes, et al., 1972].)\nClearly, under certain assumptions, this general rule is more easily used to con-\nclude Robust about an individual than the original proof process was.\nIt is important to note that we could have derived the general rule from the\ndomain theory without using the example. (In the literature, doing so is called\nstatic analysis [Etzioni, 1991].) In fact, the example told us nothing new other\nthan what it told us about Num5. The sole role of the example in this instance\nof EBL was to provide a template for a proof to help guide the generalization\nprocess. Basing the generalization process on examples helps to insure that we\nlearn rules matched to the distribution of problems that occur.\nThere are a number of quali\ufb01cations and elaborations about EBL that need\nto be mentioned.\n12.4 Evaluable Predicates\nThe domain theory includes a number of predicates other than the one occuring\nin the formula we are trying to prove and other than those that might custom-\narily be used to describe an individual. One might note, for example, that if we\nused Habile(Num5) to describe Num5, the proof would have been shorter. Why\ndidnt we? The situation is analogous to that of using a data base augmented\nby logical rules. In the latter application, the formulas in the actual data base'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 171, 'page_label': '172'}, page_content='12.4. EVALUABLE PREDICATES 163\nRobust(r)\nFixes(r, r)\nSees(r,r) Habile(s)\nRobot(r) R2D2(s)\n{r/w}\n{s/x}\n{r/x, r/y, r/s}\n{r/u}\nRobot(w)\n     => Sees(w,w)\nR2D2(x)\n         => Habile(x)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nFixes(u, u) => Robust(u)\nbecomes R2D2(r) after\napplying {r/s}\nFigure 12.3: A Generalized Proof Tree\nare extensional, and those in the logical rules are intensional. This usage\nre\ufb02ects the fact that the predicates in the data base part are de\ufb01ned by their\nextensionwe explicitly list all the tuples sastisfying a relation. The logical\nrules serve to connect the data base predicates with higher level abstractions\nthat are described (if not de\ufb01ned) by the rules. We typically cannot look up\nthe truth values of formulas containing these intensional predicates; they have\nto be derived using the rules and the database.\nThe EBL process assumes something similar. The domain theory is useful\nfor connecting formulas that we might want to prove with those whose truth\nvalues can be looked up or otherwise evaluated. In the EBL literature, such\nformulas satisfy what is called the operationality criterion. Perhaps another\nanalogy might be to neural networks. The evaluable predicates correspond to\nthe components of the input pattern vector; the predicates in the domain theory\ncorrespond to the hidden units. Finding the new rule corresponds to \ufb01nding a\nsimpler expression for the formula to be proved in terms only of the evaluable\npredicates.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 172, 'page_label': '173'}, page_content='164 CHAPTER 12. EXPLANATION-BASED LEARNING\n12.5 More General Proofs\nExamining the domain theory for our example reveals that an alternative rule\nmight have been: Robot(u) \u2227C3PO(u) \u2283 Robust(u). Such a rule might\nhave resulted if we were given {C3PO(Num6),Robot(Num6),... }and proved\nRobust(Num6). After considering these two examples (Num5 and Num6),\nthe question arises, do we want to generalize the two rules to something like:\nRobot(u)\u2227[C3PO(u)\u2228R2D2(u)] \u2283Robust(u)? Doing so is an example of what\n[DeJong & Mooney, 1986] call structural generalization (via disjunctive augmen-\ntation ).\nAdding disjunctions for every alternative proof can soon become cumbersome\nand destroy any e\ufb03ciency advantage of EBL. In our example, the e\ufb03ciency\nmight be retrieved if there were another evaluable predicate, say,Bionic(u) such\nthat the domain theory also contained R2D2(x) \u2283Bionic(x) and C3PO(x) \u2283\nBionic(x). After seeing a number of similar examples, we might be willing to\ninduce the formula Bionic(u) \u2283[C3PO(u) \u2228R2D2(u)] in which case the rule\nwith the disjunction could be replaced with Robot(u) \u2227Bionic(u) \u2283Robust(u).\n12.6 Utility of EBL\nIt is well known in theorem proving that the complexity of \ufb01nding a proof\ndepends both on the number of formulas in the domain theory and on the depth\nof the shortest proof. Adding a new rule decreases the depth of the shortest\nproof but it also increases the number of formulas in the domain theory. In\nrealistic applications, the added rules will be relevant for some tasks and not for\nothers. Thus, it is unclear whether the overall utility of the new rules will turn\nout to be positive. EBL methods have been applied in several settings, usually\nwith positive utility. (See [Minton, 1990] for an analysis).\n12.7 Applications\nThere have been several applications of EBL methods. We mention two here,\nnamely the formation of macro-operators in automatic plan generation and\nlearning how to control search.\n12.7.1 Macro-Operators in Planning\nIn automatic planning systems, e\ufb03ciency can sometimes be enhanced by chain-\ning together a sequence of operators into macro-operators. We show an exam-\nple of a process for creating macro-operators based on techniques explored by\n[Fikes, et al., 1972].\nReferring to Fig. 12.4, consider the problem of \ufb01nding a plan for a robot in\nroom R1 to fetch a box, B1, by going to an adjacent room, R2, and pushing it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 173, 'page_label': '174'}, page_content='12.7. APPLICATIONS 165\nback to R1. The goal for the robot is INROOM (B1,R1), and the facts that\nare true in the initial state are listed in the \ufb01gure.\nR1 R2\nR3\nD1\nD2\nB1\nInitial State:\nINROOM(ROBOT, R1)\nINROOM(B1,R2)\nCONNECTS(D1,R1,R2)\nCONNECTS(D1,R2,R1)\n. . .\nFigure 12.4: Initial State of a Robot Problem\nWe will construct the plan from a set of STRIPS operators that include:\nGOTHRU(d,r1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2)\nDelete list: INROOM (ROBOT,r 1)\nAdd list: INROOM (ROBOT,r 2)\nPUSHTHRU(b,d,r 1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2),INROOM (b,r1)\nDelete list: INROOM (ROBOT,r 1),INROOM (b,r1)\nAdd list: INROOM (ROBOT,r 2),INROOM (b,r2)\nA backward-reasoning STRIPS system might produce the plan shown in\nFig. 12.5. We show there the main goal and the subgoals along a solution path.\n(The conditions in each subgoal that are true in the initial state are shown\nunderlined.) The preconditions for this plan, true in the initial state, are:\nINROOM (ROBOT,R 1)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 174, 'page_label': '175'}, page_content='166 CHAPTER 12. EXPLANATION-BASED LEARNING\nCONNECTS (D1,R1,R2)\nCONNECTS (D1,R2,R1)\nINROOM (B1,R2)\nSaving this speci\ufb01c plan, valid only for the speci\ufb01c constants it mentions, would\nnot be as useful as would be saving a more general one. We \ufb01rst generalize\nthese preconditions by substituting variables for constants. We then follow the\nstructure of the speci\ufb01c plan to produce the generalized plan shown in Fig. 12.6\nthat achievesINROOM (b1,r4). Note that the generalized plan does not require\npushing the box back to the place where the robot started. The preconditions\nfor the generalized plan are:\nINROOM (ROBOT,r 1)\nCONNECTS (d1,r1,r2)\nCONNECTS (d2,r2,r4)\nINROOM (b,r4)\nINROOM(B1,R1)\nPUSHTHRU(B1,d,r1,R1)\nINROOM(ROBOT, r1),\nCONNECTS(d, r1, R1),\nINROOM(B1, r1)\nINROOM(ROBOT, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2){R2/r1,\nD1/d}\nGOTHRU(d2, r3, R2)\nINROOM(ROBOT, r3),\nCONNECTS(d2, r3, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\n{R1/r3, D1/d2}\nINROOM(ROBOT, R1),\nCONNECTS(D1, R1, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\nR1 R2\nR3\nD1\nD2\nGOTHRU(D1,R1,R2)\nPUSHTHRU(B1,D1,R2,R1)\nB1\nPLAN:\nFigure 12.5: A Plan for the Robot Problem\nAnother related technique that chains together sequences of operators to\nform more general ones is the chunking mechanism in Soar [Laird, et al., 1986].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 175, 'page_label': '176'}, page_content='12.7. APPLICATIONS 167\nINROOM(b1,r4)\nPUSHTHRU(b1,d2,r2,r4)\nINROOM(ROBOT, r2),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nGOTHRU(d1, r1, r2)\nINROOM(ROBOT, r1),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nFigure 12.6: A Generalized Plan\n12.7.2 Learning Search Control Knowledge\nBesides their use in creating macro-operators, EBL methods can be used to\nimprove the e\ufb03ciency of planning in another way also. In his system called\nPRODIGY, Minton proposed using EBL to learn e\ufb00ective ways to control\nsearch [Minton, 1988]. PRODIGY is a STRIPS-like system that solves planning\nproblems in the blocks-world, in a simple mobile robot world, and in job-shop\nscheduling. PRODIGY has a domain theory involving both the domain of the\nproblem and a simple (meta) theory about planning. Its meta theory includes\nstatements about whether a control choice about a subgoal to work on, an oper-\nator to apply, etc. either succeedsor fails. After producing a plan, it analyzes its\nsuccessful and its unsuccessful choices and attempts to explain them in terms\nof its domain theory. Using an EBL-like process, it is able to produce useful\ncontrol rules such as:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 176, 'page_label': '177'}, page_content='168 CHAPTER 12. EXPLANATION-BASED LEARNING\nIF (AND (CURRENT \u2212NODE node)\n(CANDIDATE \u2212GOAL node (ON x y))\n(CANDIDATE \u2212GOAL node (ON y z)))\nTHEN (PREFER GOAL (ON y z) TO (ON x y))\nPRODIGY keeps statistics on how often these learned rules are used, their\nsavings (in time to \ufb01nd plans), and their cost of application. It saves only the\nrules whose utility, thus measured, is judged to be high. Minton [Minton, 1990]\nhas shown that there is an overall advantage of using these rules (as against not\nhaving any rules and as against hand-coded search control rules).\n12.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 177, 'page_label': '178'}, page_content='Bibliography\n[Acorn & Walden, 1992] Acorn, T., and Walden, S., SMART: Support Man-\nagement Automated Reasoning Technology for COMPAQ Customer Ser-\nvice, Proc. Fourth Annual Conf. on Innovative Applications of Arti\ufb01cial\nIntelligence, Menlo Park, CA: AAAI Press, 1992.\n[Aha, 1991] Aha, D., Kibler, D., and Albert, M., Instance-Based Learning\nAlgorithms, Machine Learning, 6, 37-66, 1991.\n[Anderson & Bower, 1973] Anderson, J. R., and Bower, G. H., Human Asso-\nciative Memory, Hillsdale, NJ: Erlbaum, 1973.\n[Anderson, 1958] Anderson, T. W., An Introduction to Multivariate Statistical\nAnalysis, New York: John Wiley, 1958.\n[Barto, Bradtke, & Singh, 1994] Barto, A., Bradtke, S., and Singh, S., Learn-\ning to Act Using Real-Time Dynamic Programming, to appear in Ar-\nti\ufb01cial Intelligence, 1994.\n[Baum & Haussler, 1989] Baum, E, and Haussler, D., What Size Net Gives\nValid Generalization? Neural Computation, 1, pp. 151-160, 1989.\n[Baum, 1994] Baum, E., When Are k-Nearest Neighbor and Backpropagation\nAccurate for Feasible-Sized Sets of Examples? in Hanson, S., Drastal,\nG., and Rivest, R., (eds.), Computational Learning Theory and Natural\nLearning Systems, Volume 1: Constraints and Prospects , pp. 415-442,\nCambridge, MA: MIT Press, 1994.\n[Bellman, 1957] Bellman, R. E., Dynamic Programming, Princeton: Princeton\nUniversity Press, 1957.\n[Blumer, et al., 1987] Blumer, A., et al., Occams Razor, Info. Process. Lett.,\nvol 24, pp. 377-80, 1987.\n[Blumer, et al., 1990] Blumer, A., et al ., Learnability and the Vapnik-\nChervonenkis Dimension, JACM, 1990.\n[Bollinger & Du\ufb03e, 1988] Bollinger, J., and Du\ufb03e, N., Computer Control of\nMachines and Processes, Reading, MA: Addison-Wesley, 1988.\n169'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 178, 'page_label': '179'}, page_content='170 BIBLIOGRAPHY\n[Brain, et al., 1962] Brain, A. E., et al. , Graphical Data Processing Research\nStudy and Experimental Investigation, Report No. 8 (pp. 9-13) and No.\n9 (pp. 3-10), Contract DA 36-039 SC-78343, SRI International, Menlo\nPark, CA, June 1962 and September 1962.\n[Breiman, et al., 1984] Breiman, L., Friedman, J., Olshen, R., and Stone, C.,\nClassi\ufb01cation and Regression Trees, Monterey, CA: Wadsworth, 1984.\n[Brent, 1990] Brent, R. P., Fast Training Algorithms for Multi-Layer Neural\nNets, Numerical Analysis Project Manuscript NA-90-03, Computer Sci-\nence Department, Stanford University, Stanford, CA 94305, March 1990.\n[Bryson & Ho 1969] Bryson, A., and Ho, Y.-C., Applied Optimal Control, New\nYork: Blaisdell.\n[Buchanan & Wilkins, 1993] Buchanan, B. and Wilkins, D., (eds.), Readings in\nKnowledge Acquisition and Learning, San Francisco: Morgan Kaufmann,\n1993.\n[Carbonell, 1983] Carbonell, J., Learning by Analogy, in Machine Learning:\nAn Arti\ufb01cial Intelligence Approach , Michalski, R., Carbonell, J., and\nMitchell, T., (eds.), San Francisco: Morgan Kaufmann, 1983.\n[Cheeseman, et al., 1988] Cheeseman, P., et al., AutoClass: A Bayesian Clas-\nsi\ufb01cation System, Proc. Fifth Intl. Workshop on Machine Learning ,\nMorgan Kaufmann, San Mateo, CA, 1988. Reprinted in Shavlik, J. and\nDietterich, T., Readings in Machine Learning , Morgan Kaufmann, San\nFrancisco, pp. 296-306, 1990.\n[Cover & Hart, 1967] Cover, T., and Hart, P., Nearest Neighbor Pattern Clas-\nsi\ufb01cation, IEEE Trans. on Information Theory , 13, 21-27, 1967.\n[Cover, 1965] Cover, T., Geometrical and Statistical Properties of Systems\nof Linear Inequalities with Applications in Pattern Recognition, IEEE\nTrans. Elec. Comp., EC-14, 326-334, June, 1965.\n[Dasarathy, 1991] Dasarathy, B. V., Nearest Neighbor Pattern Classi\ufb01cation\nTechniques, IEEE Computer Society Press, 1991.\n[Dayan & Sejnowski, 1994] Dayan, P., and Sejnowski, T.,  TD(\u03bb) Converges\nwith Probability 1, Machine Learning, 14, pp. 295-301, 1994.\n[Dayan, 1992] Dayan, P., The Convergence of TD( \u03bb) for General \u03bb, Machine\nLearning, 8, 341-362, 1992.\n[DeJong & Mooney, 1986] DeJong, G., and Mooney, R., Explanation-Based\nLearning: An Alternative View, Machine Learning, 1:145-176, 1986.\nReprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 452-467.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 179, 'page_label': '180'}, page_content='BIBLIOGRAPHY 171\n[Dietterich & Bakiri, 1991] Dietterich, T. G., and Bakiri, G., Error-Correcting\nOutput Codes: A General Method for Improving Multiclass Induc-\ntive Learning Programs, Proc. Ninth Nat. Conf. on A.I. , pp. 572-577,\nAAAI-91, MIT Press, 1991.\n[Dietterich, et al., 1990] Dietterich, T., Hild, H., and Bakiri, G., A Compara-\ntive Study of ID3 and Backpropagation for English Text-to-Speech Map-\nping, Proc. Seventh Intl. Conf. Mach. Learning, Porter, B. and Mooney,\nR. (eds.), pp. 24-31, San Francisco: Morgan Kaufmann, 1990.\n[Dietterich, 1990] Dietterich, T., Machine Learning, Annu. Rev. Comput.\nSci., 4:255-306, Palo Alto: Annual Reviews Inc., 1990.\n[Duda & Fossum, 1966] Duda, R. O., and Fossum, H., Pattern Classi\ufb01cation\nby Iteratively Determined Linear and Piecewise Linear Discriminant\nFunctions, IEEE Trans. on Elect. Computers , vol. EC-15, pp. 220-232,\nApril, 1966.\n[Duda & Hart, 1973] Duda, R. O., and Hart, P.E., Pattern Classi\ufb01cation and\nScene Analysis, New York: Wiley, 1973.\n[Duda, 1966] Duda, R. O., Training a Linear Machine on Mislabeled Patterns,\nSRI Tech. Report prepared for ONR under Contract 3438(00), SRI In-\nternational, Menlo Park, CA, April 1966.\n[Efron, 1982] Efron, B., The Jackknife, the Bootstrap and Other Resampling\nPlans, Philadelphia: SIAM, 1982.\n[Ehrenfeucht, et al., 1988] Ehrenfeucht, A., et al., A General Lower Bound on\nthe Number of Examples Needed for Learning, in Proc. 1988 Workshop\non Computational Learning Theory, pp. 110-120, San Francisco: Morgan\nKaufmann, 1988.\n[Etzioni, 1991] Etzioni, O., STATIC: A Problem-Space Compiler for\nPRODIGY, Proc. of Ninth National Conf. on Arti\ufb01cial Intelligence ,\npp. 533-540, Menlo Park: AAAI Press, 1991.\n[Etzioni, 1993] Etzioni, O., A Structural Theory of Explanation-Based Learn-\ning, Arti\ufb01cial Intelligence, 60:1, pp. 93-139, March, 1993.\n[Evans & Fisher, 1992] Evans, B., and Fisher, D., Process Delay Analyses Using\nDecision-Tree Induction, Tech. Report CS92-06, Department of Com-\nputer Science, Vanderbilt University, TN, 1992.\n[Fahlman & Lebiere, 1990] Fahlman, S., and Lebiere, C., The Cascade-\nCorrelation Learning Architecture, in Touretzky, D., (ed.), Advances in\nNeural Information Processing Systems, 2 , pp. 524-532, San Francisco:\nMorgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 180, 'page_label': '181'}, page_content='172 BIBLIOGRAPHY\n[Fayyad, et al., 1993] Fayyad, U. M., Weir, N., and Djorgovski, S., SKICAT:\nA Machine Learning System for Automated Cataloging of Large Scale\nSky Surveys, in Proc. Tenth Intl. Conf. on Machine Learning , pp. 112-\n119, San Francisco: Morgan Kaufmann, 1993. (For a longer version of\nthis paper see: Fayyad, U. Djorgovski, G., and Weir, N., Automating\nthe Analysis and Cataloging of Sky Surveys, in Fayyad, U., et al.(eds.),\nAdvances in Knowledge Discovery and Data Mining , Chapter 19, pp.\n471\ufb00., Cambridge: The MIT Press, March, 1996.)\n[Feigenbaum, 1961] Feigenbaum, E. A., The Simulation of Verbal Learning Be-\nhavior, Proceedings of the Western Joint Computer Conference, 19:121-\n132, 1961.\n[Fikes, et al., 1972] Fikes, R., Hart, P., and Nilsson, N., Learning and Execut-\ning Generalized Robot Plans, Arti\ufb01cial Intelligence, pp 251-288, 1972.\nReprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 468-486.\n[Fisher, 1987] Fisher, D., Knowledge Acquisition via Incremental Conceptual\nClustering, Machine Learning, 2:139-172, 1987. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 267283.\n[Friedman, et al., 1977] Friedman, J. H., Bentley, J. L., and Finkel, R. A., An\nAlgorithm for Finding Best Matches in Logarithmic Expected Time,\nACM Trans. on Math. Software , 3(3):209-226, September 1977.\n[Fu, 1994] Fu, L., Neural Networks in Arti\ufb01cial Intelligence , New York:\nMcGraw-Hill, 1994.\n[Gallant, 1986] Gallant, S. I., Optimal Linear Discriminants, in Eighth Inter-\nnational Conf. on Pattern Recognition , pp. 849-852, New York: IEEE,\n1986.\n[Genesereth & Nilsson, 1987] Genesereth, M., and Nilsson, N., Logical Founda-\ntions of Arti\ufb01cial Intelligence , San Francisco: Morgan Kaufmann, 1987.\n[Gluck & Rumelhart, 1989] Gluck, M. and Rumelhart, D., Neuroscience and\nConnectionist Theory, The Developments in Connectionist Theory, Hills-\ndale, NJ: Erlbaum Associates, 1989.\n[Hammerstrom, 1993] Hammerstrom, D., Neural Networks at Work, IEEE\nSpectrum, pp. 26-32, June 1993.\n[Haussler, 1988] Haussler, D., Quantifying Inductive Bias: AI Learning Al-\ngorithms and Valiants Learning Framework, Arti\ufb01cial Intelligence ,\n36:177-221, 1988. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96-107.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 181, 'page_label': '182'}, page_content='BIBLIOGRAPHY 173\n[Haussler, 1990] Haussler, D., Probably Approximately Correct Learning,\nProc. Eighth Nat. Conf. on AI , pp. 1101-1108. Cambridge, MA: MIT\nPress, 1990.\n[Hebb, 1949] Hebb, D. O., The Organization of Behaviour , New York: John\nWiley, 1949.\n[Hertz, Krogh, & Palmer, 1991] Hertz, J., Krogh, A, and Palmer, R., Introduc-\ntion to the Theory of Neural Computation , Lecture Notes, vol. 1, Santa\nFe Inst. Studies in the Sciences of Complexity, New York: Addison-\nWesley, 1991.\n[Hirsh, 1994] Hirsh, H., Generalizing Version Spaces, Machine Learning, 17,\n5-45, 1994.\n[Holland, 1975] Holland, J., Adaptation in Natural and Arti\ufb01cial Systems , Ann\nArbor: The University of Michigan Press, 1975. (Second edition printed\nin 1992 by MIT Press, Cambridge, MA.)\n[Holland, 1986] Holland, J. H., Escaping Brittleness; The Possibilities of\nGeneral-Purpose Learning Algorithms Applied to Parallel Rule-Based\nSystems. In Michalski, R., Carbonell, J., and Mitchell, T. (eds.) , Ma-\nchine Learning: An Arti\ufb01cial Intelligence Approach, Volume 2 , chapter\n20, San Francisco: Morgan Kaufmann, 1986.\n[Hunt, Marin, & Stone, 1966] Hunt, E., Marin, J., and Stone, P., Experiments\nin Induction, New York: Academic Press, 1966.\n[Jabbour, K., et al., 1987] Jabbour, K., et al. , ALFA: Automated Load Fore-\ncasting Assistant, Proc. of the IEEE Pwer Engineering Society Summer\nMeeting, San Francisco, CA, 1987.\n[John, 1995] John, G., Robust Linear Discriminant Trees, Proc. of the Conf.\non Arti\ufb01cial Intelligence and Statistics , Ft. Lauderdale, FL, January,\n1995.\n[Kaelbling, 1993] Kaelbling, L. P., Learning in Embedded Systems, Cambridge,\nMA: MIT Press, 1993.\n[Kohavi, 1994] Kohavi, R., Bottom-Up Induction of Oblivious Read-Once De-\ncision Graphs, Proc. of European Conference on Machine Learning\n(ECML-94), 1994.\n[Kolodner, 1993] Kolodner, J., Case-Based Reasoning, San Francisco: Morgan\nKaufmann, 1993.\n[Koza, 1992] Koza, J., Genetic Programming: On the Programming of Comput-\ners by Means of Natural Selection , Cambridge, MA: MIT Press, 1992.\n[Koza, 1994] Koza, J., Genetic Programming II: Automatic Discovery of\nReusable Programs, Cambridge, MA: MIT Press, 1994.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 182, 'page_label': '183'}, page_content='174 BIBLIOGRAPHY\n[Laird, et al., 1986] Laird, J., Rosenbloom, P., and Newell, A., Chunking in\nSoar: The Anatomy of a General Learning Mechanism, Machine Learn-\ning, 1, pp. 11-46, 1986. Reprinted in Buchanan, B. and Wilkins, D.,\n(eds.), Readings in Knowledge Acquisition and Learning , pp. 518-535,\nMorgan Kaufmann, San Francisco, CA, 1993.\n[Langley, 1992] Langley, P., Areas of Application for Machine Learning,Proc.\nof Fifth Intl. Symp. on Knowledge Engineering , Sevilla, 1992.\n[Langley, 1996] Langley, P., Elements of Machine Learning , San Francisco:\nMorgan Kaufmann, 1996.\n[Lavra\u02c7 c & D\u02c7 zeroski, 1994] Lavra\u02c7 c, N., and D\u02c7 zeroski, S.,Inductive Logic Pro-\ngramming, Chichester, England: Ellis Horwood, 1994.\n[Lin, 1992] Lin, L., Self-Improving Reactive Agents Based on Reinforcement\nLearning, Planning, and Teaching, Machine Learning, 8, 293-321, 1992.\n[Lin, 1993] Lin, L., Scaling Up Reinforcement Learning for Robot Control,\nProc. Tenth Intl. Conf. on Machine Learning, pp. 182-189, San Francisco:\nMorgan Kaufmann, 1993.\n[Littlestone, 1988] Littlestone, N., Learning Quickly When Irrelevant At-\ntributes Abound: A New Linear-Threshold Algorithm, Machine Learn-\ning 2: 285-318, 1988.\n[Maass & Tur´ an, 1994] Maass, W., and Tur´ an, G., How Fast Can a Thresh-\nold Gate Learn?, in Hanson, S., Drastal, G., and Rivest, R., (eds.),\nComputational Learning Theory and Natural Learning Systems, Volume\n1: Constraints and Prospects , pp. 381-414, Cambridge, MA: MIT Press,\n1994.\n[Mahadevan & Connell, 1992] Mahadevan, S., and Connell, J., Automatic\nProgramming of Behavior-Based Robots Using Reinforcement Learn-\ning, Arti\ufb01cial Intelligence, 55, pp. 311-365, 1992.\n[Marchand & Golea, 1993] Marchand, M., and Golea, M., On Learning Sim-\nple Neural Concepts: From Halfspace Intersections to Neural Decision\nLists, Network, 4:67-85, 1993.\n[McCulloch & Pitts, 1943] McCulloch, W. S., and Pitts, W. H., A Logical Cal-\nculus of the Ideas Immanent in Nervous Activity, Bulletin of Mathe-\nmatical Biophysics, Vol. 5, pp. 115-133, Chicago: University of Chicago\nPress, 1943.\n[Michie, 1992] Michie, D., Some Directions in Machine Intelligence, unpub-\nlished manuscript, The Turing Institute, Glasgow, Scotland, 1992.\n[Minton, 1988] Minton, S., Learning Search Control Knowledge: An\nExplanation-Based Approach , Kluwer Academic Publishers, Boston,\nMA, 1988.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 183, 'page_label': '184'}, page_content='BIBLIOGRAPHY 175\n[Minton, 1990] Minton, S., Quantitative Results Concerning the Utility of\nExplanation-Based Learning, Arti\ufb01cial Intelligence , 42, pp. 363-392,\n1990. Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine\nLearning, San Francisco: Morgan Kaufmann, 1990, pp. 573-587.\n[Mitchell, et al., 1986] Mitchell, T., et al., Explanation-Based Generalization:\nA Unifying View, Machine Learning, 1:1, 1986. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 435-451.\n[Mitchell, 1982] Mitchell, T., Generalization as Search, Arti\ufb01cial Intelligence,\n18:203-226, 1982. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96107.\n[Moore & Atkeson, 1993] Moore, A., and Atkeson, C., Prioritized Sweeping:\nReinforcement Learning with Less Data and Less Time,Machine Learn-\ning, 13, pp. 103-130, 1993.\n[Moore, et al., 1994] Moore, A. W., Hill, D. J., and Johnson, M. P., An Em-\npirical Investigation of Brute Force to Choose Features, Smoothers, and\nFunction Approximators, in Hanson, S., Judd, S., and Petsche, T.,\n(eds.), Computational Learning Theory and Natural Learning Systems ,\nVol. 3, Cambridge: MIT Press, 1994.\n[Moore, 1990] Moore, A., E\ufb03cient Memory-based Learning for Robot Control ,\nPhD. Thesis; Technical Report No. 209, Computer Laboratory, Univer-\nsity of Cambridge, October, 1990.\n[Moore, 1992] Moore, A., Fast, Robust Adaptive Control by Learning Only\nForward Models, in Moody, J., Hanson, S., and Lippman, R., (eds.),\nAdvances in Neural Information Processing Systems 4 , San Francisco:\nMorgan Kaufmann, 1992.\n[Mueller & Page, 1988] Mueller, R. and Page, R., Symbolic Computing with\nLisp and Prolog, New York: John Wiley & Sons, 1988.\n[Muggleton, 1991] Muggleton, S., Inductive Logic Programming, New Gen-\neration Computing, 8, pp. 295-318, 1991.\n[Muggleton, 1992] Muggleton, S., Inductive Logic Programming, London: Aca-\ndemic Press, 1992.\n[Muroga, 1971] Muroga, S., Threshold Logic and its Applications , New York:\nWiley, 1971.\n[Natarjan, 1991] Natarajan, B., Machine Learning: A Theoretical Approach ,\nSan Francisco: Morgan Kaufmann, 1991.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 184, 'page_label': '185'}, page_content='176 BIBLIOGRAPHY\n[Nilsson, 1965] Nilsson, N. J., Theoretical and Experimental Investigations in\nTrainable Pattern-Classifying Systems, Tech. Report No. RADC-TR-\n65-257, Final Report on Contract AF30(602)-3448, Rome Air Develop-\nment Center (Now Rome Laboratories), Gri\ufb03ss Air Force Base, New\nYork, September, 1965.\n[Nilsson, 1990] Nilsson, N. J., The Mathematical Foundations of Learning Ma-\nchines, San Francisco: Morgan Kaufmann, 1990. (This book is a reprint\nof Learning Machines: Foundations of Trainable Pattern-Classifying\nSystems, New York: McGraw-Hill, 1965.)\n[Oliver, Dowe, & Wallace, 1992] Oliver, J., Dowe, D., and Wallace, C., Infer-\nring Decision Graphs using the Minimum Message Length Principle,\nProc. 1992 Australian Arti\ufb01cial Intelligence Conference , 1992.\n[Pagallo & Haussler, 1990] Pagallo, G. and Haussler, D., Boolean Feature Dis-\ncovery in Empirical Learning, Machine Learning, vol.5, no.1, pp. 71-99,\nMarch 1990.\n[Pazzani & Kibler, 1992] Pazzani, M., and Kibler, D., The Utility of Knowl-\nedge in Inductive Learning, Machine Learning, 9, 57-94, 1992.\n[Peterson, 1961] Peterson, W., Error Correcting Codes, New York: John Wiley,\n1961.\n[Pomerleau, 1991] Pomerleau, D., Rapidly Adapting Arti\ufb01cial Neural Net-\nworks for Autonomous Navigation, in Lippmann, P., et al. (eds.), Ad-\nvances in Neural Information Processing Systems, 3 , pp. 429-435, San\nFrancisco: Morgan Kaufmann, 1991.\n[Pomerleau, 1993] Pomerleau, D, Neural Network Perception for Mobile Robot\nGuidance, Boston: Kluwer Academic Publishers, 1993.\n[Quinlan & Rivest, 1989] Quinlan, J. Ross, and Rivest, Ron, Inferring Deci-\nsion Trees Using the Minimum Description Length Principle, Informa-\ntion and Computation , 80:227248, March, 1989.\n[Quinlan, 1986] Quinlan, J. Ross, Induction of Decision Trees, Machine\nLearning, 1:81106, 1986. Reprinted in Shavlik, J. and Dietterich, T.,\nReadings in Machine Learning, San Francisco: Morgan Kaufmann, 1990,\npp. 5769.\n[Quinlan, 1987] Quinlan, J. R., Generating Production Rules from Decision\nTrees, In IJCAI-87: Proceedings of the Tenth Intl. Joint Conf. on Ar-\nti\ufb01cial Intelligence, pp. 304-7, San Francisco: Morgan-Kaufmann, 1987.\n[Quinlan, 1990] Quinlan, J. R., Learning Logical De\ufb01nitions from Relations,\nMachine Learning, 5, 239-266, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 185, 'page_label': '186'}, page_content='BIBLIOGRAPHY 177\n[Quinlan, 1993] Quinlan, J. Ross, C4.5: Programs for Machine Learning , San\nFrancisco: Morgan Kaufmann, 1993.\n[Quinlan, 1994] Quinlan, J. R., Comparing Connectionist and Symbolic Learn-\ning Methods, in Hanson, S., Drastal, G., and Rivest, R., (eds.), Com-\nputational Learning Theory and Natural Learning Systems, Volume 1:\nConstraints and Prospects , pp. 445-456,, Cambridge, MA: MIT Press,\n1994.\n[Ridgway, 1962] Ridgway, W. C., An Adaptive Logic System with Generalizing\nProperties, PhD thesis, Tech. Rep. 1556-1, Stanford Electronics Labs.,\nStanford, CA, April 1962.\n[Rissanen, 1978] Rissanen, J., Modeling by Shortest Data Description, Auto-\nmatica, 14:465-471, 1978.\n[Rivest, 1987] Rivest, R. L., Learning Decision Lists, Machine Learning, 2,\n229-246, 1987.\n[Rosenblatt, 1958] Rosenblatt, F., Principles of Neurodynamics , Washington:\nSpartan Books, 1961.\n[Ross, 1983] Ross, S., Introduction to Stochastic Dynamic Programming , New\nYork: Academic Press, 1983.\n[Rumelhart, Hinton, & Williams, 1986] Rumelhart, D. E., Hinton, G. E., and\nWilliams, R. J., Learning Internal Representations by Error Propa-\ngation, In Rumelhart, D. E., and McClelland, J. L., (eds.) Parallel\nDistributed Processing, Vol 1, 318362, 1986.\n[Russell & Norvig 1995] Russell, S., and Norvig, P., Arti\ufb01cial Intelligence: A\nModern Approach, Englewood Cli\ufb00s, NJ: Prentice Hall, 1995.\n[Samuel, 1959] Samuel, A., Some Studies in Machine Learning Using the Game\nof Checkers,IBM Journal of Research and Development, 3:211-229, July\n1959.\n[Schwartz, 1993] Schwartz, A., A Reinforcement Learning Method for Max-\nimizing Undiscounted Rewards, Proc. Tenth Intl. Conf. on Machine\nLearning, pp. 298-305, San Francisco: Morgan Kaufmann, 1993.\n[Sejnowski, Koch, & Churchland, 1988] Sejnowski, T., Koch, C., and Church-\nland, P., Computational Neuroscience, Science, 241: 1299-1306, 1988.\n[Shavlik, Mooney, & Towell, 1991] Shavlik, J., Mooney, R., and Towell, G.,\nSymbolic and Neural Learning Algorithms: An Experimental Compar-\nison, Machine Learning, 6, pp. 111-143, 1991.\n[Shavlik & Dietterich, 1990] Shavlik, J. and Dietterich, T., Readings in Ma-\nchine Learning, San Francisco: Morgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 186, 'page_label': '187'}, page_content='178 BIBLIOGRAPHY\n[Sutton & Barto, 1987] Sutton, R. S., and Barto, A. G., A Temporal-\nDi\ufb00erence Model of Classical Conditioning, in Proceedings of the Ninth\nAnnual Conference of the Cognitive Science Society , Hillsdale, NJ: Erl-\nbaum, 1987.\n[Sutton, 1988] Sutton, R. S., Learning to Predict by the Methods of Temporal\nDi\ufb00erences, Machine Learning 3: 9-44, 1988.\n[Sutton, 1990] Sutton, R., Integrated Architectures for Learning, Planning,\nand Reacting Based on Approximating Dynamic Programming,Proc. of\nthe Seventh Intl. Conf. on Machine Learning, pp. 216-224, San Francisco:\nMorgan Kaufmann, 1990.\n[Taylor, Michie, & Spiegalhalter, 1994] Taylor, C., Michie, D., and Spiegal-\nhalter, D., Machine Learning, Neural and Statistical Classi\ufb01cation ,\nParamount Publishing International.\n[Tesauro, 1992] Tesauro, G., Practical Issues in Temporal Di\ufb00erence Learn-\ning, Machine Learning, 8, nos. 3/4, pp. 257-277, 1992.\n[Towell & Shavlik, 1992] Towell G., and Shavlik, J., Interpretation of Arti\ufb01-\ncial Neural Networks: Mapping Knowledge-Based Neural Networks into\nRules, in Moody, J., Hanson, S., and Lippmann, R., (eds.), Advances in\nNeural Information Processing Systems, 4 , pp. 977-984, San Francisco:\nMorgan Kaufmann, 1992.\n[Towell, Shavlik, & Noordweier, 1990] Towell, G., Shavlik, J., and Noordweier,\nM., Re\ufb01nement of Approximate Domain Theories by Knowledge-Based\nArti\ufb01cial Neural Networks, Proc. Eighth Natl., Conf. on Arti\ufb01cial In-\ntelligence, pp. 861-866, 1990.\n[Unger, 1989] Unger, S., The Essence of Logic Circuits , Englewood Cli\ufb00s, NJ:\nPrentice-Hall, 1989.\n[Utgo\ufb00, 1989] Utgo\ufb00, P., Incremental Induction of Decision Trees, Machine\nLearning, 4:161186, Nov., 1989.\n[Valiant, 1984] Valiant, L., A Theory of the Learnable, Communications of\nthe ACM, Vol. 27 , pp. 1134-1142, 1984.\n[Vapnik & Chervonenkis, 1971] Vapnik, V., and Chervonenkis, A., On the\nUniform Convergence of Relative Frequencies, Theory of Probability and\nits Applications, Vol. 16 , No. 2, pp. 264-280, 1971.\n[Various Editors, 1989-1994] Advances in Neural Information Processing Sys-\ntems, vols 1 through 6, San Francisco: Morgan Kaufmann, 1989 -1994.\n[Watkins & Dayan, 1992] Watkins, C. J. C. H., and Dayan, P., Technical Note:\nQ-Learning, Machine Learning, 8, 279-292, 1992.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 187, 'page_label': '188'}, page_content='BIBLIOGRAPHY 179\n[Watkins, 1989] Watkins, C. J. C. H., Learning From Delayed Rewards , PhD\nThesis, University of Cambridge, England, 1989.\n[Weiss & Kulikowski, 1991] Weiss, S., and Kulikowski, C., Computer Systems\nthat Learn, San Francisco: Morgan Kaufmann, 1991.\n[Werbos, 1974] Werbos, P., Beyond Regression: New Tools for Prediction and\nAnalysis in the Behavioral Sciences , Ph.D. Thesis, Harvard University,\n1974.\n[Widrow & Lehr, 1990] Widrow, B., and Lehr, M. A., 30 Years of Adaptive\nNeural Networks: Perceptron, Madaline and Backpropagation, Proc.\nIEEE, vol. 78, no. 9, pp. 1415-1442, September, 1990.\n[Widrow & Stearns, 1985] Widrow, B., and Stearns, S., Adaptive Signal Pro-\ncessing, Englewood Cli\ufb00s, NJ: Prentice-Hall.\n[Widrow, 1962] Widrow, B., Generalization and Storage in Networks of Ada-\nline Neurons, in Yovits, Jacobi, and Goldstein (eds.), Self-organizing\nSystems1962, pp. 435-461, Washington, DC: Spartan Books, 1962.\n[Winder, 1961] Winder, R., Single Stage Threshold Logic, Proc. of the AIEE\nSymp. on Switching Circuits and Logical Design , Conf. paper CP-60-\n1261, pp. 321-332, 1961.\n[Winder, 1962] Winder, R., Threshold Logic, PhD Dissertation, Princeton Uni-\nversity, Princeton, NJ, 1962.\n[Wnek, et al., 1990] Wnek, J., et al., Comparing Learning Paradigms via Di-\nagrammatic Visualization, in Proc. Fifth Intl. Symp. on Methodologies\nfor Intelligent Systems , pp. 428-437, 1990. (Also Tech. Report MLI90-2,\nUniversity of Illinois at Urbana-Champaign.)')]
INFO:root:Splits content: [Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 0, 'page_label': '1'}, page_content='INTRODUCTION\nTO\nMACHINE LEARNING\nAN EARLY DRAFT OF A PROPOSED\nTEXTBOOK\nNils J. Nilsson\nRobotics Laboratory\nDepartment of Computer Science\nStanford University\nStanford, CA 94305\ne-mail: nilsson@cs.stanford.edu\nNovember 3, 1998\nCopyright c\u20dd2005 Nils J.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 0, 'page_label': '1'}, page_content='Nilsson\nThis material may not be copied, reproduced, or distributed without the\nwritten permission of the copyright holder.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 1, 'page_label': '2'}, page_content='ii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='Contents\n1 Preliminaries 1\n1.1 Introduction . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 1\n1.1.1 What is Machine Learning? .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 1\n1.1.2 Wellsprings of Machine Learning . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 3\n1.1.3 Varieties of Machine Learning . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 4\n1.2 Learning Input-Output Functions . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 5\n1.2.1 Types of Learning . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . . . . . . . 5\n1.2.2 Input Vectors . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . 7\n1.2.3 Outputs . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 8\n1.2.4 Training Regimes . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . . . . . . . . 8\n1.2.5 Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.2.6 Performance Evaluation . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 9\n1.3 Learning Requires Bias . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.4 Sample Applications . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.5 Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.6 Bibliographical and Historical Remarks . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 13\n2 Boolean Functions 15\n2.1 Representation . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 15\n2.1.1 Boolean Algebra . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 15\n2.1.2 Diagrammatic Representations . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 16\n2.2 Classes of Boolean Functions . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . . . . . 17\n2.2.1 Terms and Clauses . . . . . . . . . . . . . . . . . . . . . . 17\n2.2.2 DNF Functions . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.2.3 CNF Functions . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 21\n2.2.4 Decision Lists . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 22\n2.2.5 Symmetric and Voting Functions . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 23\n2.2.6 Linearly Separable Functions . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. . . . . . . . . . . . . . 23\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.4 Bibliographical and Historical Remarks . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 2, 'page_label': '3'}, page_content='. 25\niii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='3 Using Version Spaces for Learning 27\n3.1 Version Spaces and Mistake Bounds . . . . . . . . . . . . . . . . 27\n3.2 Version Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n3.3 Learning as Search of a Version Space . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 32\n3.4 The Candidate Elimination Method . . . . . . . . . . . . . . . . 32\n3.5 Bibliographical and Historical Remarks . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 34\n4 Neural Networks 35\n4.1 Threshold Logic Units . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . . . . . . . . . . . . . 35\n4.1.1 De\ufb01nitions and Geometry . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 35\n4.1.2 Special Cases of Linearly Separable Functions . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 37\n4.1.3 Error-Correction Training of a TLU . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . 38\n4.1.4 Weight Space . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4.1.5 The Widrow-Ho\ufb00 Procedure . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 42\n4.1.6 Training a TLU on Non-Linearly-Separable Training Sets 44\n4.2 Linear Machines . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 44\n4.3 Networks of TLUs . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . 46\n4.3.1 Motivation and Examples . . . . . . . . . . . . . . . . . . 46\n4.3.2 Madalines . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.3.3 Piecewise Linear Machines . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 50\n4.3.4 Cascade Networks . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 51\n4.4 Training Feedforward Networks by Backpropagation . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . 52\n4.4.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 52\n4.4.2 The Backpropagation Method . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 53\n4.4.3 Computing Weight Changes in the Final Layer . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 56\n4.4.4 Computing Changes to the Weights in Intermediate Layers 58\n4.4.5 Variations on Backprop . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 59\n4.4.6 An Application: Steering a Van . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 60\n4.5 Synergies Between Neural Network and Knowledge-Based Methods 61\n4.6 Bibliographical and Historical Remarks . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 61\n5 Statistical Learning 63\n5.1 Using Statistical Decision Theory . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . . . . . . . 63\n5.1.1 Background and General Method . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 63\n5.1.2 Gaussian (or Normal) Distributions . . . . . . . . . . . . 65\n5.1.3 Conditionally Independent Binary Components . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 68\n5.2 Learning Belief Networks . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . . . . . . . . . . . 70\n5.3 Nearest-Neighbor Methods . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. . . . . . . . . . . . . . . . . . . . 70\n5.4 Bibliographical and Historical Remarks . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 3, 'page_label': '4'}, page_content='. 72\niv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='6 Decision Trees 73\n6.1 De\ufb01nitions . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 73\n6.2 Supervised Learning of Univariate Decision Trees . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 74\n6.2.1 Selecting the Type of Test . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . . . 75\n6.2.2 Using Uncertainty Reduction to Select Tests . . . . . . . 75\n6.2.3 Non-Binary Attributes . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 79\n6.3 Networks Equivalent to Decision Trees . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . 79\n6.4 Over\ufb01tting and Evaluation . . . . . . . . . . . . . . . . . . . . . 80\n6.4.1 Over\ufb01tting . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n6.4.2 Validation Methods . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 81\n6.4.3 Avoiding Over\ufb01tting in Decision Trees . . . . . . . . . . . 82\n6.4.4 Minimum-Description Length Methods . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 83\n6.4.5 Noise in Data . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . 84\n6.5 The Problem of Replicated Subtrees . . . . . . . . . . . . . . . . 84\n6.6 The Problem of Missing Attributes . . . . . . . . . . . . . . . . . 86\n6.7 Comparisons . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n6.8 Bibliographical and Historical Remarks . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 87\n7 Inductive Logic Programming 89\n7.1 Notation and De\ufb01nitions . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . . . . . . . . 90\n7.2 A Generic ILP Algorithm . . . . . . . . . . . . . . . . . . . . . . 91\n7.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 94\n7.4 Inducing Recursive Programs . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . . . . . 98\n7.5 Choosing Literals to Add . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 100\n7.6 Relationships Between ILP and Decision Tree Induction . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . 101\n7.7 Bibliographical and Historical Remarks . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 104\n8 Computational Learning Theory 107\n8.1 Notation and Assumptions for PAC Learning Theory . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . 107\n8.2 PAC Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 109\n8.2.1 The Fundamental Theorem . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . . 109\n8.2.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 111\n8.2.3 Some Properly PAC-Learnable Classes . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 112\n8.3 The Vapnik-Chervonenkis Dimension . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . 113\n8.3.1 Linear Dichotomies . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 113\n8.3.2 Capacity . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 115\n8.3.3 A More General Capacity Result . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 116\n8.3.4 Some Facts and Speculations About the VC Dimension . 117\n8.4 VC Dimension and PAC Learning . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. . . . . . . . . . . . . . . 118\n8.5 Bibliographical and Historical Remarks . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 4, 'page_label': '5'}, page_content='. 118\nv'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='9 Unsupervised Learning 119\n9.1 What is Unsupervised Learning? .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 119\n9.2 Clustering Methods . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 120\n9.2.1 A Method Based on Euclidean Distance . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 120\n9.2.2 A Method Based on Probabilities . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 124\n9.3 Hierarchical Clustering Methods . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 125\n9.3.1 A Method Based on Euclidean Distance . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 125\n9.3.2 A Method Based on Probabilities . . . . . . . . . . . . . . 126\n9.4 Bibliographical and Historical Remarks . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 130\n10 Temporal-Di\ufb00erence Learning 131\n10.1 Temporal Patterns and Prediction Problems . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . . . . . 131\n10.2 Supervised and Temporal-Di\ufb00erence Methods . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 131\n10.3 Incremental Computation of the (\u2206 W)i . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . . . . . . . 134\n10.4 An Experiment with TD Methods . . . . . . . . . . . . . . . . . 135\n10.5 Theoretical Results . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 138\n10.6 Intra-Sequence Weight Updating . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . . . . . . . . . . . 138\n10.7 An Example Application: TD-gammon . . . . . . . . . . . . . . . 140\n10.8 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 141\n11 Delayed-Reinforcement Learning 143\n11.1 The General Problem . . . . . . . . . . . . . . . . . . . . . . . . 143\n11.2 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 144\n11.3 Temporal Discounting and Optimal Policies . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . . . . . 145\n11.4 Q-Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 147\n11.5 Discussion, Limitations, and Extensions of Q-Learning . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . 150\n11.5.1 An Illustrative Example . . . . . . . . . . . . . . . . . . . 150\n11.5.2 Using Random Actions . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . . . . . . . . . . . . 152\n11.5.3 Generalizing Over Inputs . . . . . . . . . . . . . . . . . . 153\n11.5.4 Partially Observable States . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. 154\n11.5.5 Scaling Problems . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 5, 'page_label': '6'}, page_content='. . . . . . . . . . . . . . . . . . . . . 154\n11.6 Bibliographical and Historical Remarks . . . . . . . . . . . . . . 155\nvi'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='12 Explanation-Based Learning 157\n12.1 Deductive Learning . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . 157\n12.2 Domain Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n12.3 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n12.4 Evaluable Predicates . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . 162\n12.5 More General Proofs . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. 164\n12.6 Utility of EBL . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . . . 164\n12.7 Applications . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. 164\n12.7.1 Macro-Operators in Planning . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. . . . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. 164\n12.7.2 Learning Search Control Knowledge . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. 167\n12.8 Bibliographical and Historical Remarks . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 6, 'page_label': '7'}, page_content='. 168\nvii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 7, 'page_label': '8'}, page_content='viii'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 8, 'page_label': '9'}, page_content='Preface\nThese notes are in the process of becoming a textbook. The process is quite\nun\ufb01nished, and the author solicits corrections, criticisms, and suggestions from\nstudents and other readers. Although I have tried to eliminate errors, some un-\ndoubtedly remaincaveat lector. Many typographical infelicities will no doubt\npersist until the \ufb01nal version. More material has yet to be added. Please let Some of my plans for additions and\nother reminders are mentioned in\nmarginal notes.me have your suggestions about topics that are too important to be left out. I hope that future versions will cover Hop\ufb01eld nets, Elman nets and other re-\ncurrent nets, radial basis functions, grammar and automata learning, genetic\nalgorithms, and Bayes networks ... .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 8, 'page_label': '9'}, page_content='I am also collecting exercises and project\nsuggestions which will appear in future versions. My intention is to pursue a middle ground between a theoretical textbook\nand one that focusses on applications. The book concentrates on the important\nideas in machine learning. I do not give proofs of many of the theorems that I\nstate, but I do give plausibility arguments and citations to formal proofs. And, I\ndo not treat many matters that would be of practical importance in applications;\nthe book is not a handbook of machine learning practice. Instead, my goal is\nto give the reader su\ufb03cient preparation to make the extensive literature on\nmachine learning accessible. Students in my Stanford courses on machine learning have already made\nseveral useful suggestions, as have my colleague, Pat Langley, and my teaching\nassistants, Ron Kohavi, Karl P\ufb02eger, Robert Allen, and Lise Getoor. ix'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 9, 'page_label': '10'}, page_content='Chapter 1\nPreliminaries\n1.1 Introduction\n1.1.1 What is Machine Learning? Learning, like intelligence, covers such a broad range of processes that it is dif-\n\ufb01cult to de\ufb01ne precisely. A dictionary de\ufb01nition includes phrases such as to\ngain knowledge, or understanding of, or skill in, by study, instruction, or expe-\nrience, and modi\ufb01cation of a behavioral tendency by experience. Zoologists\nand psychologists study learning in animals and humans. In this book we fo-\ncus on learning in machines. There are several parallels between animal and\nmachine learning. Certainly, many techniques in machine learning derive from\nthe e\ufb00orts of psychologists to make more precise their theories of animal and\nhuman learning through computational models. It seems likely also that the\nconcepts and techniques being explored by researchers in machine learning may\nilluminate certain aspects of biological learning. As regards machines, we might say, very broadly, that a machine learns\nwhenever it changes its structure, program, or data (based on its inputs or in\nresponse to external information) in such a manner that its expected future\nperformance improves. Some of these changes, such as the addition of a record\nto a data base, fall comfortably within the province of other disciplines and are\nnot necessarily better understood for being called learning. But, for example,\nwhen the performance of a speech-recognition machine improves after hearing\nseveral samples of a persons speech, we feel quite justi\ufb01ed in that case to say\nthat the machine has learned. Machine learning usually refers to the changes in systems that perform tasks\nassociated with arti\ufb01cial intelligence (AI) . Such tasks involve recognition, diag-\nnosis, planning, robot control, prediction, etc.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 9, 'page_label': '10'}, page_content='The changes might be either\nenhancements to already performing systems or ab initio synthesis of new sys-\ntems. To be slightly more speci\ufb01c, we show the architecture of a typical AI\n1'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 10, 'page_label': '11'}, page_content='2 CHAPTER 1. PRELIMINARIES\nagent in Fig. 1.1. This agent perceives and models its environment and com-\nputes appropriate actions, perhaps by anticipating their e\ufb00ects. Changes made\nto any of the components shown in the \ufb01gure might count as learning. Di\ufb00erent\nlearning mechanisms might be employed depending on which subsystem is being\nchanged. We will study several di\ufb00erent learning methods in this book. Sensory signals\nPerception\nActions\nAction\nComputation\nModel\nPlanning and\nReasoning\nGoals\nFigure 1.1: An AI System\nOne might ask Why should machines have to learn? Why not design ma-\nchines to perform as desired in the \ufb01rst place? There are several reasons why\nmachine learning is important. Of course, we have already mentioned that the\nachievement of learning in machines might help us understand how animals and\nhumans learn. But there are important engineering reasons as well.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 10, 'page_label': '11'}, page_content='Some of\nthese are:\n Some tasks cannot be de\ufb01ned well except by example; that is, we might be\nable to specify input/output pairs but not a concise relationship between\ninputs and desired outputs. We would like machines to be able to adjust\ntheir internal structure to produce correct outputs for a large number of\nsample inputs and thus suitably constrain their input/output function to\napproximate the relationship implicit in the examples.  It is possible that hidden among large piles of data are important rela-\ntionships and correlations. Machine learning methods can often be used\nto extract these relationships ( data mining).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 11, 'page_label': '12'}, page_content='1.1. INTRODUCTION 3\n Human designers often produce machines that do not work as well as\ndesired in the environments in which they are used. In fact, certain char-\nacteristics of the working environment might not be completely known\nat design time. Machine learning methods can be used for on-the-job\nimprovement of existing machine designs.  The amount of knowledge available about certain tasks might be too large\nfor explicit encoding by humans. Machines that learn this knowledge\ngradually might be able to capture more of it than humans would want to\nwrite down.  Environments change over time. Machines that can adapt to a changing\nenvironment would reduce the need for constant redesign.  New knowledge about tasks is constantly being discovered by humans.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 11, 'page_label': '12'}, page_content='Vocabulary changes. There is a constant stream of new events in the\nworld. Continuing redesign of AI systems to conform to new knowledge is\nimpractical, but machine learning methods might be able to track much\nof it. 1.1.2 Wellsprings of Machine Learning\nWork in machine learning is now converging from several sources. These dif-\nferent traditions each bring di\ufb00erent methods and di\ufb00erent vocabulary which\nare now being assimilated into a more uni\ufb01ed discipline. Here is a brief listing\nof some of the separate disciplines that have contributed to machine learning;\nmore details will follow in the the appropriate chapters:\n Statistics: A long-standing problem in statistics is how best to use sam-\nples drawn from unknown probability distributions to help decide from\nwhich distribution some new sample is drawn. A related problem is how\nto estimate the value of an unknown function at a new point given the\nvalues of this function at a set of sample points. Statistical methods\nfor dealing with these problems can be considered instances of machine\nlearning because the decision and estimation rules depend on a corpus of\nsamples drawn from the problem environment. We will explore some of\nthe statistical methods later in the book. Details about the statistical the-\nory underlying these methods can be found in statistical textbooks such\nas [Anderson, 1958].  Brain Models: Non-linear elements with weighted inputs\nhave been suggested as simple models of biological neu-\nrons. Networks of these elements have been studied by sev-\neral researchers including [McCulloch & Pitts, 1943, Hebb, 1949,\nRosenblatt, 1958] and, more recently by [Gluck & Rumelhart, 1989,\nSejnowski, Koch, & Churchland, 1988]. Brain modelers are interested\nin how closely these networks approximate the learning phenomena of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 12, 'page_label': '13'}, page_content='4 CHAPTER 1.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 12, 'page_label': '13'}, page_content='PRELIMINARIES\nliving brains. We shall see that several important machine learning\ntechniques are based on networks of nonlinear elementsoften called\nneural networks . Work inspired by this school is sometimes called\nconnectionism, brain-style computation, or sub-symbolic processing.  Adaptive Control Theory: Control theorists study the problem of con-\ntrolling a process having unknown parameters which must be estimated\nduring operation. Often, the parameters change during operation, and the\ncontrol process must track these changes. Some aspects of controlling a\nrobot based on sensory inputs represent instances of this sort of problem. For an introduction see [Bollinger & Du\ufb03e, 1988].  Psychological Models: Psychologists have studied the performance of\nhumans in various learning tasks. An early example is the EPAM net-\nwork for storing and retrieving one member of a pair of words when\ngiven another [Feigenbaum, 1961]. Related work led to a number of\nearly decision tree [Hunt, Marin, & Stone, 1966] and semantic network\n[Anderson & Bower, 1973] methods. More recent work of this sort has\nbeen in\ufb02uenced by activities in arti\ufb01cial intelligence which we will be pre-\nsenting. Some of the work in reinforcement learning can be traced to e\ufb00orts to\nmodel how reward stimuli in\ufb02uence the learning of goal-seeking behavior in\nanimals [Sutton & Barto, 1987]. Reinforcement learning is an important\ntheme in machine learning research.  Arti\ufb01cial Intelligence: From the beginning, AI research has been con-\ncerned with machine learning. Samuel developed a prominent early pro-\ngram that learned parameters of a function for evaluating board posi-\ntions in the game of checkers [Samuel, 1959]. AI researchers have also\nexplored the role of analogies in learning [Carbonell, 1983] and how fu-\nture actions and decisions can be based on previous exemplary cases\n[Kolodner, 1993]. Recent work has been directed at discovering rules\nfor expert systems using decision-tree methods [Quinlan, 1990] and in-\nductive logic programming [Muggleton, 1991, Lavra\u02c7 c & D\u02c7 zeroski, 1994]. Another theme has been saving and generalizing the results of prob-\nlem solving using explanation-based learning [DeJong & Mooney, 1986,\nLaird, et al., 1986, Minton, 1988, Etzioni, 1993].  Evolutionary Models:\nIn nature, not only do individual animals learn to perform better, but\nspecies evolve to be better \ufb01t in their individual niches. Since the distinc-\ntion between evolving and learning can be blurred in computer systems,\ntechniques that model certain aspects of biological evolution have been\nproposed as learning methods to improve the performance of computer\nprograms. Genetic algorithms [Holland, 1975] and genetic programming\n[Koza, 1992, Koza, 1994] are the most prominent computational tech-\nniques for evolution.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 13, 'page_label': '14'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 5\n1.1.3 Varieties of Machine Learning\nOrthogonal to the question of the historical source of any learning technique is\nthe more important question of what is to be learned. In this book, we take it\nthat the thing to be learned is a computational structure of some sort. We will\nconsider a variety of di\ufb00erent computational structures:\n Functions\n Logic programs and rule sets\n Finite-state machines\n Grammars\n Problem solving systems\nWe will present methods both for the synthesis of these structures from examples\nand for changing existing structures. In the latter case, the change to the\nexisting structure might be simply to make it more computationally e\ufb03cient\nrather than to increase the coverage of the situations it can handle. Much of\nthe terminology that we shall be using throughout the book is best introduced\nby discussing the problem of learning functions, and we turn to that matter\n\ufb01rst. 1.2 Learning Input-Output Functions\nWe use Fig. 1.2 to help de\ufb01ne some of the terminology used in describing the\nproblem of learning a function. Imagine that there is a function, f, and the task\nof the learner is to guess what it is. Our hypothesis about the function to be\nlearned is denoted by h. Both f and h are functions of a vector-valued input\nX = (x1,x2,...,x i,...,x n) which has n components. We think of h as being\nimplemented by a device that has X as input and h(X) as output. Both f and\nh themselves may be vector-valued. We assume a priori that the hypothesized\nfunction, h, is selected from a class of functions H. Sometimes we know that\nf also belongs to this class or to a subset of this class. We select h based on a\ntraining set, \u039e, of minput vector examples. Many important details depend on\nthe nature of the assumptions made about all of these entities.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 13, 'page_label': '14'}, page_content='1.2.1 Types of Learning\nThere are two major settings in which we wish to learn a function. In one,\ncalled supervised learning, we know (sometimes only approximately) the values\nof f for the m samples in the training set, \u039e. We assume that if we can \ufb01nd\na hypothesis, h, that closely agrees with f for the members of \u039e, then this\nhypothesis will be a good guess for fespecially if \u039e is large.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 14, 'page_label': '15'}, page_content='6 CHAPTER 1. PRELIMINARIES\nh(X)\nh\nU = {X1, X2, . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 14, 'page_label': '15'}, page_content='. Xi, . . ., Xm}\nTraining Set:\nX =\nx1\n. . . xi\n. .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 14, 'page_label': '15'}, page_content='. xn h D H\nFigure 1.2: An Input-Output Function\nCurve-\ufb01tting is a simple example of supervised learning of a function. Sup-\npose we are given the values of a two-dimensional function,f, at the four sample\npoints shown by the solid circles in Fig. 1.3. We want to \ufb01t these four points\nwith a function, h, drawn from the set, H, of second-degree functions. We show\nthere a two-dimensional parabolic surface above the x1, x2 plane that \ufb01ts the\npoints. This parabolic function, h, is our hypothesis about the function, f, that\nproduced the four samples. In this case, h= f at the four samples, but we need\nnot have required exact matches. In the other setting, termed unsupervised learning, we simply have a train-\ning set of vectors without function values for them. The problem in this case,\ntypically, is to partition the training set into subsets, \u039e 1, . . . , \u039eR, in some ap-\npropriate way. (We can still regard the problem as one of learning a function;\nthe value of the function is the name of the subset to which an input vector be-\nlongs.) Unsupervised learning methods have application in taxonomic problems\nin which it is desired to invent ways to classify data into meaningful categories. We shall also describe methods that are intermediate between supervised\nand unsupervised learning. We might either be trying to \ufb01nd a new function, h, or to modify an existing\none. An interesting special case is that of changing an existing function into an\nequivalent one that is computationally more e\ufb03cient. This type of learning is\nsometimes called speed-uplearning. A very simple example of speed-up learning\ninvolves deduction processes. From the formulas A \u2283B and B \u2283C, we can\ndeduce C if we are given A. From this deductive process, we can create the\nformula A\u2283Ca new formula but one that does not sanction any more con-'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 15, 'page_label': '16'}, page_content='1.2. LEARNING INPUT-OUTPUT FUNCTIONS 7\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n500\n1000\n1500\n-10\n-5\n0\n5\n10-10\n-5\n0\n5\n10\n0\n00\n00\n0\nx1\nx2\nh sample f-value\nFigure 1.3: A Surface that Fits Four Points\nclusions than those that could be derived from the formulas that we previously\nhad. But with this new formula we can derive C more quickly, given A, than\nwe could have done before. We can contrast speed-up learning with methods\nthat create genuinely new functionsones that might give di\ufb00erent results after\nlearning than they did before. We say that the latter methods involve inductive\nlearning. As opposed to deduction, there are no correct inductionsonly useful\nones. 1.2.2 Input Vectors\nBecause machine learning methods derive from so many di\ufb00erent traditions, its\nterminology is rife with synonyms, and we will be using most of them in this\nbook. For example, the input vector is called by a variety of names. Some\nof these are: input vector, pattern vector, feature vector, sample, example, and\ninstance. The components, xi, of the input vector are variously called features,\nattributes, input variables, and components. The values of the components can be of three main types.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 15, 'page_label': '16'}, page_content='They might\nbe real-valued numbers, discrete-valued numbers, or categorical values. As an\nexample illustrating categorical values, information about a student might be\nrepresented by the values of the attributes class, major, sex, adviser . A par-\nticular student would then be represented by a vector such as: (sophomore,\nhistory, male, higgins). Additionally, categorical values may be ordered (as in\n{small, medium, large}) or unordered (as in the example just given). Of course,\nmixtures of all these types of values are possible. In all cases, it is possible to represent the input in unordered form by listing\nthe names of the attributes together with their values. The vector form assumes\nthat the attributes are ordered and given implicitly by a form. As an example\nof an attribute-value representation, we might have: (major: history, sex: male,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 16, 'page_label': '17'}, page_content='8 CHAPTER 1. PRELIMINARIES\nclass: sophomore, adviser: higgins, age: 19).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 16, 'page_label': '17'}, page_content='We will be using the vector form\nexclusively. An important specialization uses Boolean values, which can be regarded as\na special case of either discrete numbers (1,0) or of categorical variables ( True,\nFalse). 1.2.3 Outputs\nThe output may be a real number, in which case the process embodying the\nfunction, h, is called a function estimator , and the output is called an output\nvalue or estimate. Alternatively, the output may be a categorical value, in which case the pro-\ncess embodying h is variously called a classi\ufb01er, a recognizer, or a categorizer,\nand the output itself is called a label, a class, a category, or a decision. Classi-\n\ufb01ers have application in a number of recognition problems, for example in the\nrecognition of hand-printed characters. The input in that case is some suitable\nrepresentation of the printed character, and the classi\ufb01er maps this input into\none of, say, 64 categories. Vector-valued outputs are also possible with components being real numbers\nor categorical values. An important special case is that of Boolean output values. In that case,\na training pattern having value 1 is called a positive instance, and a training\nsample having value 0 is called a negative instance. When the input is also\nBoolean, the classi\ufb01er implements a Boolean function. We study the Boolean\ncase in some detail because it allows us to make important general points in\na simpli\ufb01ed setting. Learning a Boolean function is sometimes called concept\nlearning, and the function is called a concept. 1.2.4 Training Regimes\nThere are several ways in which the training set, \u039e, can be used to produce a\nhypothesized function.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 16, 'page_label': '17'}, page_content='In the batch method, the entire training set is available\nand used all at once to compute the function, h. A variation of this method\nuses the entire training set to modify a current hypothesis iteratively until an\nacceptable hypothesis is obtained. By contrast, in the incremental method, we\nselect one member at a time from the training set and use this instance alone\nto modify a current hypothesis. Then another member of the training set is\nselected, and so on. The selection method can be random (with replacement)\nor it can cycle through the training set iteratively. If the entire training set\nbecomes available one member at a time, then we might also use an incremental\nmethodselecting and using training set members as they arrive. (Alterna-\ntively, at any stage all training set members so far available could be used in a\nbatch process.) Using the training set members as they become available is\ncalled an online method. Online methods might be used, for example, when the'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 17, 'page_label': '18'}, page_content='1.3. LEARNING REQUIRES BIAS 9\nnext training instance is some function of the current hypothesis and the previ-\nous instanceas it would be when a classi\ufb01er is used to decide on a robots next\naction given its current set of sensory inputs. The next set of sensory inputs\nwill depend on which action was selected. 1.2.5 Noise\nSometimes the vectors in the training set are corrupted by noise. There are two\nkinds of noise. Class noise randomly alters the value of the function; attribute\nnoise randomly alters the values of the components of the input vector. In either\ncase, it would be inappropriate to insist that the hypothesized function agree\nprecisely with the values of the samples in the training set.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 17, 'page_label': '18'}, page_content='1.2.6 Performance Evaluation\nEven though there is no correct answer in inductive learning, it is important\nto have methods to evaluate the result of learning. We will discuss this matter\nin more detail later, but, brie\ufb02y, in supervised learning the induced function is\nusually evaluated on a separate set of inputs and function values for them called\nthe testing set . A hypothesized function is said to generalize when it guesses\nwell on the testing set. Both mean-squared-error and the total number of errors\nare common measures. 1.3 Learning Requires Bias\nLong before now the reader has undoubtedly asked why is learning a function\npossible at all? Certainly, for example, there are an uncountable number of\ndi\ufb00erent functions having values that agree with the four samples shown in Fig. 1.3. Why would a learning procedure happen to select the quadratic one shown\nin that \ufb01gure? In order to make that selection we had at least to limit a priori\nthe set of hypotheses to quadratic functions and then to insist that the one we\nchose passed through all four sample points. This kind of a priori information\nis called bias, and useful learning without bias is impossible. We can gain more insight into the role of bias by considering the special case\nof learning a Boolean function of n dimensions. There are 2 n di\ufb00erent Boolean\ninputs possible. Suppose we had no bias; that is His the set of all 22n\nBoolean\nfunctions, and we have no preference among those that \ufb01t the samples in the\ntraining set. In this case, after being presented with one member of the training\nset and its value we can rule out precisely one-half of the members of Hthose\nBoolean functions that would misclassify this labeled sample. The remaining\nfunctions constitute what is called a version space; well explore that concept\nin more detail later. As we present more members of the training set, the graph\nof the number of hypotheses not yet ruled out as a function of the number of\ndi\ufb00erent patterns presented is as shown in Fig. 1.4.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 17, 'page_label': '18'}, page_content='At any stage of the process,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 18, 'page_label': '19'}, page_content='10 CHAPTER 1. PRELIMINARIES\nhalf of the remaining Boolean functions have value 1 and half have value 0 for\nany training pattern not yet seen. No generalization is possible in this case\nbecause the training patterns give no clue about the value of a pattern not yet\nseen. Only memorization is possible here, which is a trivial sort of learning. log2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n2n < j\n(generalization is not possible)\n|Hv| = no. of functions not ruled out\nFigure 1.4: Hypotheses Remaining as a Function of Labeled Patterns Presented\nBut suppose we limited Hto some subset, Hc, of all Boolean functions. Depending on the subset and on the order of presentation of training patterns,\na curve of hypotheses not yet ruled out might look something like the one\nshown in Fig. 1.5. In this case it is even possible that after seeing fewer than\nall 2 n labeled samples, there might be only one hypothesis that agrees with\nthe training set. Certainly, even if there is more than one hypothesis remaining,\nmost of them may have the same value formost of the patterns not yet seen! The\ntheory of Probably Approximately Correct (PAC) learning makes this intuitive\nidea precise. Well examine that theory later. Lets look at a speci\ufb01c example of how bias aids learning. A Boolean function\ncan be represented by a hypercube each of whose vertices represents a di\ufb00erent\ninput pattern. We show a 3-dimensional version in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 18, 'page_label': '19'}, page_content='1.6. There, we show a\ntraining set of six sample patterns and have marked those having a value of 1 by\na small square and those having a value of 0 by a small circle. If the hypothesis\nset consists of just the linearly separable functionsthose for which the positive\nand negative instances can be separated by a linear surface, then there is only\none function remaining in this hypothsis set that is consistent with the training\nset. So, in this case, even though the training set does not contain all possible\npatterns, we can already pin down what the function must begiven the bias.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 19, 'page_label': '20'}, page_content='1.4. SAMPLE APPLICATIONS 11\nlog2|Hv|\n2n\n2n\nj = no. of labeled\npatterns already seen\n0\n0\n|Hv| = no. of functions not ruled out\ndepends on order\nof presentation\nlog2|Hc|\nFigure 1.5: Hypotheses Remaining From a Restricted Subset\nMachine learning researchers have identi\ufb01ed two main varieties of bias, ab-\nsolute and preference. In absolute bias (also called restricted hypothesis-space\nbias), one restricts Hto a de\ufb01nite subset of functions. In our example of Fig. 1.6,\nthe restriction was to linearly separable Boolean functions. In preference bias,\none selects that hypothesis that is minimal according to some ordering scheme\nover all hypotheses. For example, if we had some way of measuring thecomplex-\nity of a hypothesis, we might select the one that was simplest among those that\nperformed satisfactorily on the training set. The principle of Occams razor,\nused in science to prefer simple explanations to more complex ones, is a type\nof preference bias. (William of Occam, 1285-?1349, was an English philosopher\nwho said:  non sunt multiplicanda entia praeter necessitatem , which means\nentities should not be multiplied unnecessarily.)\n1.4 Sample Applications\nOur main emphasis in this book is on the concepts of machine learningnot\non its applications. Nevertheless, if these concepts were irrelevant to real-world\nproblems they would probably not be of much interest.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 19, 'page_label': '20'}, page_content='As motivation, we give\na short summary of some areas in which machine learning techniques have been\nsuccessfully applied. [Langley, 1992] cites some of the following applications and\nothers:\na. Rule discovery using a variant of ID3 for a printing industry problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 20, 'page_label': '21'}, page_content='12 CHAPTER 1. PRELIMINARIES\nx1\nx2\nx3\nFigure 1.6: A Training Set That Completely Determines a Linearly Separable\nFunction\n[Evans & Fisher, 1992]. b. Electric power load forecasting using a k-nearest-neighbor rule system\n[Jabbour, K., et al., 1987]. c. Automatic help desk assistant using a nearest-neighbor system\n[Acorn & Walden, 1992]. d. Planning and scheduling for a steel mill using ExpertEase, a marketed\n(ID3-like) system [Michie, 1992]. e. Classi\ufb01cation of stars and galaxies [Fayyad, et al., 1993]. Many application-oriented papers are presented at the annual conferences\non Neural Information Processing Systems. Among these are papers on: speech\nrecognition, dolphin echo recognition, image processing, bio-engineering, diag-\nnosis, commodity trading, face recognition, music composition, optical character\nrecognition, and various control applications [Various Editors, 1989-1994]. As additional examples, [Hammerstrom, 1993] mentions:\na. Sharps Japanese kanji character recognition system processes 200 char-\nacters per second with 99+% accuracy. It recognizes 3000+ characters.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 20, 'page_label': '21'}, page_content='b. NeuroForecasting Centres (London Business School and University Col-\nlege London) trading strategy selection network earned an average annual\npro\ufb01t of 18% against a conventional systems 12.3%.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 21, 'page_label': '22'}, page_content='1.5.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 21, 'page_label': '22'}, page_content='SOURCES 13\nc. Fujitsus (plus a partners) neural network for monitoring a continuous\nsteel casting operation has been in successful operation since early 1990. In summary, it is rather easy nowadays to \ufb01nd applications of machine learn-\ning techniques. This fact should come as no surprise inasmuch as many machine\nlearning techniques can be viewed as extensions of well known statistical meth-\nods which have been successfully applied for many years. 1.5 Sources\nBesides the rich literature in machine learning (a small part of\nwhich is referenced in the Bibliography), there are several text-\nbooks that are worth mentioning [Hertz, Krogh, & Palmer, 1991,\nWeiss & Kulikowski, 1991, Natarjan, 1991, Fu, 1994, Langley, 1996]. [Shavlik & Dietterich, 1990, Buchanan & Wilkins, 1993] are edited vol-\numes containing some of the most important papers. A survey paper by\n[Dietterich, 1990] gives a good overview of many important topics. There are\nalso well established conferences and publications where papers are given and\nappear including:\n The Annual Conferences on Advances in Neural Information Processing\nSystems\n The Annual Workshops on Computational Learning Theory\n The Annual International Workshops on Machine Learning\n The Annual International Conferences on Genetic Algorithms\n(The Proceedings of the above-listed four conferences are published by\nMorgan Kaufmann.)\n The journal Machine Learning (published by Kluwer Academic Publish-\ners). There is also much information, as well as programs and datasets, available over\nthe Internet through the World Wide Web. 1.6 Bibliographical and Historical Remarks\nTo be added. Every chapter will\ncontain a brief survey of the history\nof the material covered in that\nchapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 22, 'page_label': '23'}, page_content='14 CHAPTER 1. PRELIMINARIES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 23, 'page_label': '24'}, page_content='Chapter 2\nBoolean Functions\n2.1 Representation\n2.1.1 Boolean Algebra\nMany important ideas about learning of functions are most easily presented\nusing the special case of Boolean functions. There are several important sub-\nclasses of Boolean functions that are used as hypothesis classes for function\nlearning. Therefore, we digress in this chapter to present a review of Boolean\nfunctions and their properties. (For a more thorough treatment see, for example,\n[Unger, 1989].)\nA Boolean function, f(x1,x2,...,x n) maps an n-tuple of (0,1) values to\n{0,1}. Boolean algebra is a convenient notation for representing Boolean func-\ntions. Boolean algebra uses the connectives ·, +, and . For example, the and\nfunction of two variables is written x1 ·x2. By convention, the connective,  ·\nis usually suppressed, and the and function is written x1x2. x1x2 has value 1 if\nand only if both x1 and x2 have value 1; if either x1 or x2 has value 0, x1x2 has\nvalue 0. The (inclusive) or function of two variables is written x1 + x2. x1 + x2\nhas value 1 if and only if either or both of x1 or x2 has value 1; if both x1 and\nx2 have value 0, x1 + x2 has value 0. The complement or negation of a variable,\nx, is written x. xhas value 1 if and only if xhas value 0; if xhas value 1, xhas\nvalue 0. These de\ufb01nitions are compactly given by the following rules for Boolean\nalgebra:\n1 + 1 = 1, 1 + 0 = 1, 0 + 0 = 0,\n1 ·1 = 1, 1 ·0 = 0, 0 ·0 = 0, and\n1 = 0, 0 = 1. Sometimes the arguments and values of Boolean functions are expressed in\nterms of the constants T (True) and F (False) instead of 1 and 0, respectively.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 23, 'page_label': '24'}, page_content='15'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 24, 'page_label': '25'}, page_content='16 CHAPTER 2. BOOLEAN FUNCTIONS\nThe connectives ·and + are each commutative and associative. Thus, for\nexample, x1(x2x3) = ( x1x2)x3, and both can be written simply as x1x2x3. Similarly for +. A Boolean formula consisting of a single variable, such as x1 is called an\natom. One consisting of either a single variable or its complement, such as x1,\nis called a literal. The operators ·and + do not commute between themselves. Instead, we\nhave DeMorgans laws (which can be veri\ufb01ed by using the above de\ufb01nitions):\nx1x2 = x1 + x2, and\nx1 + x2 = x1 x2. 2.1.2 Diagrammatic Representations\nWe saw in the last chapter that a Boolean function could be represented by\nlabeling the vertices of a cube. For a function of n variables, we would need\nan n-dimensional hypercube. In Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 24, 'page_label': '25'}, page_content='2.1 we show some 2- and 3-dimensional\nexamples. Vertices having value 1 are labeled with a small square, and vertices\nhaving value 0 are labeled with a small circle. x1\nx2\nx1\nx2\nx1\nx2\nand or\nxor (exclusive or)\nx1x2 x1 + x2\nx1x2  +  x1x2\neven parity functionx1\nx2\nx3\nx1x2x3  +  x1x2x3\n+ x1x2x3 + x1x2x3\nFigure 2.1: Representing Boolean Functions on Cubes\nUsing the hypercube representations, it is easy to see how many Boolean\nfunctions of n dimensions there are. A 3-dimensional cube has 2 3 = 8 vertices,\nand each may be labeled in two di\ufb00erent ways; thus there are 2 (23) = 256'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 25, 'page_label': '26'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 17\ndi\ufb00erent Boolean functions of 3 variables. In general, there are 2 2n\nBoolean\nfunctions of n variables. We will be using 2- and 3-dimensional cubes later to provide some intuition\nabout the properties of certain Boolean functions. Of course, we cannot visualize\nhypercubes (for n > 3), and there are many surprising properties of higher\ndimensional spaces, so we must be careful in using intuitions gained in low\ndimensions. One diagrammatic technique for dimensions slightly higher than\n3 is the Karnaugh map . A Karnaugh map is an array of values of a Boolean\nfunction in which the horizontal rows are indexed by the values of some of\nthe variables and the vertical columns are indexed by the rest. The rows and\ncolumns are arranged in such a way that entries that are adjacent in the map\ncorrespond to vertices that are adjacent in the hypercube representation. We\nshow an example of the 4-dimensional even parity function in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 25, 'page_label': '26'}, page_content='2.2. (An\neven parity function is a Boolean function that has value 1 if there are an even\nnumber of its arguments that have value 1; otherwise it has value 0.) Note\nthat all adjacent cells in the table correspond to inputs di\ufb00ering in only one\ncomponent. Also describe general logic\ndiagrams, [Wnek, et al., 1990]. 00 01 1011\n00\n01\n10\n11\n11\n1\n1\n11\n1\n10\n00\n0\n0\n0\n0\n0\nx1,x2\nx3,x4\nFigure 2.2: A Karnaugh Map\n2.2 Classes of Boolean Functions\n2.2.1 Terms and Clauses\nTo use absolute bias in machine learning, we limit the class of hypotheses. In\nlearning Boolean functions, we frequently use some of the common sub-classes of\nthose functions. Therefore, it will be important to know about these subclasses. One basic subclass is called terms. A term is any function written in the\nform l1l2 ···lk, where the li are literals. Such a form is called a conjunction of\nliterals. Some example terms are x1x7 and x1x2x4. The size of a term is the\nnumber of literals it contains. The examples are of sizes 2 and 3, respectively. (Strictly speaking, the class of conjunctions of literals is called the monomials,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 26, 'page_label': '27'}, page_content='18 CHAPTER 2. BOOLEAN FUNCTIONS\nand a conjunction of literals itself is called a term. This distinction is a \ufb01ne one\nwhich we elect to blur here.)\nIt is easy to show that there are exactly 3 n possible terms of n variables. The number of terms of size kor less is bounded from above by \u2211k\ni=0 C(2n,i) =\nO(nk), where C(i,j) = i! (i\u2212j)!j! is the binomial coe\ufb03cient.Probably Ill put in a simple\nterm-learning algorithm hereso\nwe can get started on learning! Also for DNF functions and\ndecision listsas they are de\ufb01ned\nin the next few pages. A clause is any function written in the form l1 +l2 +···+lk, where the li are\nliterals. Such a form is called a disjunction of literals. Some example clauses\nare x3 + x5 + x6 and x1 + x4. The size of a clause is the number of literals it\ncontains. There are 3 n possible clauses and fewer than \u2211k\ni=0 C(2n,i) clauses of\nsize k or less. If f is a term, then (by De Morgans laws) f is a clause, and vice\nversa. Thus, terms and clauses are duals of each other. In psychological experiments, conjunctions of literals seem easier for humans\nto learn than disjunctions of literals. 2.2.2 DNF Functions\nA Boolean function is said to be in disjunctive normal form (DNF) if it can be\nwritten as adisjunction of terms. Some examples in DNF are: f = x1x2+x2x3x4\nand f = x1x3 + x2 x3 + x1x2x3. A DNF expression is called a k-term DNF\nexpression if it is a disjunction of k terms; it is in the class k-DNF if the size of\nits largest term is k. The examples above are 2-term and 3-term expressions,\nrespectively. Both expressions are in the class 3-DNF. Each term in a DNF expression for a function is called an implicant because\nit implies the function (if the term has value 1, so does the function). In\ngeneral, a term, t, is an implicant of a function, f, if f has value 1 whenever\nt does. A term, t, is a prime implicant of f if the term, t\u2032, formed by taking\nany literal out of an implicant t is no longer an implicant of f. (The implicant\ncannot be divided by any term and remain an implicant.)\nThus, both x2x3 and x1 x3 are prime implicants off = x2x3+x1 x3+x2x1x3,\nbut x2x1x3 is not. The relationship between implicants and prime implicants can be geometri-\ncally illustrated using the cube representation for Boolean functions. Consider,\nfor example, the function f = x2x3 + x1 x3 + x2x1x3.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 26, 'page_label': '27'}, page_content='We illustrate it in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 26, 'page_label': '27'}, page_content='2.3. Note that each of the three planes in the \ufb01gure cuts o\ufb00 a group of\nvertices having value 1, but none cuts o\ufb00 any vertices having value 0. These\nplanes are pictorial devices used to isolate certain lower dimensional subfaces\nof the cube. Two of them isolate one-dimensional edges, and the third isolates\na zero-dimensional vertex. Each group of vertices on a subface corresponds to\none of the implicants of the function, f, and thus each implicant corresponds\nto a subface of some dimension. A k-dimensional subface corresponds to an\n(n\u2212k)-size implicant term. The function is written as the disjunction of the\nimplicantscorresponding to the union of all the vertices cut o\ufb00 by all of the\nplanes. Geometrically, an implicant is prime if and only if its corresponding\nsubface is the largest dimensional subface that includes all of its vertices and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 27, 'page_label': '28'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 19\nno other vertices having value 0. Note that the term x2x1x3 is not a prime\nimplicant of f. (In this case, we dont even have to include this term in the\nfunction because the vertex cut o\ufb00 by the plane corresponding to x2x1x3 is\nalready cut o\ufb00 by the plane corresponding to x2x3.) The other two implicants\nare prime because their corresponding subfaces cannot be expanded without\nincluding vertices having value 0. x2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x2x1x3\n   = x2x3 + x1x3\nx2x3 and  x1x3 are prime implicants\nFigure 2.3: A Function and its Implicants\nNote that all Boolean functions can be represented in DNFtrivially by\ndisjunctions of terms of size nwhere each term corresponds to one of the vertices\nwhose value is 1. Whereas there are 22n\nfunctions of ndimensions in DNF (since\nany Boolean function can be written in DNF), there are just 2 O(nk) functions\nin k-DNF. All Boolean functions can also be represented in DNF in which each term is\na prime implicant, but that representation is not unique, as shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 27, 'page_label': '28'}, page_content='2.4. If we can express a function in DNF form, we can use the consensus method\nto \ufb01nd an expression for the function in which each term is a prime implicant. The consensus method relies on two results: We may replace this section with\none describing the\nQuine-McCluskey method instead. Consensus:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 28, 'page_label': '29'}, page_content='20 CHAPTER 2. BOOLEAN FUNCTIONS\nx2\nx1\nx3\n1, 0, 0\n1, 0, 1\n1, 1, 1\n0, 0, 1\nf = x2x3 + x1x3 + x1x2\n   = x1x2 + x1x3\nAll of the terms are prime implicants, but there\nis not a unique representation\nFigure 2.4: Non-Uniqueness of Representation by Prime Implicants\nxi ·f1 + xi ·f2 = xi ·f1 + xi ·f2 + f1 ·f2\nwhere f1 and f2 are terms such that no literal appearing in f1 appears\ncomplemented in f2. f1 ·f2 is called the consensus of xi ·f1 and xi ·\nf2. Readers familiar with the resolution rule of inference will note that\nconsensus is the dual of resolution. Examples: x1 is the consensus of x1x2 and x1x2.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 28, 'page_label': '29'}, page_content='The terms x1x2 and x1x2\nhave no consensus since each term has more than one literal appearing\ncomplemented in the other.  Subsumption:\nxi ·f1 + f1 = f1\nwhere f1 is a term. We say that f1 subsumes xi ·f1. Example: x1 x4x5 subsumes x1 x4 x2x5'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 29, 'page_label': '30'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 21\nThe consensus method for \ufb01nding a set of prime implicants for a function,\nf, iterates the following operations on the terms of a DNF expression for f until\nno more such operations can be applied:\na. initialize the process with the set, T, of terms in the DNF expression of\nf,\nb. compute the consensus of a pair of terms in T and add the result to T,\nc. eliminate any terms in T that are subsumed by other terms in T. When this process halts, the terms remaining in T are all prime implicants of\nf. Example: Let f = x1x2 + x1 x2x3 + x1 x2 x3 x4x5. We show a derivation of\na set of prime implicants in the consensus tree of Fig. 2.5.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 29, 'page_label': '30'}, page_content='The circled numbers\nadjoining the terms indicate the order in which the consensus and subsumption\noperations were performed. Shaded boxes surrounding a term indicate that it\nwas subsumed. The \ufb01nal form of the function in which all terms are prime\nimplicants is: f = x1x2 + x1x3 + x1 x4x5. Its terms are all of the non-subsumed\nterms in the consensus tree. x1x2 x1x2x3 x1x2x3x4x5\n x1x3\nx1x2x4x5\nx1x4x5\nf =  x1x2 + + x1x3 x1x4x5\n1\n2\n6\n4\n5\n3\nFigure 2.5: A Consensus Tree\n2.2.3 CNF Functions\nDisjunctive normal form has a dual: conjunctive normal form (CNF). A Boolean\nfunction is said to be in CNF if it can be written as a conjunction of clauses.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 30, 'page_label': '31'}, page_content='22 CHAPTER 2. BOOLEAN FUNCTIONS\nAn example in CNF is: f = (x1 +x2)(x2 +x3 +x4). A CNF expression is called\na k-clause CNF expression if it is a conjunction of k clauses; it is in the class\nk-CNF if the size of its largest clause is k. The example is a 2-clause expression\nin 3-CNF. If f is written in DNF, an application of De Morgans law renders f\nin CNF, and vice versa. Because CNF and DNF are duals, there are also 2 O(nk)\nfunctions in k-CNF. 2.2.4 Decision Lists\nRivest has proposed a class of Boolean functions calleddecision lists [Rivest, 1987]. A decision list is written as an ordered list of pairs:\n(tq,vq)\n(tq\u22121,vq\u22121)\n···\n(ti,vi)\n···\n(t2,v2)\n(T,v1)\nwhere the vi are either 0 or 1, the ti are terms in ( x1,...,x n), and T is a term\nwhose value is 1 (regardless of the values of the xi). The value of a decision list\nis the value of vi for the \ufb01rst ti in the list that has value 1. (At least one ti will\nhave value 1, because the last one does; v1 can be regarded as a default value of\nthe decision list.) The decision list is of size k, if the size of the largest term in\nit is k. The class of decision lists of size k or less is called k-DL. An example decision list is:\nf =\n(x1x2,1)\n(x1 x2x3,0)\nx2x3,1)\n(1,0)\nf has value 0 for x1 = 0, x2 = 0, and x3 = 1. It has value 1 for x1 = 1, x2 = 0,\nand x3 = 1.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 30, 'page_label': '31'}, page_content='This function is in 3-DL. It has been shown that the class k-DL is a strict superset of the union of\nk-DNF and k-CNF. There are 2 O[nkklog(n)] functions in k-DL [Rivest, 1987]. Interesting generalizations of decision lists use other Boolean functions in\nplace of the terms, ti. For example we might use linearly separable functions in\nplace of the ti (see below and [Marchand & Golea, 1993]).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 31, 'page_label': '32'}, page_content='2.2. CLASSES OF BOOLEAN FUNCTIONS 23\n2.2.5 Symmetric and Voting Functions\nA Boolean function is called symmetric if it is invariant under permutations\nof the input variables. For example, any function that is dependent only on\nthe number of input variables whose values are 1 is a symmetric function. The\nparity functions, which have value 1 depending on whether or not the number\nof input variables with value 1 is even or odd is a symmetric function. (The\nexclusive or function, illustrated in Fig. 2.1, is an odd-parity function of two\ndimensions. The or and and functions of two dimensions are also symmetric.)\nAn important subclass of the symmetric functions is the class of voting func-\ntions (also called m-of-nfunctions). A k-voting function has value 1 if and only\nif k or more of its n inputs has value 1. If k= 1, a voting function is the same\nas an n-sized clause; if k= n, a voting function is the same as an n-sized term;\nif k = (n+ 1)/2 for n odd or k = 1 + n/2 for n even, we have the majority\nfunction. 2.2.6 Linearly Separable Functions\nThe linearly separable functions are those that can be expressed as follows:\nf = thresh(\nn\u2211\ni=1\nwixi,\u03b8)\nwhere wi, i= 1,...,n , are real-valued numbers called weights, \u03b8is a real-valued\nnumber called the threshold, and thresh( \u03c3,\u03b8) is 1 if \u03c3 \u2265\u03b8 and 0 otherwise. (Note that the concept of linearly separable functions can be extended to non-\nBoolean inputs.) The k-voting functions are all members of the class of linearly\nseparable functions in which the weights all have unit value and the threshold\ndepends on k. Thus, terms and clauses are special cases of linearly separable\nfunctions. A convenient way to write linearly separable functions uses vector notation:\nf = thresh(X ·W,\u03b8)\nwhere X = ( x1,...,x n) is an n-dimensional vector of input variables, W =\n(w1,...,w n) is an n-dimensional vector of weight values, and X ·W is the dot\n(or inner) product of the two vectors. Input vectors for which f has value 1 lie\nin a half-space on one side of (and on) a hyperplane whose orientation is normal\nto W and whose position (with respect to the origin) is determined by \u03b8. We\nsaw an example of such a separating plane in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 31, 'page_label': '32'}, page_content='1.6. With this idea in mind,\nit is easy to see that two of the functions in Fig. 2.1 are linearly separable, while\ntwo are not. Also note that the terms in Figs. 2.3 and 2.4 are linearly separable\nfunctions as evidenced by the separating planes shown. There is no closed-form expression for the number of linearly separable func-\ntions of n dimensions, but the following table gives the numbers for n up to 6.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 32, 'page_label': '33'}, page_content='24 CHAPTER 2. BOOLEAN FUNCTIONS\nn Boolean Linearly Separable\nFunctions Functions\n1 4 4\n2 16 14\n3 256 104\n4 65,536 1,882\n5 \u22484.3 ×109 94,572\n6 \u22481.8 ×1019 15,028,134\n[Muroga, 1971] has shown that (for n> 1) there are no more than 2 n2\nlinearly\nseparable functions of n dimensions. (See also [Winder, 1961, Winder, 1962].)\n2.3 Summary\nThe diagram in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 32, 'page_label': '33'}, page_content='2.6 shows some of the set inclusions of the classes of Boolean\nfunctions that we have considered. We will be confronting these classes again\nin later chapters. DNF\n(All)\nk-DLk-DNFk-size-\nterms\nterms\nlin sep\nFigure 2.6: Classes of Boolean Functions\nThe sizes of the various classes are given in the following table (adapted from\n[Dietterich, 1990, page 262]):'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 33, 'page_label': '34'}, page_content='2.4. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 25\nClass Size of Class\nterms 3n\nclauses 3n\nk-term DNF 2O(kn)\nk-clause CNF 2O(kn)\nk-DNF 2O(nk)\nk-CNF 2O(nk)\nk-DL 2O[nkklog(n)]\nlin sep 2O(n2)\nDNF 22n\n2.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 34, 'page_label': '35'}, page_content='26 CHAPTER 2. BOOLEAN FUNCTIONS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 35, 'page_label': '36'}, page_content='Chapter 3\nUsing Version Spaces for\nLearning\n3.1 Version Spaces and Mistake Bounds\nThe \ufb01rst learning methods we present are based on the concepts of version\nspaces and version graphs. These ideas are most clearly explained for the case\nof Boolean function learning. Given an initial hypothesis set H(a subset of\nall Boolean functions) and the values of f(X) for each X in a training set, \u039e,\nthe version space is that subset of hypotheses, Hv, that is consistent with these\nvalues. A hypothesis, h, is consistent with the values of X in \u039e if and only if\nh(X) = f(X) for all X in \u039e. We say that the hypotheses in Hthat are not\nconsistent with the values in the training set are ruled out by the training set. We could imagine (conceptually only!) that we have devices for implement-\ning every function in H. An incremental training procedure could then be\nde\ufb01ned which presented each pattern in \u039e to each of these functions and then\neliminated those functions whose values for that pattern did not agree with its\ngiven value. At any stage of the process we would then have left some subset\nof functions that are consistent with the patterns presented so far; this subset\nis the version space for the patterns already presented. This idea is illustrated\nin Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 35, 'page_label': '36'}, page_content='3.1. Consider the following procedure for classifying an arbitrary input pattern,\nX: the pattern is put in the same class (0 or 1) as are the majority of the\noutputs of the functions in the version space. During the learning procedure,\nif this majority is not equal to the value of the pattern presented, we say a\nmistake is made, and we revise the version space accordinglyeliminating all\nthose (majority of the) functions voting incorrectly. Thus, whenever a mistake\nis made, we rule out at least half of the functions remaining in the version space. How many mistakes can such a procedure make? Obviously, we can make\nno more than log 2(|H|) mistakes, where |H|is the number of hypotheses in the\n27'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 36, 'page_label': '37'}, page_content='28 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nh1\nh2\nhi\nhK\nX\nA Subset, H,  of all\nBoolean Functions\nRule out hypotheses not\nconsistent with training patterns\nhj\nHypotheses not ruled out\nconstitute the version space\nK = |H|\n1 or 0\nFigure 3.1: Implementing the Version Space\noriginal hypothesis set, H. (Note, though, that the number of training patterns\nseen before this maximum number of mistakes is made might be much greater.)\nThis theoretical (and very impractical!) result (due to [Littlestone, 1988]) is an\nexample of a mistake boundan important concept in machine learning theory. It shows that there must exist a learning procedure that makes no more mistakes\nthan this upper bound.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 36, 'page_label': '37'}, page_content='Later, well derive other mistake bounds. As a special case, if our bias was to limit Hto terms, we would make no\nmore than log2(3n) = nlog2(3) = 1.585nmistakes before exhausting the version\nspace. This result means that if f were a term, we would make no more than\n1.585nmistakes before learning f, and otherwise we would make no more than\nthat number of mistakes before being able to decide that f is not a term. Even if we do not have su\ufb03cient training patterns to reduce the version\nspace to a single function, it may be that there are enough training patterns\nto reduce the version space to a set of functions such that most of them assign\nthe same values to most of the patterns we will see henceforth. We could select\none of the remaining functions at random and be reasonably assured that it\nwill generalize satisfactorily. We next discuss a computationally more feasible\nmethod for representing the version space.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 37, 'page_label': '38'}, page_content='3.2. VERSION GRAPHS 29\n3.2 Version Graphs\nBoolean functions can be ordered by generality. A Boolean function, f1, is more\ngeneral than a function, f2, (and f2 is more speci\ufb01c than f1), if f1 has value 1\nfor all of the arguments for which f2 has value 1, and f1 \u0338= f2. For example, x3\nis more general than x2x3 but is not more general than x3 + x2.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 37, 'page_label': '38'}, page_content='We can form a graph with the hypotheses, {hi}, in the version space as\nnodes. A node in the graph, hi, has an arc directed to node, hj, if and only if\nhj is more general than hi. We call such a graph a version graph. In Fig. 3.2,\nwe show an example of a version graph over a 3-dimensional input space for\nhypotheses restricted to terms (with none of them yet ruled out). 0\nx1 x2x 3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nVersion Graph for Terms\nx1\nx2\nx3\n(for simplicity, only some arcs in the graph are shown)\n(none yet ruled out)\n(k = 1)\n(k = 2)\n(k = 3)\nx1 x3\nFigure 3.2: A Version Graph for Terms\nThat function, denoted here by 1, which has value 1 for all inputs, corre-\nsponds to the node at the top of the graph. (It is more general than any other\nterm.) Similarly, the function 0 is at the bottom of the graph. Just below\n1 is a row of nodes corresponding to all terms having just one literal, and just\nbelow them is a row of nodes corresponding to terms having two literals, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 38, 'page_label': '39'}, page_content='30 CHAPTER 3.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 38, 'page_label': '39'}, page_content='USING VERSION SPACES FOR LEARNING\nso on. There are 3 3 = 27 functions altogether (the function 0, included in\nthe graph, is technically not a term). To make our portrayal of the graph less\ncluttered only some of the arcs are shown; each node in the actual graph has an\narc directed to all of the nodes above it that are more general. We use this same example to show how the version graph changes as we\nconsider a set of labeled samples in a training set, \u039e. Suppose we \ufb01rst consider\nthe training pattern (1, 0, 1) with value 0. Some of the functions in the version\ngraph of Fig. 3.2 are inconsistent with this training pattern. These ruled out\nnodes are no longer in the version graph and are shown shaded in Fig. 3.3. We\nalso show there the three-dimensional cube representation in which the vertex\n(1, 0, 1) has value 0. 0\nx1 x2 x3x2 x3\n1\nx1x2 x3\nx1x2\nx1\nNew Version Graph\n1, 0, 1 has\nvalue 0\nx1x3\nx1x2 x2x3\nx1x2x3\nx1\nx2\nx3\nx1x3\n(only some arcs in the graph are shown)\nruled out nodes\nFigure 3.3: The Version Graph Upon Seeing (1, 0, 1)\nIn a version graph, there are always a set of hypotheses that are maximally\ngeneral and a set of hypotheses that are maximally speci\ufb01c. These are called\nthe general boundary set (gbs) and the speci\ufb01c boundary set (sbs) , respectively. In Fig. 3.4, we have the version graph as it exists after learning that (1,0,1) has\nvalue 0 and (1, 0, 0) has value 1. The gbs and sbs are shown.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 39, 'page_label': '40'}, page_content='3.2. VERSION GRAPHS 31\n0\nx1 x2\nx3\nx2 x3\n1\nx1x2 x3\nx1\nx2x3x1x3\ngeneral boundary set\n(gbs)\nspecific boundary set (sbs)\nx1x2\nmore specific than gbs,\nmore general than sbs\n1, 0, 1 has\nvalue 0\nx1\nx2\nx3\n1, 0, 0 has\nvalue 1\nFigure 3.4: The Version Graph Upon Seeing (1, 0, 1) and (1, 0, 0)\nBoundary sets are important because they provide an alternative to repre-\nsenting the entire version space explicitly, which would be impractical. Given\nonly the boundary sets, it is possible to determine whether or not any hypoth-\nesis (in the prescribed class of Boolean functions we are using) is a member or\nnot of the version space. This determination is possible because of the fact that\nany member of the version space (that is not a member of one of the boundary\nsets) is more speci\ufb01c than some member of the general boundary set and is more\ngeneral than some member of the speci\ufb01c boundary set. If we limit our Boolean functions that can be in the version space to terms,\nit is a simple matter to determine maximally general and maximally speci\ufb01c\nfunctions (assuming that there is some term that is in the version space). A\nmaximally speci\ufb01c one corresponds to a subface of minimal dimension that\ncontains all the members of the training set labelled by a 1 and no members\nlabelled by a 0.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 39, 'page_label': '40'}, page_content='A maximally general one corresponds to a subface of maximal\ndimension that contains all the members of the training set labelled by a 1 and\nno members labelled by a 0. Looking at Fig. 3.4, we see that the subface of\nminimal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is just\nthe vertex (1, 0, 0) itselfcorresponding to the function x1x2 x3. The subface'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 40, 'page_label': '41'}, page_content='32 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nof maximal dimension that contains (1, 0, 0) but does not contain (1, 0, 1) is\nthe bottom face of the cubecorresponding to the function x3. In Figs.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 40, 'page_label': '41'}, page_content='3.2\nthrough 3.4 the sbs is always singular. Version spaces for terms always have\nsingular speci\ufb01c boundary sets. As seen in Fig. 3.3, however, the gbs of a\nversion space for terms need not be singular. 3.3 Learning as Search of a Version Space\n[To be written. Relate to term learning algorithm presented in Chapter\nTwo. Also discuss best-\ufb01rst search methods. See Pat Langleys example us-\ning pseudo-cells of how to generate and eliminate hypotheses.]\nSelecting a hypothesis from the version space can be thought of as a search\nproblem. One can start with a very general function and specialize it through\nvarious specialization operators until one \ufb01nds a function that is consistent (or\nadequately so) with a set of training patterns. Such procedures are usually\ncalled top-down methods. Or, one can start with a very special function and\ngeneralize itresulting in bottom-up methods. We shall see instances of both\nstyles of learning in this book.Compare this view of top-down\nversus bottom-up with the\ndivide-and-conquer and the\ncovering (or AQ) methods of\ndecision-tree induction. 3.4 The Candidate Elimination Method\nThe candidate elimination method, is an incremental method for computing the\nboundary sets. Quoting from [Hirsh, 1994, page 6]:\nThe candidate-elimination algorithm manipulates the boundary-set\nrepresentation of a version space to create boundary sets that rep-\nresent a new version space consistent with all the previous instances\nplus the new one. For a positive exmple the algorithm generalizes\nthe elements of the [sbs] as little as possible so that they cover the\nnew instance yet remain consistent with past data, and removes\nthose elements of the [gbs] that do not cover the new instance. For\na negative instance the algorithm specializes elements of the [gbs]\nso that they no longer cover the new instance yet remain consis-\ntent with past data, and removes from the [sbs] those elements that\nmistakenly cover the new, negative instance.\nThe method uses the following de\ufb01nitions (adapted from\n[Genesereth & Nilsson, 1987]):\n a hypothesis is called su\ufb03cient if and only if it has value 1 for all training\nsamples labeled by a 1,\n a hypothesis is called necessary if and only if it has value 0 for all training\nsamples labeled by a 0.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 41, 'page_label': '42'}, page_content='3.4. THE CANDIDATE ELIMINATION METHOD 33\nHere is how to think about these de\ufb01nitions: A hypothesis implements a su\ufb03-\ncient condition that a training sample has value 1 if the hypothesis has value 1\nfor all of the positive instances; a hypothesis implements a necessary condition\nthat a training sample has value 1 if the hypothesis has value 0 for all of the\nnegative instances. A hypothesis is consistent with the training set (and thus is\nin the version space) if and only if it is both su\ufb03cient and necessary. We start (before receiving any members of the training set) with the function\n0 as the singleton element of the speci\ufb01c boundary set and with the function\n1 as the singleton element of the general boundary set. Upon receiving a new\nlabeled input vector, the boundary sets are changed as follows:\na. If the new vector is labelled with a 1:\nThe new general boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not su\ufb03cient. (That is, we exclude any\nelements that have value 0 for the new vector.)\nThe new speci\ufb01c boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least generalizations. The hypothesis hg is a least generalization of h if and only if: a) h is\nmore speci\ufb01c than hg, b) hg is su\ufb03cient, c) no function (including h) that\nis more speci\ufb01c than hg is su\ufb03cient, and d) hg is more speci\ufb01c than some\nmember of the new general boundary set. It might be that hg = h. Also,\nleast generalizations of two di\ufb00erent functions in the speci\ufb01c boundary set\nmay be identical. b. If the new vector is labelled with a 0:\nThe new speci\ufb01c boundary set is obtained from the previous one by ex-\ncluding any elements in it that are not necessary. (That is, we exclude\nany elements that have value 1 for the new vector.)\nThe new general boundary set is obtained from the previous one by re-\nplacing each element, hi, in it by all of its least specializations. The hypothesis hs is a least specialization of hif and only if: a) his more\ngeneral than hs, b) hs is necessary, c) no function (including h) that is\nmore general than hs is necessary, and d) hs is more general than some\nmember of the new speci\ufb01c boundary set. Again, it might be that hs = h,\nand least specializations of two di\ufb00erent functions in the general boundary\nset may be identical.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 41, 'page_label': '42'}, page_content='As an example, suppose we present the vectors in the following order:\nvector label\n(1, 0, 1) 0\n(1, 0, 0) 1\n(1, 1, 1) 0\n(0, 0, 1) 0'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 42, 'page_label': '43'}, page_content='34 CHAPTER 3. USING VERSION SPACES FOR LEARNING\nWe start with general boundary set, 1, and speci\ufb01c boundary set, 0.\nAfter seeing the \ufb01rst sample, (1, 0, 1), labeled with a 0, the speci\ufb01c boundary\nset stays at 0 (it is necessary), and we change the general boundary set to\n{x1,x2,x3}. Each of the functions, x1, x2, and x3, are least specializations of\n1 (they are necessary, 1 is not, they are more general than 0, and there\nare no functions that are more general than they and also necessary). Then, after seeing (1, 0, 0), labeled with a 1, the general boundary set\nchanges to {x3}(because x1 and x2 are not su\ufb03cient), and the speci\ufb01c boundary\nset is changed to {x1x2 x3}. This single function is a least generalization of 0\n(it is su\ufb03cient, 0 is more speci\ufb01c than it, no function (including 0) that is\nmore speci\ufb01c than it is su\ufb03cient, and it is more speci\ufb01c than some member of\nthe general boundary set. When we see (1, 1, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the\ngeneral boundary set either because x3 is still necessary. Finally, when we see (0, 0, 1), labeled with a 0, we do not change the speci\ufb01c\nboundary set because its function is still necessary. We do not change the general\nboundary set either because x3 is still necessary.Maybe Ill put in an example of a\nversion graph for non-Boolean\nfunctions. 3.5 Bibliographical and Historical Remarks\nThe concept of version spaces and their role in learning was \ufb01rst investigated\nby Tom Mitchell [Mitchell, 1982].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 42, 'page_label': '43'}, page_content='Although these ideas are not used in prac-\ntical machine learning procedures, they do provide insight into the nature of\nhypothesis selection. In order to accomodate noisy data, version spaces have\nbeen generalized by [Hirsh, 1994] to allow hypotheses that are not necessarily\nconsistent with the training set.More to be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 43, 'page_label': '44'}, page_content='Chapter 4\nNeural Networks\nIn chapter two we de\ufb01ned several important subsets of Boolean functions. Sup-\npose we decide to use one of these subsets as a hypothesis set for supervised\nfunction learning. We next have the question of how best to implement the\nfunction as a device that gives the outputs prescribed by the function for arbi-\ntrary inputs. In this chapter we describe how networks of non-linear elements\ncan be used to implement various input-output functions and how they can be\ntrained using supervised learning methods. Networks of non-linear elements, interconnected through adjustable weights,\nplay a prominent role in machine learning. They are called neural networks be-\ncause the non-linear elements have as their inputs a weighted sum of the outputs\nof other elementsmuch like networks of biological neurons do. These networks\ncommonly use the threshold element which we encountered in chapter two in\nour study of linearly separable Boolean functions. We begin our treatment of\nneural nets by studying this threshold element and how it can be used in the\nsimplest of all networks, namely ones composed of a single threshold element. 4.1 Threshold Logic Units\n4.1.1 De\ufb01nitions and Geometry\nLinearly separable (threshold) functions are implemented in a straightforward\nway by summing the weighted inputs and comparing this sum to a threshold\nvalue as shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 43, 'page_label': '44'}, page_content='4.1. This structure we call a threshold logic unit (TLU) . Its output is 1 or 0 depending on whether or not the weighted sum of its inputs is\ngreater than or equal to a threshold value, \u03b8. It has also been called an Adaline\n(for ada ptive lin ear e lement) [Widrow, 1962, Widrow & Lehr, 1990], an LTU\n(linear threshold unit), a perceptron, and a neuron. (Although the word per-\nceptron is often used nowadays to refer to a single TLU, Rosenblatt originally\nde\ufb01ned it as a class of networks of threshold elements [Rosenblatt, 1958].)\n35'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 44, 'page_label': '45'}, page_content='36 CHAPTER 4.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 44, 'page_label': '45'}, page_content='NEURAL NETWORKS\n! x1\nx2\nxn+1 = 1\nxi\nw1\nw2\nwn+1\nwi\nwn\nX\nthreshold weight\nxn\nW threshold  "  = 0\nf\nf = thresh( ! wi xi,  0)\ni = 1\nn+1\nFigure 4.1: A Threshold Logic Unit (TLU)\nThe n-dimensional feature or input vector is denoted by X = (x1,...,x n). When we want to distinguish among di\ufb00erent feature vectors, we will attach\nsubscripts, such as Xi. The components of X can be any real-valued numbers,\nbut we often specialize to the binary numbers 0 and 1. The weights of a TLU\nare represented by an n-dimensional weight vector , W = ( w1,...,w n). Its\ncomponents are real-valued numbers (but we sometimes specialize to integers). The TLU has output 1 if \u2211n\ni=1 xiwi \u2265 \u03b8; otherwise it has output 0. The\nweighted sum that is calculated by the TLU can be simply represented as a\nvector dot product, XW. (If the pattern and weight vectors are thought of as\ncolumn vectors, this dot product is then sometimes written as XtW, where\nthe row vector Xt is the transpose of X.) Often, the threshold, \u03b8, of the TLU\nis \ufb01xed at 0; in that case, arbitrary thresholds are achieved by using ( n+ 1)-\ndimensional augmented vectors, Y, and V, whose \ufb01rst ncomponents are the\nsame as those of X and W, respectively. The ( n+ 1)-st component, xn+1, of\nthe augmented feature vector, Y, always has value 1; the (n+ 1)-st component,\nwn+1, of the augmented weight vector, V, is set equal to the negative of the\ndesired threshold value. (When we want to emphasize the use of augmented\nvectors, well use the Y,V notation; however when the context of the discussion\nmakes it clear about what sort of vectors we are talking about, well lapse back\ninto the more familiar X,W notation.) In the Y,V notation, the TLU has an\noutput of 1 if YV \u22650. Otherwise, the output is 0. We can give an intuitively useful geometric description of a TLU. A TLU\ndivides the input space by a hyperplane as sketched in Fig. 4.2. The hyperplane\nis the boundary between patterns for which XW + wn+1 > 0 and patterns\nfor which XW + wn+1 < 0. Thus, the equation of the hyperplane itself is\nXW+wn+1 = 0. The unit vector that is normal to the hyperplane is n = W\n|W|,\nwhere |W|=\n\u221a\n(w2\n1 + ... + w2n) is the length of the vector W. (The normal'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 45, 'page_label': '46'}, page_content='4.1. THRESHOLD LOGIC UNITS 37\nform of the hyperplane equation is Xn + W\n|W| = 0.) The distance from the\nhyperplane to the origin is wn+1\n|W|, and the distance from an arbitrary point, X,\nto the hyperplane is XW+wn+1\n|W| . When the distance from the hyperplane to the\norigin is negative (that is, when wn+1 < 0), then the origin is on the negative\nside of the hyperplane (that is, the side for which XW + wn+1 <0). X.W + wn+1 > 0\non this side\nW\nX\nW\nn = W\n|W|\nOrigin\nUnit vector normal\nto hyperplane\nW + wn+1 = 0X\nn +           = 0X\nEquations of hyperplane:\nwn+1\n|W|\nwn+1 W + wn+1X\nX.W + wn+1 < 0\non this side\nFigure 4.2: TLU Geometry\nAdjusting the weight vector, W, changes the orientation of the hyperplane;\nadjusting wn+1 changes the position of the hyperplane (relative to the origin). Thus, training of a TLU can be achieved by adjusting the values of the weights.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 45, 'page_label': '46'}, page_content='In this way the hyperplane can be moved so that the TLU implements di\ufb00erent\n(linearly separable) functions of the input. 4.1.2 Special Cases of Linearly Separable Functions\nTerms\nAny term of size k can be implemented by a TLU with a weight from each of\nthose inputs corresponding to variables occurring in the term. A weight of +1 is\nused from an input corresponding to a positive literal, and a weight of\u22121 is used\nfrom an input corresponding to a negative literal. (Literals not mentioned in\nthe term have weights of zerothat is, no connection at allfrom their inputs.)\nThe threshold, \u03b8, is set equal to kp \u22121/2, where kp is the number of positive\nliterals in the term. Such a TLU implements a hyperplane boundary that is'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 46, 'page_label': '47'}, page_content='38 CHAPTER 4. NEURAL NETWORKS\nparallel to a subface of dimension ( n\u2212k) of the unit hypercube. We show a\nthree-dimensional example in Fig. 4.3. Thus, linearly separable functions are a\nsuperset of terms. (1,1,1)\n(1,1,0)\nx2\nx1\nx3 f = x1x2\nx1 + x2 - 3/2 = 0\nEquation of plane is:\nFigure 4.3: Implementing a Term\nClauses\nThe negation of a clause is a term. For example, the negation of the clause\nf = x1 + x2 + x3 is the term f = x1 x2 x3. A hyperplane can be used to\nimplement this term. If we invert the hyperplane, it will implement the\nclause instead. Inverting a hyperplane is done by multiplying all of the TLU\nweightseven wn+1by \u22121. This process simply changes the orientation of the\nhyperplane\ufb02ipping it around by 180 degrees and thus changing its positive\nside. Therefore, linearly separable functions are also a superset of clauses. We\nshow an example in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 46, 'page_label': '47'}, page_content='4.4. 4.1.3 Error-Correction Training of a TLU\nThere are several procedures that have been proposed for adjusting the weights\nof a TLU. We present next a family of incremental training procedures with\nparameter c. These methods make adjustments to the weight vector only when\nthe TLU being trained makes an error on a training pattern; they are called\nerror-correction procedures. We use augmented feature and weight vectors in\ndescribing them. a. We start with a \ufb01nite training set, \u039e, of vectors, Yi , and their binary\nlabels.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 47, 'page_label': '48'}, page_content='4.1. THRESHOLD LOGIC UNITS 39\nf = x1 + x2 + x3\nx1\nx1 + x2 + x3 < 1/2 = 0\nf = x1x2x3\nEquation of plane is:\nx2\nx3\nFigure 4.4: Implementing a Clause\nb. Compose an in\ufb01nite training sequence, \u03a3, of vectors from \u039e and their\nlabels such that each member of \u039e occurs in\ufb01nitely often in \u03a3.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 47, 'page_label': '48'}, page_content='Set the\ninitial weight values of an TLU to arbitrary values. c. Repeat forever:\nPresent the next vector, Yi, in \u03a3 to the TLU and note its response. (a) If the TLU responds correctly, make no change in the weight vector. (b) If Yi is supposed to produce an output of 0 and produces an output\nof 1 instead, modify the weight vector as follows:\nV \u2190\u2212V \u2212ciYi\nwhere ci is a positive real number called the learning rate parame-\nter (whose value is di\ufb00ererent in di\ufb00erent instances of this family of\nprocedures and may depend on i). Note that after this adjustment the new dot product will be ( V \u2212\nciYi)Yi = VYi\u2212ciYiYi, which is smaller than it was before the\nweight adjustment. (c) If Yi is supposed to produce an output of 1 and produces an output\nof 0 instead, modify the weight vector as follows:\nV \u2190\u2212V + ciYi\nIn this case, the new dot product will be ( V + ciYi)Yi = VYi +\nciYiYi, which is larger than it was before the weight adjustment. Note that all three of these cases can be combined in the following rule:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 48, 'page_label': '49'}, page_content='40 CHAPTER 4. NEURAL NETWORKS\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere di is the desired response (1 or 0) for Yi , and fi is the actual\nresponse (1 or 0) for Yi.]\nNote also that because the weight vector V now includes the wn+1 thresh-\nold component, the threshold of the TLU is also changed by these adjust-\nments. We identify two versions of this procedure:\n1) In the \ufb01xed-increment procedure, the learning rate parameter, ci, is the\nsame \ufb01xed, positive constant for all i. Depending on the value of this constant,\nthe weight adjustment may or may not correct the response to an erroneously\nclassi\ufb01ed feature vector. 2) In the fractional-correction procedure, the parameter ci is set to \u03bbYiV\nYiYi\n,\nwhere V is the weight vector before it is changed. Note that if \u03bb = 0, no\ncorrection takes place at all.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 48, 'page_label': '49'}, page_content='If \u03bb = 1, the correction is just su\ufb03cient to make\nYiV = 0. If \u03bb> 1, the error will be corrected. It can be proved that if there is some weight vector, V, that produces a\ncorrect output for all of the feature vectors in \u039e, then after a \ufb01nite number\nof feature vector presentations, the \ufb01xed-increment procedure will \ufb01nd such a\nweight vector and thus make no more weight changes. The same result holds\nfor the fractional-correction procedure if 1 <\u03bb \u22642. For additional background, proofs, and examples of error-correction proce-\ndures, see [Nilsson, 1990].See [Maass & Tur´ an, 1994] for a\nhyperplane-\ufb01nding procedure that\nmakes no more than O(n2 log n)\nmistakes. 4.1.4 Weight Space\nWe can give an intuitive idea about how these procedures work by considering\nwhat happens to the augmented weight vector in weight space as corrections\nare made. We use augmented vectors in our discussion here so that the threshold\nfunction compares the dot product, YiV, against a threshold of 0. A particular\nweight vector, V, then corresponds to a point in ( n+ 1)-dimensional weight\nspace. Now, for any pattern vector, Yi, consider the locus of all points in\nweight space corresponding to weight vectors yielding YiV = 0. This locus is\na hyperplane passing through the origin of the ( n+ 1)-dimensional space. Each\npattern vector will have such a hyperplane corresponding to it. Weight points\nin one of the half-spaces de\ufb01ned by this hyperplane will cause the corresponding\npattern to yield a dot product less than 0, and weight points in the other half-\nspace will cause the corresponding pattern to yield a dot product greater than\n0. We show a schematic representation of such a weight space in Fig. 4.5. There are four pattern hyperplanes, 1, 2, 3, 4 , corresponding to patterns Y1,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 49, 'page_label': '50'}, page_content='4.1. THRESHOLD LOGIC UNITS 41\nY2, Y3, Y4, respectively, and we indicate by an arrow the half-space for each\nin which weight vectors give dot products greater than 0. Suppose we wanted\nweight values that would give positive responses for patterns Y1, Y3, and Y4,\nand a negative response for pattern Y2. The weight point, V, indicated in the\n\ufb01gure is one such set of weight values. 23\n4\n1\nV\nFigure 4.5: Weight Space\nThe question of whether or not there exists a weight vector that gives desired\nresponses for a given set of patterns can be given a geometric interpretation. To\ndo so involves reversing the polarity of those hyperplanes corresponding to\npatterns for which a negative response is desired. If we do that for our example\nabove, we get the weight space diagram shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 49, 'page_label': '50'}, page_content='4.6. 23\n4\n1\nV\n0\n1\n1\n23\n2\n3\n4\nFigure 4.6: Solution Region in Weight Space'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 50, 'page_label': '51'}, page_content='42 CHAPTER 4. NEURAL NETWORKS\nIf a weight vector exists that correctly classi\ufb01es a set of patterns, then the\nhalf-spaces de\ufb01ned by the correct responses for these patterns will have a non-\nempty intersection, called the solution region. The solution region will be a\nhyper-wedge region whose vertex is at the origin of weight space and whose\ncross-section increases with increasing distance from the origin. This region\nis shown shaded in Fig. 4.6. (The boxed numbers show, for later purposes,\nthe number of errors made by weight vectors in each of the regions.) The\n\ufb01xed-increment error-correction procedure changes a weight vector by moving it\nnormal to any pattern hyperplane for which that weight vector gives an incorrect\nresponse. Suppose in our example that we present the patterns in the sequence\nY1, Y2, Y3, Y4, and start the process with a weight point V1, as shown in Fig. 4.7. Starting at V1, we see that it gives an incorrect response for pattern Y1, so\nwe move V1 to V2 in a direction normal to plane 1. (That is what adding Y1 to\nV1 does.) Y2 gives an incorrect response for pattern Y2, and so on. Ultimately,\nthe responses are only incorrect for planes bounding the solution region. Some\nof the subsequent corrections may overshoot the solution region, but eventually\nwe work our way out far enough in the solution region that corrections (for\na \ufb01xed increment size) take us within it. The proofs for convergence of the\n\ufb01xed-increment rule make this intuitive argument precise. 23\n4\n1\nV\nV1\nV2\nV3\nV4\nV5\nV6\nFigure 4.7: Moving Into the Solution Region\n4.1.5 The Widrow-Ho\ufb00 Procedure\nThe Widrow-Ho\ufb00 procedure (also called the LMS or the delta procedure) at-\ntempts to \ufb01nd weights that minimize a squared-error function between the pat-\ntern labels and the dot product computed by a TLU. For this purpose, the\npattern labels are assumed to be either +1 or \u22121 (instead of 1 or 0).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 50, 'page_label': '51'}, page_content='The'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 51, 'page_label': '52'}, page_content='4.1. THRESHOLD LOGIC UNITS 43\nsquared error for a pattern, Xi, with label di (for desired output) is:\n\u03b5i = (di \u2212\nn+1\u2211\nj=1\nxijwj)2\nwhere xij is the j-th component of Xi. The total squared error (over all patterns\nin a training set, \u039e, containing m patterns) is then:\n\u03b5=\nm\u2211\ni=1\n(di \u2212\nn+1\u2211\nj=1\nxijwj)2\nWe want to choose the weightswj to minimize this squared error. One way to\n\ufb01nd such a set of weights is to start with an arbitrary weight vector and move it\nalong the negative gradient of\u03b5as a function of the weights. Since \u03b5is quadratic\nin the wj, we know that it has a global minimum, and thus this steepest descent\nprocedure is guaranteed to \ufb01nd the minimum. Each component of the gradient\nis the partial derivative of \u03b5 with respect to one of the weights.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 51, 'page_label': '52'}, page_content='One problem\nwith taking the partial derivative of \u03b5is that \u03b5depends on all the input vectors\nin \u039e. Often, it is preferable to use an incremental procedure in which we try the\nTLU on just one element, Xi, of \u039e at a time, compute the gradient of the single-\npattern squared error, \u03b5i, make the appropriate adjustment to the weights, and\nthen try another member of \u039e. Of course, the results of the incremental version\ncan only approximate those of the batch one, but the approximation is usually\nquite e\ufb00ective. We will be describing the incremental version here. The j-th component of the gradient of the single-pattern error is:\n\u2202\u03b5i\n\u2202wj\n= \u22122(di \u2212\nn+1\u2211\nj=1\nxijwj)xij\nAn adjustment in the direction of the negative gradient would then change each\nweight as follows:\nwj \u2190\u2212wj + ci(di \u2212fi)xij\nwhere fi = \u2211n+1\nj=1 xijwj, and ci governs the size of the adjustment. The entire\nweight vector (in augmented, or V, notation) is thus adjusted according to the\nfollowing rule:\nV \u2190\u2212V + ci(di \u2212fi)Yi\nwhere, as before, Yi is the i-th augmented pattern vector. The Widrow-Ho\ufb00 procedure makes adjustments to the weight vector when-\never the dot product itself, YiV, does not equal the speci\ufb01ed desired target'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 52, 'page_label': '53'}, page_content='44 CHAPTER 4. NEURAL NETWORKS\nvalue, di (which is either 1 or \u22121). The learning-rate factor, ci, might de-\ncrease with time toward 0 to achieve asymptotic convergence. The Widrow-\nHo\ufb00 formula for changing the weight vector has the same form as the standard\n\ufb01xed-increment error-correction formula. The only di\ufb00erence is that fi is the\nthresholded response of the TLU in the error-correction case while it is the dot\nproduct itself for the Widrow-Ho\ufb00 procedure. Finding weight values that give the desired dot products corresponds to solv-\ning a set of linear equalities, and the Widrow-Ho\ufb00 procedure can be interpreted\nas a descent procedure that attempts to minimize the mean-squared-error be-\ntween the actual and desired values of the dot product. (For more on Widrow-\nHo\ufb00 and other related procedures, see [Duda & Hart, 1973, pp. 151\ufb00].)Examples of training curves for\nTLUs; performance on training\nset; performance on test set;\ncumulative number of corrections. 4.1.6 Training a TLU on Non-Linearly-Separable Training\nSets\nWhen the training set is not linearly separable (perhaps because of noise or\nperhaps inherently), it may still be desired to \ufb01nd a best separating hy-\nperplane. Typically, the error-correction procedures will not do well on non-\nlinearly-separable training sets because they will continue to attempt to correct\ninevitable errors, and the hyperplane will never settle into an acceptable place. Several methods have been proposed to deal with this case. First, we might\nuse the Widrow-Ho\ufb00 procedure, which (although it will not converge to zero\nerror on non-linearly separable problems) will give us a weight vector that min-\nimizes the mean-squared-error. A mean-squared-error criterion often gives un-\nsatisfactory results, however, because it prefers many small errors to a few large\nones. As an alternative, error correction with a continuous decrease toward zero\nof the value of the learning rate constant,c, will result in ever decreasing changes\nto the hyperplane. Duda [Duda, 1966] has suggested keeping track of the average\nvalue of the weight vector during error correction and using this average to give a\nseparating hyperplane that performs reasonably well on non-linearly-separable\nproblems. Gallant [Gallant, 1986] proposed what he called the pocket algo-\nrithm. As described in [Hertz, Krogh, & Palmer, 1991, p. 160]:\n.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 52, 'page_label': '53'}, page_content='.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 52, 'page_label': '53'}, page_content='. the pocket algorithm . . . consists simply in storing (or putting\nin your pocket) the set of weights which has had the longest un-\nmodi\ufb01ed run of successes so far. The algorithm is stopped after some\nchosen time t . . . After stopping, the weights in the pocket are used as a set that should give a\nsmall number of errors on the training set. Error-correction proceeds as usual\nwith the ordinary set of weights.Also see methods proposed by\n[John, 1995] and by\n[Marchand & Golea, 1993]. The\nlatter is claimed to outperform the\npocket algorithm. 4.2 Linear Machines\nThe natural generalization of a (two-category) TLU to an R-category classi\ufb01er\nis the structure, shown in Fig. 4.8, called a linear machine. Here, to use more'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 53, 'page_label': '54'}, page_content='4.2. LINEAR MACHINES 45\nfamiliar notation, the Ws and X are meant to be augmented vectors (with an\n(n+1)-st component). Such a structure is also sometimes called a competitive\nnet or a winner-take-all net. The output of the linear machine is one of\nthe numbers, {1,...,R }, corresponding to which dot product is largest. Note\nthat when R = 2, the linear machine reduces to a TLU with weight vector\nW = (W1 \u2212W2). X\nW1\nWR\n.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 53, 'page_label': '54'}, page_content='. . Y\nY\nARGMAX\nW1.X\nWR.X\nFigure 4.8: A Linear Machine\nThe diagram in Fig. 4.9 shows the character of the regions in a 2-dimensional\nspace created by a linear machine for R = 5. In n dimensions, every pair of\nregions is either separated by a section of a hyperplane or is non-adjacent. R 1\nR 3\nR 4\nR 5\nX.W4  * X.Wi for i & 4\nR 2\nIn this region:\nFigure 4.9: Regions For a Linear Machine\nTo train a linear machine, there is a straightforward generalization of the\n2-category error-correction rule. Assemble the patterns in the training set into\na sequence as before. a. If the machine classi\ufb01es a pattern correctly, no change is made to any of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 54, 'page_label': '55'}, page_content='46 CHAPTER 4. NEURAL NETWORKS\nthe weight vectors. b. If the machine mistakenly classi\ufb01es a category u pattern, Xi, in category\nv (u\u0338= v), then:\nWu \u2190\u2212Wu + ciXi\nand\nWv \u2190\u2212Wv \u2212ciXi\nand all other weight vectors are not changed. This correction increases the value of the u-th dot product and decreases the\nvalue of the v-th dot product. Just as in the 2-category \ufb01xed increment proce-\ndure, this procedure is guaranteed to terminate, for constant ci, if there exists\nweight vectors that make correct separations of the training set. Note that when\nR= 2, this procedure reduces to the ordinary TLU error-correction procedure. A proof that this procedure terminates is given in [Nilsson, 1990, pp. 88-90]\nand in [Duda & Hart, 1973, pp.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 54, 'page_label': '55'}, page_content='174-177]. 4.3 Networks of TLUs\n4.3.1 Motivation and Examples\nLayered Networks\nTo classify correctly all of the patterns in non-linearly-separable training sets re-\nquires separating surfaces more complex than hyperplanes. One way to achieve\nmore complex surfaces is with networks of TLUs. Consider, for example, the 2-\ndimensional, even parity function, f = x1x2 + x1 x2. No single line through the\n2-dimensional square can separate the vertices (1,1) and (0,0) from the vertices\n(1,0) and (0,1)the function is not linearly separable and thus cannot be im-\nplemented by a single TLU. But, the network of three TLUs shown in Fig. 4.10\ndoes implement this function. In the \ufb01gure, we show the weight values along\ninput lines to each TLU and the threshold value inside the circle representing\nthe TLU. The function implemented by a network of TLUs depends on its topology\nas well as on the weights of the individual TLUs. Feedforward networks have\nno cycles; in a feedforward network no TLUs input depends (through zero\nor more intermediate TLUs) on that TLUs output. (Networks that are not\nfeedforward are calledrecurrentnetworks). If the TLUs of a feedforward network\nare arranged in layers, with the elements of layer j receiving inputs only from\nTLUs in layer j \u22121, then we say that the network is a layered, feedforward'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 55, 'page_label': '56'}, page_content='4.3. NETWORKS OF TLUS 47\nf\nx1\nx2\n1.5\n-0.5\n0.5\n1\n1-1\n-1 1\n1\nFigure 4.10: A Network for the Even Parity Function\nnetwork. The network shown in Fig. 4.10 is a layered, feedforward network\nhaving two layers (of weights). (Some people count the layers of TLUs and\ninclude the inputs as a layer also; they would call this network a three-layer\nnetwork.) In general, a feedforward, layered network has the structure shown\nin Fig. 4.11. All of the TLUs except the output units are called hidden units\n(they are hidden from the output). X\nhidden units\noutput units\nFigure 4.11: A Layered, Feedforward Network\nImplementing DNF Functions by Two-Layer Networks\nWe have already de\ufb01nedk-term DNF functionsthey are DNF functions having\nk terms. A k-term DNF function can be implemented by a two-layer network\nwith k units in the hidden layerto implement the k termsand one output\nunit to implement the disjunction of these terms. Since any Boolean function\nhas a DNF form, any Boolean function can be implemented by some two-layer\nnetwork of TLUs. As an example, consider the function f = x1x2 + x2x3 +\nx1x3.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 55, 'page_label': '56'}, page_content='The form of the network that implements this function is shown in Fig. 4.12. (We leave it to the reader to calculate appropriate values of weights and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 56, 'page_label': '57'}, page_content='48 CHAPTER 4. NEURAL NETWORKS\nthresholds.) The 3-cube representation of the function is shown in Fig. 4.13.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 56, 'page_label': '57'}, page_content='The network of Fig. 4.12 can be designed so that each hidden unit implements\none of the planar boundaries shown in Fig. 4.13. x\nconjuncts\ndisjunct\nA Feedforward, 2-layer Network\nTLUs\ndisjunction\nof terms\nconjunctions\nof literals\n(terms)\nFigure 4.12: A Two-Layer Network\nx2\nx1\nx3\nf = x1x2 + x2x3 + x1x3\nFigure 4.13: Three Planes Implemented by the Hidden Units\nTo train a two-layer network that implements a k-term DNF function, we\n\ufb01rst note that the output unit implements a disjunction, so the weights in the\n\ufb01nal layer are \ufb01xed. The weights in the \ufb01rst layer (except for the threshold\nweights) can all have values of 1, \u22121, or 0. Later, we will present a training\nprocedure for this \ufb01rst layer of weights.Discuss half-space intersections,\nhalf-space unions, NP-hardness of\noptimal versions,\nsingle-side-error-hypeplane\nmethods, relation to AQ\nmethods.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 57, 'page_label': '58'}, page_content='4.3. NETWORKS OF TLUS 49\nImportant Comment About Layered Networks\nAdding additional layers cannot compensate for an inadequate \ufb01rst layer of\nTLUs. The \ufb01rst layer of TLUs partitions the feature space so that no two dif-\nferently labeled vectors are in the same region (that is, so that no two such\nvectors yield the same set of outputs of the \ufb01rst-layer units). If the \ufb01rst layer\ndoes not partition the feature space in this way, then regardless of what subse-\nquent layers do, the \ufb01nal outputs will not be consistent with the labeled training\nset. Add diagrams showing the\nnon-linear transformation\nperformed by a layered network. 4.3.2 Madalines\nTwo-Category Networks\nAn interesting example of a layered, feedforward network is the two-layer one\nwhich has an odd number of hidden units, and a vote-taking TLU as the\noutput unit. Such a network was called a Madaline (for m any adalines by\nWidrow.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 57, 'page_label': '58'}, page_content='Typically, the response of the vote taking unit is de\ufb01ned to be the\nresponse of the majority of the hidden units, although other output logics are\npossible. Ridgway [Ridgway, 1962] proposed the following error-correction rule\nfor adjusting the weights of the hidden units of a Madaline:\n If the Madaline correctly classi\ufb01es a pattern, Xi, no corrections are made\nto any of the hidden units weight vectors,\n If the Madaline incorrectly classi\ufb01es a pattern, Xi, then determine the\nminimum number of hidden units whose responses need to be changed\n(from 0 to 1 or from 1 to 0depending on the type of error) in order that\nthe Madaline would correctly classify Xi. Suppose that minimum number\nis ki. Of those hidden units voting incorrectly, change the weight vectors\nof those ki of them whose dot products are closest to 0 by using the error\ncorrection rule:\nW \u2190\u2212W + ci(di \u2212fi)Xi\nwhere di is the desired response of the hidden unit (0 or 1) and fi is the\nactual response (0 or 1). (We assume augmented vectors here even though\nwe are using X, W notation.)\nThat is, we perform error-correction on just enough hidden units to correct\nthe vote to a majority voting correctly, and we change those that are easiest to\nchange. There are example problems in which even though a set of weight values\nexists for a given Madaline structure such that it could classify all members of\na training set correctly, this procedure will fail to \ufb01nd them. Nevertheless, the\nprocedure works e\ufb00ectively in most experiments with it. We leave it to the reader to think about how this training procedure could\nbe modi\ufb01ed if the output TLU implemented an or function (or an and function).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 58, 'page_label': '59'}, page_content='50 CHAPTER 4. NEURAL NETWORKS\nR-Category Madalines and Error-Correcting Output Codes\nIf there are k hidden units ( k > 1) in a two-layer network, their responses\ncorrespond to vertices of ak-dimensional hypercube. The ordinary two-category\nMadaline identi\ufb01es two special points in this space, namely the vertex consisting\nof k 1s and the vertex consisting of k 0s. The Madalines response is 1 if the\npoint in hidden-unit-space is closer to the all 1s vertex than it is to the all\n0s vertex. We could design an R-category Madaline by identifying R vertices\nin hidden-unit space and then classifying a pattern according to which of these\nvertices the hidden-unit response is closest to. A machine using that idea was\nimplemented in the early 1960s at SRI [Brain, et al., 1962]. It used the fact\nthat the 2p so-called maximal-length shift-register sequences[Peterson, 1961, pp. 147\ufb00] in a (2p\u22121)-dimensional Boolean space are mutually equidistant (for any\ninteger p). For similar, more recent work see [Dietterich & Bakiri, 1991]. 4.3.3 Piecewise Linear Machines\nA two-category training set is linearly separable if there exists a threshold func-\ntion that correctly classi\ufb01es all members of the training set. Similarly, we can\nsay that an R-category training set is linearly separable if there exists a linear\nmachine that correctly classi\ufb01es all members of the training set. When an R-\ncategory problem is not linearly separable, we need a more powerful classi\ufb01er. A candidate is a structure called a piecewise linear (PWL) machine illustrated\nin Fig. 4.14.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 58, 'page_label': '59'}, page_content='X\nW1\nW1\n. . . Y\nY\nMAX\n. . . Y\nY\nMAX\n. .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 58, 'page_label': '59'}, page_content='. WR\nWR\nARG\nMAX\n1\nR\n1\nN1\n1\nNR\nFigure 4.14: A Piecewise Linear Machine'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 59, 'page_label': '60'}, page_content='4.3. NETWORKS OF TLUS 51\nThe PWL machine groups its weighted summing units into R banks corre-\nsponding to the R categories. An input vector X is assigned to that category\ncorresponding to the bank with the largest weighted sum. We can use an error-\ncorrection training algorithm similar to that used for a linear machine. If a\npattern is classi\ufb01ed incorrectly, we subtract (a constant times) the pattern vec-\ntor from the weight vector producing the largest dot product (it was incorrectly\nthe largest) and add (a constant times) the pattern vector to that weight vector\nin the correct bank of weight vectors whose dot product is locally largest in\nthat bank. (Again, we use augmented vectors here.) Unfortunately, there are\nexample training sets that are separable by a given PWL machine structure\nbut for which this error-correction training method fails to \ufb01nd a solution. The\nmethod does appear to work well in some situations [Duda & Fossum, 1966], al-\nthough [Nilsson, 1965, page 89] observed that it is probably not a very e\ufb00ective\nmethod for training PWL machines having more than three [weight vectors] in\neach bank.\n4.3.4 Cascade Networks\nAnother interesting class of feedforward networks is that in which all of the TLUs\nare ordered and each TLU receives inputs from all of the pattern components\nand from all TLUs lower in the ordering. Such a network is called a cascade\nnetwork.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 59, 'page_label': '60'}, page_content='An example is shown in Fig. 4.15 in which the TLUs are labeled by\nthe linearly separable functions (of their inputs) that they implement. Each\nTLU in the network implements a set of 2 k parallel hyperplanes, where k is\nthe number of TLUs from which it receives inputs. (Each of the k preceding\nTLUs can have an output of 1 or 0; thats 2 k di\ufb00erent combinationsresulting\nin 2k di\ufb00erent positions for the parallel hyperplanes.) We show a 3-dimensional\nsketch for a network of two TLUs in Fig. 4.16. The reader might consider how\nthe n-dimensional parity function might be implemented by a cascade network\nhaving log2 n TLUs. x\nL1\nL2\noutput\nL3\nFigure 4.15: A Cascade Network'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 60, 'page_label': '61'}, page_content='52 CHAPTER 4. NEURAL NETWORKS\nL1\nL2\nL2\nFigure 4.16: Planes Implemented by a Cascade Network with Two TLUs\nCascade networks might be trained by \ufb01rst training L1 to do as good a job\nas possible at separating all the training patterns (perhaps by using the pocket\nalgorithm, for example), then training L2 (including the weight from L1 to L2)\nalso to do as good a job as possible at separating all the training patterns,\nand so on until the resulting network classi\ufb01es the patterns in the training set\nsatisfactorily.Also mention the\ncascade-correlation method of\n[Fahlman & Lebiere, 1990]. 4.4 Training Feedforward Networks by Back-\npropagation\n4.4.1 Notation\nThe general problem of training a network of TLUs is di\ufb03cult. Consider, for\nexample, the layered, feedforward network of Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 60, 'page_label': '61'}, page_content='4.11. If such a network makes\nan error on a pattern, there are usually several di\ufb00erent ways in which the error\ncan be corrected. It is di\ufb03cult to assign blame for the error to any particular\nTLU in the network. Intuitively, one looks for weight-adjusting procedures that\nmove the network in the correct direction (relative to the error) by making\nminimal changes. In this spirit, the Widrow-Ho\ufb00 method of gradient descent\nhas been generalized to deal with multilayer networks. In explaining this generalization, we use Fig. 4.17 to introduce some nota-\ntion. This network has only one output unit, but, of course, it is possible to have\nseveral TLUs in the output layereach implementing a di\ufb00erent function. Each\nof the layers of TLUs will have outputs that we take to be the components of\nvectors, just as the input features are components of an input vector. The j-th\nlayer of TLUs (1 \u2264j <k) will have as their outputs the vector X(j). The input\nfeature vector is denoted by X(0), and the \ufb01nal output (of the k-th layer TLU)\nis f. Each TLU in each layer has a weight vector (connecting it to its inputs)\nand a threshold; the i-th TLU in the j-th layer has a weight vector denoted by\nW(j)\ni . (We will assume that the threshold weight is the last component of\nthe associated weight vector; we might have used V notation instead to include'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 61, 'page_label': '62'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION53\nthis threshold component, but we have chosen here to use the familiar X,W\nnotation, assuming that these vectors are augmented as appropriate.) We\ndenote the weighted sum input to the i-th threshold unit in the j-th layer by\ns(j)\ni . (That is, s(j)\ni = X(j\u22121)W(j)\ni .) The number of TLUs in the j-th layer is\ngiven by mj. The vector W(j)\ni has components w(j)\nl,i for l= 1,...,m (j\u22121) + 1. X(0)\n. . . . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 61, 'page_label': '62'}, page_content='. Wi(1)\nW(k)\nX(1)\nm1 TLUs\n. . . Wi(j)\n. . . X(j)\n. .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 61, 'page_label': '62'}, page_content='. Wi(k-1)\nX(k-1)\nmj TLUs m(k-1) TLUs\nwli(j)\nwl(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . . f\nsi(1) si(j) si(k-1)\ns(k)\nFigure 4.17: A k-layer Network\n4.4.2 The Backpropagation Method\nA gradient descent method, similar to that used in the Widrow Ho\ufb00 method,\nhas been proposed by various authors for training a multi-layer, feedforward\nnetwork. As before, we de\ufb01ne an error function on the \ufb01nal output of the\nnetwork and we adjust each weight in the network so as to minimize the error. If we have a desired response, di, for the i-th input vector, Xi, in the training\nset, \u039e, we can compute the squared error over the entire training set to be:\n\u03b5=\n\u2211\nXi \u03f5 \u039e\n(di \u2212fi)2\nwhere fi is the actual response of the network for input Xi. To do gradient\ndescent on this squared error, we adjust each weight in the network by an\namount proportional to the negative of the partial derivative of \u03b5 with respect\nto that weight. Again, we use a single-pattern error function so that we can\nuse an incremental weight adjustment procedure. The squared error for a single\ninput vector, X, evoking an output of f when the desired output is d is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 62, 'page_label': '63'}, page_content='54 CHAPTER 4. NEURAL NETWORKS\n\u03b5= (d\u2212f)2\nIt is convenient to take the partial derivatives of\u03b5with respect to the various\nweights in groups corresponding to the weight vectors. We de\ufb01ne a partial\nderivative of a quantity \u03c6, say, with respect to a weight vector, W(j)\ni , thus:\n\u2202\u03c6\n\u2202W(j)\ni\ndef\n=\n[\n\u2202\u03c6\n\u2202w(j)\n1i\n,..., \u2202\u03c6\n\u2202w(j)\nli\n,..., \u2202\u03c6\n\u2202w(j)\nmj\u22121+1,i\n]\nwhere w(j)\nli is the l-th component of W(j)\ni . This vector partial derivative of \u03c6is\ncalled the gradient of \u03c6 with respect to W and is sometimes denoted by \u2207W\u03c6. Since \u03b5s dependence on W(j)\ni is entirely through s(j)\ni , we can use the chain\nrule to write:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\n\u2202s(j)\ni\n\u2202W(j)\ni\nBecause s(j)\ni = X(j\u22121)W(j)\ni ,\n\u2202s(j)\ni\n\u2202W(j)\ni\n= X(j\u22121). Substituting yields:\n\u2202\u03b5\n\u2202W(j)\ni\n= \u2202\u03b5\n\u2202s(j)\ni\nX(j\u22121)\nNote that \u2202\u03b5\n\u2202s(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\n.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 62, 'page_label': '63'}, page_content='Thus,\n\u2202\u03b5\n\u2202W(j)\ni\n= \u22122(d\u2212f) \u2202f\n\u2202s(j)\ni\nX(j\u22121)\nThe quantity (d\u2212f) \u2202f\n\u2202s(j)\ni\nplays an important role in our calculations; we shall\ndenote it by \u03b4(j)\ni . Each of the \u03b4(j)\ni s tells us how sensitive the squared error of\nthe network output is to changes in the input to each threshold function. Since\nwe will be changing weight vectors in directions along their negative gradient,\nour fundamental rule for weight changes throughout the network will be:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nwhere c(j)\ni is the learning rate constant for this weight vector. (Usually, the\nlearning rate constants for all weight vectors in the network are the same.) We\nsee that this rule is quite similar to that used in the error correction procedure'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 63, 'page_label': '64'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION55\nfor a single TLU. A weight vector is changed by the addition of a constant times\nits vector of (unweighted) inputs.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 63, 'page_label': '64'}, page_content='Now, we must turn our attention to the calculation of the \u03b4(j)\ni s. Using the\nde\ufb01nition, we have:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nWe have a problem, however, in attempting to carry out the partial deriva-\ntives of f with respect to the ss. The network output, f, is not continuously\ndi\ufb00erentiable with respect to the ss because of the presence of the threshold\nfunctions. Most small changes in these sums do not change f at all, and when\nf does change, it changes abruptly from 1 to 0 or vice versa. A way around this di\ufb03culty was proposed by Werbos [Werbos, 1974] and\n(perhaps independently) pursued by several other researchers, for example\n[Rumelhart, Hinton, & Williams, 1986]. The trick involves replacing all the\nthreshold functions by di\ufb00erentiable functions called sigmoids.1 The output\nof a sigmoid function, superimposed on that of a threshold function, is shown\nin Fig. 4.18. Usually, the sigmoid function used is f(s) = 1\n1+e\u2212s , where s is\nthe input and f is the output. sigmoid\nthreshold function\nf (s)\ns\nf (s) = 1/[1 + e<s]\nFigure 4.18: A Sigmoid Function\n1[Russell & Norvig 1995, page 595] attributes the use of this idea to [Bryson & Ho 1969].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 64, 'page_label': '65'}, page_content='56 CHAPTER 4. NEURAL NETWORKS\nWe show the network containing sigmoid units in place of TLUs in Fig. 4.19. The output of the i-th sigmoid unit in the j-th layer is denoted by f(j)\ni . (That\nis, f(j)\ni = 1\n1+e\u2212s(j)\ni\n.)\nX(0)\n. .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 64, 'page_label': '65'}, page_content='. . . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 64, 'page_label': '65'}, page_content='. Wi(1)\nsi(1)\nW(k)\nX(1)\nfi(1)\nm1 sigmoids\n. . . Wi(j) fi(j)\nsi(j)\n. . . X(j)\n. . . Wi(k-1)\nfi(k-1)\nsi(k-1)\nf(k)\ns(k)\nX(k-1)\nmj sigmoids m(k-1) sigmoids\nwli(j)\nwl(k)\nbi(j)bi(1)\nbi(k-1)\nb(k)\nFirst Layer j-th Layer ( k-1)-th Layer k-th Layer\n. . . Figure 4.19: A Network with Sigmoid Units\n4.4.3 Computing Weight Changes in the Final Layer\nWe \ufb01rst calculate\u03b4(k) in order to compute the weight change for the \ufb01nal sigmoid\nunit:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 65, 'page_label': '66'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION57\n\u03b4(k) = (d\u2212f(k))\u2202f(k)\n\u2202s(k)\nGiven the sigmoid function that we are using, namely f(s) = 1\n1+e\u2212s, we have\nthat \u2202f\n\u2202s = f(1 \u2212f). Substituting gives us:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nRewriting our general rule for weight vector changes, the weight vector in\nthe \ufb01nal layer is changed according to the rule:\nW(k) \u2190W(k) + c(k)\u03b4(k)X(k\u22121)\nwhere \u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nIt is interesting to compare backpropagation to the error-correction rule and\nto the Widrow-Ho\ufb00 rule. The backpropagation weight adjustment for the single\nelement in the \ufb01nal layer can be written as:\nW \u2190\u2212W + c(d\u2212f)f(1 \u2212f)X\nWritten in the same format, the error-correction rule is:\nW \u2190\u2212W + c(d\u2212f)X\nand the Widrow-Ho\ufb00 rule is:\nW \u2190\u2212W + c(d\u2212f)X\nThe only di\ufb00erence (except for the fact that f is not thresholded in Widrow-\nHo\ufb00) is the f(1 \u2212f) term due to the presence of the sigmoid function. With\nthe sigmoid function, f(1 \u2212f) can vary in value from 0 to 1.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 65, 'page_label': '66'}, page_content='When f is 0,\nf(1 \u2212f) is also 0; when f is 1, f(1 \u2212f) is 0; f(1 \u2212f) obtains its maximum\nvalue of 1/4 when f is 1/2 (that is, when the input to the sigmoid is 0). The\nsigmoid function can be thought of as implementing a fuzzy hyperplane. For\na pattern far away from this fuzzy hyperplane, f(1 \u2212f) has value close to 0,\nand the backpropagation rule makes little or no change to the weight values\nregardless of the desired output. (Small changes in the weights will have little\ne\ufb00ect on the output for inputs far from the hyperplane.) Weight changes are\nonly made within the region of fuzz surrounding the hyperplane, and these\nchanges are in the direction of correcting the error, just as in the error-correction\nand Widrow-Ho\ufb00 rules.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 66, 'page_label': '67'}, page_content='58 CHAPTER 4. NEURAL NETWORKS\n4.4.4 Computing Changes to the Weights in Intermediate\nLayers\nUsing our expression for the \u03b4s, we can similarly compute how to change each\nof the weight vectors in the network. Recall:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\nAgain we use a chain rule.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 66, 'page_label': '67'}, page_content='The \ufb01nal output, f, depends on s(j)\ni through\neach of the summed inputs to the sigmoids in the ( j+ 1)-th layer. So:\n\u03b4(j)\ni = (d\u2212f) \u2202f\n\u2202s(j)\ni\n= (d\u2212f)\n[\n\u2202f\n\u2202s(j+1)\n1\n\u2202s(j+1)\n1\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n+ ··· + \u2202f\n\u2202s(j+1)\nmj+1\n\u2202s(j+1)\nmj+1\n\u2202s(j)\ni\n]\n=\nmj+1\u2211\nl=1\n(d\u2212f) \u2202f\n\u2202s(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl\n\u2202s(j+1)\nl\n\u2202s(j)\ni\nIt remains to compute the\n\u2202s(j+1)\nl\n\u2202s(j)\ni\ns. To do that we \ufb01rst write:\ns(j+1)\nl = X(j)W(j+1)\nl\n=\nmj+1\u2211\n\u03bd=1\nf(j)\n\u03bd w(j+1)\n\u03bdl\nAnd then, since the weights do not depend on the ss:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n=\n\u2202\n[\u2211mj+1\n\u03bd=1 f(j)\n\u03bd w(j+1)\n\u03bdl\n]\n\u2202s(j)\ni\n=\nmj+1\u2211\n\u03bd=1\nw(j+1)\n\u03bdl\n\u2202f(j)\n\u03bd\n\u2202s(j)\ni\nNow, we note that \u2202f(j)\n\u03bd\n\u2202s(j)\ni\n= 0 unless \u03bd = i, in which case \u2202f(j)\n\u03bd\n\u2202s(j)\n\u03bd\n= f(j)\n\u03bd (1 \u2212f(j)\n\u03bd ). Therefore:\n\u2202s(j+1)\nl\n\u2202s(j)\ni\n= w(j+1)\nil f(j)\ni (1 \u2212f(j)\ni )'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 67, 'page_label': '68'}, page_content='4.4. TRAINING FEEDFORWARD NETWORKS BY BACKPROPAGATION59\nWe use this result in our expression for \u03b4(j)\ni to give:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nThe above equation is recursive in the \u03b4s. (It is interesting to note that\nthis expression is independent of the error function; the error function explicitly\na\ufb00ects only the computation of \u03b4(k).) Having computed the \u03b4(j+1)\ni s for layer\nj + 1, we can use this equation to compute the \u03b4(j)\ni s. The base case is \u03b4(k),\nwhich we have already computed:\n\u03b4(k) = (d\u2212f(k))f(k)(1 \u2212f(k))\nWe use this expression for the\u03b4s in our generic weight changing rule, namely:\nW(j)\ni \u2190W(j)\ni + c(j)\ni \u03b4(j)\ni X(j\u22121)\nAlthough this rule appears complex, it has an intuitively reasonable explanation. The quantity \u03b4(k) = (d\u2212f)f(1 \u2212f) controls the overall amount and sign of all\nweight adjustments in the network. (Adjustments diminish as the \ufb01nal output,\nf, approaches either 0 or 1, because they have vanishing e\ufb00ect on f then.) As\nthe recursion equation for the \u03b4s shows, the adjustments for the weights going\nin to a sigmoid unit in the j-th layer are proportional to the e\ufb00ect that such\nadjustments have on that sigmoid units output (its f(j)(1 \u2212f(j)) factor). They\nare also proportional to a kind of average e\ufb00ect that any change in the output\nof that sigmoid unit will have on the \ufb01nal output. This average e\ufb00ect depends\non the weights going out of the sigmoid unit in the j-th layer (small weights\nproduce little downstream e\ufb00ect) and the e\ufb00ects that changes in the outputs of\n(j+ 1)-th layer sigmoid units will have on the \ufb01nal output (as measured by the\n\u03b4(j+1)s). These calculations can be simply implemented by backpropagating\nthe \u03b4s through the weights in reverse direction (thus, the name backprop for\nthis algorithm).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 67, 'page_label': '68'}, page_content='4.4.5 Variations on Backprop\n[To be written: problem of local minima, simulated annealing, momemtum\n(Plaut, et al., 1986, see [Hertz, Krogh, & Palmer, 1991]), quickprop, regulariza-\ntion methods]\nSimulated Annealing\nTo apply simulated annealing, the value of the learning rate constant is gradually\ndecreased with time. If we fall early into an error-function valley that is not\nvery deep (a local minimum), it typically will neither be very broad, and soon'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 68, 'page_label': '69'}, page_content='60 CHAPTER 4. NEURAL NETWORKS\na subsequent large correction will jostle us out of it. It is less likely that we will\nmove out of deep valleys, and at the end of the process (with very small values\nof the learning rate constant), we descend to its deepest point. The process\ngets its name by analogy with annealing in metallurgy, in which a materials\ntemperature is gradually decreased allowing its crystalline structure to reach a\nminimal energy state. 4.4.6 An Application: Steering a Van\nA neural network system called ALVINN (Autonomous Land Vehicle in a Neural\nNetwork) has been trained to steer a Chevy van successfully on ordinary roads\nand highways at speeds of 55 mph [Pomerleau, 1991, Pomerleau, 1993]. The\ninput to the network is derived from a low-resolution (30 x 32) television image. The TV camera is mounted on the van and looks at the road straight ahead. This image is sampled and produces a stream of 960-dimensional input vectors\nto the neural network. The network is shown in Fig. 4.20. 960 inputs\n30 x 32 retina\n. .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 68, 'page_label': '69'}, page_content='. 5 hidden\nunits connected\nto all 960 inputs\n30 output units\nconnected to all\nhidden units\n. . . sharp left\nsharp right\nstraight ahead\ncentroid\nof outputs\nsteers\nvehicle\nFigure 4.20: The ALVINN Network\nThe network has \ufb01ve hidden units in its \ufb01rst layer and 30 output units in the\nsecond layer; all are sigmoid units. The output units are arranged in a linear\norder and control the vans steering angle. If a unit near the top of the array\nof output units has a higher output than most of the other units, the van is\nsteered to the left; if a unit near the bottom of the array has a high output, the\nvan is steered to the right. The centroid of the responses of all of the output'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 69, 'page_label': '70'}, page_content='4.5. SYNERGIES BETWEEN NEURAL NETWORK AND KNOWLEDGE-BASED METHODS61\nunits is computed, and the vans steering angle is set at a corresponding value\nbetween hard left and hard right. The system is trained by a modi\ufb01ed on-line training regime. A driver drives\nthe van, and his actual steering angles are taken as the correct labels for the\ncorresponding inputs. The network is trained incrementally by backprop to\nproduce the driver-speci\ufb01ed steering angles in response to each visual pattern\nas it occurs in real time while driving. This simple procedure has been augmented to avoid two potential problems. First, since the driver is usually driving well, the network would never get any\nexperience with far-from-center vehicle positions and/or incorrect vehicle orien-\ntations. Also, on long, straight stretches of road, the network would be trained\nfor a long time only to produce straight-ahead steering angles; this training\nwould swamp out earlier training to follow a curved road. We wouldnt want\nto try to avoid these problems by instructing the driver to drive erratically\noccasionally, because the system would learn to mimic this erratic behavior. Instead, each original image is shifted and rotated in software to create 14\nadditional images in which the vehicle appears to be situated di\ufb00erently relative\nto the road. Using a model that tells the system what steering angle ought to\nbe used for each of these shifted images, given the driver-speci\ufb01ed steering angle\nfor the original image, the system constructs an additional 14 labeled training\npatterns to add to those encountered during ordinary driver training. 4.5 Synergies Between Neural Network and\nKnowledge-Based Methods\nTo be written; discuss\nrule-generating procedures (such as\n[Towell & Shavlik, 1992]) and how\nexpert-provided rules can aid\nneural net training and vice-versa\n[Towell, Shavlik, & Noordweier, 1990].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 69, 'page_label': '70'}, page_content='4.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 70, 'page_label': '71'}, page_content='62 CHAPTER 4. NEURAL NETWORKS'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 71, 'page_label': '72'}, page_content='Chapter 5\nStatistical Learning\n5.1 Using Statistical Decision Theory\n5.1.1 Background and General Method\nSuppose the pattern vector, X, is a random variable whose probability distri-\nbution for category 1 is di\ufb00erent than it is for category 2. (The treatment given\nhere can easily be generalized to R-category problems.) Speci\ufb01cally, suppose we\nhave the two probability distributions (perhaps probability density functions),\np(X |1) and p(X |2). Given a pattern, X, we want to use statistical tech-\nniques to determine its categorythat is, to determine from which distribution\nit was drawn. These techniques are based on the idea of minimizing the ex-\npected value of a quantity similar to the error function we used in deriving the\nweight-changing rules for backprop. In developing a decision method, it is necessary to know the relative serious-\nness of the two kinds of mistakes that might be made. (We might decide that a\npattern really in category 1 is in category 2, and vice versa.) We describe this\ninformation by a loss function, \u03bb(i|j), for i,j = 1,2. \u03bb(i|j) represents the loss\nincurred when we decide a pattern is in category i when really it is in category\nj. We assume here that \u03bb(1 |1) and \u03bb(2 |2) are both 0. For any given pattern,\nX, we want to decide its category in such a way that minimizes the expected\nvalue of this loss. Given a pattern, X, if we decide category i, the expected value of the loss\nwill be:\nLX(i) = \u03bb(i|1)p(1 |X) + \u03bb(i|2)p(2 |X)\nwhere p(j |X) is the probability that given a pattern X, its category is j. Our\ndecision rule will be to decide that X belongs to category 1 if LX(1) \u2264LX(2),\nand to decide on category 2 otherwise.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 71, 'page_label': '72'}, page_content='63'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 72, 'page_label': '73'}, page_content='64 CHAPTER 5. STATISTICAL LEARNING\nWe can use Bayes Rule to get expressions for p(j |X) in terms of p(X |j),\nwhich we assume to be known (or estimatible):\np(j |X) = p(X |j)p(j)\np(X)\nwhere p(j) is the (a priori) probability of category j (one category may be much\nmore probable than the other); and p(X) is the (a priori) probability of pattern\nX being the pattern we are asked to classify. Performing the substitutions given\nby Bayes Rule, our decision rule becomes:\nDecide category 1 i\ufb00:\n\u03bb(1 |1)p(X |1)p(1)\np(X) + \u03bb(1 |2)p(X |2)p(2)\np(X)\n\u2264\u03bb(2 |1)p(X |1)p(1)\np(X) + \u03bb(2 |2)p(X |2)p(2)\np(X)\nUsing the fact that \u03bb(i |i) = 0, and noticing that p(X) is common to both\nexpressions, we obtain,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nIf \u03bb(1 |2) = \u03bb(2 |1) and if p(1) = p(2), then the decision becomes particu-\nlarly simple:\nDecide category 1 i\ufb00:\np(X |2) \u2264p(X |1)\nSince p(X |j) is called the likelihood of j with respect to X, this simple decision\nrule implements what is called a maximum-likelihood decision. More generally,\nif we de\ufb01ne k(i|j) as \u03bb(i|j)p(j), then our decision rule is simply,\nDecide category1 i\ufb00:\nk(1 |2)p(X |2) \u2264k(2 |1)p(X |1)\nIn any case, we need to compare the (perhaps weighted) quantities p(X |i) for\ni= 1 and 2. The exact decision rule depends on the the probability distributions\nassumed.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 72, 'page_label': '73'}, page_content='We will treat two interesting distributions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 73, 'page_label': '74'}, page_content='5.1. USING STATISTICAL DECISION THEORY 65\n5.1.2 Gaussian (or Normal) Distributions\nThe multivariate (n-dimensional) Gaussian distribution is given by the proba-\nbility density function:\np(X) = 1\n(2\u03c0)n/2|\u03a3|1/2 e\n\u2212(X\u2212M)t\u03a3\n\u22121\n(X\u2212M)\n2\nwhere nis the dimension of the column vector X, the column vector M is called\nthe mean vector, (X \u2212M)t is the transpose of the vector ( X \u2212M), \u03a3 is the\ncovariance matrix of the distribution (an n×n symmetric, positive de\ufb01nite\nmatrix), \u03a3\u22121 is the inverse of the covariance matrix, and |\u03a3|is the determinant\nof the covariance matrix. The mean vector, M, with components ( m1,...,m n), is the expected value\nof X (using this distribution); that is, M = E[X]. The components of the\ncovariance matrix are given by:\n\u03c32\nij = E[(xi \u2212mi)(xj \u2212mj)]\nIn particular, \u03c32\nii is called the variance of xi. Although the formula appears complex, an intuitive idea for Gaussian dis-\ntributions can be given when n = 2. We show a two-dimensional Gaussian\ndistribution in Fig. 5.1. A three-dimensional plot of the distribution is shown\nat the top of the \ufb01gure, and contours of equal probability are shown at the bot-\ntom. In this case, the covariance matrix, \u03a3, is such that the elliptical contours\nof equal probability are skewed. If the covariance matrix were diagonal, that is\nif all o\ufb00-diagonal terms were 0, then the major axes of the elliptical contours\nwould be aligned with the coordinate axes. In general the principal axes are\ngiven by the eigenvectors of \u03a3. In any case, the equi-probability contours are\nall centered on the mean vector, M, which in our \ufb01gure happens to be at the\norigin. In general, the formula in the exponent in the Gaussian distribution\nis a positive de\ufb01nite quadratic form (that is, its value is always positive); thus\nequi-probability contours are hyper-ellipsoids in n-dimensional space. Suppose we now assume that the two classes of pattern vectors that we\nwant to distinguish are each distributed according to a Gaussian distribution\nbut with di\ufb00erent means and covariance matrices. That is, one class tends to\nhave patterns clustered around one point in the n-dimensional space, and the\nother class tends to have patterns clustered around another point. We show a\ntwo-dimensional instance of this problem in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 73, 'page_label': '74'}, page_content='5.2. (In that \ufb01gure, we have\nplotted the sum of the two distributions.) What decision rule should we use to\nseparate patterns into the two appropriate categories? Substituting the Gaussian distributions into our maximum likelihood for-\nmula yields:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 74, 'page_label': '75'}, page_content='66 CHAPTER 5. STATISTICAL LEARNING\n-5\n0\n5\n-5\n0\n5\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n-5\n0\n5\n0\n25\n.5\n75\n1\n-6 -4 -2 0 2 4 6\n-6\n-4\n-2\n0\n2\n4\n6\nx1\nx2\np(x1,x2)\n2\n4\n6\n24 6\nx1\nx2\nFigure 5.1: The Two-Dimensional Gaussian Distribution\nDecide category 1 i\ufb00:\n1\n(2\u03c0)n/2|\u03a32|1/2 e\u22121/2(X\u2212M2)t\u03a3\n\u22121\n2 (X\u2212M2)\nis less than or equal to\n1\n(2\u03c0)n/2|\u03a31|1/2 e\u22121/2(X\u2212M1)t\u03a3\n\u22121\n1 (X\u2212M1)\nwhere the category 1 patterns are distributed with mean and covariance M1\nand \u03a31, respectively, and the category 2 patterns are distributed with mean\nand covariance M2 and \u03a32. The result of the comparison isnt changed if we compare logarithms instead.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 74, 'page_label': '75'}, page_content='After some manipulation, our decision rule is then:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 75, 'page_label': '76'}, page_content='5.1. USING STATISTICAL DECISION THEORY 67\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n0.25\n0.5\n0.75\n1\n-5\n0\n5\n10\n-5\n0\n5\n10\n0\n25\n.5\n75\n1\nx1\nx2\np(x1,x2)\n-5 -2.5 0 2.5 5 7.5 10\n-5\n-2.5\n0\n2.5\n5\n7.5\n10\nFigure 5.2: The Sum of Two Gaussian Distributions\nDecide category 1 i\ufb00:\n(X \u2212M1)t\u03a3\u22121\n1 (X \u2212M1) <(X \u2212M2)t\u03a3\u22121\n2 (X \u2212M2) + B\nwhere B, a constant bias term, incorporates the logarithms of the fractions\npreceding the exponential, etc. When the quadratic forms are multiplied out and represented in terms of\nthe components xi, the decision rule involves a quadric surface (a hyperquadric)\nin n-dimensional space.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 75, 'page_label': '76'}, page_content='The exact shape and position of this hyperquadric is\ndetermined by the means and the covariance matrices. The surface separates\nthe space into two parts, one of which contains points that will be assigned to\ncategory 1 and the other contains points that will be assigned to category 2. It is interesting to look at a special case of this surface. If the covariance\nmatrices for each category are identical and diagonal, with all \u03c3ii equal to each\nother, then the contours of equal probability for each of the two distributions'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 76, 'page_label': '77'}, page_content='68 CHAPTER 5. STATISTICAL LEARNING\nare hyperspherical. The quadric forms then become (1 /|\u03a3|)(X\u2212Mi)t(X\u2212Mi),\nand the decision rule is:\nDecide category 1 i\ufb00:\n(X \u2212M1)t(X \u2212M1) <(X \u2212M2)t(X \u2212M2)\nMultiplying out yields:\nXX \u22122XM1 + M1M1 <XX \u22122XM2 + M2M2\nor \ufb01nally,\nDecide category 1 i\ufb00:\nXM1 \u2265XM2 + Constant\nor\nX(M1 \u2212M2) \u2265Constant\nwhere the constant depends on the lengths of the mean vectors. We see that the optimal decision surface in this special case is a hyperplane. In fact, the hyperplane is perpendicular to the line joining the two means. The\nweights in a TLU implementation are equal to the di\ufb00erence in the mean vectors. If the parameters ( Mi,\u03a3i) of the probability distributions of the categories\nare not known, there are various techniques for estimating them, and then using\nthose estimates in the decision rule. For example, if there are su\ufb03cient training\npatterns, one can use sample means and sample covariance matrices. (Caution:\nthe sample covariance matrix will be singular if the training patterns happen to\nlie on a subspace of the whole n-dimensional spaceas they certainly will, for\nexample, if the number of training patterns is less than n.)\n5.1.3 Conditionally Independent Binary Components\nSuppose the vector X is a random variable having binary (0,1) components. We continue to denote the two probability distributions by p(X |1) and p(X |\n2).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 76, 'page_label': '77'}, page_content='Further suppose that the components of these vectors are conditionally\nindependent given the category. By conditional independence in this case, we\nmean that the formulas for the distribution can be expanded as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 77, 'page_label': '78'}, page_content='5.1. USING STATISTICAL DECISION THEORY 69\np(X |i) = p(x1 |i)p(x2 |i) ···p(xn |i)\nfor i= 1,2\nRecall the minimum-average-loss decision rule,\nDecide category 1 i\ufb00:\n\u03bb(1 |2)p(X |2)p(2) \u2264\u03bb(2 |1)p(X |1)p(1)\nAssuming conditional independence of the components and that \u03bb(1 |2) = \u03bb(2 |\n1), we obtain,\nDecide category 1 i\ufb00:\np(1)p(x1 |1)p(x2 |1) ···p(xn |1) \u2265p(x1 |2)p(x2 |2) ···p(xn |2)p(2)\nor i\ufb00:\np(x1 |1)p(x2 |1) ...p (xn |1)\np(x1 |2)p(x2 |2) ...p (xn |2) \u2265p(2)\np(1)\nor i\ufb00:\nlog p(x1 |1)\np(x1 |2) + log p(x2 |1)\np(x2 |2) + ··· + log p(xn |1)\np(xn |2) + log p(1)\np(2) \u22650\nLet us de\ufb01ne values of the components of the distribution for speci\ufb01c values of\ntheir arguments, xi :\np(xi = 1 |1) = pi\np(xi = 0 |1) = 1 \u2212pi\np(xi = 1 |2) = qi\np(xi = 0 |2) = 1 \u2212qi\nNow, we note that since xi can only assume the values of 1 or 0:\nlog p(xi |1)\np(xi |2) = xilog pi\nqi\n+ (1 \u2212xi) log (1 \u2212pi)\n(1 \u2212qi)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 78, 'page_label': '79'}, page_content='70 CHAPTER 5. STATISTICAL LEARNING\n= xilog pi(1 \u2212qi)\nqi(1 \u2212pi) + log (1 \u2212pi)\n(1 \u2212qi)\nSubstituting these expressions into our decision rule yields:\nDecide category 1 i\ufb00:\nn\u2211\ni=1\nxilog pi(1 \u2212qi)\nqi(1 \u2212pi) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi) + log p(1)\np(2) \u22650\nWe see that we can achieve this decision with a TLU with weight values as\nfollows:\nwi = log pi(1 \u2212qi)\nqi(1 \u2212pi)\nfor i= 1,...,n , and\nwn+1 = log p(1)\n1 \u2212p(1) +\nn\u2211\ni=1\nlog (1 \u2212pi)\n(1 \u2212qi)\nIf we do not know the pi,qi and p(1), we can use a sample of labeled training\npatterns to estimate these parameters. 5.2 Learning Belief Networks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 78, 'page_label': '79'}, page_content='5.3 Nearest-Neighbor Methods\nAnother class of methods can be related to the statistical ones. These are called\nnearest-neighbor methods or, sometimes, memory-based methods. (A collection\nof papers on this subject is in [Dasarathy, 1991].) Given a training set \u039e of m\nlabeled patterns, a nearest-neighbor procedure decides that some new pattern,\nX, belongs to the same category as do its closest neighbors in \u039e. More precisely,\na k-nearest-neighbor method assigns a new pattern,X, to that category to which\nthe plurality of its k closest neighbors belong. Using relatively large values of\nk decreases the chance that the decision will be unduly in\ufb02uenced by a noisy\ntraining pattern close to X. But large values of k also reduce the acuity of the\nmethod. The k-nearest-neighbor method can be thought of as estimating the\nvalues of the probabilities of the classes given X. Of course the denser are the\npoints around X, and the larger the value of k, the better the estimate.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 79, 'page_label': '80'}, page_content='5.3. NEAREST-NEIGHBOR METHODS 71\nThe distance metric used in nearest-neighbor methods (for numerical at-\ntributes) can be simple Euclidean distance. That is, the distance between two\npatterns (x11,x12,...,x 1n) and (x21,x22,...,x 2n) is\n\u221a\u2211n\nj=1(x1j \u2212x2j)2. This\ndistance measure is often modi\ufb01ed by scaling the features so that the spread of\nattribute values along each dimension is approximately the same. In that case,\nthe distance between the two vectors would be\n\u221a\u2211n\nj=1 a2\nj(x1j \u2212x2j)2, where\naj is the scale factor for dimension j. An example of a nearest-neighbor decision problem is shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 79, 'page_label': '80'}, page_content='5.3. In\nthe \ufb01gure the class of a training pattern is indicated by the number next to it. k = 8\nX (a pattern to be classified)\n1\n1\n1 1\n1\n11\n1\n2\n1\n2\n2\n2\n2\n2\n2 2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\ntraining patternclass of training pattern\nfour patterns of category 1\ntwo patterns of category 2\ntwo patterns of category 3\nplurality are in category 1, so\ndecide X is in category 1\nFigure 5.3: An 8-Nearest-Neighbor Decision\nSee [Baum, 1994] for theoretical\nanalysis of error rate as a function\nof the number of training patterns\nfor the case in which points are\nrandomly distributed on the surface\nof a unit sphere and underlying\nfunction is linearly separable. Nearest-neighbor methods are memory intensive because a large number of\ntraining patterns must be stored to achieve good generalization. Since memory\ncost is now reasonably low, the method and its derivatives have seen several\npractical applications. (See, for example, [Moore, 1992, Moore, et al., 1994]. Also, the distance calculations required to \ufb01nd nearest neighbors can often be\ne\ufb03ciently computed by kd-tree methods [Friedman, et al., 1977]. A theorem by Cover and Hart [Cover & Hart, 1967] relates the performance\nof the 1-nearest-neighbor method to the performance of a minimum-probability-\nof-error classi\ufb01er. As mentioned earlier, the minimum-probability-of-error clas-\nsi\ufb01er would assign a new patternX to that category that maximizedp(i)p(X |i),\nwhere p(i) is the a priori probability of categoryi, and p(X |i) is the probability\n(or probability density function) of X given that X belongs to category i, for\ncategories i= 1,...,R . Suppose the probability of error in classifying patterns\nof such a minimum-probability-of-error classi\ufb01er is \u03b5. The Cover-Hart theo-\nrem states that under very mild conditions (having to do with the smoothness'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 80, 'page_label': '81'}, page_content='72 CHAPTER 5. STATISTICAL LEARNING\nof probability density functions) the probability of error, \u03b5nn, of a 1-nearest-\nneighbor classi\ufb01er is bounded by:\n\u03b5\u2264\u03b5nn \u2264\u03b5\n(\n2 \u2212\u03b5 R\nR\u22121\n)\n\u22642\u03b5\nwhere R is the number of categories.Also see [Aha, 1991].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 80, 'page_label': '81'}, page_content='5.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 81, 'page_label': '82'}, page_content='Chapter 6\nDecision Trees\n6.1 De\ufb01nitions\nA decision tree (generally de\ufb01ned) is a tree whose internal nodes are tests (on\ninput patterns) and whose leaf nodes are categories (of patterns). We show an\nexample in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 81, 'page_label': '82'}, page_content='6.1. A decision tree assigns a class number (or output) to an\ninput pattern by \ufb01ltering the pattern down through the tests in the tree. Each\ntest has mutually exclusive and exhaustive outcomes. For example, test T2 in\nthe tree of Fig. 6.1 has three outcomes; the left-most one assigns the input\npattern to class 3, the middle one sends the input pattern down to test T4, and\nthe right-most one assigns the pattern to class 1. We follow the usual convention\nof depicting the leaf nodes by the class number.1 Note that in discussing decision\ntrees we are not limited to implementing Boolean functionsthey are useful for\ngeneral, categorically valued functions. There are several dimensions along which decision trees might di\ufb00er:\na. The tests might be multivariate (testing on several features of the input\nat once) or univariate (testing on only one of the features). b. The tests might have two outcomes or more than two. (If all of the tests\nhave two outcomes, we have a binary decision tree.)\nc. The features or attributes might be categorical or numeric. (Binary-valued\nones can be regarded as either.)\n1One of the researchers who has done a lot of work on learning decision trees is Ross\nQuinlan. Quinlan distinguishes between classes and categories. He calls the subsets of patterns\nthat \ufb01lter down to each tip categories and subsets of patterns having the same label classes. In Quinlans terminology, our example tree has nine categories and three classes. We will not\nmake this distinction, however, but will use the words category and class interchangeably\nto refer to what Quinlan calls class.\n73'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 82, 'page_label': '83'}, page_content='74 CHAPTER 6. DECISION TREES\nT1\nT2 T3\nT4\nT4\nT4\n3\n1\n3 2\n1 2 3\n2 1\nFigure 6.1: A Decision Tree\nd. We might have two classes or more than two. If we have two classes and\nbinary inputs, the tree implements a Boolean function, and is called a\nBoolean decision tree. It is straightforward to represent the function implemented by a univariate\nBoolean decision tree in DNF form. The DNF form implemented by such a tree\ncan be obtained by tracing down each path leading to a tip node corresponding\nto an output value of 1, forming the conjunction of the tests along this path,\nand then taking the disjunction of these conjunctions. We show an example in\nFig. 6.2. In drawing univariate decision trees, each non-leaf node is depicted by\na single attribute. If the attribute has value 0 in the input pattern, we branch\nleft; if it has value 1, we branch right. The k-DL class of Boolean functions can be implemented by a multivariate\ndecision tree having the (highly unbalanced) form shown in Fig. 6.3.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 82, 'page_label': '83'}, page_content='Each test,\nci, is a term of size k or less. The vi all have values of 0 or 1. 6.2 Supervised Learning of Univariate Decision\nTrees\nSeveral systems for learning decision trees have been proposed. Prominent\namong these are ID3 and its new version, C4.5 [Quinlan, 1986, Quinlan, 1993],\nand CART [Breiman, et al., 1984] We discuss here only batch methods, al-\nthough incremental ones have also been proposed [Utgo\ufb00, 1989].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 83, 'page_label': '84'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES75\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.2: A Decision Tree Implementing a DNF Function\n6.2.1 Selecting the Type of Test\nAs usual, we have n features or attributes. If the attributes are binary, the\ntests are simply whether the attributes value is 0 or 1. If the attributes are\ncategorical, but non-binary, the tests might be formed by dividing the attribute\nvalues into mutually exclusive and exhaustive subsets. A decision tree with such\ntests is shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 83, 'page_label': '84'}, page_content='6.4. If the attributes are numeric, the tests might involve\ninterval tests, for example 7 \u2264xi \u226413.2. 6.2.2 Using Uncertainty Reduction to Select Tests\nThe main problem in learning decision trees for the binary-attribute case is\nselecting the order of the tests. For categorical and numeric attributes, we\nmust also decide what the tests should be (besides selecting the order). Several\ntechniques have been tried; the most popular one is at each stage to select that\ntest that maximally reduces an entropy-like measure. We show how this technique works for the simple case of tests with binary\noutcomes. Extension to multiple-outcome tests is straightforward computation-\nally but gives poor results because entropy is always decreased by having more\noutcomes. The entropy or uncertainty still remaining about the class of a pattern\nknowing that it is in some set, \u039e, of patterns is de\ufb01ned as:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 84, 'page_label': '85'}, page_content='76 CHAPTER 6. DECISION TREES\ncq\ncq-1\nci\n1\nvn\nvn-1\nvi\nv1\nFigure 6.3: A Decision Tree Implementing a Decision List\nwhere p(i|\u039e) is the probability that a pattern drawn at random from \u039e belongs\nto class i, and the summation is over all of the classes. We want to select tests at\neach node such that as we travel down the decision tree, the uncertainty about\nthe class of a pattern becomes less and less.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 84, 'page_label': '85'}, page_content='Since we do not in general have the probabilitiesp(i|\u039e), we estimate them by\nsample statistics. Although these estimates might be errorful, they are never-\ntheless useful in estimating uncertainties. Let p(i|\u039e) be the number of patterns\nin \u039e belonging to class idivided by the total number of patterns in \u039e. Then an\nestimate of the uncertainty is:\nH(\u039e) = \u2212\n\u2211\ni\np(i|\u039e) log2 p(i|\u039e)\nFor simplicity, from now on well drop the hats and use sample statistics as\nif they were real probabilities. If we perform a test, T, having k possible outcomes on the patterns in \u039e, we\nwill create ksubsets, \u039e1,\u039e2,..., \u039ek. Suppose that ni of the patterns in \u039e are in\n\u039ei for i= 1,...,k . (Some ni may be 0.) If we knew that T applied to a pattern\nin \u039e resulted in the j-th outcome (that is, we knew that the pattern was in \u039e j),\nthe uncertainty about its class would be:\nH(\u039ej) = \u2212\n\u2211\ni\np(i|\u039ej) log2 p(i|\u039ej)\nand the reduction in uncertainty (beyond knowing only that the pattern was in\n\u039e) would be:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 85, 'page_label': '86'}, page_content='6.2. SUPERVISED LEARNING OF UNIVARIATE DECISION TREES77\nx3 = a, b, c, or d \n{a, c} {b}\nx1 = e, b, or d \n{e,b} {d}\nx4 = a, e, f, or g\n{a, g} {e, f}\nx2 = a, or g\n{a} {g}\n1\n2 1\n1 2\n{d}\n2\nFigure 6.4: A Decision Tree with Categorical Attributes\nH(\u039e) \u2212H(\u039ej)\nOf course we cannot say that the test T is guaranteed always to produce that\namount of reduction in uncertainty because we dont know that the result of\nthe test will be the j-th outcome. But we can estimate the average uncertainty\nover all the \u039ej, by:\nE[HT(\u039e)] =\n\u2211\nj\np(\u039ej)H(\u039ej)\nwhere by HT(\u039e) we mean the average uncertainty after performing test T on\nthe patterns in \u039e, p(\u039ej) is the probability that the test has outcome j, and the\nsum is taken from 1 to k.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 85, 'page_label': '86'}, page_content='Again, we dont know the probabilities p(\u039ej), but we\ncan use sample values. The estimate p(\u039ej) of p(\u039ej) is just the number of those\npatterns in \u039e that have outcome j divided by the total number of patterns in\n\u039e. The average reduction in uncertainty achieved by test T (applied to patterns\nin \u039e) is then:\nRT(\u039e) = H(\u039e) \u2212E[HT(\u039e)]\nAn important family of decision tree learning algorithms selects for the root\nof the tree that test that gives maximum reduction of uncertainty, and then\napplies this criterion recursively until some termination condition is met (which\nwe shall discuss in more detail later). The uncertainty calculations are particu-\nlarly simple when the tests have binary outcomes and when the attributes have'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 86, 'page_label': '87'}, page_content='78 CHAPTER 6. DECISION TREES\nbinary values.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 86, 'page_label': '87'}, page_content='Well give a simple example to illustrate how the test selection\nmechanism works in that case. Suppose we want to use the uncertainty-reduction method to build a decision\ntree to classify the following patterns:\npattern class\n(0, 0, 0) 0\n(0, 0, 1) 0\n(0, 1, 0) 0\n(0, 1, 1) 0\n(1, 0, 0) 0\n(1, 0, 1) 1\n(1, 1, 0) 0\n(1, 1, 1) 1\nWhat single test, x1, x2, or x3, should be performed \ufb01rst? The illustration in\nFig. 6.5 gives geometric intuition about the problem. x1\nx2\nx3\nThe test x1\nFigure 6.5: Eight Patterns to be Classi\ufb01ed by a Decision Tree\nThe initial uncertainty for the set, \u039e, containing all eight points is:\nH(\u039e) = \u2212(6/8) log2(6/8) \u2212(2/8) log2(2/8) = 0.81\nNext, we calculate the uncertainty reduction if we perform x1 \ufb01rst. The left-\nhand branch has only patterns belonging to class 0 (we call them the set \u039el), and\nthe right-hand-branch (\u039er) has two patterns in each class. So, the uncertainty\nof the left-hand branch is:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 87, 'page_label': '88'}, page_content='6.3. NETWORKS EQUIVALENT TO DECISION TREES 79\nHx1 (\u039el) = \u2212(4/4) log2(4/4) \u2212(0/4) log2(0/4) = 0\nAnd the uncertainty of the right-hand branch is:\nHx1 (\u039er) = \u2212(2/4) log2(2/4) \u2212(2/4) log2(2/4) = 1\nHalf of the patterns go left and half go right on test x1. Thus, the average\nuncertainty after performing the x1 test is:\n1/2Hx1 (\u039el) + 1/2Hx1 (\u039er) = 0.5\nTherefore the uncertainty reduction on \u039e achieved by x1 is:\nRx1 (\u039e) = 0.81 \u22120.5 = 0.31\nBy similar calculations, we see that the test x3 achieves exactly the same\nuncertainty reduction, but x2 achieves no reduction whatsoever. Thus, our\ngreedy algorithm for selecting a \ufb01rst test would select eitherx1 or x3. Suppose\nx1 is selected. The uncertainty-reduction procedure would select x3 as the next\ntest. The decision tree that this procedure creates thus implements the Boolean\nfunction: f = x1x3. See [Quinlan, 1986, sect.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 87, 'page_label': '88'}, page_content='4] for\nanother example. 6.2.3 Non-Binary Attributes\nIf the attributes are non-binary, we can still use the uncertainty-reduction tech-\nnique to select tests. But now, in addition to selecting an attribute, we must\nselect a test on that attribute. Suppose for example that the value of an at-\ntribute is a real number and that the test to be performed is to set a threshold\nand to test to see if the number is greater than or less than that threshold. In\nprinciple, given a set of labeled patterns, we can measure the uncertainty reduc-\ntion for each test that is achieved by every possible threshold (there are only\na \ufb01nite number of thresholds that give di\ufb00erent test results if there are only\na \ufb01nite number of training patterns). Similarly, if an attribute is categorical\n(with a \ufb01nite number of categories), there are only a \ufb01nite number of mutually\nexclusive and exhaustive subsets into which the values of the attribute can be\nsplit. We can calculate the uncertainty reduction for each split. 6.3 Networks Equivalent to Decision Trees\nSince univariate Boolean decision trees are implementations of DNF functions,\nthey are also equivalent to two-layer, feedforward neural networks. We show\nan example in Fig. 6.6. The decision tree at the left of the \ufb01gure implements'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 88, 'page_label': '89'}, page_content='80 CHAPTER 6. DECISION TREES\nthe same function as the network at the right of the \ufb01gure. Of course, when\nimplemented as a network, all of the features are evaluated in parallel for any\ninput pattern, whereas when implemented as a decision tree only those features\non the branch traveled down by the input pattern need to be evaluated. The\ndecision-tree induction methods discussed in this chapter can thus be thought of\nas particular ways to establish the structure and the weight values for networks. X\nx1\nx2\nx3\nx4\nterms\n-1\n+1\ndisjunction\nx3x2\nx3x4x1\n+1\n-1\n+1\nf\n1.5\n0.5\nx3\nx2 x4\nx1\n10\n1\n1\n0 0\n0\n1\nx3x2\nx3x2\nx3x4\nx3x4x1 x3x4x1\nf = x3x2 + x3x4x1\n1\n0\n0\n1 0\nFigure 6.6: A Univariate Decision Tree and its Equivalent Network\nMultivariate decision trees with linearly separable functions at each node can\nalso be implemented by feedforward networksin this case three-layer ones. We\nshow an example in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 88, 'page_label': '89'}, page_content='6.7 in which the linearly separable functions, each im-\nplemented by a TLU, are indicated by L1,L2,L3, and L4. Again, the \ufb01nal layer\nhas \ufb01xed weights, but the weights in the \ufb01rst two layers must be trained. Dif-\nferent approaches to training procedures have been discussed by [Brent, 1990],\nby [John, 1995], and (for a special case) by [Marchand & Golea, 1993]. 6.4 Over\ufb01tting and Evaluation\n6.4.1 Over\ufb01tting\nIn supervised learning, we must choose a function to \ufb01t the training set from\namong a set of hypotheses. We have already showed that generalization is\nimpossible without bias. When we know a priori that the function we are\ntrying to guess belongs to a small subset of all possible functions, then, even\nwith an incomplete set of training samples, it is possible to reduce the subset\nof functions that are consistent with the training set su\ufb03ciently to make useful\nguesses about the value of the function for inputs not in the training set. And,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 89, 'page_label': '90'}, page_content='6.4. OVERFITTING AND EVALUATION 81\nL1\nL2 L3\nL4\n10\n1\n1\n0 0\n0\n1\n1\n0\n0\n1 0\nX\nL1\nL2\nL3\nL4\nconjunctions\nL1L2\nL1 L3 L4\n<\n+\n++\ndisjunction\n<\nf\nFigure 6.7: A Multivariate Decision Tree and its Equivalent Network\nthe larger the training set, the more likely it is that even a randomly selected\nconsistent function will have appropriate outputs for patterns not yet seen. However, even with bias, if the training set is not su\ufb03ciently large compared\nwith the size of the hypothesis space, there will still be too many consistent\nfunctions for us to make useful guesses, and generalization performance will be\npoor. When there are too many hypotheses that are consistent with the training\nset, we say that we are over\ufb01tting the training data. Over\ufb01tting is a problem\nthat we must address for all learning methods. Since a decision tree of su\ufb03cient size can implement any Boolean function\nthere is a danger of over\ufb01ttingespecially if the training set is small. That\nis, even if the decision tree is synthesized to classify all the members of the\ntraining set correctly, it might perform poorly on new patterns that were not\nused to build the decision tree. Several techniques have been proposed to avoid\nover\ufb01tting, and we shall examine some of them here.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 89, 'page_label': '90'}, page_content='They make use of methods\nfor estimating how well a given decision tree might generalizemethods we shall\ndescribe next. 6.4.2 Validation Methods\nThe most straightforward way to estimate how well a hypothesized function\n(such as a decision tree) performs on a test set is to test it on the test set! But,\nif we are comparing several learning systems (for example, if we are comparing\ndi\ufb00erent decision trees) so that we can select the one that performs the best on\nthe test set, then such a comparison amounts to training on the test data.\nTrue, training on the test data enlarges the training set, with a consequent ex-\npected improvement in generalization, but there is still the danger of over\ufb01tting\nif we are comparing several di\ufb00erent learning systems. Another technique is to'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 90, 'page_label': '91'}, page_content='82 CHAPTER 6. DECISION TREES\nsplit the training setusing (say) two-thirds for training and the other third\nfor estimating generalization performance. But splitting reduces the size of the\ntraining set and thereby increases the possibility of over\ufb01tting. We next describe\nsome validation techniques that attempt to avoid these problems. Cross-Validation\nIn cross-validation, we divide the training set \u039e into K mutually exclusive and\nexhaustive equal-sized subsets: \u039e 1,..., \u039eK. For each subset, \u039e i, train on the\nunion of all of the other subsets, and empirically determine the error rate, \u03b5i,\non \u039ei. (The error rate is the number of classi\ufb01cation errors made on \u039e i divided\nby the number of patterns in \u039e i.) An estimate of the error rate that can be\nexpected on new patterns of a classi\ufb01er trained on all the patterns in \u039e is then\nthe average of the \u03b5i. Leave-one-out Validation\nLeave-one-out validation is the same as cross validation for the special case in\nwhich K equals the number of patterns in \u039e, and each \u039e i consists of a single\npattern. When testing on each \u039e i, we simply note whether or not a mistake\nwas made. We count the total number of mistakes and divide by K to get\nthe estimated error rate. This type of validation is, of course, more expensive\ncomputationally, but useful when a more accurate estimate of the error rate for\na classi\ufb01er is needed.Describe bootstrapping also\n[Efron, 1982]. 6.4.3 Avoiding Over\ufb01tting in Decision Trees\nNear the tips of a decision tree there may be only a few patterns per node. For these nodes, we are selecting a test based on a very small sample, and thus\nwe are likely to be over\ufb01tting. This problem can be dealt with by terminating\nthe test-generating procedure before all patterns are perfectly split into their\nseparate categories. That is, a leaf node may contain patterns of more than one\nclass, but we can decide in favor of the most numerous class. This procedure\nwill result in a few errors but often accepting a small number of errors on the\ntraining set results in fewer errors on a testing set. This behavior is illustrated in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 90, 'page_label': '91'}, page_content='6.8. One can use cross-validation techniques to determine when to stop splitting\nnodes. If the cross validation error increases as a consequence of a node split,\nthen dont split. One has to be careful about when to stop, though, because\nunder\ufb01tting usually leads to more errors on test sets than does over\ufb01tting. There\nis a general rule that the lowest error-rate attainable by a sub-tree of a fully\nexpanded tree can be no less than 1/2 of the error rate of the fully expanded\ntree [Weiss & Kulikowski, 1991, page 126].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 91, 'page_label': '92'}, page_content='6.4. OVERFITTING AND EVALUATION 83\n(From Weiss, S., and Kulikowski, C., Computer Systems that Learn,\nMorgan Kaufmann, 1991)\ntraining errors\nvalidation errors\n1 2 34 5 6 78 9\n0.2\n0.4\n0.6\n0.8\n1.0\n0\n0\nError Rate\nNumber of Terminal\nNodes\nIris Data Decision Tree\nFigure 6.8: Determining When Over\ufb01tting Begins\nRather than stopping the growth of a decision tree, one might grow it to\nits full size and then prune away leaf nodes and their ancestors until cross-\nvalidation accuracy no longer increases. This technique is called post-pruning.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 91, 'page_label': '92'}, page_content='Various techniques for pruning are discussed in [Weiss & Kulikowski, 1991]. 6.4.4 Minimum-Description Length Methods\nAn important tree-growing and pruning technique is based on the minimum-\ndescription-length (MDL) principle. (MDL is an important idea that extends\nbeyond decision-tree methods [Rissanen, 1978].) The idea is that the simplest\ndecision tree that can predict the classes of the training patterns is the best\none. Consider the problem of transmitting just the labels of a training set of\npatterns, assuming that the receiver of this information already has the ordered\nset of patterns. If there are m patterns, each labeled by one of R classes,\none could transmit a list of m R-valued numbers. Assuming equally probable\nclasses, this transmission would require mlog2 Rbits. Or, one could transmit a\ndecision tree that correctly labelled all of the patterns. The number of bits that\nthis transmission would require depends on the technique for encoding decision\ntrees and on the size of the tree. If the tree is small and accurately classi\ufb01es\nall of the patterns, it might be more economical to transmit the tree than to\ntransmit the labels directly. In between these extremes, we might transmit a\ntree plus a list of labels of all the patterns that the tree misclassi\ufb01es. In general, the number of bits (or description length of the binary encoded\nmessage) is t+ d, where t is the length of the message required to transmit\nthe tree, and d is the length of the message required to transmit the labels of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 92, 'page_label': '93'}, page_content='84 CHAPTER 6. DECISION TREES\nthe patterns misclassi\ufb01ed by the tree. In a sense, that tree associated with the\nsmallest value of t+ d is the best or most economical tree. The MDL method\nis one way of adhering to the Occams razor principle. Quinlan and Rivest [Quinlan & Rivest, 1989] have proposed techniques for\nencoding decision trees and lists of exception labels and for calculating the\ndescription length (t+d) of these trees and labels. They then use the description\nlength as a measure of quality of a tree in two ways:\na. In growing a tree, they use the reduction in description length to select\ntests (instead of reduction in uncertainty). b. In pruning a tree after it has been grown to zero error, they prune away\nthose nodes (starting at the tips) that achieve a decrease in the description\nlength. These techniques compare favorably with the uncertainty-reduction method,\nalthough they are quite sensitive to the coding schemes used. 6.4.5 Noise in Data\nNoise in the data means that one must inevitably accept some number of\nerrorsdepending on the noise level. Refusal to tolerate errors on the training\nset when there is noise leads to the problem of \ufb01tting the noise. Dealing with\nnoise, then, requires accepting some errors at the leaf nodes just as does the\nfact that there are a small number of patterns at leaf nodes. 6.5 The Problem of Replicated Subtrees\nDecision trees are not the most economical means of implementing some Boolean\nfunctions. Consider, for example, the function f = x1x2 +x3x4. A decision tree\nfor this function is shown in Fig. 6.9. Notice the replicated subtrees shown\ncircled. The DNF-form equivalent to the function implemented by this decision\ntree is f = x1x2 + x1x2x3x4 + x1x3x4. This DNF form is non-minimal (in the\nnumber of disjunctions) and is equivalent to f = x1x2 + x3x4. The need for replication means that it takes longer to learn the tree and\nthat subtrees replicated further down the tree must be learned using a smaller\ntraining subset. This problem is sometimes called the fragmentation problem.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 92, 'page_label': '93'}, page_content='Several approaches might be suggested for dealing with fragmenta-\ntion. One is to attempt to build a decision graph instead of a tree\n[Oliver, Dowe, & Wallace, 1992, Kohavi, 1994]. A decision graph that imple-\nments the same decisions as that of the decision tree of Fig. 6.9 is shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 92, 'page_label': '93'}, page_content='6.10. Another approach is to use multivariate (rather than univariate tests at each\nnode). In our example of learning f = x1x2 + x3x4, if we had a test for x1x2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 93, 'page_label': '94'}, page_content='6.6. THE PROBLEM OF MISSING ATTRIBUTES 85\nx1\nx3 x2\n10\nx4\n0 1\nx3\n0\nx4\n0 1\nFigure 6.9: A Decision Tree with Subtree Replication\nand a test for x3x4, the decision tree could be much simpli\ufb01ed, as shown in Fig. 6.11. Several researchers have proposed techniques for learning decision trees in\nwhich the tests at each node are linearly separable functions. [John, 1995] gives\na nice overview (with several citations) of learning suchlinear discriminant trees\nand presents a method based on soft entropy.\nA third method for dealing with the replicated subtree problem involves ex-\ntracting propositional rules from the decision tree. The rules will have as an-\ntecedents the conjunctions that lead down to the leaf nodes, and as consequents\nthe name of the class at the corresponding leaf node.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 93, 'page_label': '94'}, page_content='An example rule from the\ntree with the repeating subtree of our example would be: x1 \u2227¬x2 \u2227x3 \u2227x4 \u22831. Quinlan [Quinlan, 1987] discusses methods for reducing a set of rules to a sim-\npler set by 1) eliminating from the antecedent of each rule any unnecessary\nconjuncts, and then 2) eliminating unnecessary rules. A conjunct or rule is\ndetermined to be unnecessary if its elimination has little e\ufb00ect on classi\ufb01cation\naccuracyas determined by a chi-square test, for example. After a rule set is\nprocessed, it might be the case that more than one rule is active for any given\npattern, and care must be taken that the active rules do not con\ufb02ict in their\ndecision about the class of a pattern.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 94, 'page_label': '95'}, page_content='86 CHAPTER 6. DECISION TREES\nx1\nx3\nx2\n1\n0\nx4\n0 1\nFigure 6.10: A Decision Graph\n6.6 The Problem of Missing Attributes\nTo be added. 6.7 Comparisons\nSeveral experimenters have compared decision-tree, neural-net, and nearest-\nneighbor classi\ufb01ers on a wide variety of problems. For a comparison of\nneural nets versus decision trees, for example, see [Dietterich, et al., 1990,\nShavlik, Mooney, & Towell, 1991, Quinlan, 1994].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 94, 'page_label': '95'}, page_content='In their StatLog project,\n[Taylor, Michie, & Spiegalhalter, 1994] give thorough comparisons of several\nmachine learning algorithms on several di\ufb00erent types of problems. There seems\nx1x2\n1\n0\nx3x4\n1\nFigure 6.11: A Multivariate Decision Tree'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 95, 'page_label': '96'}, page_content='6.8.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 95, 'page_label': '96'}, page_content='BIBLIOGRAPHICAL AND HISTORICAL REMARKS 87\nto be no single type of classi\ufb01er that is best for all problems. And, there do\nnot seem to be any general conclusions that would enable one to say which\nclassi\ufb01er method is best for which sorts of classi\ufb01cation problems, although\n[Quinlan, 1994] does provide some intuition about properties of problems that\nmight render them ill suited for decision trees, on the one hand, or backpropa-\ngation, on the other. 6.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 96, 'page_label': '97'}, page_content='88 CHAPTER 6. DECISION TREES'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 97, 'page_label': '98'}, page_content='Chapter 7\nInductive Logic\nProgramming\nThere are many di\ufb00erent representational forms for functions of input vari-\nables. So far, we have seen (Boolean) algebraic expressions, decision trees, and\nneural networks, plus other computational mechanisms such as techniques for\ncomputing nearest neighbors. Of course, the representation most important\nin computer science is a computer program. For example, a Lisp predicate of\nbinary-valued inputs computes a Boolean function of those inputs. Similarly, a\nlogic program (whose ordinary application is to compute bindings for variables)\ncan also be used simply to decide whether or not a predicate has value True\n(T) or False (F). For example, the Boolean exclusive-or (odd parity) function\nof two variables can be computed by the following logic program:\nParity(x,y) :- True(x), ¬ True(y)\n:- True(y), ¬ True(x)\nWe follow Prolog syntax (see, for example, [Mueller & Page, 1988]), except that\nour convention is to write variables as strings beginning with lower-case letters\nand predicates as strings beginning with upper-case letters. The unary function\nTrue returns T if and only if the value of its argument is T. (We now think\nof Boolean functions and arguments as having values of T and F instead of 0\nand 1.) Programs will be written in  typewriter font. In this chapter, we consider the matter of learning logic programs given\na set of variable values for which the logic program should return T (the\npositive instances ) and a set of variable values for which it should return\nF (the negative instances). The subspecialty of machine learning that deals\nwith learning logic programs is called inductive logic programming (ILP)\n[Lavra\u02c7 c & D\u02c7 zeroski, 1994]. As with any learning problem, this one can be quite\ncomplex and intractably di\ufb03cult unless we constrain it with biases of some sort.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 97, 'page_label': '98'}, page_content='89'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 98, 'page_label': '99'}, page_content='90 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nIn ILP, there are a variety of possible biases (calledlanguage biases). One might\nrestrict the program to Horn clauses, not allow recursion, not allow functions,\nand so on. As an example of an ILP problem, suppose we are trying to induce a func-\ntion Nonstop(x,y), that is to have value T for pairs of cities connected by a\nnon-stop air \ufb02ight and F for all other pairs of cities. We are given a training set\nconsisting of positive and negative examples.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 98, 'page_label': '99'}, page_content='As positive examples, we might\nhave (A,B), (A, A1), and some other pairs; as negative examples, we might\nhave (A1, A2), and some other pairs. In ILP, we usually have additional infor-\nmation about the examples, called background knowledge. In our air-\ufb02ight\nproblem, the background information might be such ground facts as Hub(A),\nHub(B), Satellite(A1,A), plus others. ( Hub(A) is intended to mean that the\ncity denoted by A is a hub city, and Satellite(A1,A) is intended to mean that\nthe city denoted by A1 is a satellite of the city denoted by A.) From these train-\ning facts, we want to induce a program Nonstop(x,y), written in terms of the\nbackground relations Hub and Satellite, that has value T for all the positive\ninstances and has value F for all the negative instances. Depending on the exact\nset of examples, we might induce the program:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nwhich would have value T if both of the two cities were hub cities or if one were\na satellite of the other. As with other learning problems, we want the induced\nprogram to generalize well; that is, if presented with arguments not represented\nin the training set (but for which we have the needed background knowledge),\nwe would like the function to guess well. 7.1 Notation and De\ufb01nitions\nIn evaluating logic programs in ILP, we implicitly append the background facts\nto the program and adopt the usual convention that a program has value T for\na set of inputs if and only if the program interpreter returns T when actually\nrunning the program (with background facts appended) on those inputs; oth-\nerwise it has value F. Using the given background facts, the program above\nwould return T for input (A, A1), for example. If a logic program, \u03c0, returns\nT for a set of arguments X, we say that the program covers the arguments and\nwrite covers(\u03c0,X). Following our terminology introduced in connection with\nversion spaces, we will say that a program is su\ufb03cient if it covers all of the\npositive instances and that it is necessary if it does not cover any of the neg-\native instances. (That is, a program implements a su\ufb03cient condition that a\ntraining instance is positive if it covers all of the positive training instances; it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 99, 'page_label': '100'}, page_content='7.2. A GENERIC ILP ALGORITHM 91\nimplements a necessary condition if it covers none of the negative instances.) In\nthe noiseless case, we want to induce a program that is both su\ufb03cient and nec-\nessary, in which case we will call it consistent. With imperfect (noisy) training\nsets, we might relax this criterion and settle for a program that covers all but\nsome fraction of the positive instances while allowing it to cover some fraction\nof the negative instances. We illustrate these de\ufb01nitions schematically in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 99, 'page_label': '100'}, page_content='7.1. <\n<\n<\n<<\n<\n<\n/1 is a necessary program\n/2 is a sufficient program\n/3 is a consistent program\n+\n+\n+\n+\n+ +\n+\n+\n+\n+\n<\n<\nA positive instance\n covered by /2 and /3\nFigure 7.1: Su\ufb03cient, Necessary, and Consistent Programs\nAs in version spaces, if a program is su\ufb03cient but not necessary it can be\nmade to cover fewer examples by specializing it. Conversely, if it is necessary\nbut not su\ufb03cient, it can be made to cover more examples by generalizing it. Suppose we are attempting to induce a logic program to compute the relation\n\u03c1. The most general logic program, which is certainly su\ufb03cient, is the one that\nhas value T for all inputs, namely a single clause with an empty body, [ \u03c1 :-\n], which is called a fact in Prolog. The most special logic program, which is\ncertainly necessary, is the one that has value F for all inputs, namely [ \u03c1 :-\nF ]. Two of the many di\ufb00erent ways to search for a consistent logic program\nare: 1) start with [ \u03c1 :- ] and specialize until the program is consistent, or 2)\nstart with [ \u03c1 :- F ] and generalize until the program is consistent. We will\nbe discussing a method that starts with [ \u03c1 :- ], specializes until the program\nis necessary (but might no longer be su\ufb03cient), then reachieves su\ufb03ciency in\nstages by generalizingensuring within each stage that the program remains\nnecessary (by specializing). 7.2 A Generic ILP Algorithm\nSince the primary operators in our search for a consistent program are special-\nization and generalization, we must next discuss those operations. There are'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 100, 'page_label': '101'}, page_content='92 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nthree major ways in which a logic program might be generalized:\na. Replace some terms in a program clause by variables.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 100, 'page_label': '101'}, page_content='(Readers familiar\nwith substitutions in the predicate calculus will note that this process is\nthe inverse of substitution.)\nb. Remove literals from the body of a clause.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 100, 'page_label': '101'}, page_content='c. Add a clause to the program\nAnalogously, there are three ways in which a logic program might be specialized:\na. Replace some variables in a program clause by terms (a substitution). b. Add literals to the body of a clause. c. Remove a clause from the program\nWe will be presenting an ILP learning method that adds clauses to a program\nwhen generalizing and that adds literals to the body of a clause when special-\nizing. When we add a clause, we will always add the clause [ \u03c1 :- ] and then\nspecialize it by adding literals to the body. Thus, we need only describe the\nprocess for adding literals. Clauses can be partially ordered by the specialization relation. In general,\nclause c1 is more special than clause c2 if c2 |= c1. A special case, which is what\nwe use here, is that a clause c1 is more special than a clause c2 if the set of\nliterals in the body of c2 is a subset of those in c1. This ordering relation can\nbe used in a structure of partially ordered clauses, called the re\ufb01nement graph,\nthat is similar to a version space. Clause c1 is an immediate successor of clause\nc2 in this graph if and only if clause c1 can be obtained from clause c2 by adding\na literal to the body of c2. A re\ufb01nement graph then tells us the ways in which\nwe can specialize a clause by adding a literal to it. Of course there are unlimited possible literals we might add to the body of\na clause. Practical ILP systems restrict the literals in various ways. Typical\nallowed additions are:\na. Literals used in the background knowledge. b. Literals whose arguments are a subset of those in the head of the clause. c. Literals that introduce a new distinct variable di\ufb00erent from those in the\nhead of the clause. d. A literal that equates a variable in the head of the clause with another\nsuch variable or with a term mentioned in the background knowledge. (This possibility is equivalent to forming a specialization by making a\nsubstitution.)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 101, 'page_label': '102'}, page_content='7.2.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 101, 'page_label': '102'}, page_content='A GENERIC ILP ALGORITHM 93\ne. A literal that is the same (except for its arguments) as that in the head\nof the clause. (This possibility admits recursive programs, which are dis-\nallowed in some systems.)\nWe can illustrate these possibilities using our air-\ufb02ight example. We start\nwith the program [ Nonstop(x,y) :- ]. The literals used in the background\nknowledge are Hub and Satellite. Thus the literals that we might consider\nadding are:\nHub(x)\nHub(y)\nHub(z)\nSatellite(x,y)\nSatellite(y,x)\nSatellite(x,z)\nSatellite(z,y)\n(x = y)\n(If recursive programs are allowed, we could also add the literals Nonstop(x,z)\nand Nonstop(z,y).) These possibilities are among those illustrated in the re-\n\ufb01nement graph shown in Fig. 7.2. Whatever restrictions on additional literals\nare imposed, they are all syntactic ones from which the successors in the re\ufb01ne-\nment graph are easily computed. ILP programs that follow the approach we\nare discussing (of specializing clauses by adding a literal) thus have well de\ufb01ned\nmethods of computing the possible literals to add to a clause. Now we are ready to write down a simple generic algorithm for inducing a\nlogic program, \u03c0 for inducing a relation \u03c1. We are given a training set, \u039e of\nargument sets some known to be in the relation \u03c1 and some not in \u03c1; \u039e+ are\nthe positive instances, and \u039e \u2212 are the negative instances. The algorithm has\nan outer loop in which it successively adds clauses to make \u03c0 more and more\nsu\ufb03cient. It has an inner loop for constructing a clause, c, that is more and\nmore necessary and in which it refers only to a subset, \u039e cur, of the training\ninstances. (The positive instances in \u039e cur will be denoted by \u039e +\ncur, and the\nnegative ones by \u039e \u2212\ncur.) The algorithm is also given background relations and\nthe means for adding literals to a clause. It uses a logic program interpreter to\ncompute whether or not the program it is inducing covers training instances. The algorithm can be written as follows:\nGeneric ILP Algorithm\n(Adapted from [Lavra\u02c7 c & D\u02c7 zeroski, 1994, p. 60].)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 102, 'page_label': '103'}, page_content='94 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nNonstop(x,y) :-\nNonstop(x,y) :-\n   Hub(x)\nNonstop(x,y) :-\n   Satellite(x,y)\nNonstop(x,y) :-\n   (x = y)\n. .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 102, 'page_label': '103'}, page_content='. . . . . . . . . . Nonstop(x,y) :- Hub(x), Hub(y)\n. . . . . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 102, 'page_label': '103'}, page_content='. Figure 7.2: Part of a Re\ufb01nement Graph\nInitialize \u039ecur := \u039e. Initialize \u03c0:= empty set of clauses. repeat [The outer loop works to make \u03c0 su\ufb03cient.]\nInitialize c := \u03c1 : \u2212. repeat [The inner loop makes c necessary.]\nSelect a literal l to add to c. [This is a nondeterministic choice point.]\nAssign c:= c,l. until c is necessary. [That is, until c covers no negative instances in \u039e cur.]\nAssign \u03c0:= \u03c0,c. [We add the clause c to the program.]\nAssign \u039ecur := \u039ecur \u2212(the positive instances in \u039e cur covered by \u03c0). until \u03c0 is su\ufb03cient. (The termination tests for the inner and outer loops can be relaxed as appro-\npriate for the case of noisy instances.)\n7.3 An Example\nWe illustrate how the algorithm works by returning to our example of airline\n\ufb02ights. Consider the portion of an airline route map, shown in Fig. 7.3. Cities\nA, B, and C are hub cities, and we know that there are nonstop \ufb02ights between\nall hub cities (even those not shown on this portion of the route map). The other'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 103, 'page_label': '104'}, page_content='7.3. AN EXAMPLE 95\ncities are satellites of one of the hubs, and we know that there are nonstop\n\ufb02ights between each satellite city and its hub. The learning program is given a\nset of positive instances, \u039e +, of pairs of cities between which there are nonstop\n\ufb02ights and a set of negative instances, \u039e\u2212, of pairs of cities between which there\nare not nonstop \ufb02ights. \u039e + contains just the pairs:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nFor our example, we will assume that \u039e\u2212contains all those pairs of cities shown\nin Fig. 7.3 that are not in \u039e + (a type of closed-world assumption).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 103, 'page_label': '104'}, page_content='These are:\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<B,C 1 >,<B,C 2 >,\n<B,A 1 >,<B,A 2 >,<C,A 1 >,<C,A 2 >,<C,B 1 >,<C,B 2 >,\n<B 1,A>,<B 2,A>,<C 1,A>,<C 2,A>,<C 1,B >,<C 2,B >,\n<A1,B >,<A2,B >,<A1,C >,<A2,C >,<B 1,C >,<B 2,C >}\nThere may be other cities not shown on this map, so the training set does not\nnecessarily exhaust all the cities. A\nB\nC\nC1\nC2\nB1 B2\nA1\nA2\nFigure 7.3: Part of an Airline Route Map\nWe want the learning program to induce a program for computing the value\nof the relation Nonstop. The training set, \u039e, can be thought of as a partial'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 104, 'page_label': '105'}, page_content='96 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\ndescription of this relation in extensional formit explicitly names some pairs\nin the relation and some pairs not in the relation. We desire to learn the\nNonstop relation as a logic program in terms of the background relations, Hub\nand Satellite, which are also given in extensional form. Doing so will give us\na more compact, intensional, description of the relation, and this description\ncould well generalize usefully to other cities not mentioned in the map. We assume the learning program has the following extensional de\ufb01nitions of\nthe relations Hub and Satellite:\nHub\n{<A>,<B >,<C > }\nAll other cities mentioned in the map are assumed not in the relation Hub. We\nwill use the notation Hub(x) to express that the city named xis in the relation\nHub. Satellite\n{<A1,A,>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nAll other pairs of cities mentioned in the map are not in the relation Satellite. We will use the notation Satellite(x,y) to express that the pair < x,y >is\nin the relation Satellite. Knowing that the predicate Nonstop is a two-place predicate, the inner loop\nof our algorithm initializes the \ufb01rst clause to Nonstop(x,y) :- . This clause\nis not necessary because it covers all the negative examples (since it covers all\nexamples).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 104, 'page_label': '105'}, page_content='So we must add a literal to its (empty) body. Suppose (selecting\na literal from the re\ufb01nement graph) the algorithm adds Hub(x). The following\npositive instances in \u039e are covered by Nonstop(x,y) :- Hub(x):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}\nTo compute this covering, we interpret the logic program Nonstop(x,y) :-\nHub(x) for all pairs of cities in \u039e, using the pairs given in the background\nrelation Hub as ground facts. The following negative instances are also covered:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 105, 'page_label': '106'}, page_content='7.3. AN EXAMPLE 97\n{<A,B 1 >,<A,B 2 >,<A,C 1 >,<A,C 2 >,<C,A 1 >,<C,A 2 >,\n<C,B 1 >,<C,B 2 >,<B,A 1 >,<B,A 2 >,<B,C 1 >,<B,C 2 >}\nThus, the clause is not yet necessary and another literal must be added. Sup-\npose we next add Hub(y). The following positive instances are covered by\nNonstop(x,y) :- Hub(x), Hub(y):\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B > }\nThere are no longer any negative instances in \u039e covered so the clause\nNonstop(x,y) :- Hub(x), Hub(y) is necessary, and we can terminate the \ufb01rst\npass through the inner loop. But the program, \u03c0, consisting of just this clause is not su\ufb03cient. These\npositive instances are not covered by the clause:\n{<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nThe positive instances that were covered byNonstop(x,y) :- Hub(x), Hub(y)\nare removed from \u039e to form the \u039e cur to be used in the next pass through the\ninner loop. \u039e cur consists of all the negative instances in \u039e plus the positive\ninstances (listed above) that are not yet covered.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 105, 'page_label': '106'}, page_content='In order to attempt to cover\nthem, the inner loop creates another clause c, initially set to Nonstop(x,y)\n:- . This clause covers all the negative instances, and so we must add liter-\nals to make it necessary. Suppose we add the literal Satellite(x,y). The\nclause Nonstop(x,y) :- Satellite(x,y) covers no negative instances, so it is\nnecessary. It does cover the following positive instances in \u039e cur:\n{<A1,A>,<A 2,A>,<B 1,B >,<B 2,B >,<C 1,C >,<C 2,C >}\nThese instances are removed from \u039ecur for the next pass through the inner loop. The program now contains two clauses:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\nThis program is not yet su\ufb03cient since it does not cover the following positive\ninstances:\n{<A,A 1 >,<A,A 2 >,<B,B 1 >,<B,B 2 >,<C,C 1 >,<C,C 2 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 106, 'page_label': '107'}, page_content='98 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nDuring the next pass through the inner loop, we add the clauseNonstop(x,y)\n:- Satellite(y,x). This clause is necessary, and since the program containing\nall three clauses is now su\ufb03cient, the procedure terminates with:\nNonstop(x,y) :- Hub(x), Hub(y)\n:- Satellite(x,y)\n:- Satellite(y,x)\nSince each clause is necessary, and the whole program is su\ufb03cient, the pro-\ngram is also consistent with all instances of the training set. Note that this\nprogram can be applied (perhaps with good generalization) to other cities be-\nsides those in our partial mapso long as we can evaluate the relations Hub and\nSatellite for these other cities. In the next section, we show how the technique\ncan be extended to use recursion on the relation we are inducing. With that\nextension, the method can be used to induce more general logic programs. 7.4 Inducing Recursive Programs\nTo induce a recursive program, we allow the addition of a literal having the\nsame predicate letter as that in the head of the clause. Various mechanisms\nmust be used to ensure that such a program will terminate; one such is to make\nsure that the new literal has di\ufb00erent variables than those in the head literal. The process is best illustrated with another example. Our example continues\nthe one using the airline map, but we make the map somewhat simpler in order\nto reduce the size of the extensional relations used. Consider the map shown\nin Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 106, 'page_label': '107'}, page_content='7.4. Again, B and C are hub cities, B1 and B2 are satellites of B, C1\nand C2 are satellites of C. We have introduced two new cities, B3 and C3. No\n\ufb02ights exist between these cities and any other citiesperhaps there are only\nbus routes as shown by the grey lines in the map. We now seek to learn a program for Canfly(x,y) that covers only those\npairs of cities that can be reached by one or more nonstop \ufb02ights. The relation\nCanfly is satis\ufb01ed by the following pairs of postive instances:\n{<B 1,B >,<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,\n<B,B 1 >,<B 2,B1 >,<C,B 1 >,<C 1,B1 >,<C 2,B1 >,\n<B 2,B >,<B 2,C >,<B 2,C1 >,<B 2,C2 >,<B,B 2 >,\n<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C >,<B,C 1 >,\n<B,C 2 >,<C,B >,<C 1,B >,<C 2,B >,<C,C 1 >,\n<C,C 2 >,<C 1,C >,<C 2,C >,<C 1,C2 >,<C 2,C1 >}'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 107, 'page_label': '108'}, page_content='7.4. INDUCING RECURSIVE PROGRAMS 99\nB\nC\nC1\nC2\nB1\nB2\nB3\nC3\nFigure 7.4: Another Airline Route Map\nUsing a closed-world assumption on our map, we take the negative instances of\nCanfly to be:\n{<B 3,B2 >,<B 3,B >,<B 3,B1 >,<B 3,C >,<B 3,C1 >,\n<B 3,C2 >,<B 3,C3 >,<B 2,B3 >,<B,B 3 >,<B 1,B3 >,\n<C,B 3 >,<C 1,B3 >,<C 2,B3 >,<C 3,B3 >,<C 3,B2 >,\n<C 3,B >,<C 3,B1 >,<C 3,C >,<C 3,C1 >,<C 3,C2 >,\n<B 2,C3 >,<B,C 3 >,<B 1,C3 >,<C,C 3 >,<C 1,C3 >,\n<C 2,C3 >}\nWe will induce Canfly(x,y) using the extensionally de\ufb01ned background\nrelation Nonstop given earlier (modi\ufb01ed as required for our reduced airline map)\nand Canfly itself (recursively). As before, we start with the empty program and proceed to the inner loop\nto construct a clause that is necessary.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 107, 'page_label': '108'}, page_content='Suppose that the inner loop adds the\nbackground literal Nonstop(x,y). The clause Canfly(x,y) :- Nonstop(x,y)\nis necessary; it covers no negative instances. But it is not su\ufb03cient because it\ndoes not cover the following positive instances:\n{<B 1,B2 >,<B 1,C >,<B 1,C1 >,<B 1,C2 >,<B 2,B1 >,\n<C,B 1 >,<C 1,B1 >,<C 2,B1 >,<B 2,C >,<B 2,C1 >,\n<B 2,C2 >,<C,B 2 >,<C 1,B2 >,<C 2,B2 >,<B,C 1 >,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 108, 'page_label': '109'}, page_content='100 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n<B,C 2 >,<C 1,B >,<C 2,B >,<C 1,C2 >,<C 2,C1 >}\nThus, we must add another clause to the program. In the inner loop, we \ufb01rst\ncreate the clause Canfly(x,y) :- Nonstop(x,z) which introduces the new\nvariable z. We digress brie\ufb02y to describe how a program containing a clause\nwith unbound variables in its body is interpreted. Suppose we try to inter-\npret it for the positive instance Canfly(B1,B2).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 108, 'page_label': '109'}, page_content='The interpreter attempts to\nestablish Nonstop(B1,z) for some z. Since Nonstop(B1, B), for example, is\na background fact, the interpreter returns Twhich means that the instance\n< B1,B2 > is covered. Suppose now, we attempt to interpret the clause\nfor the negative instance Canfly(B3,B). The interpreter attempts to estab-\nlish Nonstop(B3,z) for some z. There are no background facts that match, so\nthe clause does not cover < B3,B >. Using the interpreter, we see that the\nclause Canfly(x,y) :- Nonstop(x,z) covers all of the positive instances not\nalready covered by the \ufb01rst clause, but it also covers many negative instances\nsuch as <B 2,B3 >, and <B,B 3 >. So the inner loop must add another literal. This time, suppose it adds Canfly(z,y) to yield the clause Canfly(x,y) :-\nNonstop(x,z), Canfly(z,y). This clause is necessary; no negative instances\nare covered. The program is now su\ufb03cient and consistent; it is:\nCanfly(x,y) :- Nonstop(x,y)\n:- Nonstop(x,z), Canfly(z,y)\n7.5 Choosing Literals to Add\nOne of the \ufb01rst practical ILP systems was Quinlans FOIL [Quinlan, 1990]. A\nmajor problem involves deciding how to select a literal to add in the inner loop\n(from among the literals that are allowed). In FOIL, Quinlan suggested that\ncandidate literals can be compared using an information-like measuresimilar\nto the measures used in inducing decision trees. A measure that gives the same\ncomparison as does Quinlans is based on the amount by which adding a literal\nincreases the odds that an instance drawn at random from those covered by the\nnew clause is a positive instance beyond what these odds were before adding\nthe literal. Let p be an estimate of the probability that an instance drawn at random\nfrom those covered by a clause before adding the literal is a positive instance. That is, p=(number of positive instances covered by the clause)/(total number\nof instances covered by the clause). It is convenient to express this probability\nin odds form. The odds, o, that a covered instance is positive is de\ufb01ned to\nbe o = p/(1 \u2212p). Expressing the probability in terms of the odds, we obtain\np= o/(1 + o).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 109, 'page_label': '110'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION101\nAfter selecting a literal, l, to add to a clause, some of the instances previously\ncovered are still covered; some of these are positive and some are negative. Let\npl denote the probability that an instance drawn at random from the instances\ncovered by the new clause (with l added) is positive. The odds will be denoted\nby ol. We want to select a literal, l, that gives maximal increase in these\nodds. That is, if we de\ufb01ne \u03bbl = ol/o, we want a literal that gives a high\nvalue of \u03bbl. Specializing the clause in such a way that it fails to cover many of\nthe negative instances previously covered but still covers most of the positive\ninstances previously covered will result in a high value of \u03bbl. (It turns out that\nthe value of Quinlans information theoretic measure increases monotonically\nwith \u03bbl, so we could just as well use the latter instead.)\nBesides \ufb01nding a literal with a high value of \u03bbl, Quinlans FOIL system also\nrestricts the choice to literals that:\na) contain at least one variable that has already been used,\nb) place further restrictions on the variables if the literal selected has the\nsame predicate letter as the literal being induced (in order to prevent in\ufb01nite\nrecursion), and\nc) survive a pruning test based on the values of \u03bbl for those literals selected\nso far. We refer the reader to Quinlans paper for further discussion of these points. Quinlan also discusses post-processing pruning methods and presents experi-\nmental results of the method applied to learning recursive relations on lists, on\nlearning rules for chess endgames and for the card game Eleusis, and for some\nother standard tasks mentioned in the machine learning literature. The reader should also refer to [Pazzani & Kibler, 1992,\nLavra\u02c7 c & D\u02c7 zeroski, 1994, Muggleton, 1991, Muggleton, 1992].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 109, 'page_label': '110'}, page_content='Discuss preprocessing,\npostprocessing, bottom-up\nmethods, and LINUS. 7.6 Relationships Between ILP and Decision\nTree Induction\nThe generic ILP algorithm can also be understood as a type of decision tree\ninduction. Recall the problem of inducing decision trees when the values of\nattributes are categorical. When splitting on a single variable, the split at\neach node involves asking to which of several mutually exclusive and exhaustive\nsubsets the value of a variable belongs. For example, if a node tested the variable\nxi, and if xi could have values drawn from {A,B,C,D,E,F }, then one possible\nsplit (among many) might be according to whether the value of xi had as value\none of {A,B,C }or one of {D,E,F }. It is also possible to make a multi-variate splittesting the values of two or\nmore variables at a time. With categorical variables, an n-variable split would\nbe based on which of several n-ary relations the values of the variables satis\ufb01ed. For example, if a node tested the variables xi and xj, and if xi and xj both\ncould have values drawn from {A,B,C,D,E,F }, then one possible binary split'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 110, 'page_label': '111'}, page_content='102 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\n(among many) might be according to whether or not < xi,xj > satis\ufb01ed the\nrelation {<A,C >,<C,D> }. (Note that our subset method of forming single-\nvariable splits could equivalently have been framed using 1-ary relationswhich\nare usually called properties.)\nIn this framework, the ILP problem is as follows: We are given a training set,\n\u039e, of positively and negatively labeled patterns whose components are drawn\nfrom a set of variables {x,y,z,... }. The positively labeled patterns in \u039e form an\nextensional de\ufb01nition of a relation, R. We are also given background relations,\nR1,...,R k, on various subsets of these variables. (That is, we are given sets\nof tuples that are in these relations.) We desire to construct an intensional\nde\ufb01nition of Rin terms of the R1,...,R k, such that all of the positively labeled\npatterns in \u039e are satis\ufb01ed by R and none of the negatively labeled patterns\nare. The intensional de\ufb01nition will be in terms of a logic program in which the\nrelation R is the head of a set of clauses whose bodies involve the background\nrelations. The generic ILP algorithm can be understood as decision tree induction,\nwhere each node of the decision tree is itself a sub-decision tree, and each sub-\ndecision tree consists of nodes that make binary splits on several variables using\nthe background relations, Ri. Thus we will speak of a top-level decision tree\nand various sub-decision trees. (Actually, our decision trees will be decision\nlistsa special case of decision trees, but we will refer to them as trees in our\ndiscussions.)\nIn broad outline, the method for inducing an intensional version of the rela-\ntion R is illustrated by considering the decision tree shown in Fig. 7.5.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 110, 'page_label': '111'}, page_content='In this\ndiagram, the patterns in \u039e are \ufb01rst \ufb01ltered through the decision tree in top-\nlevel node 1. The background relation R1 is satis\ufb01ed by some of these patterns;\nthese are \ufb01ltered to the right (to relation R2), and the rest are \ufb01ltered to the\nleft (more on what happens to these later). Right-going patterns are \ufb01ltered\nthrough a sequence of relational tests until only positively labeled patterns sat-\nisfy the last relationin this case R3. That is, the subset of patterns satisfying\nall the relations, R1, R2, and R3 contains only positive instances from \u039e.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 110, 'page_label': '111'}, page_content='(We\nmight say that this combination of tests is necessary. They correspond to the\nclause created in the \ufb01rst pass through the inner loop of the generic ILP algo-\nrithm.) Let us call the subset of patterns satisfying these relations, \u039e 1; these\nsatisfy Node 1 at the top level. All other patterns, that is {\u039e \u2212\u039e1}= \u039e2 are\n\ufb01ltered to the left by Node 1. \u039e2 is then \ufb01ltered by top-level Node 2 in much the same manner, so that\nNode 2 is satis\ufb01ed only by the positively labeled samples in \u039e 2. We continue\n\ufb01ltering through top-level nodes until only the negatively labeled patterns fail to\nsatisfy a top node. In our example, \u039e 4 contains only negatively labeled patterns\nand the union of \u039e 1 and \u039e3 contains all the positively labeled patterns. The\nrelation, R, that distinguishes positive from negative patterns in \u039e is then given\nin terms of the following logic program:\nR :- R1, R2, R3'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 111, 'page_label': '112'}, page_content='7.6. RELATIONSHIPS BETWEEN ILP AND DECISION TREE INDUCTION103\nR1\nR2\nR3\nT\nT\nT\nF\nF\nF\nT\nF\nR4\nR5\nT\nT\nF\nF\nTF\nU\nU1\nU2 = U < U1\nU3U4= U2 < U3\nNode 1\nNode 2\n(only positive\ninstances\nsatisfy all three\ntests)\n(only positivel\ninstances satisfy\nthese two tests)\n(only negative\ninstances)\nFigure 7.5: A Decision Tree for ILP\n:- R4, R5\nIf we apply this sort of decision-tree induction procedure to the problem\nof generating a logic program for the relation Nonstop (refer to Fig. 7.3), we\nobtain the decision tree shown in Fig. 7.6. The logic program resulting from\nthis decision tree is the same as that produced by the generic ILP algorithm. In setting up the problem, the training set, \u039e can be expressed as a set of 2-\ndimensional vectors with components xand y.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 111, 'page_label': '112'}, page_content='The values of these components\nrange over the cities {A,B,C,A 1,A2,B1,B2,C1,C2}except (for simplicity)\nwe do not allow patterns in which x and y have the same value. As before, the\nrelation, Nonstop, contains the following pairs of cities, which are the positive\ninstances:\n{<A,B >,<A,C >,<B,C >,<B,A>,<C,A>,<C,B >,\n<A,A 1 >,<A,A 2 >,<A 1,A>,<A 2,A>,<B,B 1 >,<B,B 2 >,\n<B 1,B >,<B 2,B >,<C,C 1 >,<C,C 2 >,<C 1,C >,<C 2,C >}\nAll other pairs of cities named in the map of Fig. 7.3 (using the closed world\nassumption) are not in the relation Nonstop and thus are negative instances. Because the values of xand y are categorical, decision-tree induction would\nbe a very di\ufb03cult taskinvolving as it does the need to invent relations on'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 112, 'page_label': '113'}, page_content='104 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING\nx and y to be used as tests. But with the background relations, Ri (in this\ncase Hub and Satellite), the problem is made much easier. We select these\nrelations in the same way that we select literals; from among the available tests,\nwe make a selection based on which leads to the largest value of \u03bbRi.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 112, 'page_label': '113'}, page_content='7.7 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 113, 'page_label': '114'}, page_content='7.7. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 105\nHub(x) T\nF\nU\nNode 1\n(top level)\n{<A,B>, <A,C>,\n<B,C>, <B,A>,\n<C,A>, <C,B>}\nHub(y) T\nT\nFNode 2\n(top level)\nSatellite(x,y)\nF T\nT {<A1,A>, <A2,A>, <B1,B>,\n<B2,B>, <C1,C>, <C2,C>}\nF\n{<A,A1>, <A,A2>,<B,B1>,\n<B,B2>,  <C,C1>, <C,C2>}\nSatellite(y,x)\nF\nF\nT\nNode 3\n(top level)\nT\n{Only negative instances}\n(Only positive instances)\n(Only positive instances)\n(Only positive instances)\nF\nFigure 7.6: A Decision Tree for the Airline Route Problem'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 114, 'page_label': '115'}, page_content='106 CHAPTER 7. INDUCTIVE LOGIC PROGRAMMING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 115, 'page_label': '116'}, page_content='Chapter 8\nComputational Learning\nTheory\nIn chapter one we posed the problem of guessing a function given a set of\nsample inputs and their values. We gave some intuitive arguments to support\nthe claim that after seeing only a small fraction of the possible inputs (and\ntheir values) that we could guess almost correctly the values of most subsequent\ninputsif we knew that the function we were trying to guess belonged to an\nappropriately restricted subset of functions. That is, a given training set of\nsample patterns might be adequate to allow us to select a function, consistent\nwith the labeled samples , from among a restricted set of hypotheses such that\nwith high probability the function we select will be approximately correct (small\nprobability of error) on subsequent samples drawn at random according to the\nsame distribution from which the labeled samples were drawn. This insight\nled to the theory of probably approximately correct (PAC) learninginitially\ndeveloped by Leslie Valiant [Valiant, 1984]. We present here a brief description\nof the theory for the case of Boolean functions. [Dietterich, 1990, Haussler, 1988,\nHaussler, 1990] give nice surveys of the important results.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 115, 'page_label': '116'}, page_content='Other overviews? 8.1 Notation and Assumptions for PAC Learn-\ning Theory\nWe assume a training set \u039e of n-dimensional vectors, Xi, i = 1 ,...,m , each\nlabeled (by 1 or 0) according to a target function, f, which is unknown to\nthe learner. The probability of any given vector X being in \u039e, or later being\npresented to the learner, is P(X). The probability distribution, P, can be\narbitrary. (In the literature of PAC learning theory, the target function is usually\ncalled the target concept and is denoted by c, but to be consistent with our\nprevious notation we will continue to denote it by f.) Our problem is to guess\n107'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 116, 'page_label': '117'}, page_content='108 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\na function, h(X), based on the labeled samples in \u039e. In PAC theory such a\nguessed function is called the hypothesis. We assume that the target function\nis some element of a set of functions, C. We also assume that the hypothesis,\nh, is an element of a set, H, of hypotheses, which includes the set, C, of target\nfunctions. His called the hypothesis space. In general, h wont be identical to f, but we can strive to have the value of\nh(X) = the value of f(X) for most Xs. That is, we want hto be approximately\ncorrect. To quantify this notion, we de\ufb01ne the error of h, \u03b5h, as the probability\nthat an X drawn randomly according to P will be misclassi\ufb01ed:\n\u03b5h =\n\u2211\n[X:h(X)\u0338=f(X)]\nP(X)\nBoldface symbols need to be\nsmaller when they are subscripts in\nmath environments. We say that h is approximately (except for \u03b5 ) correct if \u03b5h \u2264\u03b5, where \u03b5 is the\naccuracy parameter. Suppose we are able to \ufb01nd anhthat classi\ufb01es all mrandomly drawn training\nsamples correctly; that is, h is consistent with this randomly selected training\nset, \u039e. If m is large enough, will such an h be approximately correct (and\nfor what value of \u03b5)? On some training occasions, using m randomly drawn\ntraining samples, such an h might turn out to be approximately correct (for a\ngiven value of \u03b5), and on others it might not. We say that his probably (except\nfor \u03b4) approximately correct (PAC) if the probability that it is approximately\ncorrect is greater than 1\u2212\u03b4, where \u03b4is the con\ufb01dence parameter. We shall show\nthat if m is greater than some bound whose value depends on \u03b5 and \u03b4, such an\nh is guaranteed to be probably approximately correct. In general, we say that a learning algorithm PAC-learns functions from Cin\nterms of Hi\ufb00 for every function f\u03f5 C, it outputs a hypothesis h\u03f5 H, such that\nwith probability at least (1 \u2212\u03b4), \u03b5h \u2264\u03b5. Such a hypothesis is called probably\n(except for \u03b4) approximately (except for \u03b5) correct. We want learning algorithms that are tractable, so we want an algorithm\nthat PAC-learns functions in polynomial time. This can only be done for certain\nclasses of functions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 116, 'page_label': '117'}, page_content='If there are a \ufb01nite number of hypotheses in a hypothesis\nset (as there are for many of the hypothesis sets we have considered), we could\nalways produce a consistent hypothesis from this set by testing all of them\nagainst the training data. But if there are an exponential number of hypotheses,\nthat would take exponential time. We seek training methods that produce\nconsistent hypotheses in less time.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 116, 'page_label': '117'}, page_content='The time complexities for various hypothesis\nsets have been determined, and these are summarized in a table to be presented\nlater. A class, C, is polynomially PAC learnable in terms of Hprovided there exists\na polynomial-time learning algorithm (polynomial in the number of samples\nneeded, m, in the dimension, n, in 1 /\u03b5, and in 1 /\u03b4) that PAC-learns functions\nin Cin terms of H. Initial work on PAC assumed H= C, but it was later shown that some func-\ntions cannot be polynomially PAC-learned under such an assumption (assuming'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 117, 'page_label': '118'}, page_content='8.2. PAC LEARNING 109\nP \u0338= NP)but can be polynomially PAC-learned if His a strict superset of C! Also our de\ufb01nition does not specify the distribution, P, from which patterns\nare drawn nor does it say anything about the properties of the learning algo-\nrithm. Since Cand Hdo not have to be identical, we have the further restrictive\nde\ufb01nition:\nA properly PAC-learnableclass is a classCfor which there exists an algorithm\nthat polynomially PAC-learns functions from Cin terms of C. 8.2 PAC Learning\n8.2.1 The Fundamental Theorem\nSuppose our learning algorithm selects some hrandomly from among those that\nare consistent with the values of f on the mtraining patterns.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 117, 'page_label': '118'}, page_content='The probability\nthat the error of this randomly selected his greater than some \u03b5, with hconsis-\ntent with the values of f(X) for minstances of X (drawn according to arbitrary\nP), is less than or equal to |H|e\u2212\u03b5m, where |H|is the number of hypotheses in\nH. We state this result as a theorem [Blumer, et al., 1987]:\nTheorem 8.1 (Blumer, et al.) Let Hbe any set of hypotheses, \u039e be a set of\nm \u22651 training examples drawn independently according to some distribution\nP, f be any classi\ufb01cation function in H, and \u03b5> 0. Then, the probability that\nthere exists a hypothesis hconsistent with f for the members of \u039e but with error\ngreater than \u03b5 is at most |H|e\u2212\u03b5m. Proof:\nConsider the set of all hypotheses, {h1,h2,...,h i,...,h S}, in H, where S =\n|H|. The error for hi is \u03b5hi= the probability that hi will classify a pattern in\nerror (that is, di\ufb00erently than f would classify it). The probability that hi will\nclassify a pattern correctly is (1\u2212\u03b5hi). A subset, HB, of Hwill have error greater\nthan \u03b5. We will call the hypotheses in this subset bad. The probability that any\nparticular one of these bad hypotheses, sayhb, would classify a pattern correctly\nis (1\u2212\u03b5hb). Since \u03b5hb >\u03b5, the probability that hb (or any other bad hypothesis)\nwould classify a pattern correctly is less than (1 \u2212\u03b5). The probability that it\nwould classify all m independently drawn patterns correctly is then less than\n(1 \u2212\u03b5)m. That is,\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB] \u2264(1 \u2212\u03b5)m. prob[some h \u03f5HB classi\ufb01es all m patterns correctly]\n= \u2211\nhb \u03f5 HB\nprob[hb classi\ufb01es all m patterns correctly |hb \u03f5 HB]\n\u2264K(1 \u2212\u03b5)m, where K = |HB|.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 118, 'page_label': '119'}, page_content='110 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nThat is,\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n\u2264K(1 \u2212\u03b5)m. Since K \u2264|H| and (1 \u2212\u03b5)m \u2264e\u2212\u03b5m, we have:\nprob[there is a bad hypothesis that classi\ufb01es all m patterns correctly]\n= prob[there is a hypothesis with error >\u03b5 and that classi\ufb01es all mpatterns\ncorrectly] \u2264|H|e\u2212\u03b5m. QED\nA corollary of this theorem is:\nCorollary 8.2 Given m \u2265 (1/\u03b5)(ln |H|+ ln(1/\u03b4)) independent samples, the\nprobability that there exists a hypothesis in Hthat is consistent with f on these\nsamples and has error greater than \u03b5 is at most \u03b4. Proof: We are to \ufb01nd a bound on m that guarantees that\nprob[there is a hypothesis with error > \u03b5and that classi\ufb01es all m patterns\ncorrectly] \u2264 \u03b4. Thus, using the result of the theorem, we must show that\n|H|e\u2212\u03b5m \u2264\u03b4. Taking the natural logarithm of both sides yields:\nln |H|\u2212\u03b5m\u2264ln \u03b4\nor\nm\u2265(1/\u03b5)(ln |H|+ ln(1/\u03b4))\nQED\nThis corollary is important for two reasons. First it clearly states that we\ncan select any hypothesis consistent with the m samples and be assured that\nwith probability (1 \u2212\u03b4) its error will be less than \u03b5. Also, it shows that in\norder for mto increase no more than polynomially with n, |H|can be no larger\nthan 2O(nk). No class larger than that can be guaranteed to be properly PAC\nlearnable. Here is a possible point of confusion: The bound given in the corollary is\nan upper bound on the value of mneeded to guarantee polynomial probably ap-\nproximately correct learning. Values of mgreater than that bound are su\ufb03cient\n(but might not be necessary).'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 118, 'page_label': '119'}, page_content='We will present a lower (necessary) bound later\nin the chapter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 119, 'page_label': '120'}, page_content='8.2. PAC LEARNING 111\n8.2.2 Examples\nTerms\nLet Hbe the set of terms (conjunctions of literals). Then, |H|= 3n, and\nm\u2265(1/\u03b5)(ln(3n) + ln(1/\u03b4))\n\u2265(1/\u03b5)(1.1n+ ln(1/\u03b4))\nNote that the bound on m increases only polynomially with n, 1/\u03b5, and 1/\u03b4. For n= 50, \u03b5= 0.01 and \u03b4= 0.01, m\u22655,961 guarantees PAC learnability. In order to show that terms are properly PAC learnable , we additionally\nhave to show that one can \ufb01nd in time polynomial in m and n a hypothesis\nh consistent with a set of m patterns labeled by the value of a term. The\nfollowing procedure for \ufb01nding such a consistent hypothesis requires O(nm)\nsteps (adapted from [Dietterich, 1990, page 268]):\nWe are given a training sequence, \u039e, of m examples. Find the \ufb01rst pattern,\nsay X1, in that list that is labeled with a 1. Initialize a Boolean function,\nh, to the conjunction of the n literals corresponding to the values of the n\ncomponents of X1. (Components with value 1 will have corresponding positive\nliterals; components with value 0 will have corresponding negative literals.) If\nthere are no patterns labeled by a 1, we exit with the null concept ( h \u22610 for\nall patterns). Then, for each additional pattern, Xi, that is labeled with a 1,\nwe delete from h any Boolean variables appearing in Xi with a sign di\ufb00erent\nfrom their sign in h. After processing all the patterns labeled with a 1, we check\nall of the patterns labeled with a 0 to make sure that none of them is assigned\nvalue 1 by h. If, at any stage of the algorithm, any patterns labeled with a 0\nare assigned a 1 by h, then there exists no term that consistently classi\ufb01es the\npatterns in \u039e, and we exit with failure. Otherwise, we exit with h. Change this paragraph if this\nalgorithm was presented in Chapter\nThree.As an example, consider the following patterns, all labeled with a 1 (from\n[Dietterich, 1990]):\n(0,1,1,0)\n(1,1,1,0)\n(1,1,0,0)\nAfter processing the \ufb01rst pattern, we have h = x1x2x3x4; after processing the\nsecond pattern, we have h = x2x3x4; \ufb01nally, after the third pattern, we have\nh= x2x4. Linearly Separable Functions\nLet Hbe the set of all linearly separable functions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 119, 'page_label': '120'}, page_content='Then, |H|\u2264 2n2\n, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 120, 'page_label': '121'}, page_content='112 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nm\u2265(1/\u03b5)\n(\nn2 ln 2 + ln(1/\u03b4)\n)\nAgain, note that the bound on m increases only polynomially with n, 1/\u03b5, and\n1/\u03b4. For n= 50, \u03b5= 0.01 and \u03b4 = 0.01, m\u2265173,748 guarantees PAC learnabil-\nity. To show that linearly separable functions are properly PAC learnable , we\nwould have additionally to show that one can \ufb01nd in time polynomial in mand\nna hypothesis hconsistent with a set of mlabeled linearly separable patterns.Linear programming is polynomial. 8.2.3 Some Properly PAC-Learnable Classes\nSome properly PAC-learnable classes of functions are given in the following\ntable. (Adapted from [Dietterich, 1990, pages 262 and 268] which also gives\nreferences to proofs of some of the time complexities.)\nH |H| Time Complexity P. Learnable? terms 3n polynomial yes\nk-term DNF 2O(kn) NP-hard no\n(k disjunctive terms)\nk-DNF 2O(nk) polynomial yes\n(a disjunction of k-sized terms)\nk-CNF 2O(nk) polynomial yes\n(a conjunction of k-sized clauses)\nk-DL 2O(nkklg n) polynomial yes\n(decision lists with k-sized terms)\nlin. sep. 2O(n2) polynomial yes\nlin. sep. with (0,1) weights ?'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 120, 'page_label': '121'}, page_content='NP-hard no\nk-2NN ? NP-hard no\nDNF 22n\npolynomial no\n(all Boolean functions)\n(Members of the class k-2NN are two-layer, feedforward neural networks with\nexactly k hidden units and one output unit.)\nSummary: In order to show that a class of functions is Properly PAC-\nLearnable :\na. Show that there is an algorithm that produces a consistent hypothesis on\nm n-dimensional samples in time polynomial in m and n. b. Show that the sample size, m, needed to ensure PAC learnability is polyno-\nmial (or better) in (1/\u03b5), (1/\u03b4), and nby showing that ln|H|is polynomial\nor better in the number of dimensions.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 121, 'page_label': '122'}, page_content='8.3.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 121, 'page_label': '122'}, page_content='THE VAPNIK-CHERVONENKIS DIMENSION 113\nAs hinted earlier, sometimes enlarging the class of hypotheses makes learning\neasier. For example, the table above shows that k-CNF is PAC learnable, but\nk-term-DNF is not. And yet, k-term-DNF is a subclass of k-CNF! So, even if\nthe target function were in k-term-DNF, one would be able to \ufb01nd a hypothesis\nin k-CNF that is probably approximately correct for the target function. Sim-\nilarly, linearly separable functions implemented by TLUs whose weight values\nare restricted to 0 and 1 are not properly PAC learnable, whereas unrestricted\nlinearly separable functions are. It is possible that enlarging the space of hy-\npotheses makes \ufb01nding one that is consistent with the training examples easier. An interesting question is whether or not the class of functions ink-2NN is poly-\nnomially PAC learnable if the hypotheses are drawn from k\u2032-2NN with k\u2032>k . (At the time of writing, this matter is still undecided.)\nAlthough PAC learning theory is a powerful analytic tool, it (like complexity\ntheory) deals mainly with worst-case results. The fact that the class of two-\nlayer, feedforward neural networks is not polynomially PAC learnable is more an\nattack on the theory than it is on the networks, which have had many successful\napplications. As [Baum, 1994, page 416-17] says:  ...'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 121, 'page_label': '122'}, page_content='humans are capable of\nlearning in the natural world. Therefore, a proof within some model of learning\nthat learning is not feasible is an indictment of the model. We should examine\nthe model to see what constraints can be relaxed and made more realistic.\n8.3 The Vapnik-Chervonenkis Dimension\n8.3.1 Linear Dichotomies\nConsider a set, H, of functions, and a set, \u039e, of (unlabeled) patterns. One\nmeasure of the expressive power of a set of hypotheses, relative to \u039e, is its\nability to make arbitrary classi\ufb01cations of the patterns in \u039e. 1 If there are m\npatterns in \u039e, there are 2 m di\ufb00erent ways to divide these patterns into two\ndisjoint and exhaustive subsets. We say there are 2 m di\ufb00erent dichotomies of\n\u039e. If \u039e were to include all of the 2 n Boolean patterns, for example, there are\n22n\nways to dichotomize them, and (of course) the set of all possible Boolean\nfunctions dichotomizes them in all of these ways. But a subset,H, of the Boolean\nfunctions might not be able to dichotomize an arbitrary set, \u039e, of m Boolean\npatterns in all 2 m ways. In general (that is, even in the non-Boolean case), we\nsay that if a subset, H, of functions can dichotomize a set, \u039e, of m patterns in\nall 2m ways, then Hshatters \u039e. As an example, consider a set \u039e of m patterns in the n-dimensional space,\nRn. (That is, the ncomponents of these patterns are real numbers.) We de\ufb01ne\na linear dichotomy as one implemented by an (n\u22121)-dimensional hyperplane in\nthe n-dimensional space. How many linear dichotomies of m patterns in n di-\nmensions are there? For example, as shown in Fig. 8.1, there are 14 dichotomies\n1And, of course, if a hypothesis drawn from a set that could make arbitrary classi\ufb01cations\nof a set of training patterns, there is little likelihood that such a hypothesis will generalize\nwell beyond the training set.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 122, 'page_label': '123'}, page_content='114 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\nof four points in two dimensions (each separating line yields two dichotomies\ndepending on whether the points on one side of the line are classi\ufb01ed as 1 or 0). (Note that even though there are an in\ufb01nite number of hyperplanes, there are,\nnevertheless, only a \ufb01nite number of ways in which hyperplanes can dichotomize\na \ufb01nite number of patterns. Small movements of a hyperplane typically do not\nchange the classi\ufb01cations of any patterns.)\n12\n3\n4\n14 dichotomies of 4 points in 2 dimensions\n5\n6\n7\nFigure 8.1: Dichotomizing Points in Two Dimensions\nThe number of dichotomies achievable by hyperplanes depends on how the\npatterns are disposed. For the maximum number of linear dichotomies, the\npoints must be in what is called general position. For m>n , we say that a set\nof m points is in general position in an n-dimensional space if and only if no\nsubset of (n+1) points lies on an (n\u22121)-dimensional hyperplane. When m\u2264n,\na set of m points is in general position if no ( m\u22122)-dimensional hyperplane\ncontains the set. Thus, for example, a set of m\u22654 points is in general position\nin a three-dimensional space if no four of them lie on a (two-dimensional) plane. We will denote the number of linear dichotomies of mpoints in general position\nin an n-dimensional space by the expression \u03a0 L(m,n). It is not too di\ufb03cult to verify that:Include the derivation.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 122, 'page_label': '123'}, page_content='\u03a0L(m,n) = 2\nn\u2211\ni=0\nC(m\u22121,i) for m>n, and\n= 2m for m\u2264n'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 123, 'page_label': '124'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 115\nwhere C(m\u22121,i) is the binomial coe\ufb03cient (m\u22121)! (m\u22121\u2212i)!i!'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 123, 'page_label': '124'}, page_content='. The table below shows some values for \u03a0 L(m,n). m n\n(no. of patterns) (dimension)\n1 2 3 4 5\n1 2 2 2 2 2\n2 4 4 4 4 4\n3 6 8 8 8 8\n4 8 14 16 16 16\n5 10 22 30 32 32\n6 12 32 52 62 64\n7 14 44 84 114 126\n8 16 58 128 198 240\nNote that the class of linear dichotomies shatters the m patterns if m\u2264n+ 1. The bold-face entries in the table correspond to the highest values of m for\nwhich linear dichotomies shatter m patterns in n dimensions. 8.3.2 Capacity\nLet Pm,n = \u03a0L(m,n)\n2m = the probability that a randomly selected dichotomy (out\nof the 2 m possible dichotomies of m patterns in n dimensions) will be linearly\nseparable. In Fig. 8.2 we plot P\u03bb(n+1),n versus \u03bb and n, where \u03bb= m/(n+ 1). Note that for large n (say n >30) how quickly Pm,n falls from 1 to 0 as\nm goes above 2( n+ 1). For m <2(n+ 1), any dichotomy of the m points is\nalmost certainly linearly separable. But for m> 2(n+ 1), a randomly selected\ndichotomy of the m points is almost certainly not linearly separable. For this\nreason m= 2(n+ 1) is called the capacity of a TLU [Cover, 1965]. Unless the\nnumber of training patterns exceeds the capacity, the fact that a TLU separates\nthose training patterns according to their labels means nothing in terms of how\nwell that TLU will generalize to new patterns. There is nothing special about\na separation found for m <2(n+ 1) patternsalmost any dichotomy of those\npatterns would have been linearly separable. To make sure that the separation\nfound is forced by the training set and thus generalizes well, it has to be the\ncase that there are very few linearly separable functions that would separate\nthe m training patterns. Analogous results about the generalizing abilities of neural networks have\nbeen developed by [Baum & Haussler, 1989] and given intuitive and experimen-\ntal justi\ufb01cation in [Baum, 1994, page 438]:\nThe results seemed to indicate the following heuristic rule holds. If\nM examples [can be correctly classi\ufb01ed by] a net withW weights (for\nM >>W), the net will make a fraction \u03b5of errors on new examples\nchosen from the same [uniform] distribution where \u03b5= W/M.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 124, 'page_label': '125'}, page_content='116 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n0.25\n0.5\n0.75\n1\n0\n1\n2\n3\n4\n10\n20\n30\n40\n50\n0\n25\n.5\n75\n1\nPh(n + 1), n\nh\nn\nFigure 8.2: Probability that a Random Dichotomy is Linearly Separable\n8.3.3 A More General Capacity Result\nCorollary 7.2 gave us an expression for the number of training patterns su\ufb03cient\nto guarantee a required level of generalizationassuming that the function we\nwere guessing was a function belonging to a class of known and \ufb01nite cardinality. The capacity result just presented applies to linearly separable functions for non-\nbinary patterns. We can extend these ideas to general dichotomies of non-binary\npatterns. In general, let us denote the maximum number of dichotomies of any set\nof m n-dimensional patterns by hypotheses in Has \u03a0H(m,n). The number of\ndichotomies will, of course, depend on the disposition of the m points in the\nn-dimensional space; we take \u03a0 H(m,n) to be the maximum over all possible\narrangements of the m points. (In the case of the class of linearly separable\nfunctions, the maximum number is achieved when the m points are in general\nposition.) For each class, H, there will be some maximum value of mfor which\n\u03a0H(m,n) = 2m, that is, for which Hshatters the m patterns. This maximum\nnumber is called the Vapnik-Chervonenkis (VC) dimension and is denoted by\nVCdim(H) [Vapnik & Chervonenkis, 1971]. We saw that for the class of linear dichotomies, VCdim( Linear) = (n+ 1). As another example, let us calculate the VC dimension of the hypothesis space\nof single intervals on the real lineused to classify points on the real line. We\nshow an example of how points on the line might be dichotomized by a single\ninterval in Fig. 8.3.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 124, 'page_label': '125'}, page_content='The set \u039e could be, for example, {0.5, 2.5, - 2.3, 3.14}, and\none of the hypotheses in our set would be [1, 4.5]. This hypothesis would label\nthe points 2.5 and 3.14 with a 1 and the points - 2.3 and 0.5 with a 0. This'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 125, 'page_label': '126'}, page_content='8.3. THE VAPNIK-CHERVONENKIS DIMENSION 117\nset of hypotheses (single intervals on the real line) can arbitrarily classify any\ntwo points. But no single interval can classify three points such that the outer\ntwo are classi\ufb01ed as 1 and the inner one as 0. Therefore the VC dimension of\nsingle intervals on the real line is 2. As soon as we have many more than 2\ntraining patterns on the real line and provided we know that the classi\ufb01cation\nfunction we are trying to guess is a single interval, then we begin to have good\ngeneralization. Figure 8.3: Dichotomizing Points by an Interval\nThe VC dimension is a useful measure of the expressive power of a hypothesis\nset. Since any dichotomy of VCdim(H) or fewer patterns in general position inn\ndimensions can be achieved by some hypothesis in H, we must have many more\nthan VCdim(H) patterns in the training set in order that a hypothesis consistent\nwith the training set is su\ufb03ciently constrained to imply good generalization. Our examples have shown that the concept of VC dimension is not restricted\nto Boolean functions. 8.3.4 Some Facts and Speculations About the VC Dimen-\nsion\n If there are a \ufb01nite number, |H|, of hypotheses in H, then:\nVCdim(H) \u2264log(|H|)\n The VC dimension of terms in n dimensions is n.  Suppose we generalize our example that used a hypothesis set of single\nintervals on the real line.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 125, 'page_label': '126'}, page_content='Now let us consider an n-dimensional feature\nspace and tests of the form Li \u2264xi \u2264Hi. We allow only one such test per\ndimension. A hypothesis space consisting of conjunctions of these tests\n(called axis-parallel hyper-rectangles) has VC dimension bounded by:\nn\u2264 VCdim \u22642n\n As we have already seen, TLUs with n inputs have a VC dimension of\nn+ 1.  [Baum, 1994, page 438] gives experimental evidence for the proposition\nthat  ... multilayer [neural] nets have a VC dimension roughly equal to\ntheir total number of [adjustable] weights.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 126, 'page_label': '127'}, page_content='118 CHAPTER 8. COMPUTATIONAL LEARNING THEORY\n8.4 VC Dimension and PAC Learning\nThere are two theorems that connect the idea of VC dimension with PAC learn-\ning [Blumer, et al., 1990]. We state these here without proof. Theorem 8.3 (Blumer, et al.) A hypothesis space His PAC learnable i\ufb00 it\nhas \ufb01nite VC dimension. Theorem 8.4 A set of hypotheses, H, is properly PAC learnable if:\na. m\u2265(1/\u03b5) max [4 lg(2/\u03b4), 8 VCdim lg(13 /\u03b5)], and\nb. if there is an algorithm that outputs a hypothesis h\u03f5 Hconsistent with the\ntraining set in polynomial (in m and n) time. The second of these two theorems improves the bound on the number of\ntraining patterns needed for linearly separable functions to one that is linear\nin n. In our previous example of how many training patterns were needed to\nensure PAC learnability of a linearly separable function if n= 50, \u03b5= 0.01, and\n\u03b4 = 0.01, we obtained m \u2265173,748. Using the Blumer, et al.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 126, 'page_label': '127'}, page_content='result we would\nget m\u226552,756. As another example of the second theorem, let us take Hto be the set of\nclosed intervals on the real line. The VC dimension is 2 (as shown previously). With n= 50, \u03b5= 0.01, and \u03b4= 0.01, m\u226516,551 ensures PAC learnability. There is also a theorem that gives a lower (necessary) bound on the number\nof training patterns required for PAC learning [Ehrenfeucht, et al., 1988]:\nTheorem 8.5 Any PAC learning algorithm must examine at least\n\u2126(1/\u03b5lg(1/\u03b4) + VCdim(H)) training patterns. The di\ufb00erence between the lower and upper bounds is\nO(log(1/\u03b5)VCdim(H)/\u03b5). 8.5 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 127, 'page_label': '128'}, page_content='Chapter 9\nUnsupervised Learning\n9.1 What is Unsupervised Learning? Consider the various sets of points in a two-dimensional space illustrated in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 127, 'page_label': '128'}, page_content='9.1. The \ufb01rst set (a) seems naturally partitionable into two classes, while the\nsecond (b) seems di\ufb03cult to partition at all, and the third (c) is problematic. Unsupervised learning uses procedures that attempt to \ufb01nd natural partitions\nof patterns. There are two stages:\n Form an R-way partition of a set \u039e of unlabeled training patterns (where\nthe value of R, itself, may need to be induced from the patterns). The\npartition separates \u039e into R mutually exclusive and exhaustive subsets,\n\u039e1,..., \u039eR, called clusters.  Design a classi\ufb01er based on the labels assigned to the training patterns by\nthe partition. We will explain shortly various methods for deciding how many clusters there\nshould be and for separating a set of patterns into that many clusters. We can\nbase some of these methods, and their motivation, on minimum-description-\nlength (MDL) principles. In that setting, we assume that we want to encode\na description of a set of points, \u039e, into a message of minimal length. One\nencoding involves a description of each point separately; other, perhaps shorter,\nencodings might involve a description of clusters of points together with how\neach point in a cluster can be described given the cluster it belongs to. The\nspeci\ufb01c techniques described in this chapter do not explicitly make use of MDL\nprinciples, but the MDL method has been applied with success. One of the\nMDL-based methods, Autoclass II [Cheeseman, et al., 1988] discovered a new\nclassi\ufb01cation of stars based on the properties of infrared sources. Another type of unsupervised learning involves \ufb01nding hierarchies of par-\ntitionings or clusters of clusters. A hierarchical partition is one in which \u039e is\n119'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 128, 'page_label': '129'}, page_content='120 CHAPTER 9. UNSUPERVISED LEARNING\na)  two clusters\nb) one cluster\nc) ? Figure 9.1: Unlabeled Patterns\ndivided into mutually exclusive and exhaustive subsets, \u039e 1,..., \u039eR; each set,\n\u039ei, ( i = 1 ,...,R ) is divided into mutually exclusive and exhaustive subsets,\nand so on. We show an example of such a hierarchical partition in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 128, 'page_label': '129'}, page_content='9.2. The hierarchical form is best displayed as a tree, as shown in Fig. 9.3. The tip\nnodes of the tree can further be expanded into their individual pattern elements. One application of such hierarchical partitions is in organizing individuals into\ntaxonomic hierarchies such as those used in botany and zoology. 9.2 Clustering Methods\n9.2.1 A Method Based on Euclidean Distance\nMost of the unsupervised learning methods use a measure of similarity between\npatterns in order to group them into clusters. The simplest of these involves\nde\ufb01ning a distance between patterns. For patterns whose features are numeric,\nthe distance measure can be ordinary Euclidean distance between two points in\nan n-dimensional space. There is a simple, iterative clustering method based on distance. It can\nbe described as follows. Suppose we have R randomly chosen cluster seekers,\nC1,..., CR. These are points in an n-dimensional space that we want to adjust\nso that they each move toward the center of one of the clusters of patterns. We present the (unlabeled) patterns in the training set, \u039e, to the algorithm'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 129, 'page_label': '130'}, page_content='9.2. CLUSTERING METHODS 121\nU11\nU12\nU21\nU22\nU23\nU31\nU32\nU11 F U12 = U1\nU21 F U22 F U23 = U2\nU31 F U32 = U3\nU1 F U2 F U3 = U\nFigure 9.2: A Hierarchy of Clusters\none-by-one. For each pattern, Xi, presented, we \ufb01nd that cluster seeker, Cj,\nthat is closest to Xi and move it closer to Xi:\nCj \u2190\u2212(1 \u2212\u03b1j)Cj + \u03b1jXi\nwhere \u03b1j is a learning rate parameter for the j-th cluster seeker; it determines\nhow far Cj is moved toward Xi.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 129, 'page_label': '130'}, page_content='Re\ufb01nements on this procedure make the cluster seekers move less far as\ntraining proceeds. Suppose each cluster seeker, Cj, has a mass, mj, equal to\nthe number of times that it has moved. As a cluster seekers mass increases it\nmoves less far towards a pattern. For example, we might set \u03b1j = 1/(1 + mj)\nand use the above rule together with mj \u2190\u2212mj+1. With this adjustment rule,\na cluster seeker is always at the center of gravity (sample mean) of the set of\npatterns toward which it has so far moved. Intuitively, if a cluster seeker ever\ngets within some reasonably well clustered set of patterns (and if that cluster\nseeker is the only one so located), it will converge to the center of gravity of\nthat cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 130, 'page_label': '131'}, page_content='122 CHAPTER 9. UNSUPERVISED LEARNING\nU\nU2\nU11 U12 U31 U32 U21 U22 U23\nU1 U3\nFigure 9.3: Displaying a Hierarchy as a Tree\nOnce the cluster seekers have converged, the classi\ufb01er implied by the now-\nlabeled patterns in \u039e can be based on a Voronoi partitioning of the space (based\non distances to the various cluster seekers). This kind of classi\ufb01cation, an ex-\nample of which is shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 130, 'page_label': '131'}, page_content='9.4, can be implemented by a linear machine. Georgy Fedoseevich Voronoi, was a\nRussian mathematician who lived\nfrom 1868 to 1909. When basing partitioning on distance, we seek clusters whose patterns are\nas close together as possible. We can measure the badness, V, of a cluster of\npatterns, {Xi}, by computing its sample variance de\ufb01ned by:\nV = (1/K)\n\u2211\ni\n(Xi \u2212M)2\nwhere M is the sample mean of the cluster, which is de\ufb01ned to be:\nM = (1/K)\n\u2211\ni\nXi\nand K is the number of points in the cluster. We would like to partition a set of patterns into clusters such that the sum of\nthe sample variances (badnesses) of these clusters is small. Of course if we have\none cluster for each pattern, the sample variances will all be zero, so we must\narrange that our measure of the badness of a partition must increase with the\nnumber of clusters. In this way, we can seek a trade-o\ufb00 between the variances of'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 131, 'page_label': '132'}, page_content='9.2. CLUSTERING METHODS 123\nC1\nC2\nC3\nSeparating boundaries\nFigure 9.4: Minimum-Distance Classi\ufb01cation\nthe clusters and the number of them in a way somewhat similar to the principle\nof minimal description length discussed earlier. Elaborations of our basic cluster-seeking procedure allow the number of clus-\nter seekers to vary depending on the distances between them and depending on\nthe sample variances of the clusters.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 131, 'page_label': '132'}, page_content='For example, if the distance, dij, between\ntwo cluster seekers, Ci and Cj, ever falls below some threshold \u03b5, then we can\nreplace them both by a single cluster seeker placed at their center of gravity\n(taking into account their respective masses). In this way we can decrease the\noverall badness of a partition by reducing the number of clusters for compara-\ntively little penalty in increased variance. On the other hand, if any of the cluster seekers, say Ci, de\ufb01nes a cluster\nwhose sample variance is larger than some amount \u03b4, then we can place a new\ncluster seeker, Cj, at some random location somewhat adjacent to Ci and reset\nthe masses of both Ci and Cj to zero. In this way the badness of the par-\ntition might ultimately decrease by decreasing the total sample variance with\ncomparatively little penalty for the additional cluster seeker. The values of the\nparameters \u03b5 and \u03b4 are set depending on the relative weights given to sample\nvariances and numbers of clusters. In distance-based methods, it is important to scale the components of the\npattern vectors. The variation of values along some dimensions of the pattern\nvector may be much di\ufb00erent than that of other dimensions. One commonly\nused technique is to compute the standard deviation (i.e., the square root of the\nvariance) of each of the components over the entire training set and normalize\nthe values of the components so that their adjusted standard deviations are\nequal.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 132, 'page_label': '133'}, page_content='124 CHAPTER 9. UNSUPERVISED LEARNING\n9.2.2 A Method Based on Probabilities\nSuppose we have a partition of the training set, \u039e, into R mutually exclusive\nand exhaustive clusters, C1,...,C R. We can decide to which of these clusters\nsome arbitrary pattern, X, should be assigned by selecting the Ci for which\nthe probability, p(Ci|X), is largest, providing p(Ci|X) is larger than some \ufb01xed\nthreshold, \u03b4. As we saw earlier, we can use Bayes rule and base our decision on\nmaximizing p(X|Ci)p(Ci). Assuming conditional independence of the pattern\ncomponents, xi, the quantity to be maximized is:\nS(X,Ci) = p(x1|Ci)p(x2|Ci) ···p(xn|Ci)p(Ci)\nThe p(xj|Ci) can be estimated from the sample statistics of the patterns in the\nclusters and then used in the above expression. (Recall the linear form that this\nformula took in the case of binary-valued components.)\nWe call S(X,Ci) the similarity of X to a cluster, Ci, of patterns. Thus, we\nassign X to the cluster to which it is most similar, providing the similarity is\nlarger than \u03b4. Just as before, we can de\ufb01ne the sample mean of a cluster, Ci, to be:\nMi = (1/Ki)\n\u2211\nXj\u03f5 Ci\nXj\nwhere Ki is the number of patterns in Ci. We can base an iterative clustering algorithm on this measure of similarity\n[Mahadevan & Connell, 1992]. It can be described as follows:\na. Begin with a set of unlabeled patterns \u039e and an empty list, L, of clusters. b. For the next pattern, X, in \u039e, compute S(X,Ci) for each cluster, Ci. (Initially, these similarities are all zero.) Suppose the largest of these\nsimilarities is S(X,Cmax). (a) If S(X,Cmax) >\u03b4, assign X to Cmax. That is,\nCmax \u2190\u2212Cmax \u222a{X}\nUpdate the sample statisticsp(x1|Cmax),p(x2|Cmax),...,p (xn|Cmax),\nand p(Cmax) to take the new pattern into account. Go to 3. (b) If S(X,Cmax) \u2264\u03b4, create a new cluster, Cnew = {X}and add Cnew\nto L. Go to 3.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 132, 'page_label': '133'}, page_content='c. Merge any existing clusters, Ci and Cj if ( Mi \u2212Mj)2 < \u03b5. Compute\nnew sample statistics p(x1|Cmerge),p(x2|Cmerge),...,p (xn|Cmerge), and\np(Cmerge) for the merged cluster, Cmerge = Ci \u222aCj.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 133, 'page_label': '134'}, page_content='9.3.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 133, 'page_label': '134'}, page_content='HIERARCHICAL CLUSTERING METHODS 125\nd. If the sample statistics of the clusters have not changed during an entire\niteration through \u039e, then terminate with the clusters in L; otherwise go\nto 2. The value of the parameter \u03b4 controls the number of clusters. If \u03b4 is high,\nthere will be a large number of clusters with few patterns in each cluster. For\nsmall values of \u03b4, there will be a small number of clusters with many patterns in\neach cluster. Similarly, the larger the value of \u03b5, the smaller the number clusters\nthat will be found. Designing a classi\ufb01er based on the patterns labeled by the partitioning is\nstraightforward. We assign any pattern, X, to that category that maximizes\nS(X,Ci). Mention k-means and EM\nmethods. 9.3 Hierarchical Clustering Methods\n9.3.1 A Method Based on Euclidean Distance\nSuppose we have a set, \u039e, of unlabeled training patterns. We can form a hi-\nerarchical classi\ufb01cation of the patterns in \u039e by a simple agglomerative method. (The description of this algorithm is based on an unpublished manuscript by\nPat Langley.) Our description here gives the general idea; we leave it to the\nreader to generate a precise algorithm. We \ufb01rst compute the Euclidean distance between all pairs of patterns in \u039e. (Again, appropriate scaling of the dimensions is assumed.) Suppose the smallest\ndistance is between patterns Xi and Xj. We collect Xi and Xj into a cluster,\nC, eliminate Xi and Xj from \u039e and replace them by a cluster vector, C, equal\nto the average of Xi and Xj. Next we compute the Euclidean distance again\nbetween all pairs of points in \u039e. If the smallest distance is between pairs of\npatterns, we form a new cluster, C, as before and replace the pair of patterns\nin \u039e by their average. If the shortest distance is between a pattern, Xi, and\na cluster vector, Cj (representing a cluster, Cj), we form a new cluster, C,\nconsisting of the union of Cj and {Xi}. In this case, we replace Cj and Xi\nin \u039e by their (appropriately weighted) average and continue. If the shortest\ndistance is between two cluster vectors, Ci and Cj, we form a new cluster, C,\nconsisting of the union of Ci and Cj. In this case, we replace Ci and Cj by their\n(appropriately weighted) average and continue. Since we reduce the number of\npoints in \u039e by one each time, we ultimately terminate with a tree of clusters\nrooted in the cluster containing all of the points in the original training set. An example of how this method aggregates a set of two dimensional patterns\nis shown in Fig. 9.5.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 133, 'page_label': '134'}, page_content='The numbers associated with each cluster indicate the order\nin which they were formed. These clusters can be organized hierarchically in a\nbinary tree with cluster 9 as root, clusters 7 and 8 as the two descendants of the\nroot, and so on. A ternary tree could be formed instead if one searches for the\nthree points in \u039e whose triangle de\ufb01ned by those patterns has minimal area.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 134, 'page_label': '135'}, page_content='126 CHAPTER 9. UNSUPERVISED LEARNING\n1\n2 3\n5\n4\n6\n7\n8\n9\nFigure 9.5: Agglommerative Clustering\n9.3.2 A Method Based on Probabilities\nA probabilistic quality measure for partitions\nWe can develop a measure of the goodness of a partitioning based on how\naccurately we can guess a pattern given only what partition it is in. Suppose\nwe are given a partitioning of \u039e into R classes, C1,...,C R.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 134, 'page_label': '135'}, page_content='As before, we can\ncompute the sample statistics p(xi|Ck) which give probability values for each\ncomponent given the class assigned to it by the partitioning. Suppose each\ncomponent xi of X can take on the values vij, where the index j steps over the\ndomain of that component. We use the notation pi(vij|Ck) = probability(xi =\nvij|Ck). Suppose we use the following probabilistic guessing rule about the values\nof the components of a vector X given only that it is in class k. Guess that\nxi = vij with probability pi(vij|Ck). Then, the probability that we guess the\ni-th component correctly is:\n\u2211\nj\nprobability(guess is vij)pi(vij|Ck) =\n\u2211\nj\n[pi(vij|Ck)]2\nThe average number of (the n) components whose values are guessed correctly\nby this method is then given by the sum of these probabilities over all of the\ncomponents of X:\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 135, 'page_label': '136'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 127\nGiven our partitioning into R classes, the goodness measure, G, of this parti-\ntioning is the average of the above expression over all classes:\nG=\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nwhere p(Ck) is the probability that a pattern is in class Ck. In order to penalize\nthis measure for having a large number of classes, we divide it by R to get an\noverall quality measure of a partitioning:\nZ = (1/R)\n\u2211\nk\np(Ck)\n\u2211\ni\n\u2211\nj\n[pi(vij|Ck)]2\nWe give an example of the use of this measure for a trivially simple\nclustering of the four three-dimensional patterns shown in Fig. 9.6.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 135, 'page_label': '136'}, page_content='There\nare several di\ufb00erent partitionings. Lets evaluate Z values for the follow-\ning ones: P1 = {a,b,c,d }, P2 = {{a,b},{c,d}}, P3 = {{a,c},{b,d}}, and\nP4 = {{a},{b},{c},{d}}. The \ufb01rst, P1, puts all of the patterns into a single\ncluster. The sample probabilities pi(vi1 = 1) and pi(vi0 = 0) are all equal to 1/2\nfor each of the three components. Summing over the values of the components\n(0 and 1) gives (1 /2)2 + (1/2)2 = 1 /2. Summing over the three components\ngives 3/2. Averaging over all of the clusters (there is just one) also gives 3 /2. Finally, dividing by the number of clusters produces the \ufb01nal Z value of this\npartition, Z(P1) = 3/2. The second partition, P2, gives the following sample probabilities:\np1(v11 = 1|C1) = 1\np2(v21 = 1|C1) = 1/2\np3(v31 = 1|C1) = 1\nSumming over the values of the components (0 and 1) gives (1) 2 + (0)2 = 1 for\ncomponent 1, (1 /2)2 + (1/2)2 = 1/2 for component 2, and (1) 2 + (0)2 = 1 for\ncomponent 3. Summing over the three components gives 2 1 /2 for class 1. A\nsimilar calculation also gives 2 1 /2 for class 2. Averaging over the two clusters\nalso gives 2 1 /2. Finally, dividing by the number of clusters produces the \ufb01nal\nZ value of this partition, Z(P2) = 1 1/4, not quite as high as Z(P1). Similar calculations yield Z(P3) = 1 and Z(P4) = 3 /4, so this method of\nevaluating partitions would favor placing all patterns in a single cluster.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 136, 'page_label': '137'}, page_content='128 CHAPTER 9. UNSUPERVISED LEARNING\nx2\nx3\nx1\nab\ncd\nFigure 9.6: Patterns in 3-Dimensional Space\nAn iterative method for hierarchical clustering\nEvaluating all partitionings of mpatterns and then selecting the best would be\ncomputationally intractable. The following iterative method is based on a hi-\nerarchical clustering procedure called COBWEB [Fisher, 1987]. The procedure\ngrows a tree each node of which is labeled by a set of patterns. At the end\nof the process, the root node contains all of the patterns in \u039e. The successors\nof the root node will contain mutually exclusive and exhaustive subsets of \u039e. In general, the successors of a node, \u03b7, are labeled by mutually exclusive and\nexhaustive subsets of the pattern set labelling node \u03b7. The tips of the tree will\ncontain singleton sets. The method uses Z values to place patterns at the vari-\nous nodes; sample statistics are used to update the Z values whenever a pattern\nis placed at a node. The algorithm is as follows:\na.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 136, 'page_label': '137'}, page_content='We start with a tree whose root node contains all of the patterns in \u039e\nand a single empty successor node. We arrange that at all times dur-\ning the process every non-empty node in the tree has (besides any other\nsuccessors) exactly one empty successor. b. Select a pattern Xi in \u039e (if there are no more patterns to select, terminate). c. Set µ to the root node. d. For each of the successors of µ(including the empty successor!), calculate\nthe best host for Xi. A best host is determined by tentatively placing\nXi in one of the successors and calculating the resulting Z value for each'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 137, 'page_label': '138'}, page_content='9.3. HIERARCHICAL CLUSTERING METHODS 129\none of these ways of accomodating Xi. The best host corresponds to the\nassignment with the highest Z value. e. If the best host is an empty node, \u03b7, we place Xi in \u03b7, generate an empty\nsuccessor node of \u03b7, generate an empty sibling node of \u03b7, and go to 2. f. If the best host is a non-empty, singleton (tip) node, \u03b7, we place Xi in \u03b7,\ncreate one successor node of \u03b7 containing the singleton pattern that was\nin \u03b7, create another successor node of \u03b7 containing Xi, create an empty\nsuccessor node of \u03b7, create empty successor nodes of the new non-empty\nsuccessors of \u03b7, and go to 2. g. If the best host is a non-empty, non-singleton node, \u03b7, we place Xi in \u03b7,\nset µ to \u03b7, and go to 4. This process is rather sensitive to the order in which patterns are presented. To make the \ufb01nal classi\ufb01cation tree less order dependent, the COBWEB proce-\ndure incorporates node merging and splitting. Node merging:\nIt may happen that two nodes having the same parent could be merged with\nan overall increase in the quality of the resulting classi\ufb01cation performed by the\nsuccessors of that parent. Rather than try all pairs to merge, a good heuristic\nis to attempt to merge the two best hosts. When such a merging improves the\nZ value, a new node containing the union of the patterns in the merged nodes\nreplaces the merged nodes, and the two nodes that were merged are installed\nas successors of the new node. Node splitting:\nA heuristic for node splitting is to consider replacing the best host among a\ngroup of siblings by that hosts successors. This operation is performed only if\nit increases the Z value of the classi\ufb01cation performed by a group of siblings.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 137, 'page_label': '138'}, page_content='Example results from COBWEB\nWe mention two experiments with COBWEB. In the \ufb01rst, the program at-\ntempted to \ufb01nd two categories (we will call them Class 1 and Class 2) of United\nStates Senators based on their votes ( yes or no) on six issues. After the clus-\nters were established, the majority vote in each class was computed. These are\nshown in the table below. Issue Class 1 Class 2\nToxic Waste yes no\nBudget Cuts yes no\nSDI Reduction no yes\nContra Aid yes no\nLine-Item Veto yes no\nMX Production yes no'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 138, 'page_label': '139'}, page_content='130 CHAPTER 9. UNSUPERVISED LEARNING\nIn the second experiment, the program attempted to classify soybean dis-\neases based on various characteristics. COBWEB grouped the diseases in the\ntaxonomy shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 138, 'page_label': '139'}, page_content='9.7. N0\nsoybean\ndiseases\nN1\n  Diaporthe\nStem Canker\nN2\nCharcoal\n     Rot\nN3\nN31\nRhizoctonia\n       Rot\nN32\nPhytophthora\n       Rot\nFigure 9.7: Taxonomy Induced for Soybean Diseases\n9.4 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 139, 'page_label': '140'}, page_content='Chapter 10\nTemporal-Di\ufb00erence\nLearning\n10.1 Temporal Patterns and Prediction Prob-\nlems\nIn this chapter, we consider problems in which we wish to learn to predict the\nfuture value of some quantity, say z, from an n-dimensional input pattern, X. In many of these problems, the patterns occur in temporal sequence, X1, X2,\n. .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 139, 'page_label': '140'}, page_content='., Xi, Xi+1, ... , Xm, and are generated by a dynamical process. The\ncomponents of Xi are features whose values are available at time, t = i. We\ndistinguish two kinds of prediction problems. In one, we desire to predict the\nvalue of z at time t = i+ 1 based on input Xi for every i. For example, we\nmight wish to predict some aspects of tomorrows weather based on a set of\nmeasurements made today. In the other kind of prediction problem, we desire\nto make a sequence of predictions about the value of z at some \ufb01xed time, say\nt= m+ 1, based on each of the Xi, i= 1,...,m . For example, we might wish\nto make a series of predictions about some aspect of the weather on next New\nYears Day, based on measurements taken every day before New Years. Sutton\n[Sutton, 1988] has called this latter problem, multi-step prediction, and that is\nthe problem we consider here. In multi-step prediction, we might expect that\nthe prediction accuracy should get better and better as i increases toward m. 10.2 Supervised and Temporal-Di\ufb00erence Meth-\nods\nA training method that naturally suggests itself is to use the actual value of\nz at time m+ 1 (once it is known) in a supervised learning procedure using a\n131'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 140, 'page_label': '141'}, page_content='132 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nsequence of training patterns, {X1, X2, ... , Xi, Xi+1, ...'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 140, 'page_label': '141'}, page_content=', Xm}. That is, we\nseek to learn a function, f, such that f(Xi) is as close as possible to zfor each i. Typically, we would need a training set, \u039e, consisting of several such sequences. We will show that a method that is better than supervised learning for some\nimportant problems is to base learning on the di\ufb00erence between f(Xi+1) and\nf(Xi) rather than on the di\ufb00erence between zand f(Xi). Such methods involve\nwhat is called temporal-di\ufb00erence (TD) learning. We assume that our prediction, f(X), depends on a vector of modi\ufb01able\nweights, W. To make that dependence explicit, we write f(X,W). For su-\npervised learning, we consider procedures of the following type: For each Xi,\nthe prediction f(Xi,W) is computed and compared to z, and the learning rule\n(whatever it is) computes the change, (\u2206 Wi), to be made to W. Then, taking\ninto account the weight changes for each pattern in a sequence all at once after\nhaving made all of the predictions with the old weight vector, we change W as\nfollows:\nW \u2190\u2212W +\nm\u2211\ni=1\n(\u2206W)i\nWhenever we are attempting to minimize the squared error between z and\nf(Xi,W) by gradient descent, the weight-changing rule for each pattern is:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nwhere c is a learning rate parameter, fi is our prediction of z, f(Xi,W),\nat time t = i, and \u2202fi\n\u2202W is, by de\ufb01nition, the vector of partial derivatives\n( \u2202fi\n\u2202w1\n,..., \u2202fi\n\u2202wi\n,..., \u2202fi\n\u2202wn\n) in which the wi are the individual components of W. (The expression \u2202fi\n\u2202W is sometimes written \u2207Wfi.) The reader will recall that\nwe used an equivalent expression for (\u2206 W)i in deriving the backpropagation\nformulas used in training multi-layer neural networks. The Widrow-Ho\ufb00 rule results when f(X,W) = X W. Then:\n(\u2206W)i = c(z\u2212fi)Xi\nAn interesting form for (\u2206 W)i can be developed if we note that\n(z\u2212fi) =\nm\u2211\nk=i\n(fk+1 \u2212fk)\nwhere we de\ufb01ne fm+1 = z. Substituting in our formula for (\u2206 W)i yields:\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 141, 'page_label': '142'}, page_content='10.2. SUPERVISED AND TEMPORAL-DIFFERENCE METHODS 133\n= c\u2202fi\n\u2202W\nm\u2211\nk=i\n(fk+1 \u2212fk)\nIn this form, instead of using the di\ufb00erence between a prediction and the value\nof z, we use the di\ufb00erences between successive predictionsthus the phrase\ntemporal-di\ufb00erence (TD) learning. In the case when f(X,W) = X W, the temporal di\ufb00erence form of the\nWidrow-Ho\ufb00 rule is:\n(\u2206W)i = cXi\nm\u2211\nk=i\n(fk+1 \u2212fk)\nOne reason for writing (\u2206 W)i in temporal-di\ufb00erence form is to permit an\ninteresting generalization as follows:\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nwhere 0 < \u03bb\u22641. Here, the \u03bb term gives exponentially decreasing weight to\ndi\ufb00erences later in time than t = i.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 141, 'page_label': '142'}, page_content='When \u03bb = 1, we have the same rule with\nwhich we beganweighting all di\ufb00erences equally, but as\u03bb\u21920, we weight only\nthe (fi+1 \u2212fi) di\ufb00erence. With the \u03bb term, the method is called TD( \u03bb). It is interesting to compare the two extreme cases:\nFor TD(0):\n(\u2206W)i = c(fi+1 \u2212fi) \u2202fi\n\u2202W\nFor TD(1):\n(\u2206W)i = c(z\u2212fi) \u2202fi\n\u2202W\nBoth extremes can be handled by the same learning mechanism; only the error\nterm is di\ufb00erent. In TD(0), the error is the di\ufb00erence between successive predic-\ntions, and in TD(1), the error is the di\ufb00erence between the \ufb01nally revealed value\nof z and the prediction. Intermediate values of \u03bb take into account di\ufb00erently\nweighted di\ufb00erences between future pairs of successive predictions. Only TD(1) can be considered a puresupervised learning procedure, sensitive\nto the \ufb01nal value ofzprovided by the teacher. For\u03bb< 1, we have various degrees\nof unsupervised learning, in which the prediction function strives to make each\nprediction more like successive ones (whatever they might be). We shall soon\nsee that these unsupervised procedures result in better learning than do the\nsupervised ones for an important class of problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 142, 'page_label': '143'}, page_content='134 CHAPTER 10.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 142, 'page_label': '143'}, page_content='TEMPORAL-DIFFERENCE LEARNING\n10.3 Incremental Computation of the (\u2206W)i\nWe can rewrite our formula for (\u2206 W)i, namely\n(\u2206W)i = c\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nto allow a type of incremental computation. First we write the expression for\nthe weight change rule that takes into account all of the (\u2206 W)i:\nW \u2190\u2212W +\nm\u2211\ni=1\nc\u2202fi\n\u2202W\nm\u2211\nk=i\n\u03bb(k\u2212i)(fk+1 \u2212fk)\nInterchanging the order of the summations yields:\nW \u2190\u2212W +\nm\u2211\nk=1\nc\nk\u2211\ni=1\n\u03bb(k\u2212i)(fk+1 \u2212fk) \u2202fi\n\u2202W\n= W +\nm\u2211\nk=1\nc(fk+1 \u2212fk)\nk\u2211\ni=1\n\u03bb(k\u2212i) \u2202fi\n\u2202W\nInterchanging the indices k and i \ufb01nally yields:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nIf, as earlier, we want to use an expression of the formW \u2190\u2212W+\u2211m\ni=1(\u2206W)i,\nwe see that we can write:\n(\u2206W)i = c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nNow, if we let ei = \u2211i\nk=1 \u03bb(i\u2212k) \u2202fk\n\u2202W , we can develop a computationally e\ufb03cient\nrecurrence equation for ei+1 as follows:\nei+1 =\ni+1\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W\n= \u2202fi+1\n\u2202W +\ni\u2211\nk=1\n\u03bb(i+1\u2212k) \u2202fk\n\u2202W'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 143, 'page_label': '144'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 135\n= \u2202fi+1\n\u2202W + \u03bbei\nRewriting (\u2206W)i in these terms, we obtain:\n(\u2206W)i = c(fi+1 \u2212fi)ei\nwhere:\ne1 = \u2202f1\n\u2202W\ne2 = \u2202f2\n\u2202W + \u03bbe1\netc. Quoting Sutton [Sutton, 1988, page 15] (about a di\ufb00erent equation, but the\nquote applies equally well to this one):\n... this equation can be computed incrementally, because each\n(\u2206W)i depends only on a pair of successive predictions and on the\n[weighted] sum of all past values for \u2202fi\n\u2202W . This saves substantially on\nmemory, because it is no longer necessary to individually remember\nall past values of \u2202fi\n\u2202W .\n10.4 An Experiment with TD Methods\nTD prediction methods [especially TD(0)] are well suited to situations in which\nthe patterns are generated by a dynamic process. In that case, sequences of\ntemporally presented patterns contain important information that is ignored\nby a conventional supervised method such as the Widrow-Ho\ufb00 rule. Sutton\n[Sutton, 1988, page 19] gives an interesting example involving a random walk,\nwhich we repeat here.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 143, 'page_label': '144'}, page_content='In Fig. 10.1, sequences of vectors, X, are generated as\nfollows: We start with vector XD; the next vector in the sequence is equally\nlikely to be one of the adjacent vectors in the diagram. If the next vector is\nXC (or XE), the next one after that is equally likely to be one of the vectors\nadjacent to XC (or XE). When XB is in the sequence, it is equally likely that\nthe sequence terminates with z = 0 or that the next vector is XC. Similarly,\nwhen XF is in the sequence, it is equally likely that the sequence terminates\nwith z= 1 or that the next vector is XE. Thus the sequences are random, but\nthey always start with XD. Some sample sequences are shown in the \ufb01gure.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 144, 'page_label': '145'}, page_content='136 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\nz = 0 z = 1\nXB XC XD XE XF\nTypical Sequences:\nXDXCXDXEXF  1\nXDXCXBXCXDXEXDXEXF  1\nXDXEXDXCXB  0\nFigure 10.1: A Markov Process\nThis random walk is an example of a Markov process; transitions from state i\nto state j occur with probabilities that depend only on i and j. Given a set of sequences generated by this process as a training set, we want\nto be able to predict the value of z for each X in a test sequence.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 144, 'page_label': '145'}, page_content='We assume\nthat the learning system does not know the transition probabilities. For his experiments with this process, Sutton used a linear predictor, that\nis f(X,W) = X W. The learning problem is to \ufb01nd a weight vector, W, that\nminimizes the mean-squared error betweenzand the predicted value of z. Given\nthe \ufb01ve di\ufb00erent values that X can take on, we have the following predictions:\nf(XB) = w1, f(XC) = w2, f(XD) = w3, f(XE) = w4, f(XF) = w5, where\nwi is the i-th component of the weight vector. (Note that the values of the\npredictions are not limited to 1 or 0even though z can only have one of\nthose valuesbecause we are minimizing mean-squared error.) After training,\nthese predictions will be compared with the optimal onesgiven the transition\nprobabilities. The experimental setup was as follows: ten random sequences were generated\nusing the transition probabilities. Each of these sequences was presented in turn\nto a TD(\u03bb) method for various values of \u03bb. Weight vector increments, (\u2206 W)i,\nwere computed after each pattern presentation but no weight changes were\nmade until all ten sequences were presented. The weight vector increments were\nsummed after all ten sequences were presented, and this sum was used to change\nthe weight vector to be used for the next pass through the ten sequences. This\nprocess was repeated over and over (using the same training sequences) until\n(quoting Sutton) the procedure no longer produced any signi\ufb01cant changes in\nthe weight vector. For small c, the weight vector always converged in this way,'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 145, 'page_label': '146'}, page_content='10.4. AN EXPERIMENT WITH TD METHODS 137\nand always to the same \ufb01nal value [for 100 di\ufb00erent training sets of ten random\nsequences], independent of its initial value. (Even though, for \ufb01xed, small c,\nthe weight vector always converged to the same vector, it might converge to a\nsomewhat di\ufb00erent vector for di\ufb00erent values of c.)\nAfter convergence, the predictions made by the \ufb01nal weight vector are com-\npared with the optimal predictions made using the transition probabilities. These optimal predictions are simply p(z= 1|X). We can compute these proba-\nbilities to be 1/6, 1/3, 1/2, 2/3, and 5/6 forXB, XC, XD, XE, XF, respectively. The root-mean-squared di\ufb00erences between the best learned predictions (over\nall c) and these optimal ones are plotted in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 145, 'page_label': '146'}, page_content='10.2 for seven di\ufb00erent values\nof \u03bb. (For each data point, the standard error is approximately \u03c3= 0.01.)\n0.10\n0.12\n0.14\n0.16\n0.18\n0.20\n0.0 0.1 0.3 0.5 0.7 0.9 1.0\nh\nError using\nbest c\nWidrow-Hoff\nTD(1)\nTD(0)\n(Adapted from Sutton, p. 20, 1988)\nFigure 10.2: Prediction Errors for TD( \u03bb)\nNotice that the Widrow-Ho\ufb00 procedure does not perform as well as other\nversions of TD(\u03bb) for \u03bb< 1! Quoting [Sutton, 1988, page 21]:\nThis result contradicts conventional wisdom. It is well known that,\nunder repeated presentations, the Widrow-Ho\ufb00 procedure minimizes\nthe RMS error between its predictions and the actual outcomes in\nthe training set ([Widrow & Stearns, 1985]). How can it be that this\noptimal method peformed worse than all the TD methods for \u03bb <\n1? The answer is that the Widrow-Ho\ufb00 procedure only minimizes\nerror on the training set ; it does not necessarily minimize error for\nfuture experience. [Later] we prove that in fact it is linear TD(0)\nthat converges to what can be considered the optimal estimates for'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 146, 'page_label': '147'}, page_content='138 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\nmatching future experiencethose consistent with the maximum-\nlikelihood estimate of the underlying Markov process.\n10.5 Theoretical Results\nIt is possible to analyze the performance of the linear-prediction TD(\u03bb) methods\non Markov processes. We state some theorems here without proof. Theorem 10.1 (Sutton, page 24, 1988) For any absorbing Markov chain,\nand for any linearly independent set of observation vectors {Xi}for the non-\nterminal states, there exists an \u03b5> 0 such that for all positive c<\u03b5 and for any\ninitial weight vector, the predictions of linear TD(0) (with weight updates after\neach sequence) converge in expected value to the optimal (maximum likelihood)\npredictions of the true process. Even though the expected values of the predictions converge, the predictions\nthemselves do not converge but vary around their expected values depending on\ntheir most recent experience. Sutton conjectures that if c is made to approach\n0 as training progresses, the variance of the predictions will approach 0 also.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 146, 'page_label': '147'}, page_content='Dayan [Dayan, 1992] has extended the result of Theorem 9.1 to TD( \u03bb) for\narbitrary \u03bb between 0 and 1. (Also see [Dayan & Sejnowski, 1994].)\n10.6 Intra-Sequence Weight Updating\nOur standard weight updating rule for TD( \u03bb) methods is:\nW \u2190\u2212W +\nm\u2211\ni=1\nc(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere the weight update occurs after an entire sequence is observed. To make\nthe method truly incremental (in analogy with weight updating rules for neural\nnets), it would be desirable to change the weight vector after every pattern\npresentation. The obvious extension is:\nWi+1 \u2190\u2212Wi + c(fi+1 \u2212fi)\ni\u2211\nk=1\n\u03bb(i\u2212k) \u2202fk\n\u2202W\nwhere fi+1 is computed before making the weight change; that is, fi+1 =\nf(Xi+1,Wi). But that would make fi = f(Xi,Wi\u22121), and such a rule would\nmake the prediction di\ufb00erence, namely ( fi+1 \u2212fi), sensitive both to changes in\nX and changes in W and could lead to instabilities. Instead, we modify the rule\nso that, for every pair of predictions, fi+1 = f(Xi+1,Wi) and fi = f(Xi,Wi). This version of the rule has been used in practice with excellent results.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 147, 'page_label': '148'}, page_content='10.6. INTRA-SEQUENCE WEIGHT UPDATING 139\nFor TD(0) and linear predictors, the rule is:\nWi+1 = Wi + c(fi+1 \u2212fi)Xi\nThe rule is implemented as follows:\na. Initialize the weight vector, W, arbitrarily.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 147, 'page_label': '148'}, page_content='b. For i= 1,...,m , do:\n(a) fi \u2190\u2212Xi W\n(We compute fi anew each time through rather than use the value\nof fi+1 the previous time through.)\n(b) fi+1 \u2190\u2212Xi+1 W\n(c) di+1 \u2190\u2212fi+1 \u2212fi\n(d) W \u2190\u2212W + c di+1Xi\n(If fi were computed again with this changed weight vector, its value\nwould be closer to fi+1 as desired.)\nThe linear TD(0) method can be regarded as a technique for training a\nvery simple network consisting of a single dot product unit (and no threshold\nor sigmoid function). TD methods can also be used in combination with back-\npropagation to train neural networks. For TD(0) we change the network weights\naccording to the expression:\nWi+1 = Wi + c(fi+1 \u2212fi) \u2202fi\n\u2202W\nThe only change that must be made to the standard backpropagation weight-\nchanging rule is that the di\ufb00erence term between the desired output and the\noutput of the unit in the \ufb01nal ( k-th) layer, namely (d\u2212f(k)), must be replaced\nby a di\ufb00erence term between successive outputs, ( fi+1 \u2212fi). This change has a\ndirect e\ufb00ect only on the expression for \u03b4(k) which becomes:\n\u03b4(k) = 2(f\u2032(k) \u2212f(k))f(k)(1 \u2212f(k))\nwhere f\u2032(k) and f(k) are two successive outputs of the network. The weight changing rule for the i-th weight vector in the j-th layer of weights\nhas the same form as before, namely:\nW(j)\ni \u2190\u2212W(j)\ni + c\u03b4(j)\ni X(j\u22121)\nwhere the \u03b4(j)\ni are given recursively by:\n\u03b4(j)\ni = f(j)\ni (1 \u2212f(j)\ni )\nmj+1\u2211\nl=1\n\u03b4(j+1)\nl w(j+1)\nil\nand w(j+1)\nil is the l-th component of the i-th weight vector in the (j+1)-th layer\nof weights. Of course, here also it is assumed that f\u2032(k) and f(k) are computed\nusing the same weights and then the weights are changed. In the next section\nwe shall see an interesting example of this application of TD learning.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 148, 'page_label': '149'}, page_content='140 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING\n10.7 An Example Application: TD-gammon\nA program called TD-gammon [Tesauro, 1992] learns to play backgammon by\ntraining a neural network via temporal-di\ufb00erence methods. The structure of\nthe neural net, and its coding is as shown in Fig. 10.3. The network is trained\nto minimize the error between actual payo\ufb00 and estimated payo\ufb00, where the\nactual payo\ufb00 is de\ufb01ned to be df = p1 + 2p2 \u2212p3 \u22122p4, and the pi are the actual\nprobabilities of the various outcomes as de\ufb01ned in the \ufb01gure. . . . p3 = pr(black wins)\np4 = pr(black gammons)\np1 = pr(white wins)\np2 = pr(white gammons)\nestimated payoff:\nd = p1 + 2p2 < p3 < 2p4\nno. of white\non cell 1\nno. on bar,\noff board,\nand who\nmoves\n198 inputs\n1\n2\n3\n# > 3\n. .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 148, 'page_label': '149'}, page_content='. up to 40 hidden units\n2 x 24\ncells\n4 output units\nhidden and output units are sigmoids\nlearning rate:  c = 0.1; initial weights chosen\nrandomly between <0.5 and +0.5. estimated probabilities:\nFigure 10.3: The TD-gammon Network\nTD-gammon learned by using the network to select that move that results\nin the best predicted payo\ufb00. That is, at any stage of the game some \ufb01nite set of\nmoves is possible and these lead to the set, {X}, of new board positions. Each\nmember of this set is evaluated by the network, and the one with the largest'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 149, 'page_label': '150'}, page_content='10.8. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 141\npredicted payo\ufb00 is selected if it is whites move (and the smallest if it is blacks). The move is made, and the network weights are adjusted to make the predicted\npayo\ufb00 from the original position closer to that of the resulting position. The weight adjustment procedure combines temporal-di\ufb00erence (TD( \u03bb))\nlearning with backpropagation. If dt is the networks estimate of the payo\ufb00\nat time t (before a move is made), and dt+1 is the estimate at time t+ 1 (after\na move is made), the weight adjustment rule is:\n\u2206Wt = c(dt+1 \u2212dt)\nt\u2211\nk=1\n\u03bbt\u2212k \u2202dk\n\u2202W\nwhere Wt is a vector of all weights in the network at time t, and \u2202dk\n\u2202W is the\ngradient of dk in this weight space. (For a layered, feedforward network, such\nas that of TD-gammon, the weight changes for the weight vectors in each layer\ncan be expressed in the usual manner.)\nTo make the special cases clear, recall that for TD(0), the network would be\ntrained so that, for all t, its output, dt, for input Xt tended toward its expected\noutput, dt+1, for input Xt+1. For TD(1), the network would be trained so that,\nfor all t, its output, dt, for input Xt tended toward the expected \ufb01nal payo\ufb00,\ndf, given that input. The latter case is the same as the Widrow-Ho\ufb00 rule.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 149, 'page_label': '150'}, page_content='After about 200,000 games the following results were obtained. TD-gammon\n(with 40 hidden units, \u03bb= 0.7, and c= 0.1) won 66.2% of 10,000 games against\nSUN Microsystems Gammontool and 55% of 10,000 games against a neural\nnetwork trained using expert moves. Commenting on a later version of TD-\ngammon, incorporating special features as inputs, Tesauro said: It appears to\nbe the strongest program ever seen by this author.\n10.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 150, 'page_label': '151'}, page_content='142 CHAPTER 10. TEMPORAL-DIFFERENCE LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 151, 'page_label': '152'}, page_content='Chapter 11\nDelayed-Reinforcement\nLearning\n11.1 The General Problem\nImagine a robot that exists in an environment in which it can sense and act. Suppose (as an extreme case) that it has no idea about the e\ufb00ects of its actions. That is, it doesnt know how acting will change its sensory inputs. Along with\nits sensory inputs are rewards, which it occasionally receives. How should it\nchoose its actions so as to maximize its rewards over the long run? To maximize\nrewards, it will need to be able to predict how actions change inputs, and in\nparticular, how actions lead to rewards. We formalize the problem in the following way: The robot exists in an\nenvironment consisting of a set,S, of states. We assume that the robots sensory\napparatus constructs an input vector, X, from the environment, which informs\nthe robot about which state the environment is in. For the moment, we will\nassume that the mapping from states to vectors is one-to-one, and, in fact, will\nuse the notation X to refer to the state of the environment as well as to the\ninput vector. When presented with an input vector, the robot decides which\naction from a set, A, of actions to perform. Performing the action produces an\ne\ufb00ect on the environmentmoving it to a new state. The new state results in\nthe robot perceiving a new input vector, and the cycle repeats. We assume a\ndiscrete time model; the input vector at time t = i is Xi, the action taken at\nthat time is ai, and the expected reward, ri, received at t = i depends on the\naction taken and on the state, that is ri = r(Xi,ai). The learners goal is to \ufb01nd\na policy, \u03c0(X), that maps input vectors to actions in such a way that maximizes\nrewards accumulated over time. This type of learning is called reinforcement\nlearning. The learner must \ufb01nd the policy by trial and error; it has no initial\nknowledge of the e\ufb00ects of its actions. The situation is as shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 151, 'page_label': '152'}, page_content='11.1. 143'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 152, 'page_label': '153'}, page_content='144 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nXi\nri\nLearner\nEnvironment\n(reward)\n(state)\n(action)\nai\nFigure 11.1: Reinforcement Learning\n11.2 An Example\nA grid world, such as the one shown in Fig. 11.2 is often used to illustrate\nreinforcement learning. Imagine a robot initially in cell (2,3). The robot receives\ninput vector ( x1,x2) telling it what cell it is in; it is capable of four actions,\nn,e,s,w moving the robot one cell up, right, down, or left, respectively. It is\nrewarded one negative unit whenever it bumps into the wall or into the blocked\ncells. For example, if the input to the robot is (1,3), and the robot chooses\naction w, the next input to the robot is still (1,3) and it receives a reward of\n\u22121. If the robot lands in the cell marked G (for goal), it receives a reward of\n+10. Lets suppose that whenever the robot lands in the goal cell and gets its\nreward, it is immediately transported out to some random cell, and the quest\nfor reward continues. A policy for our robot is a speci\ufb01cation of what action to take for every one\nof its inputs, that is, for every one of the cells in the grid. For example, a com-\nponent of such a policy would be when in cell (3,1), move right. An optimal\npolicy is a policy that maximizes long-term reward. One way of displaying a\npolicy for our grid-world robot is by an arrow in each cell indicating the direc-\ntion the robot should move when in that cell. In Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 152, 'page_label': '153'}, page_content='11.3, we show an optimal\npolicy displayed in this manner. In this chapter we will describe methods for\nlearning optimal policies based on reward values received by the learner.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 153, 'page_label': '154'}, page_content='11.3. TEMPORAL DISCOUNTING AND OPTIMAL POLICIES 145\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.2: A Grid World\n11.3 Temporal Discounting and Optimal Poli-\ncies\nIn delayed reinforcement learning, one often assumes that rewards in the distant\nfuture are not as valuable as are more immediate rewards. This preference can\nbe accomodated by a temporal discount factor, 0 \u2264\u03b3 <1. The present value of\na reward, ri, occuring i time units in the future, is taken to be \u03b3iri. Suppose\nwe have a policy \u03c0(X) that maps input vectors into actions, and let r\u03c0(X)\ni be\nthe reward that will be received on the i-th time step after one begins executing\npolicy \u03c0 starting in state X. Then the total reward accumulated over all time\nsteps by policy \u03c0 beginning in state X is:\nV\u03c0(X) =\n\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\nOne reason for using a temporal discount factor is so that the above sum will\nbe \ufb01nite. An optimal policy is one that maximizes V\u03c0(X) for all inputs, X.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 153, 'page_label': '154'}, page_content='In general, we want to consider the case in which the rewards,ri, are random\nvariables and in which the e\ufb00ects of actions on environmental states are random. In Markovian environments, for example, the probability that action a in state\nXi will lead to state Xj is given by a transition probability p[Xj|Xi,a]. Then,\nwe will want to maximize expected future reward and would de\ufb01ne V\u03c0(X) as:\nV\u03c0(X) = E\n[\u221e\u2211\ni=0\n\u03b3ir\u03c0(X)\ni\n]\nIn either case, we call V\u03c0(X) the value of policy \u03c0 for input X.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 154, 'page_label': '155'}, page_content='146 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nR\nG\n12345 67\n1\n2\n3\n4\n5\n6\n7\n8\nFigure 11.3: An Optimal Policy in the Grid World\nIf the action prescribed by \u03c0 taken in state X leads to state X\u2032 (randomly\naccording to the transition probabilities), then we can write V\u03c0(X) in terms of\nV\u03c0(X\u2032) as follows:\nV\u03c0(X) = r[X,\u03c0(X)] + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,\u03c0(X)]V\u03c0(X\u2032)\nwhere (in summary):\n\u03b3 = the discount factor,\nV\u03c0(X) = the value of state X under policy \u03c0,\nr[X,\u03c0(X)] = the expected immediate reward received when we execute the\naction prescribed by \u03c0 in state X, and\np[X\u2032|X,\u03c0(X)] = the probability that the environment transitions to state\nX\u2032when we execute the action prescribed by \u03c0 in state X. In other words, the value of state X under policy \u03c0 is the expected value of\nthe immediate reward received when executing the action recommended by \u03c0\nplus the average value (under \u03c0) of all of the states accessible from X. For an optimal policy, \u03c0\u2217(and no others!), we have the famous optimality\nequation:\nV\u03c0\u2217\n(X) = max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nThe theory of dynamic programming (DP) [Bellman, 1957, Ross, 1983] assures\nus that there is at least one optimal policy, \u03c0\u2217, that satis\ufb01es this equation.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 154, 'page_label': '155'}, page_content='DP'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 155, 'page_label': '156'}, page_content='11.4. Q-LEARNING 147\nalso provides methods for calculating V\u03c0\u2217\n(X) and at least one \u03c0\u2217, assuming\nthat we know the average rewards and the transition probabilities. If we knew\nthe transition probabilities, the average rewards, and V\u03c0\u2217\n(X) for all X and a,\nthen it would be easy to implement an optimal policy. We would simply select\nthat a that maximizes r(X,a) + \u03b3\u2211\nX\u2032p[X\u2032|X,a]V\u03c0\u2217\n(X\u2032). That is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3\n\u2211\nX\u2032\np[X\u2032|X,a]V\u03c0\u2217\n(X\u2032)\n]\nBut, of course, we are assuming that we do not know these average rewards nor\nthe transition probabilities, so we have to \ufb01nd a method that e\ufb00ectively learns\nthem. If we had a model of actions, that is, if we knew for every state, X, and\naction a, which state, X\u2032 resulted, then we could use a method called value\niteration to \ufb01nd an optimal policy. Value iteration works as follows: We begin\nby assigning, randomly, an estimated value V(X) to every state, X. On the i-th\nstep of the process, suppose we are at state Xi (that is, our input on the i-th\nstep is Xi), and that the estimated value of state Xi on the i-th step is Vi(Xi). We then select that actionathat maximizes the estimated value of the predicted\nsubsequent state. Suppose this subsequent state having the highest estimated\nvalue is X\u2032\ni. Then we update the estimated value, Vi(Xi), of state Xi as follows:\nVi(X) = (1 \u2212ci) Vi\u22121(X) + ci\n[\nri + \u03b3Vi\u22121(X\u2032\ni)\n]\nif X = Xi,\n= Vi\u22121(X)\notherwise. We see that this adjustment moves the value ofVi(Xi) an increment (depend-\ning on ci) closer to\n[\nri + \u03b3Vi(X\u2032\ni)\n]\n. Assuming that Vi(X\u2032\ni) is a good estimate for\nVi(X\u2032\ni), then this adjustment helps to make the two estimates more consistent. Providing that 0 < ci < 1 and that we visit each state in\ufb01nitely often, this\nprocess of value iteration will converge to the optimal values. Discuss synchronous dynamic\nprogramming, asynchronous\ndynamic programming, and policy\niteration. 11.4 Q-Learning\nWatkins [Watkins, 1989] has proposed a technique that he calls incremental\ndynamic programming. Let a; \u03c0 stand for the policy that chooses action aonce,\nand thereafter chooses actions according to policy \u03c0.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 155, 'page_label': '156'}, page_content='We de\ufb01ne:\nQ\u03c0(X,a) = Va;\u03c0(X)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 156, 'page_label': '157'}, page_content='148 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nThen the optimal value from state X is given by:\nV\u03c0\u2217\n(X) = max\na\nQ\u03c0\u2217\n(X,a)\nThis equation holds only for an optimal policy, \u03c0\u2217. The optimal policy is given\nby:\n\u03c0\u2217(X) = arg max\na\nQ\u03c0\u2217\n(X,a)\nNote that if an actionamakes Q\u03c0(X,a) larger than V\u03c0(X), then we can improve\n\u03c0 by changing it so that \u03c0(X) = a. Making such a change is the basis for a\npowerful learning rule that we shall describe shortly.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 156, 'page_label': '157'}, page_content='Suppose action ain state X leads to state X\u2032. Then using the de\ufb01nitions of\nQ and V, it is easy to show that:\nQ\u03c0(X,a) = r(X,a) + \u03b3E[V\u03c0(X\u2032)]\nwhere r(X,a) is the average value of the immediate reward received when we\nexecute action a in state X. For an optimal policy (and no others), we have\nanother version of the optimality equation in terms of Q values:\nQ\u03c0\u2217\n(X,a) = max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nfor all actions, a, and states, X. Now, if we had the optimal Q values (for all\na and X), then we could implement an optimal policy simply by selecting that\naction that maximized r(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]\n. That is,\n\u03c0\u2217(X) = arg max\na\n[\nr(X,a) + \u03b3E\n[\nQ\u03c0\u2217\n(X\u2032,a)\n]]\nWatkins proposal amounts to a TD(0) method of learning the Q values. We quote (with minor notational changes) from [Watkins & Dayan, 1992, page\n281]:\nIn Q-Learning, the agents experience consists of a sequence of dis-\ntinct stages or episodes. In the i-th episode, the agent:\n observes its current state Xi,\n selects [using the method described below] and performs an\naction ai,\n observes the subsequent state X\u2032\ni,\n receives an immediate reward ri, and'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 157, 'page_label': '158'}, page_content='11.4. Q-LEARNING 149\n adjusts its Qi\u22121 values using a learning factor ci, according to:\nQi(X,a) = (1 \u2212ci)Qi\u22121(X,a) + ci[ri + \u03b3Vi\u22121(X\u2032\ni)]\nif X = Xi and a= ai,\n= Qi\u22121(X,a)\notherwise,\nwhere\nVi\u22121(X\u2032) = max\nb\n[Qi\u22121(X\u2032,b)]\nis the best the agent thinks it can do from state X\u2032. ... The\ninitial Qvalues, Q0(X,a), for all states and actions are assumed\ngiven.\nUsing the current Q values, Qi(X,a), the agent always selects that action\nthat maximizes Qi(X,a). Note that only the Q value corresponding to the\nstate just exited and the action just taken is adjusted. And that Q value is\nadjusted so that it is closer (by an amount determined by ci) to the sum of\nthe immediate reward plus the discounted maximum (over all actions) of the Q\nvalues of the state just entered. If we imagine the Qvalues to be predictions of\nultimate (in\ufb01nite horizon) total reward, then the learning procedure described\nabove is exactly a TD(0) method of learning how to predict these Q values. Q learning strengthens the usual TD methods, however, because TD (applied\nto reinforcement problems using value iteration) requires a one-step lookahead,\nusing a model of the e\ufb00ects of actions, whereas Q learning does not. A convenient notation (proposed by [Schwartz, 1993]) for representing the\nchange in Q value is:\nQ(X,a)\n\u03b2\n\u2190\u2212r+ \u03b3V(X\u2032)\nwhere Q(X,a) is the new Qvalue for input X and action a, r is the immediate\nreward when action a is taken in response to input X, V(X\u2032) is the maximum\n(over all actions) of the Qvalue of the state next reached when action ais taken\nfrom state X, and \u03b2 is the fraction of the way toward which the new Q value,\nQ(X,a), is adjusted to equal r+ \u03b3V(X\u2032). Watkins and Dayan [Watkins & Dayan, 1992] prove that, under certain con-\nditions, the Q values computed by this learning procedure converge to optimal\nones (that is, to ones on which an optimal policy can be based). We de\ufb01ne ni(X,a) as the index (episode number) of thei-th time that action\na is tried in state X.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 157, 'page_label': '158'}, page_content='Then, we have:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 158, 'page_label': '159'}, page_content='150 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nTheorem 11.1 (Watkins and Dayan) For Markov problems with states{X}\nand actions {a}, and given bounded rewards |rn|\u2264 R, learning rates 0 \u2264cn <1,\nand\n\u221e\u2211\ni=0\ncni(X,a) = \u221e,\n\u221e\u2211\ni=0\n[\ncni(X,a)\n]2\n<\u221e\nfor all X and a, then\nQn(X,a) \u2192Q\u2217\nn(X,a) as n \u2192\u221e, for all X and a, with probability 1, where\nQ\u2217\nn(X,a) corresponds to the Q values of an optimal policy. Again, we quote from [Watkins & Dayan, 1992, page 281]:\nThe most important condition implicit in the convergence theorem\n... is that the sequence of episodes that forms the basis of learning\nmust include an in\ufb01nite number of episodes for each starting state\nand action. This may be considered a strong condition on the way\nstates and actions are selectedhowever, under the stochastic con-\nditions of the theorem, no method could be guaranteed to \ufb01nd an\noptimal policy under weaker conditions. Note, however, that the\nepisodes need not form a continuous sequencethat is the X\u2032of one\nepisode need not be the X of the next episode.\nThe relationships among Q learning, dynamic programming, and control\nare very well described in [Barto, Bradtke, & Singh, 1994]. Q learning is best\nthought of as a stochastic approximation method for calculating the Q values. Although the de\ufb01nition of the optimalQvalues for any state depends recursively\non expected values of the Q values for subsequent states (and on the expected\nvalues of rewards), no expected values are explicitly computed by the procedure. Instead, these values are approximated by iterative sampling using the actual\nstochastic mechanism that produces successor states. 11.5 Discussion, Limitations, and Extensions of\nQ-Learning\n11.5.1 An Illustrative Example\nThe Q-learning procedure requires that we maintain a table of Q(X,a) values\nfor all state-action pairs. In the grid world that we described earlier, such a\ntable would not be excessively large.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 158, 'page_label': '159'}, page_content='We might start with random entries in the\ntable; a portion of such an intial table might be as follows:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 159, 'page_label': '160'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING151\nX a Q(X,a) r(X,a)\n(2,3) w 7 0\n(2,3) n 4 0\n(2,3) e 3 0\n(2,3) s 6 0\n(1,3) w 4 -1\n(1,3) n 5 0\n(1,3) e 2 0\n(1,3) s 4 0\nSuppose the robot is in cell (2,3). The maximumQvalue occurs fora= w, so the\nrobot moves west to cell (1,3)receiving no immediate reward. The maximum\nQ value in cell (1,3) is 5, and the learning mechanism attempts to make the\nvalue of Q((2,3),w) closer to the discounted value of 5 plus the immediate\nreward (which was 0 in this case). With a learning rate parameter c = 0 .5\nand \u03b3 = 0.9, the Q value of Q((2,3),w) is adjusted from 7 to 5.75. No other\nchanges are made to the table at this episode.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 159, 'page_label': '160'}, page_content='The reader might try this learning\nprocedure on the grid world with a simple computer program. Notice that an\noptimal policy might not be discovered if some cells are not visited nor some\nactions not tried frequently enough. The learning problem faced by the agent is to associate speci\ufb01c actions with\nspeci\ufb01c input patterns. Q learning gradually reinforces those actions that con-\ntribute to positive rewards by increasing the associated Q values. Typically, as\nin this example, rewards occur somewhat after the actions that lead to them\nhence the phrase delayed-reinforcement learning. One can imagine that better\nand better approximations to the optimal Q values gradually propagate back\nfrom states producing rewards toward all of the other states that the agent fre-\nquently visits. With random Qvalues to begin, the agents actions amount to a\nrandom walk through its space of states. Only when this random walk happens\nto stumble into rewarding states does Q learning begin to produce Q values\nthat are useful, and, even then, the Q values have to work their way outward\nfrom these rewarding states. The general problem of associating rewards with\nstate-action pairs is called the temporal credit assignment problemhow should\ncredit for a reward be apportioned to the actions leading up to it? Qlearning is,\nto date, the most successful technique for temporal credit assignment, although\na related method, called the bucket brigade algorithm , has been proposed by\n[Holland, 1986]. Learning problems similar to that faced by the agent in our grid world have\nbeen thoroughly studied by Sutton who has proposed an architecture, called\nDYNA, for solving them [Sutton, 1990]. DYNA combines reinforcement learning\nwith planning. Sutton characterizes planning as learning in a simulated world\nthat models the world that the agent inhabits. The agents model of the world\nis obtained by Q learning in its actual world, and planning is accomplished by\nQ learning in its model of the world. We should note that the learning problem faced by our grid-world robot'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 160, 'page_label': '161'}, page_content='152 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\ncould be modi\ufb01ed to have several places in the grid that give positive rewards. This possibility presents an interesting way to generalize the classical notion of\na goal in AI planning systemseven in those that do no learning. Instead of\nrepresenting a goal as a condition to be achieved, we represent a goal struc-\nture as a set of rewards to be given for achieving various conditions. Then,\nthe generalized goal becomes maximizing discounted future reward instead of\nsimply achieving some particular condition. This generalization can be made to\nencompass so-called goals of maintenance and goals of avoidance. The exam-\nple presented above included avoiding bumping into the grid-world boundary.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 160, 'page_label': '161'}, page_content='A goal of maintenance, of a particular state, could be expressed in terms of a\nreward that was earned whenever the agent was in that state and performed an\naction that transitioned back to that state in one step. 11.5.2 Using Random Actions\nWhen the next pattern presentation in a sequence of patterns is the one caused\nby the agents own action in response to the last pattern, we have what is called\nan on-line learning method. In Watkins and Dayans terminology, in on-line\nlearning the episodes form a continous sequence. As already mentioned, the\nconvergence theorem for Q learning does not require on-line learning; indeed,\nspecial precautions must be taken to ensure that on-line learning meets the\nconditions of the theorem. If on-line learning discovers some good paths to\nrewards, the agent may \ufb01xate on these and never discover a policy that leads\nto a possibly greater long-term reward. In reinforcement learning phraseology,\nthis problem is referred to as the problem of exploitation (of already learned\nbehavior) versus exploration (of possibly better behavior). One way to force exploration is to perform occasional random actions (in-\nstead of that single action prescribed by the current Q values). For example,\nin the grid-world problem, one could imagine selecting an action randomly ac-\ncording to a probability distribution over the actions ( n,e,s, and w). This\ndistribution, in turn, could depend on the Q values. For example, we might\n\ufb01rst \ufb01nd that action prescribed by the Q values and then choose that action\nwith probability 1/2, choose the two orthogonal actions with probability 3/16\neach, and choose the opposite action with probability 1/8. This policy might be\nmodi\ufb01ed by simulated annealing which would gradually increase the probabil-\nity of the action prescribed by theQvalues more and more as time goes on. This\nstrategy would favor exploration at the beginning of learning and exploitation\nlater. Other methods, also, have been proposed for dealing with exploration, in-\ncluding making unvisited states intrinsically rewarding and using an interval\nestimate, which is related to the uncertainty in the estimate of a states value\n[Kaelbling, 1993].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 161, 'page_label': '162'}, page_content='11.5. DISCUSSION, LIMITATIONS, AND EXTENSIONS OF Q-LEARNING153\n11.5.3 Generalizing Over Inputs\nFor large problems it would be impractical to maintain a table like that used\nin our grid-world example. Various researchers have suggested mechanisms for\ncomputing Q values, given pattern inputs and actions. One method that sug-\ngests itself is to use a neural network. For example, consider the simple linear\nmachine shown in Fig. 11.4. X\n. . . . .'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 161, 'page_label': '162'}, page_content='. Y\nY\nY\ntrainable weights\nY\nWi\nR dot product units\nQ(ai, X) = X . Wi\nQ(a1, X)\nQ(a2, X)\nQ(aR, X)\nFigure 11.4: A Net that Computes Q Values\nSuch a neural net could be used by an agent that has R actions to select\nfrom. The Qvalues (as a function of the input pattern X and the action ai) are\ncomputed as dot products of weight vectors (one for each action) and the input\nvector. Weight adjustments are made according to a TD(0) procedure to bring\nthe Qvalue for the action last selected closer to the sum of the immediate reward\n(if any) and the (discounted) maximum Q value for the next input pattern. If the optimum Qvalues for the problem (whatever they might be) are more\ncomplex than those that can be computed by a linear machine, a layered neural\nnetwork might be used. Sigmoid units in the \ufb01nal layer would compute Qvalues\nin the range 0 to 1. The TD(0) method for updatingQvalues would then have to\nbe combined with a multi-layer weight-changing rule, such as backpropagation. Networks of this sort are able to aggregate di\ufb00erent input vectors into regions\nfor which the same action should be performed. This kind of aggregation is an\nexample of what has been calledstructural credit assignment. Combining TD(\u03bb)\nand backpropagation is a method for dealing with both the temporal and the\nstructural credit assignment problems.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 162, 'page_label': '163'}, page_content='154 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING\nInteresting examples of delayed-reinforcement training of simulated and\nactual robots requiring structural credit assignment have been reported by\n[Lin, 1992, Mahadevan & Connell, 1992]. 11.5.4 Partially Observable States\nSo far, we have identi\ufb01ed the input vector, X, with the actual state of the envi-\nronment. When the input vector results from an agents perceptual apparatus\n(as we assume it does), there is no reason to suppose that it uniquely identi\ufb01es\nthe environmental state. Because of inevitable perceptual limitations, several\ndi\ufb00erent environmental states might give rise to the same input vector. This\nphenomenon has been referred to as perceptual aliasing. With perceptual alias-\ning, we can no longer guarantee that Qlearning will result in even useful action\npolicies, let alone optimal ones. Several researchers have attempted to deal with\nthis problem using a variety of methods including attempting to model hid-\nden states by using internal memory [Lin, 1993]. That is, if some aspect of\nthe environment cannot be sensed currently, perhaps it was sensed once and\ncan be remembered by the agent. When such is the case, we no longer have a\nMarkov problem; that is, the next X vector, given any action, may depend on\na sequence of previous ones rather than just the immediately preceding one. It\nmight be possible to reinstate a Markov framework (over the Xs) if X includes\nnot only current sensory precepts but information from the agents memory. 11.5.5 Scaling Problems\nSeveral di\ufb03culties have so far prohibited wide application of reinforcement learn-\ning to large problems. (The TD-gammon program, mentioned in the last chap-\nter, is probably unique in terms of success on a high-dimensional problem.)\nWe have already touched on some di\ufb03culties; these and others are summarized\nbelow with references to attempts to overcome them. a.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 162, 'page_label': '163'}, page_content='Exploration versus exploitation.  use random actions\n favor states not visited recently\n separate the learning phase from the use phase\n employ a teacher to guide exploration\nb. Slow time to convergence\n combine learning with prior knowledge; use estimates of Q values\n(rather than random values) initially\n use a hierarchy of actions; learn primitive actions \ufb01rst and freeze the\nuseful sequences into macros and then learn how to use the macros'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 163, 'page_label': '164'}, page_content='11.6. BIBLIOGRAPHICAL AND HISTORICAL REMARKS 155\n employ a teacher; use graded lessonsstarting near the rewards\nand then backing away, and use examples of good behavior [Lin, 1992]\n use more e\ufb03cient computations; e.g. do several updates per episode\n[Moore & Atkeson, 1993]\nc. Large state spaces\n use hand-coded features\n use neural networks\n use nearest-neighbor methods [Moore, 1990]\nd. Temporal discounting problems. Using small \u03b3 can make the learner too\ngreedy for present rewards and indi\ufb00erent to the future; but using large \u03b3\nslows down learning.  use a learning method based on average rewards [Schwartz, 1993]\ne. No transfer of learning . What is learned depends on the reward struc-\nture; if the rewards change, learning has to start over.  Separate the learning into two parts: learn an action model which\npredicts how actions change states (and is constant over all prob-\nlems), and then learn the values of states by reinforcement learn-\ning for each di\ufb00erent set of rewards. Sometimes the reinforcement\nlearning part can be replaced by a planner that uses the action\nmodel to produce plans to achieve goals. Also see other articles in the special issue on reinforcement learning:Machine\nLearning, 8, May, 1992.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 163, 'page_label': '164'}, page_content='11.6 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 164, 'page_label': '165'}, page_content='156 CHAPTER 11. DELAYED-REINFORCEMENT LEARNING'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 165, 'page_label': '166'}, page_content='Chapter 12\nExplanation-Based\nLearning\n12.1 Deductive Learning\nIn the learning methods studied so far, typically the training set does not ex-\nhaust the version space. Using logical terminology, we could say that the classi-\n\ufb01ers output does not logically follow from the training set. In this sense, these\nmethods are inductive. In logic, a deductive system is one whose conclusions\nlogically follow from a set of input facts, if the system is sound. 1\nTo contrast inductive with deductive systems in a logical setting, suppose\nwe have a set of facts (the training set) that includes the following formulas:\n{Round(Obj1),Round(Obj2),Round(Obj3),Round(Obj4),\nBall(Obj1),Ball(Obj2),Ball(Obj3),Ball(Obj4)}\nA learning system that forms the conclusion ( \u2200x)[Ball(x) \u2283Round(x)] is in-\nductive. This conclusion may be useful (if there are no facts of the form\nBall(\u03c3) \u2227¬Round(\u03c3)), but it does not logically follow from the facts.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 165, 'page_label': '166'}, page_content='On the\nother hand, if we had the facts Green(Obj5) and Green(Obj5) \u2283Round(Obj5),\nthen we could logically conclude Round(Obj5). Making this conclusion and sav-\ning it is an instance of deductive learninga topic we study in this chapter. Suppose that some logical proposition, \u03c6, logically follows from some set of\nfacts, \u2206. Under what circumstances might we say that the process of deducing\n\u03c6 from \u2206 results in our learning \u03c6? In a sense, we implicitly knew \u03c6 all along,\nsince it was inherent in knowing \u2206. Yet, \u03c6 might not be obvious given \u2206, and\n1Logical reasoning systems that are not sound, for example those using non-monotonic\nreasoning, themselves might produce inductive conclusions that do not logically follow from\nthe input facts. 157'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 166, 'page_label': '167'}, page_content='158 CHAPTER 12. EXPLANATION-BASED LEARNING\nthe deduction process to establish \u03c6might have been arduous. Rather than have\nto deduce \u03c6 again, we might want to save it, perhaps along with its deduction,\nin case it is needed later. Shouldnt that process count as learning? Dietterich\n[Dietterich, 1990] has called this type of learning speed-up learning. Strictly speaking, speed-up learning does not result in a system being able to\nmake decisions that, in principle, could not have been made before the learning\ntook place. Speed-up learning simply makes it possible to make those decisions\nmore e\ufb03ciently. But, in practice, this type of learning might make possible\ncertain decisions that might otherwise have been infeasible. To take an extreme case, a chess player can be said to learn chess even though\noptimal play is inherent in the rules of chess. On the surface, there seems to be\nno real di\ufb00erence between the experience-based hypotheses that a chess player\nmakes about what constitutes good play and the kind of learning we have been\nstudying so far. As another example, suppose we are given some theorems about geometry\nand are asked to prove that the sum of the angles of a right triangle is 180\ndegrees. Let us further suppose that the proof we constructed did not depend\non the given triangle being a right triangle; in that case we can learn a more\ngeneral fact. The learning technique that we are going to study next is related\nto this example.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 166, 'page_label': '167'}, page_content='It is called explanation-based learning (EBL) . EBL can be\nthought of as a process in which implicit knowledge is converted into explicit\nknowledge. In EBL, we specialize parts of a domain theory to explain a particular ex-\nample, then we generalize the explanation to produce another element of the\ndomain theory that will be useful on similar examples. This process is illustrated\nin Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 166, 'page_label': '167'}, page_content='12.1. 12.2 Domain Theories\nTwo types of information were present in the inductive methods we have studied:\nthe information inherent in the training samples and the information about the\ndomain that is implied by the bias (for example, the hypothesis set from which\nwe choose functions). The learning methods are successful only if the hypothesis\nset is appropriate for the problem. Typically, the smaller the hypothesis set (that\nis, the more a priori information we have about the function being sought), the\nless dependent we are on information being supplied by a training set (that\nis, fewer samples). A priori information about a problem can be expressed in\nseveral ways. The methods we have studied so far restrict the hypotheses in a\nrather direct way. A less direct method involves making assertions in a logical\nlanguage about the property we are trying to learn. A set of such assertions is\nusually called a domain theory.\nSuppose, for example, that we wanted to classify people according to whether\nor not they were good credit risks. We might represent a person by a set of\nproperties (income, marital status, type of employment, etc.), assemble such'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 167, 'page_label': '168'}, page_content='12.3. AN EXAMPLE 159\nDomain\nTheory\nExample\n(X is P) Prove: X is P\nspecialize\nExplanation\n(Proof)\ngeneralize\nA New Domain Rule:\nThings "like" X are P\nY is like X\nComplex Proof\nProcess\nTrivial  Proof\nY is P\nFigure 12.1: The EBL Process\ndata about people who are known to be good and bad credit risks and train a\nclassi\ufb01er to make decisions. Or, we might go to a loan o\ufb03cer of a bank, ask him\nor her what sorts of things s/he looks for in making a decision about a loan,\nencode this knowledge into a set of rules for an expert system, and then use\nthe expert system to make decisions. The knowledge used by the loan o\ufb03cer\nmight have originated as a set of policies (the domain theory), but perhaps the\napplication of these policies were specialized and made more e\ufb03cient through\nexperience with the special cases of loans made in his or her district. 12.3 An Example\nTo make our discussion more concrete, lets consider the following fanciful exam-\nple.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 167, 'page_label': '168'}, page_content='We want to \ufb01nd a way to classify robots as robust or not. The attributes\nthat we use to represent a robot might include some that are relevant to this\ndecision and some that are not.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 168, 'page_label': '169'}, page_content='160 CHAPTER 12. EXPLANATION-BASED LEARNING\nSuppose we have a domain theory of logical sentences that taken together,\nhelp to de\ufb01ne whether or not a robot can be classi\ufb01ed as robust. (The same\ndomain theory may be useful for several other purposes also, but among other\nthings, it describes the concept robust.)\nIn this example, lets suppose that our domain theory includes the sentences:\nFixes(u,u) \u2283Robust(u)\n(An individual that can \ufb01x itself is robust.)\nSees(x,y) \u2227Habile(x) \u2283Fixes(x,y)\n(A habile individual that can see another entity can \ufb01x that entity.)\nRobot(w) \u2283Sees(w,w)\n(All robots can see themselves.)\nR2D2(x) \u2283Habile(x)\n(R2D2-class individuals are habile.)\nC3PO(x) \u2283Habile(x)\n(C3PO-class individuals are habile.)\n... (By convention, variables are assumed to be universally quanti\ufb01ed.) We could\nuse theorem-proving methods operating on this domain theory to conclude\nwhether certain robots are robust. These methods might be computationally\nquite expensive because extensive search may have to be performed to derive a\nconclusion.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 168, 'page_label': '169'}, page_content='But after having found a proof for some particular robot, we might\nbe able to derive some new sentence whose use allows a much faster conclusion. We next show how such a new rule might be derived in this example. Suppose\nwe are given a number of facts about Num5, such as:\nRobot(Num5)\nR2D2(Num5)\nAge(Num5,5)\nManufacturer(Num5,GR)\n...'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 169, 'page_label': '170'}, page_content='12.3. AN EXAMPLE 161\nFixes(u, u) => Robust(u)\nRobust(Num5)\nFixes(Num5, Num5)\nSees(Num5,Num5) Habile(Num5)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nRobot(w)\n     => Sees(w,w)\nRobot(Num5)\nR2D2(x)\n         => Habile(x)\nR2D2(Num5)\nFigure 12.2: A Proof Tree\nWe are also told that Robust(Num5) is true, but we nevertheless attempt to\n\ufb01nd a proof of that assertion using these facts about Num5 and the domain\ntheory. The facts about Num5 correspond to the features that we might use\nto represent Num5. In this example, not all of them are relevant to a decision\nabout Robust(Num5). The relevant ones are those used or needed in proving\nRobust(Num5) using the domain theory. The proof tree in Fig. 12.2 is one that\na typical theorem-proving system might produce. In the language of EBL, this proof is an explanation for the fact\nRobust(Num5). We see from this explanation that the only facts about Num5\nthat were used were Robot(Num5) and R2D2(Num5). In fact, we could con-\nstruct the following rule from this explanation:\nRobot(Num5) \u2227R2D2(Num5) \u2283Robust(Num5)\nThe explanation has allowed us to prune some attributes about Num5 that are\nirrelevant (at least for decidingRobust(Num5)). This type of pruning is the \ufb01rst\nsense in which an explanation is used to generalize the classi\ufb01cation problem. ([DeJong & Mooney, 1986] call this aspect of explanation-based learning feature\nelimination.) But the rule we extracted from the explanation applies only to\nNum5. There might be little value in learning that rule since it is so speci\ufb01c.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 169, 'page_label': '170'}, page_content='Can it be generalized so that it can be applied to other individuals as well?'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 170, 'page_label': '171'}, page_content='162 CHAPTER 12. EXPLANATION-BASED LEARNING\nExamination of the proof shows that the same proof structure, using the\nsame sentences from the domain theory, could be used independently of whether\nwe are talking about Num5 or some other individual. We can generalize the\nproof by a process that replaces constants in the tip nodes of the proof tree\nwith variables and works upwardusing uni\ufb01cation to constrain the values of\nvariables as needed to obtain a proof. In this example, we replace Robot(Num5) by Robot(r) and R2D2(Num5)\nby R2D2(s) and redo the proofusing the explanation proof as a template. Note that we use di\ufb00erent values for the two di\ufb00erent occurrences of Num5 at\nthe tip nodes. Doing so sometimes results in more general, but nevertheless\nvalid rules.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 170, 'page_label': '171'}, page_content='We now apply the rules used in the proof in the forward direction,\nkeeping track of the substitutions imposed by the most general uni\ufb01ers used in\nthe proof. (Note that we always substitute terms that are already in the tree for\nvariables in rules.) This process results in the generalized proof tree shown in\nFig. 12.3. Note that the occurrence of Sees(r,r) as a node in the tree forces the\nuni\ufb01cation of xwith yin the domain rule, Sees(x,y)\u2227Habile(y) \u2283Fixes(x,y). The substitutions are then applied to the variables in the tip nodes and the root\nnode to yield the general rule: Robot(r) \u2227R2D2(r) \u2283Robust(r). This rule is the end result of EBL for this example. The process\nby which Num5 in this example was generalized to a variable is what\n[DeJong & Mooney, 1986] call identity elimination (the precise identity of Num5\nturned out to be irrelevant). (The generalization process described in this ex-\nample is based on that of [DeJong & Mooney, 1986] and di\ufb00ers from that of\n[Mitchell, et al., 1986]. It is also similar to that used in [Fikes, et al., 1972].)\nClearly, under certain assumptions, this general rule is more easily used to con-\nclude Robust about an individual than the original proof process was. It is important to note that we could have derived the general rule from the\ndomain theory without using the example. (In the literature, doing so is called\nstatic analysis [Etzioni, 1991].) In fact, the example told us nothing new other\nthan what it told us about Num5. The sole role of the example in this instance\nof EBL was to provide a template for a proof to help guide the generalization\nprocess. Basing the generalization process on examples helps to insure that we\nlearn rules matched to the distribution of problems that occur. There are a number of quali\ufb01cations and elaborations about EBL that need\nto be mentioned. 12.4 Evaluable Predicates\nThe domain theory includes a number of predicates other than the one occuring\nin the formula we are trying to prove and other than those that might custom-\narily be used to describe an individual. One might note, for example, that if we\nused Habile(Num5) to describe Num5, the proof would have been shorter.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 170, 'page_label': '171'}, page_content='Why\ndidnt we? The situation is analogous to that of using a data base augmented\nby logical rules. In the latter application, the formulas in the actual data base'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 171, 'page_label': '172'}, page_content='12.4. EVALUABLE PREDICATES 163\nRobust(r)\nFixes(r, r)\nSees(r,r) Habile(s)\nRobot(r) R2D2(s)\n{r/w}\n{s/x}\n{r/x, r/y, r/s}\n{r/u}\nRobot(w)\n     => Sees(w,w)\nR2D2(x)\n         => Habile(x)\nSees(x,y) & Habile(x)\n              => Fixes(x,y)\nFixes(u, u) => Robust(u)\nbecomes R2D2(r) after\napplying {r/s}\nFigure 12.3: A Generalized Proof Tree\nare extensional, and those in the logical rules are intensional. This usage\nre\ufb02ects the fact that the predicates in the data base part are de\ufb01ned by their\nextensionwe explicitly list all the tuples sastisfying a relation. The logical\nrules serve to connect the data base predicates with higher level abstractions\nthat are described (if not de\ufb01ned) by the rules.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 171, 'page_label': '172'}, page_content='We typically cannot look up\nthe truth values of formulas containing these intensional predicates; they have\nto be derived using the rules and the database. The EBL process assumes something similar. The domain theory is useful\nfor connecting formulas that we might want to prove with those whose truth\nvalues can be looked up or otherwise evaluated. In the EBL literature, such\nformulas satisfy what is called the operationality criterion. Perhaps another\nanalogy might be to neural networks. The evaluable predicates correspond to\nthe components of the input pattern vector; the predicates in the domain theory\ncorrespond to the hidden units. Finding the new rule corresponds to \ufb01nding a\nsimpler expression for the formula to be proved in terms only of the evaluable\npredicates.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 172, 'page_label': '173'}, page_content='164 CHAPTER 12. EXPLANATION-BASED LEARNING\n12.5 More General Proofs\nExamining the domain theory for our example reveals that an alternative rule\nmight have been: Robot(u) \u2227C3PO(u) \u2283 Robust(u). Such a rule might\nhave resulted if we were given {C3PO(Num6),Robot(Num6),... }and proved\nRobust(Num6). After considering these two examples (Num5 and Num6),\nthe question arises, do we want to generalize the two rules to something like:\nRobot(u)\u2227[C3PO(u)\u2228R2D2(u)] \u2283Robust(u)? Doing so is an example of what\n[DeJong & Mooney, 1986] call structural generalization (via disjunctive augmen-\ntation ). Adding disjunctions for every alternative proof can soon become cumbersome\nand destroy any e\ufb03ciency advantage of EBL. In our example, the e\ufb03ciency\nmight be retrieved if there were another evaluable predicate, say,Bionic(u) such\nthat the domain theory also contained R2D2(x) \u2283Bionic(x) and C3PO(x) \u2283\nBionic(x). After seeing a number of similar examples, we might be willing to\ninduce the formula Bionic(u) \u2283[C3PO(u) \u2228R2D2(u)] in which case the rule\nwith the disjunction could be replaced with Robot(u) \u2227Bionic(u) \u2283Robust(u). 12.6 Utility of EBL\nIt is well known in theorem proving that the complexity of \ufb01nding a proof\ndepends both on the number of formulas in the domain theory and on the depth\nof the shortest proof. Adding a new rule decreases the depth of the shortest\nproof but it also increases the number of formulas in the domain theory. In\nrealistic applications, the added rules will be relevant for some tasks and not for\nothers.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 172, 'page_label': '173'}, page_content='Thus, it is unclear whether the overall utility of the new rules will turn\nout to be positive. EBL methods have been applied in several settings, usually\nwith positive utility. (See [Minton, 1990] for an analysis). 12.7 Applications\nThere have been several applications of EBL methods. We mention two here,\nnamely the formation of macro-operators in automatic plan generation and\nlearning how to control search. 12.7.1 Macro-Operators in Planning\nIn automatic planning systems, e\ufb03ciency can sometimes be enhanced by chain-\ning together a sequence of operators into macro-operators. We show an exam-\nple of a process for creating macro-operators based on techniques explored by\n[Fikes, et al., 1972]. Referring to Fig. 12.4, consider the problem of \ufb01nding a plan for a robot in\nroom R1 to fetch a box, B1, by going to an adjacent room, R2, and pushing it'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 173, 'page_label': '174'}, page_content='12.7.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 173, 'page_label': '174'}, page_content='APPLICATIONS 165\nback to R1. The goal for the robot is INROOM (B1,R1), and the facts that\nare true in the initial state are listed in the \ufb01gure. R1 R2\nR3\nD1\nD2\nB1\nInitial State:\nINROOM(ROBOT, R1)\nINROOM(B1,R2)\nCONNECTS(D1,R1,R2)\nCONNECTS(D1,R2,R1)\n. . . Figure 12.4: Initial State of a Robot Problem\nWe will construct the plan from a set of STRIPS operators that include:\nGOTHRU(d,r1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2)\nDelete list: INROOM (ROBOT,r 1)\nAdd list: INROOM (ROBOT,r 2)\nPUSHTHRU(b,d,r 1,r2)\nPreconditions: INROOM (ROBOT,r 1),CONNECTS (d,r1,r2),INROOM (b,r1)\nDelete list: INROOM (ROBOT,r 1),INROOM (b,r1)\nAdd list: INROOM (ROBOT,r 2),INROOM (b,r2)\nA backward-reasoning STRIPS system might produce the plan shown in\nFig. 12.5. We show there the main goal and the subgoals along a solution path. (The conditions in each subgoal that are true in the initial state are shown\nunderlined.) The preconditions for this plan, true in the initial state, are:\nINROOM (ROBOT,R 1)'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 174, 'page_label': '175'}, page_content='166 CHAPTER 12. EXPLANATION-BASED LEARNING\nCONNECTS (D1,R1,R2)\nCONNECTS (D1,R2,R1)\nINROOM (B1,R2)\nSaving this speci\ufb01c plan, valid only for the speci\ufb01c constants it mentions, would\nnot be as useful as would be saving a more general one. We \ufb01rst generalize\nthese preconditions by substituting variables for constants. We then follow the\nstructure of the speci\ufb01c plan to produce the generalized plan shown in Fig.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 174, 'page_label': '175'}, page_content='12.6\nthat achievesINROOM (b1,r4). Note that the generalized plan does not require\npushing the box back to the place where the robot started. The preconditions\nfor the generalized plan are:\nINROOM (ROBOT,r 1)\nCONNECTS (d1,r1,r2)\nCONNECTS (d2,r2,r4)\nINROOM (b,r4)\nINROOM(B1,R1)\nPUSHTHRU(B1,d,r1,R1)\nINROOM(ROBOT, r1),\nCONNECTS(d, r1, R1),\nINROOM(B1, r1)\nINROOM(ROBOT, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2){R2/r1,\nD1/d}\nGOTHRU(d2, r3, R2)\nINROOM(ROBOT, r3),\nCONNECTS(d2, r3, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\n{R1/r3, D1/d2}\nINROOM(ROBOT, R1),\nCONNECTS(D1, R1, R2),\nCONNECTS(D1, R2, R1),\nINROOM(B1, R2)\nR1 R2\nR3\nD1\nD2\nGOTHRU(D1,R1,R2)\nPUSHTHRU(B1,D1,R2,R1)\nB1\nPLAN:\nFigure 12.5: A Plan for the Robot Problem\nAnother related technique that chains together sequences of operators to\nform more general ones is the chunking mechanism in Soar [Laird, et al., 1986].'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 175, 'page_label': '176'}, page_content='12.7. APPLICATIONS 167\nINROOM(b1,r4)\nPUSHTHRU(b1,d2,r2,r4)\nINROOM(ROBOT, r2),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nGOTHRU(d1, r1, r2)\nINROOM(ROBOT, r1),\nCONNECTS(d1, r1, r2),\nCONNECTS(d2, r2, r4),\nINROOM(b1, r4)\nFigure 12.6: A Generalized Plan\n12.7.2 Learning Search Control Knowledge\nBesides their use in creating macro-operators, EBL methods can be used to\nimprove the e\ufb03ciency of planning in another way also. In his system called\nPRODIGY, Minton proposed using EBL to learn e\ufb00ective ways to control\nsearch [Minton, 1988]. PRODIGY is a STRIPS-like system that solves planning\nproblems in the blocks-world, in a simple mobile robot world, and in job-shop\nscheduling. PRODIGY has a domain theory involving both the domain of the\nproblem and a simple (meta) theory about planning. Its meta theory includes\nstatements about whether a control choice about a subgoal to work on, an oper-\nator to apply, etc. either succeedsor fails.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 175, 'page_label': '176'}, page_content='After producing a plan, it analyzes its\nsuccessful and its unsuccessful choices and attempts to explain them in terms\nof its domain theory. Using an EBL-like process, it is able to produce useful\ncontrol rules such as:'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 176, 'page_label': '177'}, page_content='168 CHAPTER 12. EXPLANATION-BASED LEARNING\nIF (AND (CURRENT \u2212NODE node)\n(CANDIDATE \u2212GOAL node (ON x y))\n(CANDIDATE \u2212GOAL node (ON y z)))\nTHEN (PREFER GOAL (ON y z) TO (ON x y))\nPRODIGY keeps statistics on how often these learned rules are used, their\nsavings (in time to \ufb01nd plans), and their cost of application. It saves only the\nrules whose utility, thus measured, is judged to be high.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 176, 'page_label': '177'}, page_content='Minton [Minton, 1990]\nhas shown that there is an overall advantage of using these rules (as against not\nhaving any rules and as against hand-coded search control rules). 12.8 Bibliographical and Historical Remarks\nTo be added.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 177, 'page_label': '178'}, page_content='Bibliography\n[Acorn & Walden, 1992] Acorn, T., and Walden, S., SMART: Support Man-\nagement Automated Reasoning Technology for COMPAQ Customer Ser-\nvice, Proc. Fourth Annual Conf.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 177, 'page_label': '178'}, page_content='on Innovative Applications of Arti\ufb01cial\nIntelligence, Menlo Park, CA: AAAI Press, 1992. [Aha, 1991] Aha, D., Kibler, D., and Albert, M., Instance-Based Learning\nAlgorithms, Machine Learning, 6, 37-66, 1991. [Anderson & Bower, 1973] Anderson, J. R., and Bower, G. H., Human Asso-\nciative Memory, Hillsdale, NJ: Erlbaum, 1973. [Anderson, 1958] Anderson, T. W., An Introduction to Multivariate Statistical\nAnalysis, New York: John Wiley, 1958. [Barto, Bradtke, & Singh, 1994] Barto, A., Bradtke, S., and Singh, S., Learn-\ning to Act Using Real-Time Dynamic Programming, to appear in Ar-\nti\ufb01cial Intelligence, 1994. [Baum & Haussler, 1989] Baum, E, and Haussler, D., What Size Net Gives\nValid Generalization? Neural Computation, 1, pp. 151-160, 1989. [Baum, 1994] Baum, E., When Are k-Nearest Neighbor and Backpropagation\nAccurate for Feasible-Sized Sets of Examples? in Hanson, S., Drastal,\nG., and Rivest, R., (eds.), Computational Learning Theory and Natural\nLearning Systems, Volume 1: Constraints and Prospects , pp. 415-442,\nCambridge, MA: MIT Press, 1994. [Bellman, 1957] Bellman, R. E., Dynamic Programming, Princeton: Princeton\nUniversity Press, 1957. [Blumer, et al., 1987] Blumer, A., et al., Occams Razor, Info. Process. Lett.,\nvol 24, pp.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 177, 'page_label': '178'}, page_content='377-80, 1987. [Blumer, et al., 1990] Blumer, A., et al ., Learnability and the Vapnik-\nChervonenkis Dimension, JACM, 1990. [Bollinger & Du\ufb03e, 1988] Bollinger, J., and Du\ufb03e, N., Computer Control of\nMachines and Processes, Reading, MA: Addison-Wesley, 1988. 169'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 178, 'page_label': '179'}, page_content='170 BIBLIOGRAPHY\n[Brain, et al., 1962] Brain, A. E., et al. , Graphical Data Processing Research\nStudy and Experimental Investigation, Report No. 8 (pp. 9-13) and No.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 178, 'page_label': '179'}, page_content='9 (pp. 3-10), Contract DA 36-039 SC-78343, SRI International, Menlo\nPark, CA, June 1962 and September 1962. [Breiman, et al., 1984] Breiman, L., Friedman, J., Olshen, R., and Stone, C.,\nClassi\ufb01cation and Regression Trees, Monterey, CA: Wadsworth, 1984. [Brent, 1990] Brent, R. P., Fast Training Algorithms for Multi-Layer Neural\nNets, Numerical Analysis Project Manuscript NA-90-03, Computer Sci-\nence Department, Stanford University, Stanford, CA 94305, March 1990. [Bryson & Ho 1969] Bryson, A., and Ho, Y.-C., Applied Optimal Control, New\nYork: Blaisdell. [Buchanan & Wilkins, 1993] Buchanan, B. and Wilkins, D., (eds.), Readings in\nKnowledge Acquisition and Learning, San Francisco: Morgan Kaufmann,\n1993. [Carbonell, 1983] Carbonell, J., Learning by Analogy, in Machine Learning:\nAn Arti\ufb01cial Intelligence Approach , Michalski, R., Carbonell, J., and\nMitchell, T., (eds.), San Francisco: Morgan Kaufmann, 1983. [Cheeseman, et al., 1988] Cheeseman, P., et al., AutoClass: A Bayesian Clas-\nsi\ufb01cation System, Proc. Fifth Intl. Workshop on Machine Learning ,\nMorgan Kaufmann, San Mateo, CA, 1988. Reprinted in Shavlik, J. and\nDietterich, T., Readings in Machine Learning , Morgan Kaufmann, San\nFrancisco, pp. 296-306, 1990. [Cover & Hart, 1967] Cover, T., and Hart, P., Nearest Neighbor Pattern Clas-\nsi\ufb01cation, IEEE Trans. on Information Theory , 13, 21-27, 1967. [Cover, 1965] Cover, T., Geometrical and Statistical Properties of Systems\nof Linear Inequalities with Applications in Pattern Recognition, IEEE\nTrans. Elec.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 178, 'page_label': '179'}, page_content='Comp., EC-14, 326-334, June, 1965. [Dasarathy, 1991] Dasarathy, B. V., Nearest Neighbor Pattern Classi\ufb01cation\nTechniques, IEEE Computer Society Press, 1991. [Dayan & Sejnowski, 1994] Dayan, P., and Sejnowski, T.,  TD(\u03bb) Converges\nwith Probability 1, Machine Learning, 14, pp. 295-301, 1994. [Dayan, 1992] Dayan, P., The Convergence of TD( \u03bb) for General \u03bb, Machine\nLearning, 8, 341-362, 1992. [DeJong & Mooney, 1986] DeJong, G., and Mooney, R., Explanation-Based\nLearning: An Alternative View, Machine Learning, 1:145-176, 1986. Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 452-467.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 179, 'page_label': '180'}, page_content='BIBLIOGRAPHY 171\n[Dietterich & Bakiri, 1991] Dietterich, T. G., and Bakiri, G., Error-Correcting\nOutput Codes: A General Method for Improving Multiclass Induc-\ntive Learning Programs, Proc. Ninth Nat.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 179, 'page_label': '180'}, page_content='Conf. on A.I.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 179, 'page_label': '180'}, page_content=', pp. 572-577,\nAAAI-91, MIT Press, 1991. [Dietterich, et al., 1990] Dietterich, T., Hild, H., and Bakiri, G., A Compara-\ntive Study of ID3 and Backpropagation for English Text-to-Speech Map-\nping, Proc. Seventh Intl.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 179, 'page_label': '180'}, page_content='Conf. Mach. Learning, Porter, B. and Mooney,\nR. (eds.), pp. 24-31, San Francisco: Morgan Kaufmann, 1990. [Dietterich, 1990] Dietterich, T., Machine Learning, Annu. Rev. Comput. Sci., 4:255-306, Palo Alto: Annual Reviews Inc., 1990. [Duda & Fossum, 1966] Duda, R. O., and Fossum, H., Pattern Classi\ufb01cation\nby Iteratively Determined Linear and Piecewise Linear Discriminant\nFunctions, IEEE Trans. on Elect. Computers , vol. EC-15, pp. 220-232,\nApril, 1966. [Duda & Hart, 1973] Duda, R. O., and Hart, P.E., Pattern Classi\ufb01cation and\nScene Analysis, New York: Wiley, 1973. [Duda, 1966] Duda, R. O., Training a Linear Machine on Mislabeled Patterns,\nSRI Tech. Report prepared for ONR under Contract 3438(00), SRI In-\nternational, Menlo Park, CA, April 1966. [Efron, 1982] Efron, B., The Jackknife, the Bootstrap and Other Resampling\nPlans, Philadelphia: SIAM, 1982. [Ehrenfeucht, et al., 1988] Ehrenfeucht, A., et al., A General Lower Bound on\nthe Number of Examples Needed for Learning, in Proc. 1988 Workshop\non Computational Learning Theory, pp. 110-120, San Francisco: Morgan\nKaufmann, 1988. [Etzioni, 1991] Etzioni, O., STATIC: A Problem-Space Compiler for\nPRODIGY, Proc. of Ninth National Conf. on Arti\ufb01cial Intelligence ,\npp. 533-540, Menlo Park: AAAI Press, 1991. [Etzioni, 1993] Etzioni, O., A Structural Theory of Explanation-Based Learn-\ning, Arti\ufb01cial Intelligence, 60:1, pp. 93-139, March, 1993. [Evans & Fisher, 1992] Evans, B., and Fisher, D., Process Delay Analyses Using\nDecision-Tree Induction, Tech. Report CS92-06, Department of Com-\nputer Science, Vanderbilt University, TN, 1992. [Fahlman & Lebiere, 1990] Fahlman, S., and Lebiere, C., The Cascade-\nCorrelation Learning Architecture, in Touretzky, D., (ed.), Advances in\nNeural Information Processing Systems, 2 , pp. 524-532, San Francisco:\nMorgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 180, 'page_label': '181'}, page_content='172 BIBLIOGRAPHY\n[Fayyad, et al., 1993] Fayyad, U. M., Weir, N., and Djorgovski, S., SKICAT:\nA Machine Learning System for Automated Cataloging of Large Scale\nSky Surveys, in Proc. Tenth Intl.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 180, 'page_label': '181'}, page_content='Conf. on Machine Learning , pp. 112-\n119, San Francisco: Morgan Kaufmann, 1993. (For a longer version of\nthis paper see: Fayyad, U. Djorgovski, G., and Weir, N., Automating\nthe Analysis and Cataloging of Sky Surveys, in Fayyad, U., et al.(eds.),\nAdvances in Knowledge Discovery and Data Mining , Chapter 19, pp. 471\ufb00., Cambridge: The MIT Press, March, 1996.)\n[Feigenbaum, 1961] Feigenbaum, E. A., The Simulation of Verbal Learning Be-\nhavior, Proceedings of the Western Joint Computer Conference, 19:121-\n132, 1961. [Fikes, et al., 1972] Fikes, R., Hart, P., and Nilsson, N., Learning and Execut-\ning Generalized Robot Plans, Arti\ufb01cial Intelligence, pp 251-288, 1972. Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine Learn-\ning, San Francisco: Morgan Kaufmann, 1990, pp 468-486. [Fisher, 1987] Fisher, D., Knowledge Acquisition via Incremental Conceptual\nClustering, Machine Learning, 2:139-172, 1987. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 267283. [Friedman, et al., 1977] Friedman, J. H., Bentley, J. L., and Finkel, R. A., An\nAlgorithm for Finding Best Matches in Logarithmic Expected Time,\nACM Trans. on Math.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 180, 'page_label': '181'}, page_content='Software , 3(3):209-226, September 1977. [Fu, 1994] Fu, L., Neural Networks in Arti\ufb01cial Intelligence , New York:\nMcGraw-Hill, 1994. [Gallant, 1986] Gallant, S. I., Optimal Linear Discriminants, in Eighth Inter-\nnational Conf. on Pattern Recognition , pp. 849-852, New York: IEEE,\n1986. [Genesereth & Nilsson, 1987] Genesereth, M., and Nilsson, N., Logical Founda-\ntions of Arti\ufb01cial Intelligence , San Francisco: Morgan Kaufmann, 1987. [Gluck & Rumelhart, 1989] Gluck, M. and Rumelhart, D., Neuroscience and\nConnectionist Theory, The Developments in Connectionist Theory, Hills-\ndale, NJ: Erlbaum Associates, 1989. [Hammerstrom, 1993] Hammerstrom, D., Neural Networks at Work, IEEE\nSpectrum, pp. 26-32, June 1993. [Haussler, 1988] Haussler, D., Quantifying Inductive Bias: AI Learning Al-\ngorithms and Valiants Learning Framework, Arti\ufb01cial Intelligence ,\n36:177-221, 1988. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96-107.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 181, 'page_label': '182'}, page_content='BIBLIOGRAPHY 173\n[Haussler, 1990] Haussler, D., Probably Approximately Correct Learning,\nProc. Eighth Nat.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 181, 'page_label': '182'}, page_content='Conf. on AI , pp. 1101-1108. Cambridge, MA: MIT\nPress, 1990. [Hebb, 1949] Hebb, D. O., The Organization of Behaviour , New York: John\nWiley, 1949. [Hertz, Krogh, & Palmer, 1991] Hertz, J., Krogh, A, and Palmer, R., Introduc-\ntion to the Theory of Neural Computation , Lecture Notes, vol. 1, Santa\nFe Inst. Studies in the Sciences of Complexity, New York: Addison-\nWesley, 1991. [Hirsh, 1994] Hirsh, H., Generalizing Version Spaces, Machine Learning, 17,\n5-45, 1994. [Holland, 1975] Holland, J., Adaptation in Natural and Arti\ufb01cial Systems , Ann\nArbor: The University of Michigan Press, 1975. (Second edition printed\nin 1992 by MIT Press, Cambridge, MA.)\n[Holland, 1986] Holland, J. H., Escaping Brittleness; The Possibilities of\nGeneral-Purpose Learning Algorithms Applied to Parallel Rule-Based\nSystems. In Michalski, R., Carbonell, J., and Mitchell, T. (eds.) , Ma-\nchine Learning: An Arti\ufb01cial Intelligence Approach, Volume 2 , chapter\n20, San Francisco: Morgan Kaufmann, 1986. [Hunt, Marin, & Stone, 1966] Hunt, E., Marin, J., and Stone, P., Experiments\nin Induction, New York: Academic Press, 1966. [Jabbour, K., et al., 1987] Jabbour, K., et al. , ALFA: Automated Load Fore-\ncasting Assistant, Proc. of the IEEE Pwer Engineering Society Summer\nMeeting, San Francisco, CA, 1987. [John, 1995] John, G., Robust Linear Discriminant Trees, Proc. of the Conf.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 181, 'page_label': '182'}, page_content='on Arti\ufb01cial Intelligence and Statistics , Ft. Lauderdale, FL, January,\n1995. [Kaelbling, 1993] Kaelbling, L. P., Learning in Embedded Systems, Cambridge,\nMA: MIT Press, 1993. [Kohavi, 1994] Kohavi, R., Bottom-Up Induction of Oblivious Read-Once De-\ncision Graphs, Proc. of European Conference on Machine Learning\n(ECML-94), 1994. [Kolodner, 1993] Kolodner, J., Case-Based Reasoning, San Francisco: Morgan\nKaufmann, 1993. [Koza, 1992] Koza, J., Genetic Programming: On the Programming of Comput-\ners by Means of Natural Selection , Cambridge, MA: MIT Press, 1992. [Koza, 1994] Koza, J., Genetic Programming II: Automatic Discovery of\nReusable Programs, Cambridge, MA: MIT Press, 1994.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 182, 'page_label': '183'}, page_content='174 BIBLIOGRAPHY\n[Laird, et al., 1986] Laird, J., Rosenbloom, P., and Newell, A., Chunking in\nSoar: The Anatomy of a General Learning Mechanism, Machine Learn-\ning, 1, pp. 11-46, 1986. Reprinted in Buchanan, B. and Wilkins, D.,\n(eds.), Readings in Knowledge Acquisition and Learning , pp. 518-535,\nMorgan Kaufmann, San Francisco, CA, 1993. [Langley, 1992] Langley, P., Areas of Application for Machine Learning,Proc. of Fifth Intl. Symp. on Knowledge Engineering , Sevilla, 1992. [Langley, 1996] Langley, P., Elements of Machine Learning , San Francisco:\nMorgan Kaufmann, 1996. [Lavra\u02c7 c & D\u02c7 zeroski, 1994] Lavra\u02c7 c, N., and D\u02c7 zeroski, S.,Inductive Logic Pro-\ngramming, Chichester, England: Ellis Horwood, 1994. [Lin, 1992] Lin, L., Self-Improving Reactive Agents Based on Reinforcement\nLearning, Planning, and Teaching, Machine Learning, 8, 293-321, 1992. [Lin, 1993] Lin, L., Scaling Up Reinforcement Learning for Robot Control,\nProc. Tenth Intl.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 182, 'page_label': '183'}, page_content='Conf. on Machine Learning, pp. 182-189, San Francisco:\nMorgan Kaufmann, 1993. [Littlestone, 1988] Littlestone, N., Learning Quickly When Irrelevant At-\ntributes Abound: A New Linear-Threshold Algorithm, Machine Learn-\ning 2: 285-318, 1988. [Maass & Tur´ an, 1994] Maass, W., and Tur´ an, G., How Fast Can a Thresh-\nold Gate Learn?, in Hanson, S., Drastal, G., and Rivest, R., (eds.),\nComputational Learning Theory and Natural Learning Systems, Volume\n1: Constraints and Prospects , pp. 381-414, Cambridge, MA: MIT Press,\n1994. [Mahadevan & Connell, 1992] Mahadevan, S., and Connell, J., Automatic\nProgramming of Behavior-Based Robots Using Reinforcement Learn-\ning, Arti\ufb01cial Intelligence, 55, pp. 311-365, 1992. [Marchand & Golea, 1993] Marchand, M., and Golea, M., On Learning Sim-\nple Neural Concepts: From Halfspace Intersections to Neural Decision\nLists, Network, 4:67-85, 1993. [McCulloch & Pitts, 1943] McCulloch, W. S., and Pitts, W. H., A Logical Cal-\nculus of the Ideas Immanent in Nervous Activity, Bulletin of Mathe-\nmatical Biophysics, Vol. 5, pp.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 182, 'page_label': '183'}, page_content='115-133, Chicago: University of Chicago\nPress, 1943. [Michie, 1992] Michie, D., Some Directions in Machine Intelligence, unpub-\nlished manuscript, The Turing Institute, Glasgow, Scotland, 1992. [Minton, 1988] Minton, S., Learning Search Control Knowledge: An\nExplanation-Based Approach , Kluwer Academic Publishers, Boston,\nMA, 1988.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 183, 'page_label': '184'}, page_content='BIBLIOGRAPHY 175\n[Minton, 1990] Minton, S., Quantitative Results Concerning the Utility of\nExplanation-Based Learning, Arti\ufb01cial Intelligence , 42, pp. 363-392,\n1990. Reprinted in Shavlik, J. and Dietterich, T., Readings in Machine\nLearning, San Francisco: Morgan Kaufmann, 1990, pp. 573-587. [Mitchell, et al., 1986] Mitchell, T., et al., Explanation-Based Generalization:\nA Unifying View, Machine Learning, 1:1, 1986. Reprinted in Shavlik,\nJ. and Dietterich, T., Readings in Machine Learning , San Francisco:\nMorgan Kaufmann, 1990, pp. 435-451. [Mitchell, 1982] Mitchell, T., Generalization as Search, Arti\ufb01cial Intelligence,\n18:203-226, 1982. Reprinted in Shavlik, J. and Dietterich, T.,Readings in\nMachine Learning, San Francisco: Morgan Kaufmann, 1990, pp. 96107. [Moore & Atkeson, 1993] Moore, A., and Atkeson, C., Prioritized Sweeping:\nReinforcement Learning with Less Data and Less Time,Machine Learn-\ning, 13, pp. 103-130, 1993.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 183, 'page_label': '184'}, page_content='[Moore, et al., 1994] Moore, A. W., Hill, D.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 183, 'page_label': '184'}, page_content='J., and Johnson, M. P., An Em-\npirical Investigation of Brute Force to Choose Features, Smoothers, and\nFunction Approximators, in Hanson, S., Judd, S., and Petsche, T.,\n(eds.), Computational Learning Theory and Natural Learning Systems ,\nVol. 3, Cambridge: MIT Press, 1994. [Moore, 1990] Moore, A., E\ufb03cient Memory-based Learning for Robot Control ,\nPhD. Thesis; Technical Report No. 209, Computer Laboratory, Univer-\nsity of Cambridge, October, 1990. [Moore, 1992] Moore, A., Fast, Robust Adaptive Control by Learning Only\nForward Models, in Moody, J., Hanson, S., and Lippman, R., (eds.),\nAdvances in Neural Information Processing Systems 4 , San Francisco:\nMorgan Kaufmann, 1992. [Mueller & Page, 1988] Mueller, R. and Page, R., Symbolic Computing with\nLisp and Prolog, New York: John Wiley & Sons, 1988. [Muggleton, 1991] Muggleton, S., Inductive Logic Programming, New Gen-\neration Computing, 8, pp. 295-318, 1991. [Muggleton, 1992] Muggleton, S., Inductive Logic Programming, London: Aca-\ndemic Press, 1992. [Muroga, 1971] Muroga, S., Threshold Logic and its Applications , New York:\nWiley, 1971. [Natarjan, 1991] Natarajan, B., Machine Learning: A Theoretical Approach ,\nSan Francisco: Morgan Kaufmann, 1991.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 184, 'page_label': '185'}, page_content='176 BIBLIOGRAPHY\n[Nilsson, 1965] Nilsson, N. J., Theoretical and Experimental Investigations in\nTrainable Pattern-Classifying Systems, Tech. Report No. RADC-TR-\n65-257, Final Report on Contract AF30(602)-3448, Rome Air Develop-\nment Center (Now Rome Laboratories), Gri\ufb03ss Air Force Base, New\nYork, September, 1965. [Nilsson, 1990] Nilsson, N.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 184, 'page_label': '185'}, page_content='J., The Mathematical Foundations of Learning Ma-\nchines, San Francisco: Morgan Kaufmann, 1990. (This book is a reprint\nof Learning Machines: Foundations of Trainable Pattern-Classifying\nSystems, New York: McGraw-Hill, 1965.)\n[Oliver, Dowe, & Wallace, 1992] Oliver, J., Dowe, D., and Wallace, C., Infer-\nring Decision Graphs using the Minimum Message Length Principle,\nProc. 1992 Australian Arti\ufb01cial Intelligence Conference , 1992. [Pagallo & Haussler, 1990] Pagallo, G. and Haussler, D., Boolean Feature Dis-\ncovery in Empirical Learning, Machine Learning, vol.5, no.1, pp. 71-99,\nMarch 1990. [Pazzani & Kibler, 1992] Pazzani, M., and Kibler, D., The Utility of Knowl-\nedge in Inductive Learning, Machine Learning, 9, 57-94, 1992. [Peterson, 1961] Peterson, W., Error Correcting Codes, New York: John Wiley,\n1961. [Pomerleau, 1991] Pomerleau, D., Rapidly Adapting Arti\ufb01cial Neural Net-\nworks for Autonomous Navigation, in Lippmann, P., et al. (eds.), Ad-\nvances in Neural Information Processing Systems, 3 , pp. 429-435, San\nFrancisco: Morgan Kaufmann, 1991. [Pomerleau, 1993] Pomerleau, D, Neural Network Perception for Mobile Robot\nGuidance, Boston: Kluwer Academic Publishers, 1993. [Quinlan & Rivest, 1989] Quinlan, J. Ross, and Rivest, Ron, Inferring Deci-\nsion Trees Using the Minimum Description Length Principle, Informa-\ntion and Computation , 80:227248, March, 1989. [Quinlan, 1986] Quinlan, J. Ross, Induction of Decision Trees, Machine\nLearning, 1:81106, 1986. Reprinted in Shavlik, J. and Dietterich, T.,\nReadings in Machine Learning, San Francisco: Morgan Kaufmann, 1990,\npp. 5769. [Quinlan, 1987] Quinlan, J. R., Generating Production Rules from Decision\nTrees, In IJCAI-87: Proceedings of the Tenth Intl. Joint Conf.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 184, 'page_label': '185'}, page_content='on Ar-\nti\ufb01cial Intelligence, pp. 304-7, San Francisco: Morgan-Kaufmann, 1987. [Quinlan, 1990] Quinlan, J. R., Learning Logical De\ufb01nitions from Relations,\nMachine Learning, 5, 239-266, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 185, 'page_label': '186'}, page_content='BIBLIOGRAPHY 177\n[Quinlan, 1993] Quinlan, J. Ross, C4.5: Programs for Machine Learning , San\nFrancisco: Morgan Kaufmann, 1993. [Quinlan, 1994] Quinlan, J. R., Comparing Connectionist and Symbolic Learn-\ning Methods, in Hanson, S., Drastal, G., and Rivest, R., (eds.), Com-\nputational Learning Theory and Natural Learning Systems, Volume 1:\nConstraints and Prospects , pp. 445-456,, Cambridge, MA: MIT Press,\n1994. [Ridgway, 1962] Ridgway, W. C., An Adaptive Logic System with Generalizing\nProperties, PhD thesis, Tech. Rep.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 185, 'page_label': '186'}, page_content='1556-1, Stanford Electronics Labs.,\nStanford, CA, April 1962. [Rissanen, 1978] Rissanen, J., Modeling by Shortest Data Description, Auto-\nmatica, 14:465-471, 1978. [Rivest, 1987] Rivest, R. L., Learning Decision Lists, Machine Learning, 2,\n229-246, 1987. [Rosenblatt, 1958] Rosenblatt, F., Principles of Neurodynamics , Washington:\nSpartan Books, 1961. [Ross, 1983] Ross, S., Introduction to Stochastic Dynamic Programming , New\nYork: Academic Press, 1983. [Rumelhart, Hinton, & Williams, 1986] Rumelhart, D. E., Hinton, G. E., and\nWilliams, R. J., Learning Internal Representations by Error Propa-\ngation, In Rumelhart, D. E., and McClelland, J. L., (eds.) Parallel\nDistributed Processing, Vol 1, 318362, 1986. [Russell & Norvig 1995] Russell, S., and Norvig, P., Arti\ufb01cial Intelligence: A\nModern Approach, Englewood Cli\ufb00s, NJ: Prentice Hall, 1995. [Samuel, 1959] Samuel, A., Some Studies in Machine Learning Using the Game\nof Checkers,IBM Journal of Research and Development, 3:211-229, July\n1959. [Schwartz, 1993] Schwartz, A., A Reinforcement Learning Method for Max-\nimizing Undiscounted Rewards, Proc. Tenth Intl.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 185, 'page_label': '186'}, page_content='Conf. on Machine\nLearning, pp. 298-305, San Francisco: Morgan Kaufmann, 1993. [Sejnowski, Koch, & Churchland, 1988] Sejnowski, T., Koch, C., and Church-\nland, P., Computational Neuroscience, Science, 241: 1299-1306, 1988. [Shavlik, Mooney, & Towell, 1991] Shavlik, J., Mooney, R., and Towell, G.,\nSymbolic and Neural Learning Algorithms: An Experimental Compar-\nison, Machine Learning, 6, pp. 111-143, 1991. [Shavlik & Dietterich, 1990] Shavlik, J. and Dietterich, T., Readings in Ma-\nchine Learning, San Francisco: Morgan Kaufmann, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 186, 'page_label': '187'}, page_content='178 BIBLIOGRAPHY\n[Sutton & Barto, 1987] Sutton, R. S., and Barto, A. G., A Temporal-\nDi\ufb00erence Model of Classical Conditioning, in Proceedings of the Ninth\nAnnual Conference of the Cognitive Science Society , Hillsdale, NJ: Erl-\nbaum, 1987. [Sutton, 1988] Sutton, R. S., Learning to Predict by the Methods of Temporal\nDi\ufb00erences, Machine Learning 3: 9-44, 1988. [Sutton, 1990] Sutton, R., Integrated Architectures for Learning, Planning,\nand Reacting Based on Approximating Dynamic Programming,Proc. of\nthe Seventh Intl. Conf. on Machine Learning, pp. 216-224, San Francisco:\nMorgan Kaufmann, 1990. [Taylor, Michie, & Spiegalhalter, 1994] Taylor, C., Michie, D., and Spiegal-\nhalter, D., Machine Learning, Neural and Statistical Classi\ufb01cation ,\nParamount Publishing International. [Tesauro, 1992] Tesauro, G., Practical Issues in Temporal Di\ufb00erence Learn-\ning, Machine Learning, 8, nos. 3/4, pp. 257-277, 1992. [Towell & Shavlik, 1992] Towell G., and Shavlik, J., Interpretation of Arti\ufb01-\ncial Neural Networks: Mapping Knowledge-Based Neural Networks into\nRules, in Moody, J., Hanson, S., and Lippmann, R., (eds.), Advances in\nNeural Information Processing Systems, 4 , pp. 977-984, San Francisco:\nMorgan Kaufmann, 1992. [Towell, Shavlik, & Noordweier, 1990] Towell, G., Shavlik, J., and Noordweier,\nM., Re\ufb01nement of Approximate Domain Theories by Knowledge-Based\nArti\ufb01cial Neural Networks, Proc. Eighth Natl., Conf. on Arti\ufb01cial In-\ntelligence, pp. 861-866, 1990. [Unger, 1989] Unger, S., The Essence of Logic Circuits , Englewood Cli\ufb00s, NJ:\nPrentice-Hall, 1989. [Utgo\ufb00, 1989] Utgo\ufb00, P., Incremental Induction of Decision Trees, Machine\nLearning, 4:161186, Nov., 1989. [Valiant, 1984] Valiant, L., A Theory of the Learnable, Communications of\nthe ACM, Vol. 27 , pp. 1134-1142, 1984. [Vapnik & Chervonenkis, 1971] Vapnik, V., and Chervonenkis, A., On the\nUniform Convergence of Relative Frequencies, Theory of Probability and\nits Applications, Vol. 16 , No. 2, pp.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 186, 'page_label': '187'}, page_content='264-280, 1971. [Various Editors, 1989-1994] Advances in Neural Information Processing Sys-\ntems, vols 1 through 6, San Francisco: Morgan Kaufmann, 1989 -1994. [Watkins & Dayan, 1992] Watkins, C.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 186, 'page_label': '187'}, page_content='J. C. H., and Dayan, P., Technical Note:\nQ-Learning, Machine Learning, 8, 279-292, 1992.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 187, 'page_label': '188'}, page_content='BIBLIOGRAPHY 179\n[Watkins, 1989] Watkins, C. J.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 187, 'page_label': '188'}, page_content='C. H., Learning From Delayed Rewards , PhD\nThesis, University of Cambridge, England, 1989. [Weiss & Kulikowski, 1991] Weiss, S., and Kulikowski, C., Computer Systems\nthat Learn, San Francisco: Morgan Kaufmann, 1991. [Werbos, 1974] Werbos, P., Beyond Regression: New Tools for Prediction and\nAnalysis in the Behavioral Sciences , Ph.D. Thesis, Harvard University,\n1974. [Widrow & Lehr, 1990] Widrow, B., and Lehr, M. A., 30 Years of Adaptive\nNeural Networks: Perceptron, Madaline and Backpropagation, Proc. IEEE, vol. 78, no. 9, pp. 1415-1442, September, 1990. [Widrow & Stearns, 1985] Widrow, B., and Stearns, S., Adaptive Signal Pro-\ncessing, Englewood Cli\ufb00s, NJ: Prentice-Hall. [Widrow, 1962] Widrow, B., Generalization and Storage in Networks of Ada-\nline Neurons, in Yovits, Jacobi, and Goldstein (eds.), Self-organizing\nSystems1962, pp. 435-461, Washington, DC: Spartan Books, 1962. [Winder, 1961] Winder, R., Single Stage Threshold Logic, Proc. of the AIEE\nSymp. on Switching Circuits and Logical Design , Conf. paper CP-60-\n1261, pp. 321-332, 1961. [Winder, 1962] Winder, R., Threshold Logic, PhD Dissertation, Princeton Uni-\nversity, Princeton, NJ, 1962. [Wnek, et al., 1990] Wnek, J., et al., Comparing Learning Paradigms via Di-\nagrammatic Visualization, in Proc. Fifth Intl. Symp. on Methodologies\nfor Intelligent Systems , pp. 428-437, 1990.'), Document(metadata={'producer': 'pdfTeX-1.40.10', 'creator': 'TeX', 'creationdate': '2010-06-21T10:24:16-07:00', 'moddate': '2010-06-21T10:24:16-07:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-1.40.10-2.2 (TeX Live 2009) kpathsea version 5.0.0', 'source': 'temp_MLpdf.pdf', 'total_pages': 188, 'page': 187, 'page_label': '188'}, page_content='(Also Tech. Report MLI90-2,\nUniversity of Illinois at Urbana-Champaign.)')], Type: <class 'list'>
INFO:root:Document added to vectorstore: temp_MLpdf.pdf
INFO:root:Document indexed successfully
INFO:root:Documents to return: [{'id': 5, 'filename': 'MLpdf.pdf', 'upload_timestamp': datetime.datetime(2025, 4, 22, 22, 28, 49)}]
INFO:root:Session ID: None, User Query: what are linear machines, Model: Llama-3.1-8B-Instant
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: c9a86e21-1e13-4d65-bebc-a6c4cb1225c2, AI response: Based on the provided context, a Linear Machine is a type of machine learning model that can be used for classification tasks. Specifically, it is a type of binary classifier that can be used to separate patterns in a multidimensional space.

In the context of the provided figures, a Linear Machine is represented by the diagram in Figure 4.8, which shows the following components:

- `Y`: The decision boundary, which is a hyperplane that separates the two classes.
- `W1.X`: The weight vector, which is used to compute the dot product between the input pattern `X` and the weight vector `W1`.
- `ARGMAX`: The argmax function, which is used to select the class with the highest scoring pattern.

The Linear Machine works by computing the dot product between the input pattern `X` and the weight vector `W1`, and then selecting the class with the highest scoring pattern.

The regions created by a Linear Machine in a 2-dimensional space are shown in Figure 4.9, where every pair of regions is either separated by a section of a hyperplane or is non-adjacent.

In terms of training a Linear Machine, there is a straightforward generalization of the 2-category error-correction rule, which involves assembling the patterns in the training set into a sequence and then modifying the weight vector `W1` based on the classification error.

Overall, Linear Machines are a simple yet powerful tool for binary classification tasks, and are often used as a building block for more complex machine learning models.
INFO:backoff:Backing off send_request(...) for 0.9s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Read timed out. (read timeout=15))
INFO:root:Session ID: c9a86e21-1e13-4d65-bebc-a6c4cb1225c2, User Query: what are tools of it, Model: Llama-3.1-8B-Instant
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: c9a86e21-1e13-4d65-bebc-a6c4cb1225c2, AI response: Based on the provided context, the tools or components of a Linear Machine are:

1. **Weight Vector (W1)**: This is a vector that is used to compute the dot product between the input pattern `X` and the weight vector `W1`. The weight vector is used to determine the decision boundary of the Linear Machine.

2. **Input Pattern (X)**: This is the input to the Linear Machine, which consists of a set of features or attributes.

3. **Decision Boundary (Y)**: This is the hyperplane that separates the two classes in the multidimensional space.

4. **Hyperplane**: This is a flat surface in a multidimensional space that is used to separate the two classes.

5. **Argmax Function**: This is a function that selects the class with the highest scoring pattern.

6. **Weighted Sum**: This is the sum of the products of the input pattern `X` and the weight vector `W1`. The weighted sum is used to determine the output of the Linear Machine.

7. **Threshold**: This is a value that is used to determine whether the weighted sum is greater than or less than the threshold. If the weighted sum is greater than the threshold, the Linear Machine outputs one class; otherwise, it outputs the other class.

In terms of the functions used to train a Linear Machine, the following are some of the key components:

1. **Error-Correction Rule**: This is a rule that is used to modify the weight vector `W1` based on the classification error.

2. **Dot Product**: This is a function that computes the sum of the products of the input pattern `X` and the weight vector `W1`.

3. **Classification Error**: This is the difference between the predicted output and the actual output of the Linear Machine.

4. **Weight Update**: This is the process of modifying the weight vector `W1` based on the classification error.

5. **Training Patterns**: These are the input patterns that are used to train the Linear Machine.

Overall, the tools or components of a Linear Machine are used to classify input patterns into one of two classes based on the decision boundary determined by the weight vector and the threshold value.
INFO:root:Documents to return: [{'id': 5, 'filename': 'MLpdf.pdf', 'upload_timestamp': datetime.datetime(2025, 4, 22, 22, 28, 49)}]
INFO:root:Session ID: None, User Query: what is machine learning in one line, Model: Llama-3.1-8B-Instant
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 17f455ba-b4f6-4c2b-b595-a1d74583766f, AI response: Machine learning refers to the changes in a system's structure, program, or data that improve its future performance in tasks associated with artificial intelligence.
INFO:root:Session ID: 17f455ba-b4f6-4c2b-b595-a1d74583766f, User Query: what are it's components in one line, Model: Llama-3.1-8B-Instant
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 17f455ba-b4f6-4c2b-b595-a1d74583766f, AI response: Machine learning has three primary components: Data, Algorithms, and Models, which work together to enable a system to learn, improve, and make predictions or decisions.
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized with HuggingFace embeddings
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized with HuggingFace embeddings
INFO:root:Documents to return: [{'id': 5, 'filename': 'MLpdf.pdf', 'upload_timestamp': datetime.datetime(2025, 4, 22, 22, 28, 49)}]
INFO:root:Session ID: None, User Query: what is ai, Model: Llama-3.1-8B-Instant
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 2dad2eb3-ca30-47fb-bac9-c759a25478f2, AI response: **What is AI?**

Artificial Intelligence (AI) is a field of computer science that focuses on developing intelligent machines that can perform tasks that typically require human intelligence, such as:

1. **Learning**: AI systems can learn from data, experiences, and feedback.
2. **Reasoning**: AI systems can draw conclusions, make decisions, and solve problems.
3. **Perception**: AI systems can interpret and understand data from sensors, images, and speech.
4. **Language understanding**: AI systems can comprehend and generate human language.

AI systems use various techniques, including:

1. **Machine learning** (ML): AI systems learn from data and improve their performance over time.
2. **Deep learning** (DL): A type of ML that uses neural networks to analyze data.
3. **Natural language processing** (NLP): AI systems can understand and generate human language.
4. **Computer vision**: AI systems can interpret and understand visual data from images and videos.

**Types of AI:**

1. **Narrow or Weak AI**: Designed to perform a specific task, such as facial recognition or language translation.
2. **General or Strong AI**: A hypothetical AI system that can perform any intellectual task that a human can.
3. **Superintelligence**: A hypothetical AI system that significantly surpasses human intelligence.

**Applications of AI:**

1. **Virtual assistants**: AI-powered assistants, such as Siri, Alexa, and Google Assistant.
2. **Image and speech recognition**: AI-powered systems that can recognize objects, people, and speech.
3. **Predictive maintenance**: AI-powered systems that can predict equipment failures and schedule maintenance.
4. **Healthcare**: AI-powered systems that can diagnose diseases, develop personalized treatment plans, and predict patient outcomes.

**Benefits of AI:**

1. **Increased efficiency**: AI can automate repetitive tasks, freeing up human time for more strategic work.
2. **Improved accuracy**: AI can analyze large datasets and identify patterns that humans may miss.
3. **Enhanced decision-making**: AI can provide data-driven insights to support human decision-making.
4. **Personalization**: AI can tailor experiences and recommendations to individual preferences.

**Challenges and limitations of AI:**

1. **Bias and fairness**: AI systems can perpetuate biases and unfairness if trained on biased data.
2. **Explainability**: AI systems can be difficult to understand and interpret.
3. **Job displacement**: AI can automate jobs, potentially displacing human workers.
4. **Security and ethics**: AI systems can be vulnerable to cyber attacks and raise ethical concerns.

I hope this helps! Do you have any specific questions about AI?
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized with HuggingFace embeddings
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
INFO:root:vectorstore initialized with HuggingFace embeddings
INFO:root:Session ID: 2dad2eb3-ca30-47fb-bac9-c759a25478f2, User Query: what is bias in one line, Model: Llama-3.1-8B-Instant
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Session ID: 2dad2eb3-ca30-47fb-bac9-c759a25478f2, AI response: **Bias in AI**: A systematic error or prejudice that causes AI systems to unfairly favor or discriminate against certain individuals, groups, or outcomes, often due to flawed data, algorithms, or training methods.
INFO:root:File ID: 6, Temp file path: temp_sample-file.pdf
INFO:root:File ID: 6, file path: temp_sample-file.pdf
INFO:root:PDF file loaded: temp_sample-file.pdf
INFO:root:documents info after: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-22T17:36:21+00:00', 'author': 'Nimrod Geva', 'moddate': '2025-04-22T17:36:21+00:00', 'source': 'temp_sample-file.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Video provides a powerful way to help you prove your point. When you click Online Video, you can \npaste in the embed code for the video you want to add. You can also type a keyword to search online for \nthe video that best fits your document. To make your document look professionally produced, Word \nprovides header, footer, cover page, and text box designs that complement each other. For example, \nyou can add a matching cover page, header, and sidebar. Click Insert and then choose the elements you \nwant from the different galleries. Themes and styles also help keep your document coordinated. When \nyou click Design and choose a new Theme, the pictures, charts, and SmartArt graphics change to match \nyour new theme. When you apply styles, your headings change to match the new theme. Save time in \nWord with new buttons that show up where you need them. \n \nTo change the way a picture fits in your document, click it and a button for layout options appears next \nto it. When you work on a table, click where you want to add a row or a column, and then click the plus \nsign. Reading is easier, too, in the new Reading view. You can collapse parts of the document and focus \non the text you want. If you need to stop reading before you reach the end, Word remembers where \nyou left off - even on another device. Video provides a powerful way to help you prove your point. \nWhen you click Online Video, you can paste in the embed code for the video you want to add. You can \nalso type a keyword to search online for the video that best fits your document. To make your document \nlook professionally produced, Word provides header, footer, cover page, and text box designs that \ncomplement each other. For example, you can add a matching cover page, header, and sidebar. \nClick Insert and then choose the elements you want from the different galleries. Themes and styles also \nhelp keep your document coordinated. When you click Design and choose a new Theme, the pictures, \ncharts, and SmartArt graphics change to match your new theme. When you apply styles, your headings \nchange to match the new theme. Save time in Word with new buttons that show up where you need \nthem. To change the way a picture fits in your document, click it and a button for layout options appears \nnext to it. When you work on a table, click where you want to add a row or a column, and then click the \nplus sign. Reading is easier, too, in the new Reading view. You can collapse parts of the document and \nfocus on the text you want. If you need to stop reading before you reach the end, Word remembers \nwhere you left off - even on another device.')]
INFO:root:Splits content: [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-22T17:36:21+00:00', 'author': 'Nimrod Geva', 'moddate': '2025-04-22T17:36:21+00:00', 'source': 'temp_sample-file.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Video provides a powerful way to help you prove your point. When you click Online Video, you can \npaste in the embed code for the video you want to add. You can also type a keyword to search online for \nthe video that best fits your document. To make your document look professionally produced, Word \nprovides header, footer, cover page, and text box designs that complement each other. For example, \nyou can add a matching cover page, header, and sidebar. Click Insert and then choose the elements you \nwant from the different galleries. Themes and styles also help keep your document coordinated. When \nyou click Design and choose a new Theme, the pictures, charts, and SmartArt graphics change to match \nyour new theme. When you apply styles, your headings change to match the new theme. Save time in \nWord with new buttons that show up where you need them. To change the way a picture fits in your document, click it and a button for layout options appears next \nto it. When you work on a table, click where you want to add a row or a column, and then click the plus \nsign. Reading is easier, too, in the new Reading view.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-22T17:36:21+00:00', 'author': 'Nimrod Geva', 'moddate': '2025-04-22T17:36:21+00:00', 'source': 'temp_sample-file.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='You can collapse parts of the document and focus \non the text you want. If you need to stop reading before you reach the end, Word remembers where \nyou left off - even on another device. Video provides a powerful way to help you prove your point. When you click Online Video, you can paste in the embed code for the video you want to add. You can \nalso type a keyword to search online for the video that best fits your document. To make your document \nlook professionally produced, Word provides header, footer, cover page, and text box designs that \ncomplement each other. For example, you can add a matching cover page, header, and sidebar. Click Insert and then choose the elements you want from the different galleries. Themes and styles also \nhelp keep your document coordinated. When you click Design and choose a new Theme, the pictures, \ncharts, and SmartArt graphics change to match your new theme. When you apply styles, your headings \nchange to match the new theme. Save time in Word with new buttons that show up where you need \nthem. To change the way a picture fits in your document, click it and a button for layout options appears \nnext to it. When you work on a table, click where you want to add a row or a column, and then click the \nplus sign. Reading is easier, too, in the new Reading view.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-04-22T17:36:21+00:00', 'author': 'Nimrod Geva', 'moddate': '2025-04-22T17:36:21+00:00', 'source': 'temp_sample-file.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='You can collapse parts of the document and \nfocus on the text you want. If you need to stop reading before you reach the end, Word remembers \nwhere you left off - even on another device.')], Type: <class 'list'>
INFO:root:Document added to vectorstore: temp_sample-file.pdf
INFO:root:Document indexed successfully
INFO:root:Documents to return: [{'id': 5, 'filename': 'MLpdf.pdf', 'upload_timestamp': datetime.datetime(2025, 4, 22, 22, 28, 49)}, {'id': 6, 'filename': 'sample-file.pdf', 'upload_timestamp': datetime.datetime(2025, 4, 22, 23, 8, 18)}]
